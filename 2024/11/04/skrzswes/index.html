
  <!DOCTYPE html>
  <html lang="zh-CN"  >
  <head>
  <meta charset="utf-8">
  

  

  

  <script>window.REIMU_CONFIG = {};window.REIMU_CONFIG.icon_font = '4552607_tq6stt6tcg';window.REIMU_CONFIG.clipboard_tips = {"success":"复制成功(*^▽^*)","fail":"复制失败 (ﾟ⊿ﾟ)ﾂ","copyright":{"enable":false,"count":50,"content":"本文版权：本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！"}};window.REIMU_CONFIG.outdate = {"enable":true,"daysAgo":730,"message":"本文最后更新于 {time}，请注意文中内容可能已经发生变化。"};window.REIMU_CONFIG.code_block = {"expand":30};</script>
  
  <title>
    Transformer：Attention Is All You Need |
    
    小小白的笔记屋
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link rel="preload" as="style" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CJetBrains%20Mono:400,400italic,700,700italic&display=swap"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CJetBrains%20Mono:400,400italic,700,700italic&display=swap" media="print" onload="this.media&#x3D;&#39;all&#39;">
  
    <link rel="preload" href="//at.alicdn.com/t/c/font_4552607_tq6stt6tcg.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  
  
    
<link rel="stylesheet" href="/css/loader.css">

  
  
    <meta name="description" content="文章链接  Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing syste">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer：Attention Is All You Need">
<meta property="og:url" content="https://luoying.netlify.app/2024/11/04/skrzswes/index.html">
<meta property="og:site_name" content="小小白的笔记屋">
<meta property="og:description" content="文章链接  Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing syste">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214213436546.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214214041382.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214222641650.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214220939993.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214220200245.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214220853164.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214221259460.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214221432239.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241214221551627.png">
<meta property="og:image" content="https://luoying.netlify.app/images/banner.webp">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241215144352531.png">
<meta property="og:image" content="https://luoying.netlify.app/images/assets//image-20241215143828976.png">
<meta property="article:published_time" content="2024-11-04T14:24:35.000Z">
<meta property="article:modified_time" content="2025-10-01T10:48:10.496Z">
<meta property="article:author" content="LuoYing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://luoying.netlify.app/images/assets//image-20241214213436546.png">
  
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="preload" href="https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
    
      
        
<link rel="stylesheet" href="https://npm.webcache.cn/katex@0.16.11/dist/katex.min.css">

      
    
  
  
  
  
    
<script src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous"></script>

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/@reimujs/aos@0.1.0/dist/aos.css">

  
<meta name="generator" content="Hexo 7.3.0"></head>

  <body>
    
  <div id='loader'>
    <div class="loading-left-bg loading-bg"></div>
    <div class="loading-right-bg loading-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi">
        
          <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="https://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
            <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="var(--red-1, #ff5252)" />
            <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z 
           M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95z" fill="var(--red-1, #ff5252)" />
          </svg>
        
      </div>
      <div class="loading-word">小小白祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    var startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    var endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('DOMContentLoaded', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>

<div id="copy-tooltip" style="pointer-events: none; opacity: 0; transition: all 0.2s ease; position: fixed;top: 50%;left: 50%;z-index: 999;transform: translate(-50%, -50%);color: white;background: rgba(0, 0, 0, 0.5);padding: 10px 15px;border-radius: 10px;">
</div>


    <div id="container">
      <div id="wrap">
        <div id="header-nav">
  <nav id="main-nav">
    
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
            &#xe62b;
          </div>
          <a class="main-nav-link" href="/">首页</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
            &#xe62b;
          </div>
          <a class="main-nav-link" href="/archives">归档</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
            &#xe62b;
          </div>
          <a class="main-nav-link" href="/about">关于</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
            &#xe62b;
          </div>
          <a class="main-nav-link" href="/friend">友链</a>
        </span>
      
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
    
    
      <a id="nav-search-btn" class="nav-icon popup-trigger" title="搜索"></a>
    
  </nav>
</div>
<header id="header">
  
    
      <img fetchpriority="high" src="/images/banner.webp" alt="Transformer：Attention Is All You Need">
    
  
  <div id="header-outer">
    <div id="header-title">
      
        
        
          <a href="/" id="logo">
            <h1 data-aos="slide-up">Transformer：Attention Is All You Need</h1>
          </a>
        
      
      
        
        <h2 id="subtitle-wrap" data-aos="slide-down">
          
        </h2>
      
    </div>
  </div>
</header>

        <div id="content">
          
            <aside id="sidebar">
  <div class="sidebar-wrapper wrap-sticky">
    <div class="sidebar-wrap" data-aos="fade-up">
      
        <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">文章目录</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E9%93%BE%E6%8E%A5"><span class="toc-number">1.</span> <span class="toc-text"> 文章链接</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text"> 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">3.</span> <span class="toc-text"> 摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">4.</span> <span class="toc-text"> 创新点</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text"> 主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%89%8D%E9%A1%BB%E7%9F%A5"><span class="toc-number">5.1.</span> <span class="toc-text"> 读前须知</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.2.</span> <span class="toc-text"> 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">5.3.</span> <span class="toc-text"> 背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">5.4.</span> <span class="toc-text"> 模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8%E4%B8%8E%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-number">5.4.1.</span> <span class="toc-text"> 编码器与解码器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.</span> <span class="toc-text"> 注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.1.</span> <span class="toc-text"> 缩放点积注意力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.2.</span> <span class="toc-text"> 多头注意力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"><span class="toc-number">5.4.2.3.</span> <span class="toc-text"> 基于位置的前馈网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%92%8Csoftmax"><span class="toc-number">5.4.2.4.</span> <span class="toc-text"> 嵌入和Softmax</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">5.4.2.5.</span> <span class="toc-text"> 位置编码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">5.5.</span> <span class="toc-text"> 为什么选择自注意力机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.6.</span> <span class="toc-text"> 训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%89%B9%E5%A4%84%E7%90%86"><span class="toc-number">5.6.1.</span> <span class="toc-text"> 训练数据与批处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E4%B8%8E%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92"><span class="toc-number">5.6.2.</span> <span class="toc-text"> 硬件与时间安排</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">5.6.3.</span> <span class="toc-text"> 优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">5.6.4.</span> <span class="toc-text"> 正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">5.7.</span> <span class="toc-text"> 结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="toc-number">5.7.1.</span> <span class="toc-text"> 机器翻译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%98%E4%BD%93"><span class="toc-number">5.7.2.</span> <span class="toc-text"> 模型变体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8B%B1%E8%AF%AD%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">5.7.3.</span> <span class="toc-text"> 英语成分句法分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text"> 结论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">7.</span> <span class="toc-text"> 注意力可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE3"><span class="toc-number">7.1.</span> <span class="toc-text"> 图3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE4"><span class="toc-number">7.2.</span> <span class="toc-text"> 图4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE5"><span class="toc-number">7.3.</span> <span class="toc-text"> 图5</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">8.</span> <span class="toc-text"> 参考文献</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer%E5%8F%91%E5%B1%95"><span class="toc-number">9.</span> <span class="toc-text"> transformer发展</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#transformer%E6%A8%A1%E5%9E%8B%E5%8F%98%E4%BD%93"><span class="toc-number">9.1.</span> <span class="toc-text"> transformer模型变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E4%B8%8E%E5%88%9B%E6%96%B0%E6%96%B9%E5%90%91"><span class="toc-number">9.2.</span> <span class="toc-text"> 优化与创新方向</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%9C%A8%E6%96%B0%E4%BB%BB%E5%8A%A1%E4%B8%8A%E4%BC%98%E5%8C%96-transformer-%E6%9E%B6%E6%9E%84"><span class="toc-number">9.3.</span> <span class="toc-text"> 如何在新任务上优化 transformer 架构？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%BE%E4%BE%8B"><span class="toc-number">10.</span> <span class="toc-text"> transformer代码实现举例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA-transformer-%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.1.</span> <span class="toc-text"> 构建 transformer 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">10.2.</span> <span class="toc-text"> 训练数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.3.</span> <span class="toc-text"> 训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.4.</span> <span class="toc-text"> 测试模型</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
        <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/avatar.webp" data-sizes="auto" alt="LuoYing" class="lazyload">
  <div class="sidebar-author-name">LuoYing</div>
  <div class="sidebar-description">一方小筑，与君共勉</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div>
    <div class="sidebar-state-number">119</div>
  </div>
  <div class="sidebar-state-category">
    <div>分类</div>
    <div class="sidebar-state-number">15</div>
  </div>
  <div class="sidebar-state-tag">
    <div>标签</div>
    <div class="sidebar-state-number">2</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/" aria-label="首页"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">首页</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/archives" aria-label="归档"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">归档</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/about" aria-label="关于"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">关于</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/friend" aria-label="友链"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">友链</div>
      </div>
    
  
</div>
</div>
      
      
        <div class="sidebar-btn-wrapper" style="position:static">
          <div class="sidebar-toc-btn current"></div>
          <div class="sidebar-common-btn"></div>
        </div>
      
    </div>
  </div>

  
</aside>

          
          <section id="main"><article id="post-skrzswes" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner" data-aos="fade-up">
    <div class="article-meta">
      <div class="article-date">
  <a href="/2024/11/04/skrzswes/" class="article-date-link" data-aos="zoom-in">
    <time datetime="2024-11-04T14:24:35.000Z" itemprop="datePublished">2024-11-04</time>
    <time style="display: none;" id="post-update-time">2025-10-01</time>
  </a>
</div>

      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" data-aos="zoom-in">论文解读</a>
  </div>


    </div>
    <div class="hr-line"></div>
    

    <div class="e-content article-entry" itemprop="articleBody">
      
        <blockquote id="outdate-blockquote" style="display: none;"><p></p></blockquote>
      
      
        <h1 id="文章链接"><a class="markdownIt-Anchor" href="#文章链接"></a> 文章链接</h1>
<blockquote>
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30, 5998-6008. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a></p>
</blockquote>
<h1 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h1>
<p>提出<code>Transformer</code>模型架构，它完全基于注意力机制，摒弃了此前序列转导模型中普遍使用的循环神经网络(<code>RNN</code>)和卷积神经网络(<code>CNN</code>)结构。这是第一个完全依赖<code>自注意力机制</code>来计算输入输出表示的转导模型。</p>
<h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1>
<p>当前主流的<code>序列转导模型</code>都基于复杂的循环或卷积神经网络，包含编码器和解码器结构。性能最好的模型还通过<code>注意力机制（attention mechanism）</code>连接编码器和解码器。</p>
<blockquote>
<p><code>编码器和解码器</code>：编码器负责处理输入序列(比如源语言句子)，将其转换成一系列向量表示，这些向量编码了输入的语义和结构信息。解码器则基于这些编码向量，逐个生成输出序列(比如目标语言句子)。</p>
</blockquote>
<p>我们提出了一种新的简单网络架构<code>Transformer</code>，它完全基于注意力机制，彻底摒弃了循环和卷积结构。在两个机器翻译任务上的实验表明，这些模型在质量上具有优势，同时具有更好的并行性，所需训练时间大大减少。</p>
<p>我们的模型在<code>WMT2014</code>英德翻译任务上获得了<code>28.4BLEU</code>分数，超过现有最佳结果（包括集成模型）<code>2个BLEU</code>以上。在<code>WMT2014</code>英法翻译任务上，我们的模型通过在<code>8个GPU</code>上训练<code>3.5天</code>，建立了新的单模型最高水平，达到了<code>41.8 BLEU</code>分数，仅用了文献中最佳模型训练成本的一小部分。我们还通过将其成功应用于英语句法解析任务，展示了<code>Transformer</code>具有良好的泛化能力，无论是在大规模还是受限训练数据的情况下都表现出色。</p>
<blockquote>
<p><code>WMT2014英德翻译</code>：机器翻译领域的一个重要基准测试。该数据集包含约450万个英语-德语的平行句子对作为训练数据，通常使用<code>newstest2014</code>作为测试集来评估模型性能。评估标准主要是BLEU分数，该分数越高表示机器翻译的质量越好。</p>
<p><code>BLEU (Bilingual Evaluation Understudy) </code>：一种评估机器翻译质量的指标，通过比较机器翻译结果和人工参考翻译的<code>n-gram重合度</code>来打分。分数范围是<code>0到1</code>，越接近1表示翻译质量越好。</p>
</blockquote>
<h1 id="创新点"><a class="markdownIt-Anchor" href="#创新点"></a> 创新点</h1>
<ul>
<li>提出了完全基于注意力机制的新架构，摒弃了<code>RNN</code>和<code>CNN</code>结构</li>
<li>提出了多头注意力机制(<code>Multi-Head Attention</code>)，允许模型关注不同子空间的信息</li>
<li>引入了位置编码(<code>Positional Encoding</code>)，使模型能够处理序列的顺序信息</li>
<li>使用缩放点积注意力(<code>Scaled Dot-Product Attention</code>)，提高了计算效率</li>
<li>采用残差连接(<code>Residual Connection</code>)和层归一化(<code>Layer Normalization</code>)，有利于深层网络训练</li>
<li>具有更好的并行性能，训练速度快，效果好，在多个任务上达到了（当时的）最好水平</li>
</ul>
<h1 id="主要内容"><a class="markdownIt-Anchor" href="#主要内容"></a> 主要内容</h1>
<h2 id="读前须知"><a class="markdownIt-Anchor" href="#读前须知"></a> 读前须知</h2>
<ol>
<li>论文解读尽可能的还原原文，若有不恰当之处，还请见谅；</li>
<li>排版上，插图会尽量贴近出处，而扩展图之类的，会放置末尾处；</li>
<li>左边👈有目录，可自行跳转至想看的部分；</li>
<li>代码超过30行，会折叠，想浏览代码可点击右边按钮展开；</li>
<li>部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（<code>Receptive field</code>）。请注意，仅首次出现会标明；</li>
</ol>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>循环神经网络，特别是<code>长短期记忆网络（Long Short-Term Memory，LSTM）</code>和<code>门控循环神经网络（Gated Recurrent Neural Networks）</code>，已经在序列建模和转导问题（如语言建模和机器翻译）中牢固确立了最先进的地位。此后，众多研究工作持续推进循环语言模型和编码器-解码器架构的边界。</p>
<blockquote>
<p>长短期记忆网络：一种特殊的循环神经网络架构，设计用来解决普通RNN难以学习长期依赖关系的问题。它的核心是引入了一个记忆单元和三个控制门：输入门控制新信息进入记忆单元的程度，遗忘门决定丢弃多少旧信息，输出门控制记忆单元信息输出的多少。这种精细的门控机制让LSTM能够在长序列任务中表现出色。</p>
<p>门控循环神经网络：循环神经网络的一种改进版本，设计用来有效缓解传统RNN中的梯度消失问题，让网络能更好地处理长序列数据，捕捉长期依赖关系。它的典型代表是GRU（Gated Recurrent Unit），相比LSTM结构更简单但效果相当。</p>
</blockquote>
<p>循环模型通常沿着输入和输出序列的符号位置进行计算。将位置与计算时间步骤对齐，它们生成一系列隐藏状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，作为前一个隐藏状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf h_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathbf">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 和位置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">t</mi></mrow><annotation encoding="application/x-tex">\mathbf t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63492em;vertical-align:0em;"></span><span class="mord mathbf">t</span></span></span></span> 的输入的函数。这种本质上的<code>顺序特性</code>阻碍了训练样本内的并行化，这在序列较长时变得尤为关键，因为内存限制会限制跨样本的批处理。</p>
<p>最近的工作通过分解技巧和条件计算在计算效率方面取得了显著改进，后者还改善了模型性能。然而，顺序计算的基本约束仍然存在。</p>
<p><code>注意力机制（attention mechanisms）</code>已经成为各种序列建模和转导模型中不可或缺的组成部分，使模型能够建立与输入或输出序列中距离无关的依赖关系。然而，除了少数情况外，这种注意力机制都是与循环网络结合使用的。</p>
<p>在本工作中，我们提出了<code>Transformer</code>，这是一种<code>摒弃循环而完全依赖注意力机制</code>来捕获输入和输出之间全局依赖关系的模型架构。<code>Transformer</code>允许更多的并行化，在经过仅仅<code>12小时</code>的训练（使用<code>8个 P100 GPU</code>）后，就能在翻译质量上达到新的最高水平。</p>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>减少顺序计算的目标也构成了<code>Extended Neural GPU</code>、<code>ByteNet</code>和<code>ConvS2S</code>的基础，这些模型都使用卷积神经网络作为基本构建模块，为所有输入和输出位置并行计算隐藏表示。</p>
<p>在这些模型中，将两个任意输入或输出位置的信号关联起来所需的操作数会随着位置之间的距离而增长：对于<code>ConvS2S</code>是线性增长，对于<code>ByteNet</code>则是对数增长。这使得学习远距离位置之间的依赖关系变得更加困难。</p>
<p>在<code>Transformer</code>中，这种操作数被减少到<code>常数级别</code>，尽管由于对注意力加权位置的平均化导致<code>有效分辨率降低</code>，但我们通过<code>多头注意力（Multi-Head Attention）</code>机制来抵消这种影响。</p>
<p><code>自注意力（Self-attention）</code>，有时也称为<code>内部注意力（intra-attention）</code>，是一种将单个序列的不同位置关联起来以计算序列表示的注意力机制。自注意力已经在多种任务中成功应用，包括阅读理解、摘要生成、文本蕴涵和学习任务无关的句子表示。</p>
<p>基于循环注意力机制而非序列对齐循环的<code>端到端记忆网络（End-to-end memory networks）</code>已经被证明在简单语言问答和语言建模任务上表现良好。</p>
<p>然而，据我们所知，<code>Transformer</code>是第一个完全依赖自注意力来计算其输入和输出表示的转导模型，无需使用序列对齐的<code>RNN</code>或<code>卷积</code>。在接下来的章节中，我们将描述<code>Transformer</code>，阐述选择自注意力的动机，并讨论它相比其他模型的优势。</p>
<h2 id="模型架构"><a class="markdownIt-Anchor" href="#模型架构"></a> 模型架构</h2>
<p>大多具有竞争力的神经序列转导模型都具有编码器-解码器结构。其中，编码器将符号表示的输入序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, ..., x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 映射为连续表示序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z = (z_1, ..., z_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。有了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 后，解码器再逐个生成输出序列的符号 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(y_1, ..., y_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。在每一步，模型都是自回归的，在生成下一个符号时将之前生成的符号作为额外输入。</p>
<p><code>Transformer</code>遵循这种整体架构，对编码器和解码器都使用堆叠的<code>自注意力</code>和<code>逐点全连接层</code>，如图1所示（分别在左半部分和右半部分）。</p>
<img src="/images/assets//image-20241214213436546.png" width="400">
<h3 id="编码器与解码器"><a class="markdownIt-Anchor" href="#编码器与解码器"></a> 编码器与解码器</h3>
<p><strong>编码器</strong>：编码器由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>N</mtext><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">\text N = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord">N</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> 个相同的层堆叠而成。每一层都有两个子层：</p>
<ol>
<li>
<p>多头自注意力机制（multi-head self-attention mechanism）；</p>
</li>
<li>
<p>简单的、逐位置的全连接前馈网络；</p>
</li>
</ol>
<blockquote>
<p><code>全连接前馈网络</code>：最基本的神经网络架构，由多个全连接层顺序堆叠而成。每一层的每个神经元都与上一层的所有神经元相连，通过权重矩阵和偏置项进行线性变换，再经过非线性激活函数（如ReLU）进行处理。</p>
</blockquote>
<p>我们在这两个子层的每一个周围都采用了残差连接，然后进行层标准化。即每个子层的输出是：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>LayerNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mtext>Sublayer</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{LayerNorm}(x + \text{Sublayer}(x))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">LayerNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Sublayer</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Sublayer</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Sublayer}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Sublayer</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 是由子层本身实现的函数。为了便于这些残差连接，模型中所有的子层以及嵌入层产生的输出维度都是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mtext>model</mtext></msub><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">d_{\text{model}} = 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>。</p>
<blockquote>
<p><code>残差连接(Residual Connection)</code>：一种网络架构设计，通过在深层神经网络中添加&quot;捷径&quot;，让输入信息可以直接跳过某些层直达后面的层。这种设计有效缓解了深层网络的梯度消失问题，使得训练更深的网络成为可能，同时也能提升模型性能。</p>
</blockquote>
<p><strong>解码器</strong>：解码器同样由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>N</mtext><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">\text N = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord">N</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> 个相同的层堆叠而成。除了编码器层中的两个子层外，解码器还插入了第三个子层，该层对解码器堆栈的输出执行多头注意力。</p>
<p>与编码器类似，我们在每个子层周围使用残差连接，然后进行层标准化。我们还修改了解码器堆栈中的自注意力子层，以防止位置关注后续位置。这种遮蔽与输出嵌入偏移一个位置的事实相结合，确保对位置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 的预测只能依赖于位置小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 处的已知输出。</p>
<blockquote>
<p><code>解码器堆栈</code>：由多个相同的解码器层叠加而成。每个解码器层包含三个主要部分：</p>
<ol>
<li>带掩码的自注意力层，确保当前位置只能看到之前生成的内容</li>
<li>交叉注意力层，允许解码器访问编码器的输出信息</li>
<li>前馈神经网络层，进行特征变换</li>
</ol>
<p>通过这种堆叠结构，解码器能够逐个生成输出序列的每个元素。</p>
</blockquote>
<h3 id="注意力"><a class="markdownIt-Anchor" href="#注意力"></a> 注意力</h3>
<p>注意力函数可以描述为将一个查询（<code>query</code>）和一组键值对（<code>key</code>-<code>value</code> pairs）映射到输出的过程，其中查询、键、值和输出都是<code>向量</code>。输出是<code>值的加权和</code>，其中分配给每个值的权重是通过查询和对应键的兼容函数计算得到的。</p>
<h4 id="缩放点积注意力"><a class="markdownIt-Anchor" href="#缩放点积注意力"></a> 缩放点积注意力</h4>
<p>我们称我们特别使用的注意力为&quot;<code>缩放点积注意力</code>（<code>Scaled Dot-Product Attention</code>）&quot;。输入包含维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的查询和键，以及维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的值。我们计算查询和所有键的点积，将每个点积除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.87722em;"><span class="svg-align" style="top:-3.01em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8272199999999996em;"><span class="pstrut" style="height:3.01em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.09em;"><svg width='400em' height='1.09em' viewBox='0 0 400000 1090' preserveAspectRatio='xMinYMin slice'><path d='M95,712
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l4.819277108433735 -10.000000000000002
c5.3,-9.3,12,-14,20,-14
H400000v50H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M844 80h400000v50h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span>，然后应用<code>softmax</code>函数来获得值的权重。</p>
<p>实践中，我们同时计算一组查询的注意力函数，将其打包成矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 。键和值也同样打包成矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 。于是我们得到以下输出矩阵：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.503331em;vertical-align:-0.9850000000000001em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.518331em;"><span style="top:-2.19778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.87722em;"><span class="svg-align" style="top:-3.01em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8272199999999996em;"><span class="pstrut" style="height:3.01em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.09em;"><svg width='400em' height='1.09em' viewBox='0 0 400000 1090' preserveAspectRatio='xMinYMin slice'><path d='M95,712
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l4.819277108433735 -10.000000000000002
c5.3,-9.3,12,-14,20,-14
H400000v50H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M844 80h400000v50h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span><span style="top:-3.225em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9850000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p>
<p>最常用的两种注意力函数是<code>加性注意力</code>和<code>点积（乘性）注意力</code>。除了缩放因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.412108em;vertical-align:-0.567em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5574385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8822307142857143em;"><span class="svg-align" style="top:-3.01em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.832230714285714em;"><span class="pstrut" style="height:3.01em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.09em;"><svg width='400em' height='1.09em' viewBox='0 0 400000 1090' preserveAspectRatio='xMinYMin slice'><path d='M95,712
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l4.819277108433735 -10.000000000000002
c5.3,-9.3,12,-14,20,-14
H400000v50H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M844 80h400000v50h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.225em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.567em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 外，点积注意力与我们的算法相同。加性注意力使用<code>单隐层前馈网络</code>来计算兼容性函数。虽然这两种方法在理论复杂度上相似，但<code>点积注意力</code>在实践中更快、更节省空间，因为它可以使用<code>高度优化的矩阵乘法代码</code>来实现。</p>
<p>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 较小时，这两种机制表现相似。但对于较大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 值，在未经缩放的情况下，点积的量级会增大，将<code>softmax</code>函数推入具有极小梯度的区域。为了抵消这种影响，我们将点积除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.87722em;"><span class="svg-align" style="top:-3.01em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8272199999999996em;"><span class="pstrut" style="height:3.01em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.09em;"><svg width='400em' height='1.09em' viewBox='0 0 400000 1090' preserveAspectRatio='xMinYMin slice'><path d='M95,712
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l4.819277108433735 -10.000000000000002
c5.3,-9.3,12,-14,20,-14
H400000v50H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M844 80h400000v50h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> 。</p>
<h4 id="多头注意力"><a class="markdownIt-Anchor" href="#多头注意力"></a> 多头注意力</h4>
<p>我们发现，与使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 维度的单个注意力函数相比，将查询、键和值分别用不同的、学习得到的线性映射到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 维度上，并行计算注意力 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> 次会<code>更有益</code>。然后将这些注意力输出的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 维向量拼接起来，再经过一次线性映射得到最终输出，这种方式更有利。</p>
<p>这允许模型共同关注来自不同位置的不同表示子空间的信息，如图2所示。使用单个注意力头，平均化会抑制这种效果。</p>
<img src="/images/assets//image-20241214214041382.png" width="520">
<p>多头注意力的计算公式如下：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Concat</mtext><mo stretchy="false">(</mo><msub><mtext>head</mtext><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mtext>head</mtext><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">MultiHead</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Concat</span></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>head</mtext><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator="true">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592389999999998em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>这里，投影矩阵为</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>q</mi></msub></mrow></msup><mo separator="true">,</mo><mtext>  </mtext><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo separator="true">,</mo><mtext>  </mtext><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>v</mi></msub></mrow></msup><mo separator="true">,</mo><mtext>  </mtext><msup><mi>W</mi><mi>O</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>h</mi><msub><mi>d</mi><mi>v</mi></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup><mo separator="true">,</mo><mtext>  </mtext></mrow><annotation encoding="application/x-tex">W_i^Q \in \mathbb{R}^{d_{model} \times d_q} ,~~
W_i^K \in \mathbb{R}^{d_{model} \times d_k} ,~~
W_i^V \in \mathbb{R}^{d_{model} \times d_v} ,~~
W^O \in \mathbb{R}^{hd_v \times d_{model}},~~
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592389999999998em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999998em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0935479999999997em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999998em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0935479999999997em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999998em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span></span></span></span></span></p>
<p>在本工作中，我们采用了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">h=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span> 个并行注意力层（头）。对于每个注意力头，我们使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><msub><mi>d</mi><mi>v</mi></msub><mo>=</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant="normal">/</mi><mi>h</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">d_k = d_v = d_{model}/h = 64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span></span></span></span> 维度。由于每个头的维度减小，总的计算成本与使用单个头的完整维度注意力相似。</p>
<h4 id="基于位置的前馈网络"><a class="markdownIt-Anchor" href="#基于位置的前馈网络"></a> 基于位置的前馈网络</h4>
<p>除了注意力子层外，编码器和解码器中的每一层都包含一个完全连接的前馈网络，该网络独立且相同地应用于每个位置。这包含两个线性变换和一个<code>ReLU激活函数</code>：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>FFN</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\text{FFN}(x) = \max(0, xW_1 + b_1)W_2 + b_2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">FFN</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>虽然不同位置的线性变换相同，但层与层之间使用不同的参数。这种操作也可以描述为两个卷积核大小为1的卷积。输入和输出的维度是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">d_{model} = 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>，内层的维度是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo>=</mo><mn>2048</mn></mrow><annotation encoding="application/x-tex">d_{ff} = 2048</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">4</span><span class="mord">8</span></span></span></span>。</p>
<h4 id="嵌入和softmax"><a class="markdownIt-Anchor" href="#嵌入和softmax"></a> 嵌入和Softmax</h4>
<blockquote>
<p><code>嵌入(Embedding)</code>：将离散的符号（如单词、字符）转换为连续的密集向量表示的过程。这些向量具有语义意义，相似的符号在向量空间中距离较近。例如，&quot;猫&quot;和&quot;狗&quot;的嵌入向量会比&quot;猫&quot;和&quot;汽车&quot;的更接近。</p>
</blockquote>
<p>与其他序列转导模型类似，我们使用学习得到的<code>嵌入</code>将输入标记和输出标记转换为维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的向量。我们也使用普通的<code>线性变换</code>和<code>softmax函数</code>将<code>解码器输出</code>转换为预测的下一个标记概率。</p>
<p>在我们的模型中，我们在两个嵌入层和<code>softmax</code>前的线性变换中共享相同的权重矩阵。在嵌入层中，我们将这些权重乘以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_{model}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.87722em;"><span class="svg-align" style="top:-3.01em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8272199999999996em;"><span class="pstrut" style="height:3.01em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.09em;"><svg width='400em' height='1.09em' viewBox='0 0 400000 1090' preserveAspectRatio='xMinYMin slice'><path d='M95,712
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l4.819277108433735 -10.000000000000002
c5.3,-9.3,12,-14,20,-14
H400000v50H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M844 80h400000v50h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span>。</p>
<p>表1：不同层类型的<code>最大路径长度</code>、<code>每层复杂度</code>和<code>最小顺序操作数</code>。其中，<code>n</code>是序列长度，<code>d</code>是表示维度，<code>k</code>是卷积核大小，<code>r</code>是受限自注意力中的邻域大小。</p>
<img src="/images/assets//image-20241214222641650.png" width="600">
<h4 id="位置编码"><a class="markdownIt-Anchor" href="#位置编码"></a> 位置编码</h4>
<p>由于我们的模型不包含循环和卷积，为了让模型利用序列的顺序信息，我们必须注入一些关于标记在序列中相对或绝对位置的信息。为此，我们在编码器和解码器堆栈底部的输入嵌入中添加&quot;<code>位置编码</code>&quot;。位置编码的维度与嵌入维度相同（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>），因此两者可以相加。</p>
<p>这里有多种位置编码可供选择，学习得到的和固定的都可以。在本工作中，我们使用不同频率的正弦和余弦函数：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>  </mtext><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE_{(pos,2i)} = \sin(\dfrac {pos}{10000^{\frac {2i}{d_{model}}}}),~~PE_{(pos,2i+1)} = \cos(\dfrac {pos}{10000^{\frac {2i}{d_{model}}}})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-0.3551999999999999em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.15449em;vertical-align:-1.04693em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.075em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1219299999999999em;"><span style="top:-3.5233700000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.225em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5937428571428571em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.34693em;"><span class="pstrut" style="height:3.12193em;"></span><span class="frac-line" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.79893em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.04693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.15449em;vertical-align:-1.04693em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.075em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1219299999999999em;"><span style="top:-3.5233700000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.225em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5937428571428571em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.34693em;"><span class="pstrut" style="height:3.12193em;"></span><span class="frac-line" style="border-bottom-width:0.05em;"></span></span><span style="top:-3.79893em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.04693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中<code>pos</code>是位置，<code>i</code>是维度。也就是说，位置编码的每个维度对应于一个正弦曲线。波长形成从<code>2π</code>到<code>10000·2π</code>的几何级数。我们选择这个函数是因为我们假设它能让模型轻松学习通过相对位置来关注，因为对于任何固定<code>偏移量k</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">PE_{pos+k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 可以表示为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">PE_{pos}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 的线性函数。</p>
<p>我们还尝试了使用学习得到的位置嵌入，发现两种版本产生了几乎相同的结果（见表3）。我们选择正弦版本是因为它可能允许模型推断出比训练过程中遇到的序列长度更长的序列长度。</p>
<h2 id="为什么选择自注意力机制"><a class="markdownIt-Anchor" href="#为什么选择自注意力机制"></a> 为什么选择自注意力机制</h2>
<p>在本节中，我们将比较自<code>注意力层</code>与<code>循环层</code>和<code>卷积层</code>在不同方面的特点。这些层通常用于将一个<code>可变长度</code>的符号表示序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, ..., x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 映射到另一个等长序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(z_1, ..., z_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">x_i, z_i \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>，比如典型序列转换编码器或解码器中的隐藏层。为论证使用自注意力的合理性，我们考虑三个期望目标：</p>
<ol>
<li>
<p>每层的总计算复杂度；</p>
</li>
<li>
<p>可并行计算的数量，用所需的最小顺序操作数来衡量。</p>
</li>
<li>
<p>网络中长距离依赖的路径长度。</p>
</li>
</ol>
<p>在许多序列转换任务中，<code>学习长距离依赖关系</code>是一个关键挑战。影响学习这种依赖关系能力的一个重要因素是信号在网络中前向和后向传播所必须经过的路径长度。输入和输出序列中任意位置之间的这些路径越短，就越容易学习长距离依赖关系。因此，我们还比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。</p>
<p>如表1所示，自注意力层通过恒定数量的<code>顺序执行操作</code>就能连接所有位置，而循环层则需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> 个顺序操作。在计算复杂度方面，当序列长度 <code>n</code> 小于表示维度 <code>d</code> 时，自注意力层比循环层更快，这在机器翻译中使用的句子表示（如词片段和字节对编码）的最新模型中经常出现。</p>
<p>为了提高涉及超长序列任务的计算性能，可以将自注意力限制为仅考虑输入序列中以相应输出位置为中心的大小为 <code>r</code> 的邻域。这会将最大路径长度增加到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi mathvariant="normal">/</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n/r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>。我们计划在未来的工作中进一步研究这种方法。</p>
<p>单个核宽度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k &lt; n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> 的卷积层无法连接所有的输入和输出位置对。要实现这一点，在连续核的情况下需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi mathvariant="normal">/</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n/k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span> 层卷积层堆叠，或在扩张卷积的情况下需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mi>k</mi></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log_k(n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.24196799999999993em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> 层，这增加了网络中任意两个位置之间最长路径的长度。卷积层通常比循环层的计算开销更大，系数为 <code>k</code>。然而，可分离卷积能显著降低复杂度至 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo>+</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k \cdot n \cdot d + n \cdot d^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。即使在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k = n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> 的情况下，可分离卷积的复杂度也等于自注意力层和逐点前馈层的组合，这正是我们在模型中采用的方法。</p>
<p>作为附加好处，自注意力可能产生<code>更容易解释</code>的模型。我们检查了模型中的<code>注意力分布</code>，并在附录中展示和讨论了示例。不仅是各个注意力头明显学会执行不同的任务，许多注意力头似乎表现出与句子句法和语义结构相关的行为。</p>
<h2 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h2>
<p>本节描述了我们模型的训练方案。</p>
<h3 id="训练数据与批处理"><a class="markdownIt-Anchor" href="#训练数据与批处理"></a> 训练数据与批处理</h3>
<p>我们在标准的 <code>WMT 2014</code> 英德数据集上进行训练，该数据集包含约450万个句子对。句子使用字节对编码（<code>byte-pair encoding</code>）进行编码，共享源语言和目标语言的词表，包含约37000个词元。对于英法翻译，我们使用了明显更大的 <code>WMT 2014</code> 英法数据集，包含3600万个句子，并将词元分割成32000个词片（<code>word-piece</code>）词表。句子对按照近似序列长度进行批处理。每个训练批次包含一组句子对，大约包含25000个源语言词元和25000个目标语言词元。</p>
<h3 id="硬件与时间安排"><a class="markdownIt-Anchor" href="#硬件与时间安排"></a> 硬件与时间安排</h3>
<p>我们使用一台配备8块 <code>NVIDIA P100 GPU</code> 的机器训练模型。对于使用文中描述的超参数的基础模型，每个训练步骤大约需要0.4秒。我们总共训练了<code>100,000</code>步，即12小时。对于我们的大型模型（在表3的底部描述），每步用时1秒。大型模型训练了300,000步（3.5天）。</p>
<h3 id="优化器"><a class="markdownIt-Anchor" href="#优化器"></a> 优化器</h3>
<p>我们使用 <code>Adam</code> 优化器，参数设置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\beta_1 = 0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.98</mn></mrow><annotation encoding="application/x-tex">\beta_2 = 0.98</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">8</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\epsilon = 10^{-9}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span></span>。在训练过程中，我们根据以下公式调整学习率：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>lrate</mtext><mo>=</mo><msubsup><mi>d</mi><mtext>model</mtext><mrow><mo>−</mo><mn>0.5</mn></mrow></msubsup><mo>⋅</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mtext>step_num</mtext><mrow><mo>−</mo><mn>0.5</mn></mrow></msup><mo separator="true">,</mo><mtext>step_num</mtext><mo>⋅</mo><msup><mtext>warmup_steps</mtext><mrow><mo>−</mo><mn>1.5</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text {lrate} = d_{\text {model}}^{-0.5} \cdot \min(\text {step\_num}^{-0.5}, \text {step\_num} \cdot \text {warmup\_steps}^{-1.5})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">lrate</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1555469999999999em;vertical-align:-0.2914389999999999em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.408561em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2914389999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.174108em;vertical-align:-0.31em;"></span><span class="mop">min</span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord">step_num</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">step_num</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.174108em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord text"><span class="mord">warmup_steps</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>这相当于在前 <code>warmup_steps</code> 训练步骤中线性增加学习率，之后按步数的平方根的倒数比例降低学习率。我们使用 <code>warmup_steps=4000</code>。</p>
<blockquote>
<p>在Adam优化器中这三个参数的含义是：</p>
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\beta_1 = 0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span> 是一阶动量的衰减率，控制历史梯度的影响程度。0.9意味着新的梯度占10%，过去的累积梯度占90%，使参数更新更平滑</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.98</mn></mrow><annotation encoding="application/x-tex">\beta_2 = 0.98</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">8</span></span></span></span> 是二阶动量的衰减率，用于控制学习率的自适应程度。0.98表示历史梯度平方的影响会更持久，让学习率调整更稳定</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\epsilon = 10^{-9}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span></span> 是一个很小的常数，添加到分母以防止除零，保证数值稳定性。通常取很小的值，对优化结果影响不大</p>
</li>
</ul>
<p>这些是Adam常用的默认值，在实践中表现良好。</p>
</blockquote>
<h3 id="正则化"><a class="markdownIt-Anchor" href="#正则化"></a> 正则化</h3>
<p>我们在训练期间采用三种类型的正则化：</p>
<ul>
<li>
<p><strong>残差丢弃</strong>：我们对每个子层的输出应用丢弃（<code>dropout</code>），然后再将其添加到子层输入并进行归一化。此外，我们对编码器和解码器堆栈中的嵌入和位置编码的和也应用丢弃。对于基础模型，我们使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mtext>d</mtext><mi>r</mi><mi>o</mi><mi>p</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P_{\text drop} = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">d</span></span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span> 的丢弃率。</p>
</li>
<li>
<p><strong>标签平滑</strong>：在训练期间，我们采用值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>l</mi><mi>s</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\epsilon_{ls} = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span> 的标签平滑。这会损害困惑度，因为模型学会了更加不确定，但能提高准确率和 <code>BLEU</code> 分数。</p>
</li>
</ul>
<p>表2：<code>Transformer</code>在英德和英法 <code>newstest2014</code> 测试中，以较少的训练成本达到了比之前最先进模型更好的 <code>BLEU</code> 分数。</p>
<img src="/images/assets//image-20241214220939993.png" width="600">
<h2 id="结果"><a class="markdownIt-Anchor" href="#结果"></a> 结果</h2>
<h3 id="机器翻译"><a class="markdownIt-Anchor" href="#机器翻译"></a> 机器翻译</h3>
<p>在 <code>WMT 2014</code> 英德翻译任务中，<code>Transformer</code> 大型模型（表2中的 <code>Transformer (big)</code>）比之前报告的最佳模型（包括集成模型）的表现高出超过2.0个 <code>BLEU</code> 分，创造了新的 <code>BLEU</code> 分数记录：28.4。该模型的配置列在表3的最后一行。训练在8块 <code>P100 GPU</code> 上用时3.5天。即使是我们的基础模型也超越了所有先前发表的模型和集成模型，而且训练成本只是竞争模型的一小部分。</p>
<p>在 <code>WMT 2014</code> 英法翻译任务中，我们的大型模型达到了41.0的 <code>BLEU</code> 分数，超越了所有先前发表的单一模型，且训练成本不到之前最先进模型的四分之一。用于英法翻译的 <code>Transformer</code> 大型模型使用了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mtext>d</mtext><mi>r</mi><mi>o</mi><mi>p</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P_{\text drop} = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">d</span></span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span> 的丢弃率，而不是0.3。</p>
<p>对于基础模型，我们使用了通过平均最后5个检查点获得的单一模型，这些检查点以10分钟的间隔写入。对于大型模型，我们平均了最后20个检查点。我们使用束搜索，束宽为4，长度惩罚 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.6</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span></span></span></span> 。这些超参数是在开发集上实验后选择的。我们在推理过程中将最大输出长度设置为输入长度加50，但在可能的情况下提前终止。</p>
<p>表2总结了我们的结果，并将我们的翻译质量和训练成本与文献中的其他模型架构进行了比较。我们通过将训练时间、使用的 <code>GPU</code> 数量以及每个<code> GPU</code> 的估计单精度浮点持续计算能力相乘来估算训练模型所使用的浮点运算次数。</p>
<h3 id="模型变体"><a class="markdownIt-Anchor" href="#模型变体"></a> 模型变体</h3>
<p>为了评估 <code>Transformer</code> 不同组件的重要性，我们以不同方式改变了基础模型，在英德翻译的开发集（<code>newstest2013</code>）上测量性能变化。我们使用了如前一节所述的束搜索，但没有进行检查点平均。这些结果在表3中展示。</p>
<p>表3：<code>Transformer</code> 架构的变体。未列出的值与基础模型相同。所有指标都基于英德翻译开发集 <code>newstest2013</code>。列出的困惑度是按照我们的字节对编码的每词片（<code>per-wordpiece</code>）计算的，不应与每词（<code>per-word</code>）困惑度进行比较。</p>
<img src="/images/assets//image-20241214220200245.png" width="600">
<p>在表3的（A）行中，我们改变了注意力头的数量以及注意力键值维度，同时保持计算量不变。虽然单头注意力比最佳设置低0.9 <code>BLEU</code>，但头数过多时质量也会下降。</p>
<p>在表3的（B）行中，我们观察到减小注意力键的大小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 会损害模型质量。这表明确定兼容性并不容易，可能需要比点积更复杂的兼容性函数。我们在（C）和（D）行中进一步观察到，正如预期的那样，更大的模型效果更好，且丢弃对避免过拟合非常有帮助。在（E）行中，我们用学习的位置嵌入替换了正弦位置编码，观察到与基础模型几乎相同的结果。</p>
<h3 id="英语成分句法分析"><a class="markdownIt-Anchor" href="#英语成分句法分析"></a> 英语成分句法分析</h3>
<p>为了评估<code>Transformer</code>是否能够泛化到其他任务，我们在英语成分句法分析上进行了实验。这项任务具有特定的挑战：输出受到强结构约束，并且显著长于输入。此外，基于<code>RNN</code>的序列到序列模型在小数据条件下无法达到最优水平。</p>
<p>我们在<code>Penn Treebank</code>（宾夕法尼亚树库）的<code>Wall Street Journal</code>（华尔街日报，简称<code>WSJ</code>）部分训练了一个4层的<code>transformer</code>模型，模型参数<code>dmodel=1024</code>，训练数据约4万句。我们还在半监督设置下进行了训练，使用了更大的高可信度语料库和<code>BerkleyParser</code>语料库，包含约1700万句。在仅使用<code>WSJ</code>的设置中，我们使用了16K词汇量，在半监督设置中使用了32K词汇量。</p>
<p>我们仅在第22部分的开发集上进行了少量实验来选择<code>dropout</code>（包括注意力和残差部分）、学习率和束搜索大小，其他所有参数均保持与英德翻译基础模型相同。在推理过程中，我们将最大输出长度增加到输入长度<code>+300</code>。在<code>WSJ</code>单独训练和半监督设置中，我们都使用了束大小为<code>21</code>且<code>α=0.3</code>的设置。</p>
<p>表4：<code>Transformer</code>在英语成分句法分析上的良好泛化性能（结果基于<code>WSJ</code>第<code>23</code>部分）</p>
<img src="/images/assets//image-20241214220853164.png" width="600">
<p>我们的结果如表<code>4</code>所示，尽管缺乏特定任务的调优，我们的模型表现出人意料地好，除了递归神经网络文法外，取得了优于所有先前报告模型的结果。</p>
<p>与<code>RNN</code>序列到序列模型相比，即使仅在包含4万句的<code>WSJ</code>训练集上训练，<code>Transformer</code>的表现也优于<code>BerkeleyParser</code>。</p>
<h1 id="结论"><a class="markdownIt-Anchor" href="#结论"></a> 结论</h1>
<p>在这项工作中，我们提出了<code>Transformer</code>，这是第一个完全基于注意力机制的序列转换模型，它用多头自注意力机制取代了编码器-解码器架构中最常用的循环层。</p>
<p>对于翻译任务，<code>Transformer</code>的训练速度明显快于基于循环层或卷积层的架构。在<code>WMT 2014</code>英德翻译和<code>WMT 2014</code>英法翻译任务上，我们都达到了新的最优水平。在前一个任务中，我们的最佳模型甚至超越了所有此前报告的集成模型的性能。</p>
<p>我们对基于注意力模型的未来充满期待，并计划将其应用于其他任务。我们计划将<code>Transformer</code>扩展到涉及文本以外的输入和输出模态的问题，并研究局部的、受限制的注意力机制，以有效处理大规模输入和输出，如图像、音频和视频。使生成过程减少顺序依赖性也是我们的研究目标之一。</p>
<p>我们用于训练和评估模型的代码可在 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a> 获取。</p>
<p>致谢：我们感谢<code>Nal Kalchbrenner</code>和<code>Stephan Gouws</code>富有成效的评论、修正和启发。</p>
<h1 id="注意力可视化"><a class="markdownIt-Anchor" href="#注意力可视化"></a> 注意力可视化</h1>
<h2 id="图3"><a class="markdownIt-Anchor" href="#图3"></a> 图3</h2>
<img src="/images/assets//image-20241214221259460.png" width="600">
<p>图3：在编码器第5层（共6层）的自注意力机制中跟踪长距离依赖关系的示例。许多注意力头都关注动词&quot;making&quot;的远距离依赖，完成短语&quot;making…more difficult&quot;。此处仅显示针对单词&quot;making&quot;的注意力。不同颜色代表不同的注意力头。最佳以彩色查看。</p>
<h2 id="图4"><a class="markdownIt-Anchor" href="#图4"></a> 图4</h2>
<img src="/images/assets//image-20241214221432239.png" width="500">
<p>图4：两个位于第5层（共6层）的注意力头，显然参与了回指消解。上图：第5个头的完整注意力分布。下图：仅展示来自单词&quot;its&quot;的注意力分布（注意力头5和6）。注意这个词的注意力分布非常清晰明确。</p>
<h2 id="图5"><a class="markdownIt-Anchor" href="#图5"></a> 图5</h2>
<img src="/images/assets//image-20241214221551627.png" width="500">
<p>图5：许多注意力头表现出与句子结构相关的行为模式。我们在上面给出了两个这样的示例，来自编码器第5层（共6层）自注意力机制中的两个不同头。这些注意力头明显学会了执行不同的任务。</p>
<h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h1>
<ol>
<li>
<p>Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.06450">arXiv:1607.06450</a>, 2016.</p>
</li>
<li>
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.</p>
</li>
<li>
<p>Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.</p>
</li>
<li>
<p>Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1601.06733">arXiv:1601.06733</a>, 2016.</p>
</li>
<li>
<p>Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.</p>
</li>
<li>
<p>Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.02357">arXiv:1610.02357</a>, 2016.</p>
</li>
<li>
<p>Junyoung Chung, Çağlar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.</p>
</li>
<li>
<p>Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In Proc. of NAACL, 2016.</p>
</li>
<li>
<p>Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence to sequence learning. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.03122v2">arXiv:1705.03122v2</a>, 2017.</p>
</li>
<li>
<p>Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1308.0850">arXiv:1308.0850</a>, 2013.</p>
</li>
<li>
<p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770-778, 2016.</p>
</li>
<li>
<p>Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001.</p>
</li>
<li>
<p>Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780, 1997.</p>
</li>
<li>
<p>Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 832-841. ACL, August 2009.</p>
</li>
<li>
<p>Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.02410">arXiv:1602.02410</a>, 2016.</p>
</li>
<li>
<p>Lukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016.</p>
</li>
<li>
<p>Lukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on Learning Representations (ICLR), 2016.</p>
</li>
<li>
<p>Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.10099v2">arXiv:1610.10099v2</a>, 2017.</p>
</li>
<li>
<p>Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In International Conference on Learning Representations, 2017.</p>
</li>
<li>
<p>Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.</p>
</li>
<li>
<p>Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.10722">arXiv:1703.10722</a>, 2017.</p>
</li>
<li>
<p>Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.03130">arXiv:1703.03130</a>, 2017.</p>
</li>
<li>
<p>Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.06114">arXiv:1511.06114</a>, 2015.</p>
</li>
<li>
<p>Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1508.04025">arXiv:1508.04025</a>, 2015.</p>
</li>
<li>
<p>Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313-330, 1993.</p>
</li>
<li>
<p>David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152-159. ACL, June 2006.</p>
</li>
<li>
<p>Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.</p>
</li>
<li>
<p>Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.04304">arXiv:1705.04304</a>, 2017.</p>
</li>
<li>
<p>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 433-440. ACL, July 2006.</p>
</li>
<li>
<p>Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.05859">arXiv:1608.05859</a>, 2016.</p>
</li>
<li>
<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1508.07909">arXiv:1508.07909</a>, 2015.</p>
</li>
<li>
<p>Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1701.06538">arXiv:1701.06538</a>, 2017.</p>
</li>
<li>
<p>Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929-1958, 2014.</p>
</li>
<li>
<p>Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440-2448. Curran Associates, Inc., 2015.</p>
</li>
<li>
<p>Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104-3112, 2014.</p>
</li>
<li>
<p>Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.</p>
</li>
<li>
<p>Vinyals &amp; Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.</p>
</li>
<li>
<p>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1609.08144">arXiv:1609.08144</a>, 2016.</p>
</li>
<li>
<p>Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.</p>
</li>
<li>
<p>Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434-443. ACL, August 2013.</p>
</li>
</ol>
<h1 id="transformer发展"><a class="markdownIt-Anchor" href="#transformer发展"></a> transformer发展</h1>
<h2 id="transformer模型变体"><a class="markdownIt-Anchor" href="#transformer模型变体"></a> transformer模型变体</h2>
<p>自<code>2017</code> 年发表的这篇奠基性论文《<code>Attention is All You Need</code>》中提出的原始 <code>transformer</code> 架构之后，transformer的变体模型越来越多，同时适用的领域也越来越精细化，下表列出了近几年 <code>transformer</code> 的<code>变体模型</code>及其特点等信息：</p>
<table>
<thead>
<tr>
<th>模型名称</th>
<th>发表年份</th>
<th>特点</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BERT</strong></td>
<td>2018</td>
<td>双向编码预训练语言模型，使用遮掩语言模型（MLM）和下一句预测（NSP）任务</td>
<td>在多个NLP任务上取得了显著的性能提升</td>
<td>预训练和微调需要大量计算资源，缺乏对生成任务的支持</td>
</tr>
<tr>
<td><strong>GPT</strong></td>
<td>2018</td>
<td>基于Transformer的单向自回归语言模型</td>
<td>在生成任务上表现出色，模型架构简单，易于扩展</td>
<td>单向性限制了对上下文信息的完整捕捉</td>
</tr>
<tr>
<td><strong>GPT-2</strong></td>
<td>2019</td>
<td>扩大了GPT的规模，参数量增加，生成更长的文本</td>
<td>文本生成更连贯，表现更佳</td>
<td>存在滥用风险，计算资源需求高</td>
</tr>
<tr>
<td><strong>RoBERTa</strong></td>
<td>2019</td>
<td>改进了BERT，取消NSP任务，增加训练数据和训练时间</td>
<td>在多项NLP任务上超过了BERT的性能</td>
<td>训练成本高，依赖大量数据</td>
</tr>
<tr>
<td><strong>ALBERT</strong></td>
<td>2019</td>
<td>引入参数共享和因子化嵌入，减少模型参数量</td>
<td>模型更小，训练速度更快，性能接近BERT</td>
<td>参数共享可能限制模型的表达能力</td>
</tr>
<tr>
<td><strong>XLNet</strong></td>
<td>2019</td>
<td>结合自回归和自编码的预训练方法，使用Transformer-XL作为基础</td>
<td>超越了BERT在多个任务上的性能，能够捕捉双向上下文</td>
<td>模型更复杂，训练难度增加</td>
</tr>
<tr>
<td><strong>T5</strong></td>
<td>2019</td>
<td>将所有NLP任务统一为“文本到文本”的框架，进行大规模预训练</td>
<td>在多项任务上表现出色，统一的架构便于迁移学习</td>
<td>模型体积庞大，训练和推理成本高</td>
</tr>
<tr>
<td><strong>ELECTRA</strong></td>
<td>2020</td>
<td>使用替换词检测作为预训练任务，提高训练效率</td>
<td>在相同计算预算下，性能优于BERT</td>
<td>训练过程更复杂，可能需要精细的超参数调节</td>
</tr>
<tr>
<td><strong>Reformer</strong></td>
<td>2020</td>
<td>利用局部敏感哈希（LSH）和可逆残差网络，减少内存和计算需求</td>
<td>能处理长序列，降低计算复杂度和内存占用</td>
<td>实现复杂度增加，可能在某些任务上不稳定</td>
</tr>
<tr>
<td><strong>Longformer</strong></td>
<td>2020</td>
<td>采用稀疏注意力机制，增强长序列处理能力</td>
<td>能有效处理长文档，在长序列任务上性能优异</td>
<td>对于短序列任务优势不明显，模型复杂度增加</td>
</tr>
<tr>
<td><strong>Performer</strong></td>
<td>2020</td>
<td>使用随机特征映射近似软max注意力，实现线性计算复杂度</td>
<td>能够高效处理长序列，计算效率高</td>
<td>近似可能导致性能下降，在某些任务上效果不如精确注意力</td>
</tr>
<tr>
<td><strong>Linformer</strong></td>
<td>2020</td>
<td>通过低秩投影将注意力机制的复杂度降为线性</td>
<td>大幅降低注意力的计算和内存需求，适用于长序列</td>
<td>低秩近似可能损失部分信息，影响模型性能</td>
</tr>
<tr>
<td><strong>BigBird</strong></td>
<td>2020</td>
<td>结合局部、随机和全局注意力机制，扩展到更长的序列</td>
<td>能处理非常长的序列，在长文本理解上表现良好</td>
<td>模型结构更复杂，实现和调试难度增大</td>
</tr>
<tr>
<td><strong>ViT（Vision Transformer）</strong></td>
<td>2020</td>
<td>将Transformer应用于图像任务，将图像划分为patches进行处理</td>
<td>在图像分类任务上取得了优异性能，突破了传统CNN的限制</td>
<td>需要大量数据进行预训练，对小样本数据集表现较差</td>
</tr>
<tr>
<td><strong>Switch Transformer</strong></td>
<td>2021</td>
<td>基于专家混合（MoE）的稀疏激活模型，极大地扩大模型规模</td>
<td>增加模型容量的同时保持计算成本较低，在大规模预训练中表现出色</td>
<td>通信和负载均衡成为训练的瓶颈，模型复杂度高</td>
</tr>
<tr>
<td><strong>Swin Transformer</strong></td>
<td>2021</td>
<td>使用层次化的Transformer结构和滑动窗口机制，适用于视觉任务</td>
<td>在图像分类、目标检测等任务上性能优异，具有良好的扩展性</td>
<td>模型结构复杂，训练时间较长，需要更多资源</td>
</tr>
<tr>
<td><strong>GPT-3</strong></td>
<td>2020</td>
<td>超大规模语言模型，拥有1750亿参数，具备强大的生成能力</td>
<td>具有卓越的零样本和少样本学习能力，可处理多种任务</td>
<td>参数规模庞大，训练和推理成本极高，存在偏见和不准确性</td>
</tr>
<tr>
<td><strong>GPT-4</strong></td>
<td>2023</td>
<td>多模态模型，支持文本和图像输入，进一步提升推理能力</td>
<td>在广泛的任务上表现优异，更好的上下文理解和生成能力</td>
<td>模型巨大，推理成本高，仍存在生成错误信息的风险</td>
</tr>
</tbody>
</table>
<p>这些 <code>transformer</code> 变体各有特点，通过在模型结构、预训练任务和训练策略等方面的创新，不断提升了模型在各种任务上的性能。然而，随着模型规模的扩大，训练和推理的计算成本也显著增加，<code>如何在性能和效率之间取得平衡仍是一个重要的研究方向</code>。</p>
<h2 id="优化与创新方向"><a class="markdownIt-Anchor" href="#优化与创新方向"></a> 优化与创新方向</h2>
<p>细分看来，上述这些模型，主要在以下几个方向上进行了<code>优化和创新</code>：</p>
<ol>
<li>
<p><strong><code>模型架构优化</code></strong></p>
<ul>
<li>
<p><strong>稀疏注意力机制</strong>：为了降低计算复杂度，提高对长序列的处理能力，一些模型引入了稀疏注意力机制。例如：</p>
<ul>
<li><strong>Longformer</strong>：采用局部和全局的稀疏注意力模式，能够处理更长的文本。</li>
<li><strong>BigBird</strong>：结合局部、随机和全局注意力，扩展了模型的上下文范围。</li>
<li><strong>Reformer</strong>：利用局部敏感哈希（LSH）替代传统的点积注意力，减少了计算和内存开销。</li>
</ul>
</li>
<li>
<p><strong>线性化注意力</strong>：通过近似方法将注意力机制的计算复杂度从二次降为线性。例如：</p>
<ul>
<li><strong>Performer</strong>：使用随机特征映射近似软max注意力，实现线性时间复杂度。</li>
<li><strong>Linformer</strong>：采用低秩矩阵分解技术，降低了注意力矩阵的维度。</li>
</ul>
</li>
<li>
<p><strong>层次化结构</strong>：在视觉领域，引入了层次化的特征表示，以更好地捕捉不同尺度的信息。例如：</p>
<ul>
<li><strong>Swin Transformer</strong>：使用滑动窗口和金字塔结构，适用于图像和视频任务。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>预训练任务和目标的改进</code></strong></p>
<ul>
<li>
<p><strong>新的预训练任务</strong>：为了更有效地学习语言表示，模型引入了新的预训练任务。</p>
<ul>
<li><strong>BERT</strong>：使用了遮掩语言模型（MLM）和下一句预测（NSP）。</li>
<li><strong>RoBERTa</strong>：改进了预训练策略，取消了NSP任务，使用动态遮掩。</li>
<li><strong>ELECTRA</strong>：提出了替换词检测任务，训练一个判别器来区分真实词和生成的假词，提高了训练效率。</li>
</ul>
</li>
<li>
<p><strong>自回归与自编码的结合</strong>：</p>
<ul>
<li><strong>XLNet</strong>：融合了自回归和自编码的预训练方法，通过掩码排列方式捕获双向上下文信息。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>模型规模的扩展</code></strong></p>
<ul>
<li>
<p><strong>参数规模的增加</strong>：为了提升模型的表达能力，研究者们不断扩大模型的参数规模。</p>
<ul>
<li><strong>GPT-2</strong>：参数量达到15亿，比GPT大了一个数量级。</li>
<li><strong>GPT-3</strong>：进一步扩展到1750亿参数，具备强大的生成和推理能力。</li>
<li><strong>Switch Transformer</strong>：采用专家混合（MoE）结构，实现了万亿级参数的模型。</li>
</ul>
</li>
<li>
<p><strong>稀疏激活和专家模型</strong>：</p>
<ul>
<li><strong>Switch Transformer</strong>：在模型中引入了稀疏激活的专家层，每次只激活部分参数，减少计算成本。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>参数高效化</code></strong></p>
<ul>
<li><strong>参数共享和压缩</strong>：为了减少模型参数量，提升训练和推理效率。
<ul>
<li><strong>ALBERT</strong>：使用跨层参数共享和因子化嵌入，将参数量大幅减少，同时保持性能。</li>
<li><strong>DistilBERT</strong>：通过蒸馏技术，从大型模型中学习，生成轻量级模型。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>任务统一化</code></strong></p>
<ul>
<li><strong>统一的框架处理多种任务</strong>：
<ul>
<li><strong>T5（Text-to-Text Transfer Transformer）</strong>：将各种NLP任务统一建模为文本到文本的问题，方便了多任务学习和迁移学习。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>跨模态扩展</code></strong></p>
<ul>
<li><strong>将Transformer应用于视觉和多模态任务</strong>：
<ul>
<li><strong>ViT（Vision Transformer）</strong>：将Transformer直接应用于图像分类任务，效果超过了一些经典的卷积神经网络。</li>
<li><strong>GPT-4</strong>：支持文本和图像输入的多模态模型，能够理解并生成跨模态的内容。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>更好的长程依赖建模</code></strong></p>
<ul>
<li><strong>相对位置编码和循环机制</strong>：
<ul>
<li><strong>Transformer-XL</strong>：引入了递归机制和相对位置编码，改善了对长序列的依赖。</li>
<li><strong>XLNet</strong>：利用相对位置编码，增强了模型对长距离依赖的捕捉能力。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>计算效率和内存优化</code></strong></p>
<ul>
<li>
<p><strong>可逆网络和压缩技术</strong>：</p>
<ul>
<li><strong>Reformer</strong>：引入可逆残差网络，减少了模型的内存占用，因为可以在反向传播中无需存储中间激活值。</li>
</ul>
</li>
<li>
<p><strong>低秩和近似计算</strong>：</p>
<ul>
<li><strong>Linformer</strong>：通过低秩近似，减少了注意力矩阵的尺寸，降低了计算量。</li>
<li><strong>Performer</strong>：用核方法近似softmax函数，提升了计算效率。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>训练策略的改进</code></strong></p>
<ul>
<li><strong>大规模数据和训练技巧</strong>：
<ul>
<li><strong>RoBERTa</strong>：增加了训练数据量，延长了训练时间，并调整了超参数，取得了比BERT更好的性能。</li>
<li><strong>DeepSpeed和Megatron-LM</strong>：提供了高效的模型并行和数据并行策略，支持训练超大规模模型。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code>应用领域的拓展</code></strong></p>
<ul>
<li>
<p><strong>领域特定的预训练</strong>：</p>
<ul>
<li><strong>BioBERT、SciBERT</strong>：针对生物医学和科学文献进行预训练，提升了在特定领域的性能。</li>
</ul>
</li>
<li>
<p><strong>多语言和跨语言模型</strong>：</p>
<ul>
<li><strong>mBERT、XLM-R</strong>：在多语言数据上进行预训练，支持跨语言的理解和生成。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>综合上述内容，这些改进旨在提升模型的性能、效率和适用范围等等，以应对不同的任务需求和计算资源限制。</p>
<h2 id="如何在新任务上优化-transformer-架构"><a class="markdownIt-Anchor" href="#如何在新任务上优化-transformer-架构"></a> 如何在新任务上优化 transformer 架构？</h2>
<p>个人认为，可从以下几个方面考虑：</p>
<ul>
<li>
<p><strong><code>架构创新</code></strong>：通过改进注意力机制和引入新的网络结构，提升模型对长序列和复杂任务的处理能力。</p>
</li>
<li>
<p><strong><code>预训练策略</code></strong>：设计新的预训练任务和目标，使模型能够更有效地学习新任务所需特征。</p>
</li>
<li>
<p><strong><code>规模和效率</code></strong>：扩大模型规模以提高性能，同时引入参数共享、模型压缩和稀疏激活等技术，优化计算资源的利用。</p>
</li>
<li>
<p><strong><code>任务和领域拓展</code></strong>：将Transformer应用于新的领域和任务，如基因组学数据分析、计算机视觉、多模态处理等等。</p>
</li>
<li>
<p><strong><code>训练优化</code></strong>：改进训练算法和并行策略，以支持大规模模型的训练，降低训练时间和资源消耗。</p>
</li>
</ul>
<h1 id="transformer代码实现举例"><a class="markdownIt-Anchor" href="#transformer代码实现举例"></a> transformer代码实现举例</h1>
<p>作为参考，这里的示例基于<code>Transformer</code>架构的语言模型实现，具体是一个<code>仅包含解码器</code>的变体，功能是<code>语言生成</code>。</p>
<p>先来回顾一下transformer模型中的概念：</p>
<ul>
<li><code>嵌入层</code>：将词汇等源转换为密集向量表示</li>
<li><code>位置编码</code>：为序列中的每个位置添加位置信息</li>
<li><code>Transformer解码器</code>：核心计算单元</li>
<li><code>输出层</code>：将结果映射回词汇等源大小的空间</li>
</ul>
<p>重要参数：</p>
<ul>
<li><code>vocab_size</code>: 词汇表等源大小</li>
<li><code>embed_size</code>: 嵌入维度</li>
<li><code>num_heads</code>: 注意力头数</li>
<li><code>hidden_dim</code>: 前馈网络维度</li>
<li><code>num_layers</code>: 解码器层数</li>
</ul>
<h2 id="构建-transformer-模型"><a class="markdownIt-Anchor" href="#构建-transformer-模型"></a> 构建 transformer 模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个仅包含解码器的transformer模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerDecoderModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_size, num_heads, hidden_dim, num_layers</span>):</span><br><span class="line">        <span class="comment"># 调用基类的初始化函数</span></span><br><span class="line">        <span class="built_in">super</span>(TransformerDecoderModel, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="comment"># 创建嵌入层，将词索引转换为嵌入向量</span></span><br><span class="line">        <span class="variable language_">self</span>.embed = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        <span class="comment"># 初始化位置编码，是一个可学习的参数</span></span><br><span class="line">        <span class="variable language_">self</span>.positional_encoding = nn.Parameter(torch.randn(embed_size).unsqueeze(<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># 定义Transformer解码器层</span></span><br><span class="line">        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim)</span><br><span class="line">        <span class="comment"># 堆叠多个解码器层构成完整的解码器</span></span><br><span class="line">        <span class="variable language_">self</span>.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)</span><br><span class="line">        <span class="comment"># 定义输出层，将解码器输出转换回词汇空间</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(embed_size, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src</span>):</span><br><span class="line">        <span class="comment"># 嵌入输入并添加位置编码</span></span><br><span class="line">        src = <span class="variable language_">self</span>.embed(src) + <span class="variable language_">self</span>.positional_encoding</span><br><span class="line">        <span class="comment"># 生成源序列的掩码，用于屏蔽未来的信息</span></span><br><span class="line">        src_mask = <span class="variable language_">self</span>.generate_square_subsequent_mask(src.size(<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># 通过解码器传递源数据和掩码</span></span><br><span class="line">        output = <span class="variable language_">self</span>.transformer_decoder(src, src, src_mask)</span><br><span class="line">        <span class="comment"># 应用线性层输出最终的预测结果</span></span><br><span class="line">        output = <span class="variable language_">self</span>.fc(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_square_subsequent_mask</span>(<span class="params">self, sz</span>):</span><br><span class="line">        <span class="comment"># 上三角矩阵，用于序列生成中遮蔽未来位置的信息</span></span><br><span class="line">        mask = (torch.triu(torch.ones(sz, sz)) == <span class="number">1</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将掩码的非零位置设为无穷大，零位置设为0</span></span><br><span class="line">        mask = mask.<span class="built_in">float</span>().masked_fill(mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)).masked_fill(mask == <span class="number">1</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br><span class="line">        <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure>
<h2 id="训练数据集"><a class="markdownIt-Anchor" href="#训练数据集"></a> 训练数据集</h2>
<p>transformer架构的模型，整体<code>训练成本</code>都非常高，这里仅作演示，我们极大<code>缩小训练量级</code>，将以下文本存为“<code>sentence.txt</code>”作为训练数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">数学</span><br><span class="line"></span><br><span class="line">数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定义中建立起严谨推导出的定理。</span><br><span class="line"></span><br><span class="line">基础数学的知识与运用总是个人与团体生活中不可或缺的一环。对数学基本概念的完善，早在古埃及、美索不达米亚及古印度内的古代数学文本便可观见，而在古希腊那里有更为严谨的处理。从那时开始，数学的发展便持续不断地小幅进展，至16世纪的文艺复兴时期，因为新的科学发现和数学革新两者的交互，致使数学的加速发展，直至今日。数学并成为许多国家及地区的教育范畴中的一部分。</span><br><span class="line"></span><br><span class="line">今日，数学使用在不同的领域中，包括科学、工程、医学、经济学和金融学等。数学对这些领域的应用通常被称为应用数学，有时亦会激起新的数学发现，并导致全新学科的发展，例如物理学的实质性发展中建立的某些理论激发数学家对于某些问题的不同角度的思考。数学家也研究纯数学，就是数学本身的实质性内容，而不以任何实际应用为目标。虽然许多研究以纯数学开始，但其过程中也发现许多应用之处。</span><br><span class="line"></span><br><span class="line">西方语言中“数学”（）一词源自于古希腊语的（），其有“学习”、“学问”、“科学”，以及另外还有个较狭义且技术性的意思－「数学研究」，即使在其语源内。其形容词（），意思为&quot;和学习有关的&quot;或&quot;用功的&quot;，亦会被用来指&quot;数学的&quot;。其在英语中表面上的复数形式，及在法语中的表面复数形式&#x27;，可溯至拉丁文的中性复数&#x27;，由西塞罗译自希腊文复数（），此一希腊语被亚里士多德拿来指「万物皆数」的概念。</span><br><span class="line"></span><br><span class="line">汉字表示的「数学」一词大约产生于中国宋元时期。多指象数之学，但有时也含有今天上的数学意义，例如，秦九韶的《数学九章》（《永乐大典》记，即《数书九章》也被宋代周密所著的《癸辛杂识》记为《数学大略》）、《数学通轨》（明代柯尚迁著）、《数学钥》（清代杜知耕著）、《数学拾遗》（清代丁取忠撰）。直到1939年，经过中国数学名词审查委员会研究“算学”与“数学”两词的使用状况后，确认以“数学”表示今天意义上的数学含义。</span><br><span class="line"></span><br><span class="line">数学有着久远的历史。它被认为起源于人类早期的生产活动：中国古代的六艺之一就有「数」，数学一词在西方有希腊语词源（mathematikós），意思是“学问的基础”，源于（máthema，“科学，知识，学问”）。</span><br><span class="line"></span><br><span class="line">史前的人类就已尝试用自然的法则来衡量物质的多少、时间的长短等抽象的数量关系，比如时间单位有日、季节和年等。算术（加减乘除）也自然而然地产生了。古代的石碑及泥版亦证实了当时已有几何的知识。</span><br><span class="line"></span><br><span class="line">更进一步则需要写作或其他可记录数字的系统，如符木或于印加帝国内用来储存数据的奇普。历史上曾有过许多不同的记数系统。</span><br><span class="line"></span><br><span class="line">在最初有历史记录的时候，数学内的主要原理是为了做税务和贸易等相关计算，为了解数字间的关系，为了测量土地，以及为了预测天文事件而形成的。这些需要可以简单地被概括为数学对数量、结构、空间及时间方面的研究。</span><br><span class="line"></span><br><span class="line">到了16世纪，算术、初等代数以及三角学等初等数学已大体完备。17世纪变量概念的产生使人们开始研究变化中的量与量的互相关系和图形间的互相变换，微积分的概念也在此时形成。随着数学转向形式化，为研究数学基础而产生的集合论和数理逻辑等也开始发展。数学的重心从求解实际问题转变到对一般形式上的思考。</span><br><span class="line"></span><br><span class="line">从古至今，数学便一直不断地延展，且与科学有丰富的相互作用，两者的发展都受惠于彼此。在历史上有著许多数学发现，并且直至今日都不断地有新的发现。据Mikhail B. Sevryuk于2006年1月的期刊中所说，「存放于数学评论资料库中论文和书籍的数量自1940年（数学评论的创刊年份）现已超过了一百九十万份，而且每年还增加超过七万五千份。此一学海的绝大部份为新的数学定理及其证明。」</span><br><span class="line"></span><br><span class="line">每当有涉及数量、结构、空间及变化等方面的困难问题时，通常就需要用到数学工具去解决问题，而这往往也拓展了数学的研究范畴。一开始，数学的运用可见于贸易、土地测量及之后的天文学。今日，所有的科学都存在著值得数学家研究的问题，且数学本身亦给出了许多的问题。牛顿和莱布尼兹是微积分的发明者，费曼发明了费曼路径积分，这是推理及物理洞察二者的产物，而今日的弦理论亦引申出新的数学。一些数学只和生成它的领域有关，且用来解答此领域的更多问题。但一般被一领域生成的数学在其他许多领域内也十分有用，且可以成为一般的数学概念。即使是「最纯的」数学通常亦有实际的用途，此一非比寻常的事实，被1963年诺贝尔物理奖得主维格纳称为「数学在自然科学中不可想像的有效性」。</span><br><span class="line"></span><br><span class="line">如同大多数的研究领域，科学知识的爆发导致了数学的专业化。主要的分歧为纯数学和应用数学。在应用数学内，又被分成两大领域，并且变成了它们自身的学科——统计学和电脑科学。</span><br><span class="line"></span><br><span class="line">许多数学家谈论数学的&quot;优美&quot;，其内在的美学及美。「简单」和「一般化」即为美的一种。另外亦包括巧妙的证明，如欧几里得对存在无限多质数的证明；又或者是加快计算的数值方法，如快速傅立叶变换。高德菲·哈罗德·哈代在《一个数学家的自白》一书中表明他相信单单是美学上的意义，就已经足够作为纯数学研究的正当理由。</span><br><span class="line"></span><br><span class="line">我们现今所使用的大部分数学符号在16世纪后才被发明出来的。在此之前，数学以文字的形式书写出来，这种形式会限制了数学的发展。现今的符号使得数学对于专家而言更容易掌握，但初学者却常对此望而却步。它被极度的压缩：少量的符号包含著大量的讯息。如同音乐符号一般，现今的数学符号有明确的语法，并且有效地对讯息作编码，这是其他书写方式难以做到的。符号化和形式化使得数学迅速发展，并帮助各个科学领域建立基础支撑理论。</span><br><span class="line"></span><br><span class="line">数学语言亦对初学者而言感到困难。如“或”和“只”这些字有著比日常用语更精确的意思。亦困恼著初学者的，如“开放”和“域”等字在数学里有著特别的意思。数学术语亦包括如“同胚”及“可积性”等专有名词。但使用这些特别符号和专有术语是有其原因的：数学需要比日常用语更多的精确性。数学家将此对语言及逻辑精确性的要求称为「严谨」。但在现实应用中，舍弃一些严谨性往往会得到更好的结果。</span><br><span class="line"></span><br><span class="line">严谨是数学证明中很重要且基本的一部份。数学家希望他们的定理以系统化的推理依著公理被推论下去。这是为了避免依著不可靠的直观而推出错误的「定理」，而这情形在历史上曾出现过许多的例子。在数学中被期许的严谨程度因著时间而不同：希腊人期许著仔细的论证，但在牛顿的时代，所使用的方法则较不严谨。牛顿为了解决问题所做的定义，到了十九世纪才重新以小心的分析及正式的证明来处理。今日，数学家们则持续地在争论电脑辅助证明的严谨度。当大量的计算难以被验证时，其证明亦很难说是足够地严谨。</span><br><span class="line"></span><br><span class="line">公理在传统的思想中是「不证自明的真理」，但这种想法是有问题的。在形式上，公理只是一串符号，其只对可以由公理系统导出的公式之内容有意义。希尔伯特计划即是想将所有的数学放在坚固的公理基础上，但依据哥德尔不完备定理，每一相容且能蕴涵皮亚诺公理的公理系统必含有一不可决定的公式；因而所有数学的最终公理化是不可能的。尽管如此，数学常常被想像成只是某种公理化的集合论，在此意义下，所有数学叙述或证明都可以写成集合论的公式。</span><br><span class="line"></span><br><span class="line">卡尔·弗里德里希·高斯称数学为「科学的皇后」。在拉丁原文&#x27;，以及其德语&#x27;中，对应于「科学」的单字的意思皆为知识（领域）。而实际上，science一词在英语内本来就是这个意思，且无疑问地数学在此意义下确实是一门「科学」。将科学限定在自然科学则是在此之后的事。若认为科学是只指物理的世界时，则数学，或至少是纯数学，不会是一门科学。爱因斯坦曾如此描述：「数学定律越和现实有关，它们越不确定；若它们越是确定的话，它们和现实越不会有关。」</span><br><span class="line"></span><br><span class="line">许多哲学家相信数学在经验上不具可否证性，且因此不是卡尔·波普尔所定义的科学。但在1930年代时，在数理逻辑上的重大进展显示数学不能归并至逻辑内，且波普尔推断「大部份的数学定律，如物理及生物学一样，是假设演绎的：纯数学因此变得更接近其假设为猜测的自然科学，比它现在看起来更接近。」然而，其他的思想家，如较著名的拉卡托斯，便提供了一个关于数学本身的可否证性版本。</span><br><span class="line"></span><br><span class="line">另一观点则为某些科学领域（如理论物理）是其公理为尝试著符合现实的数学。而事实上，理论物理学家齐曼（John Ziman）即认为科学是一种公众知识，因此亦包含著数学。在任何的情况下，数学和物理科学的许多领域都有著很多相同的地方，尤其是从假设所得的逻辑推论之探索。直觉和实验在数学和科学的猜想建构上皆扮演著重要的角色。实验数学在数学中的重要性正持续地在增加，且计算和模拟在科学及数学中所扮演的角色也越来越加重，减轻了数学不使用科学方法的缺点。在史蒂芬·沃尔夫勒姆2002年的著作《一种新科学》中他提出，计算数学应被视为其自身的一科学领域来探索。</span><br><span class="line"></span><br><span class="line">数学家对此的态度并不一致。一些研究应用数学的数学家觉得他们是科学家，而那些研究纯数学的数学家则时常觉得他们是在一门较接近逻辑的领域内工作，且因此基本上是个哲学家。许多数学家认为称他们的工作是一种科学，是低估了其美学方面的重要性，以及其做为七大博雅教育之一的历史；另外亦有人认为若忽略其与科学之间的关联，是假装没看到数学和其在科学与工程之间的交互影响，进而促进了数学在许多科学上的发展此一事实。这两种观点之间的差异在哲学上产生了数学是「被创造」（如艺术）或是「被发现」（如科学）的争议。大学院系划分中常见「科学和数学系」，这指出了这两个领域被看作有紧密联系而非一样。实际上，数学家通常会在大体上与科学家合作，但在细节上却会分开。此争议亦是数学哲学众多议题的其中一个。</span><br><span class="line"></span><br><span class="line">如上所述，数学主要的学科最先产生于商业上计算的需要、了解数字间的关系、测量土地及预测天文事件。这四种需要大致地与数量、结构、空间及变化（即算术、代数、几何及分析）等数学上广泛的子领域相关连著。除了上述主要的关注之外，亦有用来探索由数学核心至其他领域上之间的连结的子领域：至逻辑、至集合论（基础）、至不同科学的经验上的数学（应用数学）、及较近代的至不确定性的严格研究。</span><br><span class="line">为了阐明数学基础，数学逻辑和集合论等领域被发展了出来。</span><br><span class="line"></span><br><span class="line">数学逻辑专注于将数学置在一坚固的公理架构上，并研究此一架构的结果。就数学逻辑本身而言，其为哥德尔第二不完备定理所属的领域，而这或许是逻辑中最广为流传的成果－总存在一不能被证明而又为真的定理。</span><br><span class="line"></span><br><span class="line">现代逻辑被分成递归论、模型论和证明论，且和理论电脑科学有著密切的关连性，千禧年大奖难题中的P/NP问题就是理论电脑科学中的著名问题。</span><br><span class="line"></span><br><span class="line">数量的研究起于数，一开始为熟悉的自然数及整数与被描述在算术内的自然数及整数的算术运算。整数更深的性质于数论中有详细的研究，此一理论包括了如费马最后定理等著名的结果。数论还包括两个被广为探讨的未解问题：孪生质数猜想及哥德巴赫猜想。</span><br><span class="line"></span><br><span class="line">当数系更进一步发展时，整数被视为有理数的子集，而有理数则包含于实数中，连续的量即是以实数来表示的。实数则可以被进一步广义化成复数。数的进一步广义化可以持续至包含四元数及八元数。从自然数亦可以推广到超限数，它形式化了计数至无限的这一概念。另一个研究的领域为大小，这个导致了基数和之后对无限的另外一种概念：阿列夫数，它允许无限集合之间的大小可以做有意义的比较。</span><br><span class="line"></span><br><span class="line">许多如数及函数的集合等数学物件都有著内含的结构。这些物件的结构性质被探讨于群、环、-&#123;zh-cn:域;zh-tw:体&#125;-等抽象系统中，该些物件事实上也就是这样的系统。此为代数的领域。在此有一个很重要的概念，即广义化至向量空间的向量，它于线性代数中被研究。向量的研究结合了数学的三个基本领域：数量、结构及空间。向量分析则将其扩展至第四个基本的领域内，即变化。</span><br><span class="line"></span><br><span class="line">创立于二十世纪三十年代的法国的布尔巴基学派认为：纯粹数学，是研究抽象结构的理论。</span><br><span class="line">结构，就是以初始概念和公理出发的演绎系统。</span><br><span class="line">布尔巴基学派认为，有三种基本的抽象结构：代数结构（群，环，域……），序结构（偏序，全序……），拓扑结构（邻域，极限，连通性，维数……）。</span><br><span class="line"></span><br><span class="line">空间的研究源自于几何－尤其是欧几里得几何。三角学则结合了空间及数，且包含有著名的勾股定理。现今对空间的研究更推广到了更高维的几何、非欧几里得几何（其在广义相对论中扮演著核心的角色）及拓扑学。数和空间在解析几何、微分几何和代数几何中都有著很重要的角色。在微分几何中有著纤维丛及流形上的微积分等概念。在代数几何中有著如多项式方程的解集等几何物件的描述，结合了数和空间的概念；亦有著拓扑群的研究，结合了结构与空间。李群被用来研究空间、结构及变化。在其许多分支中，拓扑学可能是二十世纪数学中有著最大进展的领域，并包含有存在已久的庞加莱猜想，以及有争议的四色定理。庞加莱猜想已在2006年确认由俄罗斯数学家格里戈里·佩雷尔曼证明，而四色定理已在1976年由凯尼斯·阿佩尔和沃夫冈·哈肯用电脑证明，而从来没有由人力来验证过。</span><br><span class="line"></span><br><span class="line">了解及描述变化在自然科学里是一普遍的议题，而微积分更为研究变化的有利工具。函数诞生于此，做为描述一变化的量的核心概念。对于实数及实变函数的严格研究为实分析，而复分析则为复数的等价领域。黎曼猜想－数学最基本的未决问题之一－便是以复分析来描述的。泛函分析注重在函数的（一般为无限维）空间上。泛函分析的众多应用之一为量子力学。许多的问题很自然地会导出一个量与其变化率之间的关系，而这在微分方程中被研究。在自然界中的许多现象可以被动力系统所描述；混沌理论则是对系统的既不可预测而又是决定的行为作明确的描述。</span><br><span class="line">离散数学是指对理论电脑科学最有用处的数学领域之总称，这包含有可计算理论、计算复杂性理论及资讯理论。可计算理论检验电脑的不同理论模型之极限，这包含现知最有力的模型－图灵机。复杂性理论研究可以由电脑做为较易处理的程度；有些问题即使理论是可以以电脑解出来，但却因为会花费太多的时间或空间而使得其解答仍然不为实际上可行的，尽管电脑硬体的快速进步。最后，资讯理论专注在可以储存在特定媒介内的资料总量，且因此有压缩及熵等概念。</span><br><span class="line"></span><br><span class="line">作为一相对较新的领域，离散数学有许多基本的未解问题。其中最有名的为P/NP问题－千禧年大奖难题之一。一般相信此问题的解答是否定的。</span><br><span class="line"></span><br><span class="line">应用数学思考将抽象的数学工具运用在解答科学、工商业及其他领域上之现实问题。应用数学中的一重要领域为统计学，它利用机率论为其工具并允许对含有机会成分的现象进行描述、分析与预测。大部份的实验、调查及观察研究需要统计对其资料的分析。（许多的统计学家并不认为他们是数学家，而比较觉得是合作团体的一份子。）数值分析研究有什么计算方法，可以有效地解决那些人力所限而算不出的数学问题；它亦包含了对计算中舍入误差或其他来源的误差之研究。</span><br><span class="line"></span><br><span class="line">数学奖通常和其他科学的奖项分开。数学上最有名的奖为菲尔兹奖，创立于1936年，每四年颁奖一次。它通常被认为是数学的诺贝尔奖。另一个国际上主要的奖项为阿贝尔奖，创立于2003年。两者都颁奖于特定的工作主题，包括数学新领域的创新或已成熟领域中未解决问题的解答。著名的23个问题，称为希尔伯特的23个问题，于1900年由德国数学家大卫·希尔伯特所提出。这一连串的问题在数学家之间有著极高的名望，且至少有九个问题已经被解答了出来。另一新的七个重要问题，称为千禧年大奖难题，发表于2000年。对其每一个问题的解答都有著一百万美元的奖金，而当中只有一个问题（黎曼猜想）和希尔伯特的问题重复。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>定义<code>TextDataset</code>类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment"># 初始化函数，filepath为输入文件路径</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):</span><br><span class="line">        words = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filepath, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">                <span class="comment"># 使用jieba库进行分词，并去除每行的首尾空白字符</span></span><br><span class="line">                words.extend(<span class="built_in">list</span>(jieba.cut(line.strip())))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将所有单词转换为一个集合来去除重复，然后再转回列表形式，形成词汇表</span></span><br><span class="line">        <span class="variable language_">self</span>.vocab = <span class="built_in">list</span>(<span class="built_in">set</span>(words))</span><br><span class="line">        <span class="variable language_">self</span>.vocab_size = <span class="built_in">len</span>(<span class="variable language_">self</span>.vocab)  <span class="comment"># 计算词汇表的大小</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建从单词到整数的映射和从整数到单词的映射</span></span><br><span class="line">        <span class="variable language_">self</span>.word_to_int = &#123;word: i <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.vocab)&#125;</span><br><span class="line">        <span class="variable language_">self</span>.int_to_word = &#123;i: word <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.vocab)&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将映射关系保存为JSON文件</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;word_to_int.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(<span class="variable language_">self</span>.word_to_int, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;int_to_word.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(<span class="variable language_">self</span>.int_to_word, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将所有单词转换为对应的整数索引，形成数据列表</span></span><br><span class="line">        <span class="variable language_">self</span>.data = [<span class="variable language_">self</span>.word_to_int[word] <span class="keyword">for</span> word <span class="keyword">in</span> words]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回数据集的长度减1，这通常是因为在机器学习中可能需要使用当前数据点预测下一个数据点</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据索引idx返回数据，这里用于返回模型训练时的输入序列和目标输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># 固定序列长度为50</span></span><br><span class="line">        sequence_length = <span class="number">50</span></span><br><span class="line">        <span class="comment"># 获取输入序列</span></span><br><span class="line">        <span class="keyword">if</span> idx &lt; sequence_length:</span><br><span class="line">            <span class="comment"># 如果idx小于序列长度，用0填充前面的部分</span></span><br><span class="line">            input_data = <span class="variable language_">self</span>.data[<span class="number">0</span>:idx]</span><br><span class="line">            padding_length = sequence_length - <span class="built_in">len</span>(input_data)</span><br><span class="line">            input_seq = torch.tensor([<span class="number">0</span>] * padding_length + input_data, dtype=torch.long)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果idx大于等于序列长度，直接取前50个元素</span></span><br><span class="line">            input_seq = torch.tensor(<span class="variable language_">self</span>.data[idx - sequence_length:idx], dtype=torch.long)</span><br><span class="line">        <span class="comment"># 确保输入序列长度为50</span></span><br><span class="line">        <span class="keyword">assert</span> input_seq.size(<span class="number">0</span>) == sequence_length</span><br><span class="line">        <span class="comment"># 获取目标输出</span></span><br><span class="line">        target = torch.tensor(<span class="variable language_">self</span>.data[idx], dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> input_seq, target</span><br></pre></td></tr></table></figure>
<p>通过以下方式<code>加载数据集</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = TextDataset(<span class="string">&#x27;sentence.txt&#x27;</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="训练模型"><a class="markdownIt-Anchor" href="#训练模型"></a> 训练模型</h2>
<p>创建模型并发送：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = TransformerDecoderModel(vocab_size=dataset.vocab_size, embed_size=<span class="number">512</span>, num_heads=<span class="number">8</span>, hidden_dim=<span class="number">2048</span>, num_layers=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型传送到定义的设备上（例如GPU或CPU），以便进行训练</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>
<p>模型<code>优化器</code>和<code>损失函数</code>设置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化优化器，这里使用Adam优化器，设置学习率，从模型中获取参数</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"><span class="comment"># 添加学习率调度器</span></span><br><span class="line">scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, patience=<span class="number">3</span>, factor=<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 初始化损失函数，这里使用交叉熵损失</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>优化器和损失函数可参考这篇文章：<div class="post-link-card-wrap">
    <div class="post-link-card">
      <a href="/2024/09/01/nyeno8kr/" title="优化器和损失函数"></a>
      <div class="post-link-card-cover-wrap"><img src="/images/banner.webp" class="no-lightbox" title="优化器和损失函数" alt="优化器和损失函数"/></div>
      <div class="post-link-card-item-wrap">
        <div class="post-link-card-title">优化器和损失函数</div>
        <div class="post-link-card-excerpt">
在深度学习和机器学习中，`优化器`和`损失函数`是模型训练的核心要素。

- 优化器决定了模型的参数如何更新，以最小化损失函数
- 损失函数度量了模型预测值和真实值之间的差异

下面将详细介绍常用的优化器和损失函数。

---

# 优化器（Optimizers）

## 梯度下降（Gradient Descent，GD）

**原理：**

梯度下降是最基本的优化算法。其核心思想是在参数空间中</div>
      </div>
    </div>
  </div></p>
</blockquote>
<p>开始训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模式</span></span><br><span class="line">model.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环遍历所有的训练周期</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="comment"># 循环遍历数据加载器中的每个批次</span></span><br><span class="line">    <span class="keyword">for</span> i, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># 将输入数据转置，以符合模型的期望输入维度</span></span><br><span class="line">        inputs = inputs.t()</span><br><span class="line">        <span class="comment"># 在每次迭代前清空梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 前向传播：计算模型对当前批次的输出</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        <span class="comment"># 选择输出的最后一个元素进行损失计算</span></span><br><span class="line">        outputs = outputs[-<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 计算损失值</span></span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        <span class="comment"># 反向传播：计算损失的梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 更新模型的参数</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 每隔50步打印一次当前的训练状态</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;<span class="number">3</span>&#125;</span>], Step [<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(dataloader)&#125;</span>], Loss: <span class="subst">&#123;loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型到指定路径</span></span><br><span class="line">torch.save(model, <span class="string">&quot;transformer_model.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;模型已保存到&#x27;</span>, <span class="string">&quot;transformer_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>仅用于演示，这里只训练了<code>3轮</code>，训练大致耗时几分钟，过程截图：</p>
<p><img src="/images/assets//image-20241215144352531.png" alt="image-20241215144352531" /></p>
<h2 id="测试模型"><a class="markdownIt-Anchor" href="#测试模型"></a> 测试模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">model_path</span>):</span><br><span class="line">    <span class="comment"># 加载模型到CPU</span></span><br><span class="line">    model = torch.load(model_path, map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">    <span class="comment"># 设置为评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vocab</span>(<span class="params">json_file</span>):</span><br><span class="line">    <span class="comment"># 读取词汇表文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        vocab = json.load(f)</span><br><span class="line">    <span class="keyword">return</span> vocab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">model, initial_seq, max_len=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># 加载数字到单词的映射</span></span><br><span class="line">    int_to_word = load_vocab(<span class="string">&#x27;int_to_word.json&#x27;</span>)</span><br><span class="line">    <span class="comment"># 确保模型处于评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment"># 关闭梯度计算</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        generated = initial_seq</span><br><span class="line">        <span class="comment"># 生成最多max_len个词</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_len):</span><br><span class="line">            input_tensor = torch.tensor([generated], dtype=torch.long)</span><br><span class="line">            output = model(input_tensor)</span><br><span class="line">            predicted_idx = torch.argmax(output[:, -<span class="number">1</span>], dim=-<span class="number">1</span>).item()</span><br><span class="line">            generated.append(predicted_idx)</span><br><span class="line">            <span class="comment"># 如果生成结束标记，则停止生成</span></span><br><span class="line">            <span class="keyword">if</span> predicted_idx == <span class="built_in">len</span>(int_to_word) - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 将生成的索引转换为单词</span></span><br><span class="line">        <span class="keyword">return</span> [int_to_word[<span class="built_in">str</span>(idx)] <span class="keyword">for</span> idx <span class="keyword">in</span> generated]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">model, input_sentence, max_len=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># 使用结巴分词对输入句子进行分词</span></span><br><span class="line">    input_words = <span class="built_in">list</span>(jieba.cut(input_sentence.strip()))</span><br><span class="line">    <span class="comment"># 加载单词到数字的映射</span></span><br><span class="line">    word_to_int = load_vocab(<span class="string">&#x27;word_to_int.json&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将单词转换为索引</span></span><br><span class="line">    input_seq = [word_to_int.get(word, <span class="built_in">len</span>(word_to_int) - <span class="number">1</span>) <span class="keyword">for</span> word <span class="keyword">in</span> input_words]</span><br><span class="line">    <span class="comment"># 生成文本</span></span><br><span class="line">    generated_text = predict(model, input_seq, max_len)</span><br><span class="line">    <span class="comment"># 将生成的单词列表合并为字符串</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(generated_text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 定义输入提示</span></span><br><span class="line">    prompt = <span class="string">&quot;介绍一下数学历史。&quot;</span></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    model = load_model(<span class="string">&#x27;transformer_model.pth&#x27;</span>)</span><br><span class="line">    <span class="comment"># 生成文本</span></span><br><span class="line">    completion = generate(model, prompt)</span><br><span class="line">    <span class="comment"># 打印生成的文本</span></span><br><span class="line">    <span class="built_in">print</span>(prompt, completion)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p><img src="/images/assets//image-20241215143828976.png" alt="image-20241215143828976" /></p>
<p>不出意外的烂哈哈哈，如果要<code>提升质量</code>，就需要在增加<code>训练集量级</code>和<code>训练周期</code>的基础之上，<code>优化模型参数</code>了。</p>

      
    </div>
    <footer class="article-footer">
      
        <blockquote class="article-copyright">
    <p><strong>本文作者：</strong>LuoYing @ 小小白的笔记屋</p>
    <p><strong>本文链接：</strong><a href="https://luoying.netlify.app/2024/11/04/skrzswes/">https://luoying.netlify.app/2024/11/04/skrzswes/</a></p>
    <p><strong>本文标题：</strong>Transformer：Attention Is All You Need</p>
    
    
    <p><strong>本文版权：</strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><span class="icon-creative-commons"></span>BY-NC-SA</a> 许可协议。转载请注明出处！</p>
    <span class="icon-creative-commons article-copyright-bg"></span>
  </blockquote>
      
      
      
      
      
      
      
      

    </footer>
  </div>
  
  <nav id="article-nav" data-aos="fade-up">
    
      <div class="article-nav-link-wrap article-nav-link-left">
        
          
          
            <img data-src="/covers/文件13.jpg" data-sizes="auto" alt="DNABERT：针对基因组DNA语言的预训练双向编码器Transformers模型" class="lazyload">
          
        
        <a href="/2024/11/15/yete4apn/"></a>
        <div class="article-nav-caption">前一篇</div>
        <h3 class="article-nav-title">
          
            DNABERT：针对基因组DNA语言的预训练双向编码器Transformers模型
          
        </h3>
      </div>
    
    
    <div class="article-nav-link-wrap article-nav-link-right">
      
        
        
          <img data-src="/covers/文件46.jpg" data-sizes="auto" alt="Latex数学公式符号汇总" class="lazyload">
        
      
      <a href="/2024/10/20/xf4572aq/"></a>
      <div class="article-nav-caption">后一篇</div>
      <h3 class="article-nav-title">
        
          Latex数学公式符号汇总
        
      </h3>
    </div>
    
  </nav>


</article>






</section>
          
        </div>
        <footer id="footer">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div id="footer-info">
    
    <div>
      <span class="icon-copyright"></span>
      2020-2025
      <span class="footer-info-sep rotate"></span>
      LuoYing
    </div>
    
      <div>
        基于&nbsp;<a href="https://hexo.io/" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a>&nbsp;
        Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" rel="noopener external nofollow noreferrer" target="_blank">Reimu</a>
      </div>
    
    
      <div>
        <span class="icon-brush"></span>
        285.3k
        &nbsp;|&nbsp;
        <span class="icon-coffee"></span>
        18:26
      </div>
    
    
    
    
      <div>
        <span class="icon-eye"></span>
        <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
        &nbsp;|&nbsp;
        <span class="icon-user"></span>
        <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
      </div>
    
  </div>
</footer>

        
          <div class="sidebar-top">
            <div class="sidebar-top-taichi rotate"></div>
            <div class="arrow-up"></div>
          </div>
        
        <div id="mask" class="hide"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">文章目录</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E9%93%BE%E6%8E%A5"><span class="toc-number">1.</span> <span class="toc-text"> 文章链接</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text"> 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">3.</span> <span class="toc-text"> 摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">4.</span> <span class="toc-text"> 创新点</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text"> 主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%89%8D%E9%A1%BB%E7%9F%A5"><span class="toc-number">5.1.</span> <span class="toc-text"> 读前须知</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.2.</span> <span class="toc-text"> 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">5.3.</span> <span class="toc-text"> 背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">5.4.</span> <span class="toc-text"> 模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8%E4%B8%8E%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-number">5.4.1.</span> <span class="toc-text"> 编码器与解码器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.</span> <span class="toc-text"> 注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.1.</span> <span class="toc-text"> 缩放点积注意力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">5.4.2.2.</span> <span class="toc-text"> 多头注意力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"><span class="toc-number">5.4.2.3.</span> <span class="toc-text"> 基于位置的前馈网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%92%8Csoftmax"><span class="toc-number">5.4.2.4.</span> <span class="toc-text"> 嵌入和Softmax</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">5.4.2.5.</span> <span class="toc-text"> 位置编码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">5.5.</span> <span class="toc-text"> 为什么选择自注意力机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.6.</span> <span class="toc-text"> 训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%89%B9%E5%A4%84%E7%90%86"><span class="toc-number">5.6.1.</span> <span class="toc-text"> 训练数据与批处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E4%B8%8E%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92"><span class="toc-number">5.6.2.</span> <span class="toc-text"> 硬件与时间安排</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">5.6.3.</span> <span class="toc-text"> 优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">5.6.4.</span> <span class="toc-text"> 正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">5.7.</span> <span class="toc-text"> 结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="toc-number">5.7.1.</span> <span class="toc-text"> 机器翻译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%98%E4%BD%93"><span class="toc-number">5.7.2.</span> <span class="toc-text"> 模型变体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8B%B1%E8%AF%AD%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">5.7.3.</span> <span class="toc-text"> 英语成分句法分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text"> 结论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">7.</span> <span class="toc-text"> 注意力可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE3"><span class="toc-number">7.1.</span> <span class="toc-text"> 图3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE4"><span class="toc-number">7.2.</span> <span class="toc-text"> 图4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE5"><span class="toc-number">7.3.</span> <span class="toc-text"> 图5</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">8.</span> <span class="toc-text"> 参考文献</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer%E5%8F%91%E5%B1%95"><span class="toc-number">9.</span> <span class="toc-text"> transformer发展</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#transformer%E6%A8%A1%E5%9E%8B%E5%8F%98%E4%BD%93"><span class="toc-number">9.1.</span> <span class="toc-text"> transformer模型变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E4%B8%8E%E5%88%9B%E6%96%B0%E6%96%B9%E5%90%91"><span class="toc-number">9.2.</span> <span class="toc-text"> 优化与创新方向</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%9C%A8%E6%96%B0%E4%BB%BB%E5%8A%A1%E4%B8%8A%E4%BC%98%E5%8C%96-transformer-%E6%9E%B6%E6%9E%84"><span class="toc-number">9.3.</span> <span class="toc-text"> 如何在新任务上优化 transformer 架构？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%BE%E4%BE%8B"><span class="toc-number">10.</span> <span class="toc-text"> transformer代码实现举例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA-transformer-%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.1.</span> <span class="toc-text"> 构建 transformer 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">10.2.</span> <span class="toc-text"> 训练数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.3.</span> <span class="toc-text"> 训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.4.</span> <span class="toc-text"> 测试模型</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/avatar.webp" data-sizes="auto" alt="LuoYing" class="lazyload">
  <div class="sidebar-author-name">LuoYing</div>
  <div class="sidebar-description">一方小筑，与君共勉</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div>
    <div class="sidebar-state-number">119</div>
  </div>
  <div class="sidebar-state-category">
    <div>分类</div>
    <div class="sidebar-state-number">15</div>
  </div>
  <div class="sidebar-state-tag">
    <div>标签</div>
    <div class="sidebar-state-number">2</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/" aria-label="首页"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">首页</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/archives" aria-label="归档"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">归档</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/about" aria-label="关于"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">关于</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/friend" aria-label="友链"></a>
        <div class="sidebar-menu-icon icon rotate">
          &#xe62b;
        </div>
        <div class="sidebar-menu-link">友链</div>
      </div>
    
  
</div>
</div>
    
  </div>
  
    <div class="sidebar-btn-wrapper">
      <div class="sidebar-toc-btn current"></div>
      <div class="sidebar-common-btn"></div>
    </div>
  
</nav>

    </div>
    
      <div class="site-search">
        <div class="reimu-popup popup">
          <div class="reimu-search">
            <div class="reimu-search-input-icon"></div>
            <div class="reimu-search-input" id="reimu-search-input"></div>
            <div class="popup-btn-close"></div>
          </div>
          <div class="reimu-results">
            <div id="reimu-stats"></div>
            <div id="reimu-hits"></div>
            <div id="reimu-pagination" class="reimu-pagination"></div>
          </div>
          <img class="reimu-bg" src="/images/reimu.png"/>
        </div>
      </div>
    
    
<script src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js" integrity="sha384-3gT&#x2F;vsepWkfz&#x2F;ff7PpWNUeMzeWoH3cDhm&#x2F;A8jM7ouoAK0&#x2F;fP&#x2F;9bcHHR5kHq2nf+e" crossorigin="anonymous"></script>


<script src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js" integrity="sha384-J08i8An&#x2F;QeARD9ExYpvphB8BsyOj3Gh2TSh1aLINKO3L0cMSH2dN3E22zFoXEi0Q" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>



  
<script src="/js/aos.js"></script>

  <script>
    var aosInit = () => {
      AOS.init({
        duration: 1000,
        easing: "ease",
        once: true,
        offset: 50,
      });
    };
    if (document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', aosInit);
    } else {
      aosInit();
    }
  </script>



<script src="/js/pjax_script.js" data-pjax></script>



  
<script src="/js/generator_search.js" defer></script>






  
<script src="https://npm.webcache.cn/mouse-firework@0.0.6/dist/index.umd.js" integrity="sha384-vkGvf25gm1C1PbcoD5dNfc137HzNL&#x2F;hr1RKA5HniJOaawtvUmH5lTVFgFAruE9Ge" crossorigin="anonymous"></script>

  <script>
    window.firework && window.firework(JSON.parse('{"excludeElements":["a","button"],"particles":[{"shape":"circle","move":["emit"],"easing":"easeOutExpo","colors":["#ff5252","#ff7c7c","#ffafaf","#ffd0d0"],"number":20,"duration":[1200,1800],"shapeOptions":{"radius":[16,32],"alpha":[0.3,0.5]}},{"shape":"circle","move":["diffuse"],"easing":"easeOutExpo","colors":["#ff0000"],"number":1,"duration":[1200,1800],"shapeOptions":{"radius":20,"alpha":[0.2,0.5],"lineWidth":6}}]}'))
  </script>








<div id="lazy-script">
  <div>
    
    
      
        
<script src="/js/insert_highlight.js" data-pjax></script>

      
    
    
      <script type="module" data-pjax>
        const PhotoSwipeLightbox = (await safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe-lightbox.esm.min.js", "sha384-DiL6M/gG+wmTxmCRZyD1zee6lIhawn5TGvED0FOh7fXcN9B0aZ9dexSF/N6lrZi/")).default;
        
        const pswp = () => {
          if (_$$('.article-entry a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-entry',
              children: 'a.article-gallery-item',
              pswpModule: () => safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8+oTJ7m3DfYEWX1fu1scuS4+s")
            }).init();
          }
          if(_$$('.article-gallery a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-gallery',
              children: 'a.article-gallery-item',
              pswpModule: () => safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8+oTJ7m3DfYEWX1fu1scuS4+s")
            }).init();
          }
          window.lightboxStatus = 'done';
          window.removeEventListener('lightbox:ready', pswp);
        }
        if(window.lightboxStatus === 'ready') {
          pswp()
        } else {
          window.addEventListener('lightbox:ready', pswp);
        }
      </script>
      








    
  </div>
</div>


  <script>
    console.log(String.raw`%c 
 ______     ______     __     __    __     __  __    
/\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
\ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
 \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
  \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                  
`,'color: #ff5252;')
    console.log('%c Theme.Reimu v' + '1.1.0' + ' %c https://github.com/D-Sketon/hexo-theme-reimu ', 'color: white; background: #ff5252; padding:5px 0;', 'padding:4px;border:1px solid #ff5252;')
  </script>
  

<script data-pjax>
  var updateTime = _$('#post-update-time')?.innerHTML;

  if (updateTime) {
    const update = new Date(updateTime);
    const now = new Date();
    const diff = now - update;
    const days = diff / 86400000;
    const { daysAgo, message: template } = window.REIMU_CONFIG.outdate;
    if (days >= daysAgo) {
      const message = template.replace(/{time}/, updateTime);
      const blockquote = _$('#outdate-blockquote');
      if (blockquote) {
        blockquote.querySelector('p').innerText = message;
        blockquote.style.display = 'block';
      }
    }
  }
</script>


  
<script src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js" integrity="sha384-0M75wtSkhjIInv4coYlaJU83+OypaRCIq2SukQVQX04eGTCBXJDuWAbJet56id+S" crossorigin="anonymous" async></script>




<script>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.getRegistrations().then((registrations) => {
      for (let registration of registrations) {
        registration.unregister();
      }
    });
  }
</script>



  


  </body>
  </html>

