[{"title":"Biomni：通用生物医学人工智能代理","url":"/2025/06/16/s02ypw9c/","content":"\n### Biomni：通用生物医学人工智能代理\n\n#### 链接\n\n[https://www.biorxiv.org/content/10.1101/2025.05.30.656746v1.full](https://www.biorxiv.org/content/10.1101/2025.05.30.656746v1.full)\n\npdf：\n\n[https://biomni.stanford.edu/paper.pdf](https://biomni.stanford.edu/paper.pdf)\n\n#### 背景\n\n以前的方法很大程度上依赖于为缩小生物医学任务范围而定制的专业代理工作流程，这限制了它们在回答关键研究问题所需的整个生物医学领域的流畅移动和概括的能力。给人工智能代理能够处理广泛的生物医学任务带来了巨大的技术挑战。\n\n最明显的是，需要将高级推理与执行高度专业化的生物医学动作的能力紧密结合起来。虽然基于 LLM 的推理已经取得了重大进展，但这样的 LLM 需要访问明确定义`生物医学动作空间`的环境，而`生物医学动作空间`本质上是多样化、领域特定和复杂的。此外，一个真正有能力的系统需要一个能够与这种`生物医学环境`进行本地交互的代理架构——自主选择和组合动作，使用其推理能力来计划和执行各种任务，而不依赖于僵化的、预定义的工作流程。\n\n#### 概括\n\nBiomni，一款通用型生物医学 AI 代理，旨在自动化和推进广泛子领域的生物医学研究。Biomni 扮演着虚拟 AI 生物学家的角色，能够`自主提出新颖且可验证的假设`，`执行复杂的生物信息学分析`，并`设计严谨的实验方案`。\n\n为了实现这一能力，我们首先通过系统分析从主要生物文献库中精选的涵盖 25 个不同子领域的数万篇生物医学研究论文，构建了一个统一且全面的`生物医学行动空间`。在此基础上，我们开发了一个由 LLM 驱动的`行动发现代理`，该代理能够`阅读论文并提取推动生物医学发现的关键任务、工具和数据库`。然后，我们筛选这些元素并将其部署到 Biomni-E1 中，Biomni-E1 是定义代理交互的`生物医学行动空间`的基础环境。Biomni-E1 包含 150 个专用生物医学工具、105 个软件包和 59 个数据库。\n\n我们随后设计了`Biomni-A1`，这是一种通用的代理架构，能够`利用Biomni E1`提供的工具和数据集灵活地执行各种生物医学任务。对于用户提出的查询，该代理首先使用检索系统来识别所需的最相关工具、数据库和软件。然后，它运用基于LLM的推理和领域专业知识，生成详细的分步计划。每个步骤都通过可执行代码表达，从而实现精确灵活的生物医学操作组合——鉴于该领域对高度专业化的工具和数据资源的依赖，这一点至关重要。\n\n与传统的函数调用方法不同，这种方法支持生物医学工作流程的动态性和复杂性。这个集成系统使Biomni不仅能够高效地解决具有挑战性的大规模生物医学问题，还能将其推广到前所未有的生物医学研究领域的新任务。\n\n#### 测试结果\n\n严格的基准测试表明，Biomni 在现有的`生物医学问答基准测试`中表现出色，并在八个开发过程中从未遇到的具有挑战性的实际场景中表现出强大的泛化能力。此外，我们通过三个具有影响力的案例研究强调了 Biomni 的实践能力：\n\n(1) 分析 458 个可穿戴传感器数据文件以产生新的见解；\n\n(2) 快速对海量原始数据集（例如单细胞 RNA 测序和 ATAC 测序数据）进行全面的生物信息学分析，以产生新的见解和假设；\n\n(3) 自主设计实验室方案以协助湿实验室研究人员。\n\nBiomni 是我们推出的第一代可扩展通用生物医学 AI 代理，为虚拟 AI 生物学家与人类研究人员协同工作的时代奠定了基础，从而显著加速了从基础研究到转化的生物医学发现。\n\n#### 代理结构\n\nBiomni 是一种通用的生物医学 AI 代理，由两个主要组件组成：\n\n1. Biomni-E1（具有统一动作空间的`基础生物医学环境`）；\n\n2. Biomni-A1（旨在有效利用该环境的智能代理）。\n\n#### 如何整理一个统一的生物医学行动空间？\n\n![](/images/assets/F1.large.jpg)\n\nBiomni 中统一生物医学行动空间和代理环境的概览。\n\n(a) 系统化整理统一生物医学行动空间的工作流程。使用 AI 驱动的发现代理，从 25 个生物医学子领域的 2,500 篇近期 bioRxiv 出版物中提取了开展生物医学研究所需的行动。提取的行动经过人类专家的严格验证和整理，最终整合了 105 种生物医学软件工具、150 种专用生物学工具（包括湿实验室方案、AI 驱动的预测模型和特定领域的专业知识）以及 59 个综合生物医学数据库。\n\n(b) 涵盖遗传学、基因组学、合成生物学、细胞生物学、生理学、微生物学、药理学、生物工程、生物物理学、分子生物学和病理学等不同生物医学子领域的`统一生物医学行动空间`的图示。图中展示了集成到 Biomni 环境中的代表性工具和数据库，突出了其通用功能。 \n\n(c) 示例工作流程展示了 Biomni 的推理和动作组合过程，该过程能够自主回答一个复杂的生物学问题。Biomni 根据用户的查询检索相关工具，制定结构化的推理计划，并编写可执行代码以执行全面的生物信息学分析，并根据观察结果不断改进其推理，直至最终得到精确的答案。\n\n#### 如何构建一个能够处理各种生物医学任务的通用代理？\n\n一个专门的代理架构——一种避免为每个单独任务硬编码工作流的架构。这促成了 Biomni-A1 的开发，它融合了多项对整个生物医学研究领域至关重要的核心创新。\n\n首先，我们引入了一种基于 `LLM 的工具选择机制`，旨在应对生物医学工具的复杂性和专业化，并根据用户目标动态检索定制的`资源子集`。\n\n其次，考虑到生物医学任务通常需要丰富的程序逻辑，Biomni-A1 使用代码作为`通用操作接口`——使其能够编写和执行涉及循环、并行化和条件逻辑的复杂工作流。至关重要的是，这种方法还使代理能够交错调用不符合预定义函数签名的软件、工具、数据库和原始数据操作——从而支持灵活、动态地集成异构资源。\n\n第三，该智能体采用`自适应规划策略`：它基于生物医学知识制定初始计划，并在执行过程中不断迭代完善，从而实现响应迅速、情境感知的行为。\n\n这些创新共同使 Biomni-A1 能够泛化到前所未有的任务和领域，动态地组合智能动作，并与软件、数据和工具进行交互，从而体现出通用生物医学智能（图 1c）。\n\n#### 效果\n\n![](/images/assets/F2.large.jpg)\n\nBiomni 在各种现实生物医学任务中的零样本泛化。\n\n(a) 在问答类多项选择基准测试中，Biomni 的表现优于 6 个基准模型，这些基准测试广泛评估了该模型在生物医学领域的能力；\n\n(b) Biomni 在八个前所未有的真实生物医学场景中展现出强大的零样本性能，这些场景涵盖多个生物医学子领域，且无需任何特定任务的微调或快速工程。评估的任务包括：\n\n- `变异优先级排序`（基因组学）：从某个性状的潜在变异列表中找出最可能的致病变异，这需要推理非编码区域的调控功能；\n- `GWAS 致病基因检测`（遗传学和基因组学）：选择某个基因座内最可能的致病基因，这需要细粒度的基因座级推断；\n- `扰动筛选设计`（功能基因组学和免疫学）：构建基因面板，以在大型（>20,000 个基因）搜索空间中最大化扰动后效应；\n- `患者基因优先级排序`：给定个体患者的基因图谱和表型描述，确定最合理的致病基因；\n- `罕见疾病诊断`（临床基因组学）：将患者表型和基因发现与罕见病诊断联系起来；\n- `药物再利用`（药理学）：给定一种罕见疾病和一系列候选药物，选择最佳治疗方案；\n- `微生物组疾病分类单元生物信息学分析`（微生物学）：对微生物组数据集进行统计关联检验，以发现与疾病相关的分类单元；\n- `单细胞 RNA 测序细胞注释`（单细胞生物学）：为跨组织、跨物种和跨平台的单个细胞谱分配准确的细胞类型标签；\n\n在这些不同的场景中，Biomni 的表现始终优于基线模型（Base LLM、ReAct+Code）和专门环境（Biomni ReAct），突显了其通用生物医学能力以及自主适应新的复杂生物医学任务的能力。\n\n#### Biomni 联合分析 458 个可穿戴传感器文件以生成生理假设\n\n略。\n\n#### Biomni 自动化复杂的多组学分析，以揭示骨骼谱系的转录调控\n\n略。\n\n#### 讨论\n\nBiomni 通过将复杂且劳动密集型的工作流程（通常需要专业知识和编程技能）自动化，`使研究人员能够将精力转向创造性假设生成、实验创新和跨学科合作`。这一转变意义深远。\n\n- 在生物制药的靶点和药物发现领域，Biomni 可以自主确定靶点的优先级、设计扰动筛选或重新利用药物，从而为更快、更具成本效益的研究提供途径。\n- 在临床应用领域，其在基因优先级排序和罕见病诊断方面的能力有助于提供更精准、个性化的洞察和更高效的诊断流程。\n- 在消费者健康领域，Biomni 将可穿戴数据与多组学分析相结合，旨在实现实时、个性化的健康监测和干预。\n\n#### 局限性\n\n- 虽然 Biomni 的统一环境涵盖了广泛的生物医学工具和数据库，但评估的任务仅代表了该领域的一个子集，关键领域仍未得到探索。\n- 在行动发现代理中，我们优先考虑最新文献的决定使代理显得与时俱进，但这也存在着忽略一些基础概念和技术的风险，这些概念和技术尽管具有持久的相关性，但已经从当前的讨论中淡出。\n- 尽管 Biomni 在数据库查询、序列分析和分子克隆等任务上的表现接近人类水平，但在需要细致入微的临床判断、新颖的实验推理、分析性发明或深度生物学思考与综合的领域，它仍然举步维艰。目前还没有系统能够完全涵盖人类生物医学专业知识。\n\n#### 方法\n\n##### 从文献中发现行动\n\n收集并分析了 biorxiv 上 2024 年的 100 篇近期出版物，提取并解析其 PDF 内容。每篇论文均按块处理，并由专门的提示引导法 (LLM) 逐一识别并提取三类可操作的见解：任务、软件和数据库。\n\n具体到任务方面，LLM 被要求重点突出那些在生物医学研究工作流程中需要专门实现的重复性任务。\n\n##### 实施 Biomni 环境\n\n在环境构建的初始迭代中，我们采用了一种保守且有针对性的工具管理方法。\n\n最初，我们根据与主要研究兴趣（药物研发和临床生物医学）的相关性筛选任务，这些研究领域涵盖生物化学、生物工程、生物物理学、癌症生物学、细胞生物学、发育生物学、遗传学、基因组学、免疫学、微生物学、分子生物学、病理学、药理学、生理学、合成生物学和系统生物学。\n\n随后，我们将这些任务的范围缩小到大约 1,900 个常见的重复任务。我们进一步手动审查这些任务，以消除冗余，并排除那些琐碎或易于通过简单代码实现的任务。我们强调选择需要大量领域专业知识的高度专业化任务，例如湿实验室方案和高级 AI 模型。\n\n随后，人类科学家与配备网络搜索功能的软件工程代理合作，实现了每个专用工具。每个工具都经过了严格的验证，需要一个明确定义的测试用例来确保其成功通过。这一严格的流程最终催生了150个专用工具的精选集。此外，还包含了PubMed和Google Scholar等重要的文献检索工具，并为未来的迭代扩展做好了准备。\n\n每个工具都使用一份全面的清单进行严格定义，该清单要求：\n\n（1）清晰且具有描述性的名称，\n\n（2）详细的文档，\n\n（3）格式化为针对 LLM 解释优化的详细研究日志的输出，\n\n（4）包含并成功通过特定的测试用例，\n\n（5）专业化标准 - 如果可以通过简短的 LLM 生成的代码（例如，简单的数据库查询）轻松实现任务，则无需创建专门的工具。\n\n对数据库进行了分类，并使用统一的查询函数集成了可通过 Web API 访问的大量关系数据库（例如 PDB、OpenTargets、ClinVar）。该函数接受自然语言输入，并利用 LLM 动态解析数据库模式并执行相应的查询。缺少 Web API 的数据库会被下载并在本地预处理成结构化的 Pandas DataFrame，以便代理无缝访问。\n\n在软件集成方面，考虑到经常需要同时使用多个软件工具，我们构建了一个统一的容器化环境，并预装了一套完整的相关软件。此外，该环境还支持执行 R 包和命令行界面 (CLI) 工具。\n\n##### Biomni-A1\n\nBiomni 智能体是一个基于 CodeAct 31框架构建的通用生物医学 AI 智能体，旨在通过将 LLM 与交互式编码环境相结合，系统地解决生物医学任务。\n\n当用户提出查询时，Biomni 首先会提示 LLM 生成一个清晰的、带编号的项目符号列表计划，详细说明解决给定问题所需的步骤，并持续跟踪进度和调整。由于工具、软件和数据库空间巨大，查询任务可能仅使用其中一小部分资源。为了避免冗长的上下文，我们使用了一个基于提示的检索器，该检索器由一个独立的 LLM 驱动，智能体会从可用资源中动态选择最相关的函数、数据集和软件库。在执行过程中，LLM 会生成代码，在编码环境（Python、R 或 Bash）中执行，并返回结果观察结果以指导后续推理。这种迭代方法持续进行，直到智能体收敛到一个准确且经过验证的解决方案。\n\n#### 代码地址\n\n[https://github.com/snap-stanford/biomni](https://github.com/snap-stanford/biomni)\n\n","categories":["论文解读"]},{"title":"CodeAct：代码即行动","url":"/2025/06/15/cvalxpiq/","content":"\n#### 链接\n\n[https://arxiv.org/html/2402.01030v4](https://arxiv.org/html/2402.01030v4)\n\npdf:\n\n[https://arxiv.org/pdf/2402.01030v4](https://arxiv.org/pdf/2402.01030v4)\n\n#### 通俗解释\n\n用大白话解释一下 **CodeAct** 的原理，就像聊天一样：\n\n**核心思想：让大语言模型（LLM）通过写和运行真实的 Python 代码来与外部世界（工具、数据、API）互动，而不是用死板的 JSON 或纯文本指令。**\n\n##### **为什么需要这个？**\n\n想象一下你让一个聪明的助手（LLM）帮你做事，比如查天气、分析数据、甚至训练一个小模型。传统方式有两种：\n\n1.  **JSON/结构化指令：** 你让助手说：`{\"action\": \"get_weather\", \"location\": \"北京\"}`。这就像填表格，选项是固定的（只能“get_weather”），很死板，没法组合复杂操作（比如先查天气，再根据天气推荐活动）。\n2.  **纯文本指令：** 你让助手说：“请帮我查一下北京的天气”。助手理解后，可能需要“告诉”另一个专门查天气的工具去执行。这步骤多，容易出错，灵活性也有限。\n\n##### **CodeAct 怎么解决？简单说：让助手直接写 Python 代码！**\n\n1.  **代码就是行动：** CodeAct 把助手（LLM）的“想法”直接变成可执行的 Python 代码。比如助手想查天气，它就直接生成一段代码：`weather = get_weather(\"北京\")`。\n2.  **万能“翻译官”（Python 解释器）：** 系统内置一个 Python 解释器。助手写的代码会被这个解释器**真正运行**。解释器负责：\n    *   调用真实的工具（`get_weather` 背后连接着真实的天气 API）。\n    *   处理数据（比如读取文件、做计算 `average_temp = (high + low) / 2`）。\n    *   执行逻辑（`if...else...`, `for` 循环）。\n3.  **边做边看，错了就改（多轮交互）：** 这是关键优势！助手不是一次性写完所有代码就完事。\n    *   它先写一段代码（比如 `data = load_csv(\"sales.csv\")`）。\n    *   解释器运行这段代码。\n    *   解释器把**运行结果**（比如 `data` 的前几行内容，或者一个报错信息 `FileNotFoundError`）反馈给助手。\n    *   助手**看到结果**后：\n        *   如果结果符合预期，就接着写下一段代码（比如 `total_sales = data['amount'].sum()`）。\n        *   如果出错了或者结果不对，它就能**立刻修改前面的代码**或写新代码来修正（比如改成 `data = load_csv(\"sales_data.csv\")`）。\n    *   如此反复，直到完成任务。这就像程序员在调试程序一样！\n\n##### **CodeAct 厉害在哪？**\n\n1.  **能力超强（强大的行动空间）：** Python 本身功能就极其强大，能调用无数现成的库（`pandas` 处理数据、`requests` 访问网络、`scikit-learn` 训练模型）。助手能做的事情范围一下子变得非常非常广，几乎不受限制。\n2.  **灵活组合（自由编排）：** 助手可以用代码轻松地把多个步骤、多个工具组合起来，完成复杂任务（比如：下载数据 -> 清洗数据 -> 训练模型 -> 评估模型 -> 生成报告），一气呵成写在几行代码里。JSON 很难做到这种自由组合。\n3.  **自我纠错（动态调试）：** 多轮交互让助手能根据运行结果即时调整策略，自己发现并修复代码里的错误，大大提高了任务成功率。死板的 JSON 或一次性文本指令很难做到这点。\n4.  **“说人话”协作（自然语言接口）：** 虽然底层用代码行动，但用户仍然可以用自然语言给助手下达指令（比如“帮我分析一下上个月的销售趋势”）。助手内部把用户的话“翻译”成代码去执行，执行完再用自然语言把结果“翻译”回给用户。用户体验还是自然的对话。\n\n##### **类比理解**\n\n*   **传统方式（JSON/Text）：** 你是一个指挥官，手下有几个特种兵（固定工具）。你每次只能给一个特种兵发一条非常具体的指令（“狙击手，瞄准A点目标”）。想完成复杂任务需要反复发令，配合困难。\n*   **CodeAct：** 你是一个指挥官，手下有一个万能机器人。你直接给机器人写一个程序脚本（Python 代码），告诉它整个任务流程（“先去A点侦察，如果发现敌人就呼叫炮火覆盖，然后去B点取情报...”）。机器人能自己按脚本执行，遇到问题还会实时报告请示。你只需要在关键节点做决策或修改脚本。\n\n##### **总结**\n\nCodeAct 的核心就是 **让 LLM 用写真实、可执行的 Python 代码作为它“行动”的语言**，并配合一个 Python 解释器来运行这些代码、获取结果。通过这种 **“写代码 -> 运行 -> 看结果 -> 修改代码/写新代码 -> 再运行”** 的多轮交互循环，LLM 就能以极其灵活和强大的方式，利用现有的软件工具和库，自主完成非常复杂的任务，并且能自己调试错误。它把 LLM 的规划推理能力和 Python 生态的强大功能完美结合在了一起。\n\n**论文里那个“自主训练模型”的例子，就是 CodeAct 威力的最好体现：** 助手能生成调用机器学习库（如 scikit-learn）的代码来加载数据、选择模型、设置参数、启动训练、评估结果，整个过程通过多轮交互和自调试完成，完全不需要人工一步步指导。\n\n#### 例子\n\n假设我们有一个支持 CodeAct 的 AI 助手，用户要求：「帮我分析销售数据，找出销售额最高的产品」。\n\n##### 传统 JSON 方式 (对比)\n\n```json\n{\n  \"action\": \"analyze_sales\",\n  \"parameters\": {\n    \"file\": \"sales.csv\",\n    \"metric\": \"max_sales\"\n  }\n}\n```\n*   只能使用预定义的 `analyze_sales` 功能\n*   灵活性差（无法组合多个操作）\n*   无法处理异常（如文件不存在）\n\n##### CodeAct 方式 (分步交互)\n\n**用户请求：** 「帮我分析 sales.csv，找出销售额最高的产品」\n\n##### 第一轮：AI 生成代码\n\n```python\n# 尝试读取数据文件\nimport pandas as pd\ntry:\n    data = pd.read_csv('sales.csv')\n    print(\"数据加载成功！前5行：\")\n    print(data.head())\nexcept FileNotFoundError:\n    print(\"错误：找不到文件 sales.csv\")\n```\n\n##### 执行结果：\n\n```\n错误：找不到文件 sales.csv\n```\n\n##### 第二轮：AI 调整代码\n\n```python\n# 尝试不同文件名\ntry:\n    data = pd.read_csv('sales_data.csv')  # 尝试另一个文件名\n    print(\"数据加载成功！前5行：\")\n    print(data.head())\nexcept FileNotFoundError:\n    print(\"错误：仍然找不到文件。请检查文件名\")\n```\n\n##### 执行结果：\n\n```\n数据加载成功！前5行：\n   Product  Sales\n0    Apple    150\n1   Banana    200\n2   Orange    180\n3    Grape    120\n4  Mango     250\n```\n\n##### 第三轮：AI 完成分析\n\n```python\n# 分析数据\nif 'data' in locals():\n    # 找出最高销售额\n    max_sale = data['Sales'].max()\n    \n    # 找出对应产品\n    best_product = data[data['Sales'] == max_sale]['Product'].values[0]\n    \n    # 格式化结果\n    print(f\"销售额最高的产品是: {best_product}\")\n    print(f\"销售额: ¥{max_sale}\")\nelse:\n    print(\"数据未加载，无法分析\")\n```\n\n##### 最终输出：\n\n```\n销售额最高的产品是: Mango\n销售额: ¥250\n```\n\n##### CodeAct 关键优势解析：\n\n1. **真实代码执行**：\n   ```python\n   pd.read_csv('sales_data.csv')  # 实际调用 pandas 库\n   data['Sales'].max()           # 真实的数据操作\n   ```\n\n2. **动态错误处理**：\n   - 第一轮尝试 `sales.csv` → 失败\n   - 第二轮自动调整尝试 `sales_data.csv` → 成功\n\n3. **多步组合操作**：\n   - 文件加载 → 数据处理 → 计算最大值 → 结果格式化\n   - 全部在一个代码空间中完成\n\n4. **利用现有库**：\n   ```python\n   import pandas as pd  # 使用成熟的 pandas 数据分析库\n   ```\n\n5. **自我调试**：\n   - 通过 `try-except` 捕获异常\n   - 根据错误信息调整策略\n\n6. **自然语言整合**：\n   ```python\n   print(f\"销售额最高的产品是: {best_product}\")  # 最终用自然语言输出\n   ```\n\n##### 完整交互流程：\n\n```\n用户：分析 sales.csv\nAI：生成代码1 → 执行 → 报错（文件不存在）\nAI：生成代码2 → 执行 → 成功（显示数据预览）\nAI：生成代码3 → 执行 → 成功（输出分析结果）\n用户：看到自然语言结果\n```\n\n这就是 CodeAct 的核心：**AI 通过生成真实 Python 代码与环境交互，利用解释器执行代码，观察结果，动态调整后续操作**。整个过程就像有个程序员在实时编写和调试脚本，但完全由 AI 自主完成。","categories":["深度学习"]},{"title":"LightGBM：一种高效的梯度提升决策树","url":"/2025/02/18/gaxvt0rd/","content":"\n这里介绍一种由微软团队开发的高效的梯度提升决策树 `LightGBM`。相关代码实现已开源至 github：\n\n[https://github.com/microsoft/LightGBM](https://github.com/microsoft/LightGBM)。\n\n论文出处：\n\n[https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)。\n\n以下是论文翻译：\n\n# 摘要\n\n`梯度提升决策树`（GBDT）是一种流行的机器学习算法，已经有许多有效的实现，例如`XGBoost`和`pGBRT`。尽管这些实现中采用了许多工程优化，然而当`特征维度高且数据量大`时，其效率和可扩展性仍然不理想。\n\n主要原因在于，对于每个特征，算法需要扫描所有数据实例来估算所有可能分割点的信息增益，这一过程非常耗时。为了解决这个问题，我们提出了两种新技术：基于梯度的单边采样（`GOSS`）和特征互斥捆绑（`EFB`）。在GOSS中，我们排除了大量梯度较小的数据实例，仅使用剩余的数据实例来估算信息增益。我们证明，由于具有较大梯度的数据实例在信息增益计算中起着更重要的作用，GOSS可以在使用更小的数据集时，获得较为准确的信息增益估计。在EFB中，我们将互斥特征捆绑在一起（即它们很少同时取非零值），以减少特征的数量。\n\n我们证明，找到最优的互斥特征捆绑是NP-难问题，但贪心算法可以获得相当好的近似比率（从而有效地减少特征数量，同时不会大幅损害分割点判定的准确性）。我们将新的GBDT实现称为带有GOSS和EFB的`LightGBM`。我们在多个公开数据集上的实验表明，`LightGBM`加速了传统GBDT的训练过程，速度提升超过20倍，同时几乎保持相同的准确性。\n\n# 引言\n\n`梯度提升决策树`（GBDT）是一种广泛使用的机器学习算法，由于其在许多机器学习任务中的高效性、准确性和可解释性，GBDT在多类分类、点击预测和排序学习等任务中取得了最先进的性能。近年来，随着大数据的出现（特征数量和样本数都大幅增加），GBDT面临着新的挑战，特别是在`准确性和效率之间的权衡问题`。传统的GBDT实现需要为每个特征扫描所有数据实例，以估算所有可能的分割点的信息增益。因此，其计算复杂度将同时与特征数和样本数成正比。这使得在处理大数据时，这些实现非常耗时。\n\n为了解决这一挑战，一个直接的想法是减少数据实例的数量和特征的数量。然而，这个问题非常复杂。例如，如何为GBDT执行数据采样仍然不清楚。虽然已有一些研究尝试根据样本的权重来进行数据采样，从而加速提升过程，但这些方法不能直接应用于GBDT，因为GBDT中根本没有样本权重。\n\n我们提出了两种新技术来解决这一问题，具体如后文所述。\n\n## **基于梯度的单边采样（GOSS）**\n\n尽管在GBDT中没有原生的数据实例权重，但我们注意到具有不同梯度的数据实例在信息增益的计算中扮演着不同的角色。具体来说，根据`信息增益`的定义，梯度较大的数据实例（即训练不足的实例）对信息增益的贡献较大。因此，在下采样数据实例时，为了保持信息增益估计的准确性，我们应该`保留那些梯度较大的实例`（例如，梯度大于预定义的阈值，或者位于梯度的前几个百分位），并随机丢弃那些梯度较小的实例。\n\n我们证明，这种处理方法可以在目标采样率相同的情况下，获得比均匀随机采样更准确的信息增益估计，尤其是在信息增益的取值范围较大时。\n\n## **特征互斥捆绑（EFB）**\n\n通常在实际应用中，尽管特征数量很多，但特征空间是相当稀疏的，这为我们设计一种近乎无损的方法来减少有效特征的数量提供了可能性。具体来说，在稀疏特征空间中，许多特征是（几乎）互斥的，即它们很少同时取非零值。\n\n举例来说，包括单热编码特征（例如，文本挖掘中的单热词表示）。我们可以安全地将这些互斥特征捆绑在一起，通过减少最优捆绑问题的复杂度来实现。为此，我们将最优捆绑问题转化为图着色问题（通过将特征看作顶点，并在每两个不互斥的特征之间添加边），并通过`贪心算法`以常数近似比率来解决该问题。\n\n我们将带有`GOSS`和`EFB`的新GBDT算法称为`LightGBM`。我们在多个公开数据集上的实验表明，`LightGBM`可以将训练过程加速至传统GBDT的`20倍`以上，同时实现几乎相同的`准确性`。\n\n## **本文结构**\n\n本文结构安排如下：\n\n- `第2节`：回顾GBDT算法及相关工作；\n- `第3节`：v介绍GOSS的细节；\n- `第4节`：介绍EFB的细节；\n- `第5节`：实验结果展示LightGBM在公开数据集上的表现；\n- `第6节`：总结本文内容。\n\n# 预备知识\n\n## **GBDT及其复杂度分析**\n\nGBDT是一种决策树的集成模型，决策树是按序列训练的。在每次迭代中，GBDT通过`拟合负梯度（也称为残差误差）来学习决策树`。\n\nGBDT的主要开销在于`学习决策树`，而学习决策树最耗时的部分是`寻找最佳的分割点`。最常用的寻找分割点的算法之一是预排序算法，该算法枚举了所有可能的分割点，基于预排序的特征值。这个算法简单且能够找到最优的分割点，但在训练速度和内存消耗上效率较低。\n\n另一个常用算法是基于直方图的算法，如算法1所示。该算法通过将特征值划分到离散的区间中，使用这些区间来构建特征直方图，从而避免了在排序特征上的分割点查找。由于基于直方图的算法在内存消耗和训练速度上更高效，我们将在此基础上开展工作。\n\n如算法1所示，基于直方图的算法根据特征直方图来寻找最佳分割点，构建直方图的复杂度为**O(数据数 × 特征数)**，而分割点查找的复杂度为 **O(箱数 × 特征数)**。由于**箱数**通常远小于**数据数**，因此在计算复杂度中，直方图构建的开销将占主导地位。如果我们能够减少**数据数**或**特征数**，则能够显著加速GBDT的训练过程。\n\n![image-20250218234605531](../images/assets//image-20250218234605531.png)\n\n## **相关工作**\n\n在文献中，已有不少GBDT的实现，包括`XGBoost`、`pGBRT`、scikit-learn和R中的`gbm`。Scikit-learn和R中的`gbm`实现了预排序算法，而`pGBRT`实现了基于直方图的算法。`XGBoost`支持这两种算法。\n\n为减少训练数据的大小，一种常见的方法是对数据实例进行下采样。例如，在[5]中，当数据实例的权重小于某个固定阈值时，会对其进行过滤。SGB [20]在每次迭代中使用随机子集来训练弱学习器。在[6]中，采样率会根据训练进度动态调整。然而，除SGB [20]外，所有这些方法都是基于AdaBoost的[21]，而且不能直接应用于GBDT，因为GBDT没有数据实例的原生权重。尽管SGB可以应用于GBDT，但通常会损害准确性，因此它不是一个理想的选择。\n\n为了减少特征数量，通常通过`主成分分析`（PCA）或投影追踪来过滤弱特征。然而，这些方法通常依赖于特征之间存在显著冗余的假设，而这一假设在实践中可能并不总是成立（特征通常是根据它们独特的贡献来设计的，去除其中任何一个可能会在某种程度上影响训练准确度）。\n\n在实际应用中使用的大规模数据集通常是相当`稀疏`的。使用预排序算法的GBDT可以通过忽略零值特征来减少训练成本。然而，GBDT与基于直方图的算法并没有高效的稀疏优化解决方案。其原因在于基于直方图的算法需要为每个数据实例检索特征的bin值，无论特征值是否为零（参见算法1）。因此，`非常希望GBDT能够有效地利用这些稀疏特性`。\n\n为了应对之前方法的局限性，我们提出了两种新技术，分别是`梯度的单边采样（GOSS）`和`排他性特征捆绑（EFB）`。更多细节将在接下来的章节中介绍。\n\n# 基于梯度的单边采样\n\n在本节中，我们提出了一种新的`GBDT采样方法`，能够在减少数据实例数量和保持所学决策树准确性之间取得良好的平衡。\n\n## 算法描述\n\n在`AdaBoost`中，样本权重是一个很好的数据实例重要性的指示器。然而，在GBDT中，并没有原生的样本权重，因此无法直接应用`AdaBoost`提出的采样方法。幸运的是，我们注意到GBDT中每个数据实例的梯度提供了有用的信息来进行数据采样。也就是说，如果一个实例与小梯度相关联，则该实例的训练误差很小，且它已经被很好地训练。一个直接的想法是丢弃那些具有小梯度的数据实例。然而，这样做会改变数据分布，从而影响所学模型的准确性。为了避免这个问题，我们提出了一种名为梯度基于单边采样（GOSS）的方法。\n\n`GOSS保留所有具有大梯度的实例`，并对具有`小梯度的实例执行随机采样`。为了补偿对数据分布的影响，在计算信息增益时，GOSS为小梯度的数据实例引入了一个常数乘子（见算法2）。具体来说，GOSS首先根据其梯度的绝对值对数据实例进行排序，并选择前 $a \\times 100%$ 的实例。然后它从剩余的数据中随机采样 $b \\times 100%$ 的实例。之后，GOSS通过常数 $\\frac{1-a}{b}$ 来放大这些小梯度数据的采样值，以计算信息增益。这样，我们能够在不改变原始数据分布的情况下，更加关注那些未被充分训练的实例。\n\n## 理论分析\n\nGBDT使用决策树从数据空间 $\\mathcal{X}^s$ 学习函数到梯度空间 $\\mathcal{G}$ [1]。假设我们有一个包含 $n$ 个独立同分布（i.i.d.）样本的数据集 ${x_1, \\cdots, x_n}$，其中每个 $x_i$ 的维度为 $s$，即 $x_i \\in \\mathcal{X}^s$。在每次梯度提升的迭代中，模型参数的负梯度记为 ${g_1, \\cdots, g_n}$。决策树模型在每个节点上分裂最具有信息增益的特征（信息增益最大）。对于GBDT，信息增益通常通过分裂后节点的方差来衡量，如下所定义。\n\n**定义 3.1**。设 $O$ 为决策树固定节点 $d$ 的训练数据集，特征 $j$ 在点 $d$ 的方差增益定义为：\n$$\nV_{j|O}(d) = \\frac{1}{n_O} \\left( \\frac{\\left( \\sum_{x_i \\in O : x_{ij} \\leq d} g_i \\right)^2}{n_{j|O}(d)} + \\frac{\\left( \\sum_{x_i \\in O : x_{ij} > d} g_i \\right)^2}{n_{j|R}(d)} \\right),\n$$\n其中 $n_O = \\sum I[x_i \\in O]$，$n_{j|O}(d) = \\sum I[x_i \\in O : x_{ij} \\leq d]$ 和 $n_{j|R}(d) = \\sum I[x_i \\in O : x_{ij} > d]$。\n\n对于特征 $j$，决策树算法选择 $d_j^* = \\arg \\max_j V_j(d)$，并计算该特征的最大增益 $V_j(d^*)$。然后，数据根据特征 $j^*$ 在点 $d^*$ 上分裂成左右子节点。\n\n在我们提出的GOSS方法中，首先，我们根据梯度的绝对值对训练实例进行排序；其次，我们保留前 $a \\times 100%$ 的梯度较大的实例；然后，对于其余的样本集 $A^c$（包含 $1-a \\times 100%$ 实例），我们进一步随机采样一个大小为 $B$ 的子集，其中 $B$ 为 $|A^c|$ 的向量大小；最后，我们根据合并子集 $A \\cup B$ 上的估计方差增益 $V_j^*(d)$ 来分裂数据。\n$$\nV_j^*(d) = \\frac{1}{n} \\left( \\frac{\\left( \\sum_{x_i \\in A_l : x_{ij} \\leq d} g_i \\right)^2}{n_j(d)} + \\frac{\\left( \\sum_{x_i \\in A_r : x_{ij} > d} g_i \\right)^2}{n_r(d)} \\right),\n$$\n其中 $A_l = {x_i \\in A : x_{ij} \\leq d }$，$A_r = {x_i \\in A : x_{ij} > d }$，$B_l = {x_i \\in B : x_{ij} \\leq d }$，$B_r = {x_i \\in B : x_{ij} > d }$；并且系数 $\\frac{1-a}{b}$ 用于将梯度总和归一化回到 $B$ 上。\n\n因此，在GOSS中，我们使用 $V_j^*(d)$ 来代替 $V_j(d)$ 对所有实例进行分裂点的确定，计算成本得以大幅减少。更重要的是，理论证明表明，GOSS不会丧失太多训练精度，并且将优于随机采样。由于空间限制，我们将在附录中给出证明。\n\n**定义 3.2**。我们将GOSS中的近似误差表示为 $\\mathcal{E}(d) = | \\hat{V}_j(d) - V_j(d) |$ 和 $\\vec{g}*l(d) = \\sum*{x_i \\in (A \\cup A_r)} |g_i| / n_j(d)$。\n\n对于至少概率 $1 - \\delta$，我们有：\n$$\n\\mathcal{E}(d) \\leq C_{a,b} h \\frac{1}{n_l(d)} \\max \\left\\{ \\frac{1}{n_l(d)}, \\frac{1}{n_r(d)} \\right\\} + 2D C_{a,b} \\sqrt{\\frac{\\ln \\frac{1}{\\delta}}{n}},\n$$\n其中 $C_{a,b} = \\frac{1-a}{\\sqrt{b}} \\max_{x_i \\in A \\cup A_r} |g_i|$，并且 $D = \\max(\\vec{g}_l(d), \\vec{g}_r(d))$。\n\n根据定理，我们得出以下讨论：\n\n1. GOSS的渐进近似比率是 $O \\left( \\frac{1}{n_l(d)} + \\frac{1}{n_r(d)} + \\frac{1}{\\sqrt{n}} \\right)$。如果分裂不是特别不平衡（即，$n_l(d) \\geq O(\\sqrt{n})$ 和 $n_r(d) \\geq O(\\sqrt{n})$），则近似误差将主要由不等式（2）中的第二项支配。\n\n   其次，随着数据量 $n$ 的增加，近似误差将趋于 $O(\\sqrt{n})$，当 $n$ 足够大时，这意味着近似非常准确。\n\n2. 随机采样是GOSS的一个特殊情形，当 $a = 0$ 时。在许多情况下，GOSS能够优于随机采样，在条件 $C_{0,\\beta} > C_{a,\\beta - a}$ 下，且等效于条件 $\\frac{a}{\\sqrt{b}} > \\frac{1-a}{\\beta - a}$，其中 $a = \\max_{x_i \\in A \\cup A_r} |g_i| / \\max_{x_i \\in A^c} |g_i|$。\n\n接下来，我们分析GOSS的泛化性能。我们考虑GOSS的泛化误差 $\\mathcal{E}_{GOSS}(d) = | \\hat{V}_j(d) - V^*(d) |$，这是由GOSS计算的方差增益与基础数据分布的真实方差增益之间的差距。我们有：\n$$\n\\mathcal{E}_{GOSS}^{gen}(d) \\leq | \\hat{V}_j(d) - V_j(d) | + | \\hat{V}_j(d) - V^*(d) | \\triangleq \\mathcal{E}_{GOSS}(d) + \\mathcal{E}^{gen}(d)。\n$$\n因此，GOSS的泛化误差将接近于当使用所有数据实例时的误差，前提是GOSS的近似是准确的。另一方面，采样将增加基础学习者的泛化误差，进而可能有助于提高模型的泛化能力 [24]。\n\n# 排他性特征捆绑\n\n在本节中，我们提出了一种`有效减少特征数量`的新方法。\n\n`高维数据通常非常稀疏`。特征空间的稀疏性为我们提供了减少特征数量的可能性。具体来说，在稀疏特征空间中，许多特征是相互排斥的，即它们从不同时取非零值。我们可以将排他性特征捆绑到一个单一特征中（我们称之为`排他性特征捆绑`）。通过精心设计的`特征扫描算法`，我们可以像构建单独特征的特征直方图一样，构建来自特征捆绑的相同特征直方图。通过这种方式，直方图构建的复杂度从 **O(数据数 × 特征数)** 改变为 **O(数据数 × 箱数)**，其中 **箱数 << 特征数**。这样我们可以显著加速 GBDT 的训练，而不会损害准确性。接下来，我们将详细介绍如何实现这一目标。\n\n有两个问题需要解决。第一个是`如何确定哪些特征应该被捆绑在一起`。第二个是`如何构建捆绑`。\n\n**定理 4.1**。 将特征划分为最小数量的排他性捆绑问题是 `NP-难` 的。\n\n**证明**：我们将图着色问题[25]归约到我们的问题中。由于图着色问题是 `NP-难` 的，我们可以得出结论。\n\n给定图着色问题 G=(V,E)。G = (V, E) 的任意实例，我们构造一个我们的实例。对于图的每一行作为特征，我们得到一个我们的实例问题，且容易看出，问题中的排他性特征捆绑对应于具有相同颜色的顶点集合，反之亦然。\n\n对于第一个问题，我们在定理 4.1 中证明它是 NP-难 的，无法在多项式时间内找到最优捆绑策略，这表明不可能找到精确的解。为了找到一个良好的近似算法，我们首先将最优捆绑问题归约到图着色问题，将特征作为顶点，对于每两个特征如果它们不是互斥的，就在它们之间添加边，然后使用贪心算法可以产生合理的结果。\n\n（具有`常数近似比率`的）`图着色算法`用于生成捆绑。此外，我们注意到，通常有一些特征，尽管不是 100% 互斥，但也很少同时取非零值。如果我们的算法允许一小部分冲突，我们可以得到更少的特征捆绑，并进一步提高计算效率。通过简单计算，随机污染特征值的少部分将影响训练准确度，最多约为 $O([(1 - \\gamma)n]^{-2/3})$（见附录材料中的命题 2.1），其中 $\\gamma$ 是每个捆绑中最大冲突率。因此，如果我们选择相对较小的 $\\gamma$，我们将能够在准确性和效率之间取得良好的平衡。\n\n基于上述讨论，我们设计了如算法 3 所示的`排他性特征捆绑算法`。首先，我们构建了一个加权图，其中边的权重表示特征之间的总冲突。然后，我们按图中每个特征的度数对特征进行降序排序。最后，检查每个特征并将其分配给现有捆绑中的一个（如果冲突较小，受 $\\gamma$ 控制），或者创建一个新的捆绑。算法 3 的时间复杂度为 **O(特征数)**，并且在训练前仅处理一次。当特征数量不是非常大时，这个复杂度是可以接受的，但如果有数百万个特征，仍然可能会存在问题。为了提高效率，我们提出了一种无需构建图的更高效排序策略，通过按非零值的数量对特征进行排序，这类似于按度数对特征进行排序，因为更多非零值通常会导致更高的冲突概率。由于我们只是在重新排序策略方面进行调整，因此新算法的细节省略，以避免重复。\n\n对于第二个问题，我们需要一种有效的方式来`合并同一捆绑中的特征`，以减少相应的训练复杂度。关键是确保原始特征的值可以通过特征捆绑来识别。由于基于直方图的算法存储特征的离散值，因此我们可以通过让排他性特征在不同的 bin 中进行排序，从而构造一个特征捆绑。这样就可以通过对原始特征的值添加偏移量来构造特征捆绑。例如，假设我们有两个特征在一个特征捆绑中。最初，特征 A 的值范围是 [0, 10]，特征 B 的值范围是 [0, 20]。然后，我们对特征 A 的值添加 10 的偏移量，使得 refined feature 的值范围变为 [10, 30]。此后，特征 A 和 B 可以安全地合并，并使用范围 [0, 30] 的特征捆绑来替代原始特征 A 和 B。详细的算法见算法 4。\n\nEFB 算法可以将许多`排他性特征捆绑成更少的稠密特征`，从而有效避免对零特征值的无谓计算。实际上，我们还可以通过使用表格记录每个特征的非零值，优化基本的基于直方图的算法，忽略零特征值。通过扫描该表，特征的直方图构建成本将从 **O(数据数)** 变为 **O(非零数据数)**。然而，这种方法需要额外的内存和计算开销，以维护这些每个特征的表格以记录非零数据。我们在 LightGBM 中实现了此优化作为基本功能。请注意，此优化不会与 EFB 冲突，即使当捆绑稀疏时。\n\n# **实验**\n\n在本节中，我们报告了关于我们提出的 `LightGBM 算法`的实验结果。我们使用了五个不同的公开数据集，这些数据集的详细信息列在表 1 中。其中，`Microsoft Learning to Rank (LETOR) 数据集`包含了 30K 个网页搜索查询。该数据集中使用的特征大多是密集的数值特征。`Allstate Insurance Claim` 和 `Flight Delay` 数据集都包含了大量的独热编码特征。最后两个数据集来自 `KDD CUP 2010` 和 `KDD CUP 2012`。我们直接使用了 `NTU 获胜方案`中使用的特征，这些特征包含了密集和稀疏特征，这两个数据集非常大。这些数据集既大又包含密集和稀疏特征，并覆盖了许多现实世界的任务。因此，我们可以使用它们来全面测试我们的算法。\n\n我们的实验环境是一个 `Linux 服务器`，配备了两颗 `E5-2670 v3 CPU`（共 24 核心）和 `256GB` 内存。所有实验均采用多线程运行，线程数固定为 `16`。\n\n## 总体比较\n我们在本小节中展示了`总体比较`。\n\nXGBoost [13] 和 LightGBM 没有使用 GOSS 和 EFB（称为 lgb_baseline）作为基准。对于 XGBoost，我们使用了两个版本，`xgb_exa（预排序算法）`和 `xgb_his（基于直方图的算法）`。对于 `LightGBM`，我们使用了`叶子-wise 树生长策略` [32]。对于 `xgb_exa`，由于它只支持`层次-wise 生长策略`，我们调节了 `xgb_exa` 的参数，让它像其他算法一样`生长树`。\n\n- 表1：实验中使用的`数据集`\n\n| 名称         | 数据量 | 特征数量 | 描述 | 任务   | 指标   |\n| ------------ | ------ | -------- | ---- | ------ | ------ |\n| Allstate     | 12M    | 4228     | 稀疏 | 二分类 | AUC    |\n| Flight Delay | 10M    | 700      | 稀疏 | 二分类 | AUC    |\n| LETOR        | 2M     | 136      | 密集 | 排序   | NDCG@4 |\n| KDD10        | 19M    | 29M      | 稀疏 | 二分类 | AUC    |\n| KDD12        | 119M   | 54M      | 稀疏 | 二分类 | AUC    |\n\n- 表2：`总体训练时间成本比较`。LightGBM 是 lgb_baseline 与 GOSS 和 EFB。EFB_only 是 lgb_baseline 与 EFB。表中的值是平均训练时间（秒）每次训练一次。\n\n| 算法         | xgb_exa    | xgb_his | lgb_baseline | EFB_only | LightGBM |\n| ------------ | ---------- | ------- | ------------ | -------- | -------- |\n| Allstate     | 10.85      | 2.63    | 6.07         | 0.61     | 0.28     |\n| Flight Delay | 5.94       | 1.05    | 1.39         | 0.27     | 0.22     |\n| LETOR        | 5.55       | 0.63    | 0.49         | 0.46     | 0.31     |\n| KDD10        | 108.27 OOM | 39.85   | 6.33         | 8.73     | 2.26     |\n| KDD12        | 191.99 OOM | 168.26  | 20.23        | 12.67    |          |\n\n- 表3：`测试数据集上的总体准确率比较`。用于分类任务的 `AUC`，排序任务使用 `NDCG@10`。`SGB` 是 `lgb_baseline` 与随机梯度提升，其采样策略与 `LightGBM` 相同。\n\n| 算法         | xgb_exa | xgb_his | lgb_baseline | SGB           | LightGBM      |\n| ------------ | ------- | ------- | ------------ | ------------- | ------------- |\n| Allstate     | 0.6070  | 0.6089  | 0.6093       | 0.6064 ± 7e-4 | 0.6093 ± 9e-5 |\n| Flight Delay | 0.7601  | 0.7840  | 0.7847       | 0.7780 ± 4e-4 | 0.7846 ± 4e-5 |\n| LETOR        | 0.4977  | 0.4982  | 0.5277       | 0.5239 ± 6e-4 | 0.5275 ± 5e-4 |\n| KDD10        | 0.7796  | 0.7901  | 0.7873       | 0.7759 ± 3e-4 | 0.7873 ± 1e-4 |\n| KDD12        | 0.7029  | 0.7047  | 0.7084       | 0.6989 ± 8e-4 | 0.7051 ± 5e-5 |\n\n我们还对所有数据集进行了`参数调节`，以便更好地`平衡速度和准确性`。\n\n- 设置 `α = 0.05，β = 0.05` 对 `Allstate，KDD10 和 KDD12 数据集`；\n- 设置 `α = 0.1，β = 0.1` 对 `Flight Delay 和 LETOR`；\n- 设置 $\\gamma=0$ 在 EFB 中。\n\n所有算法都运行`固定迭代次数`，并且我们从`最佳迭代`中获取了准确率结果。\n\n![image-20250219001407155](../images/assets//image-20250219001407155.png)\n\n训练时间和测试准确度分别在表2和表3中总结。\n\n从这些结果来看，`LightGBM` 是最快的，同时保持几乎相同的准确性。`xgb_exa` 基于预排序算法，与基于直方图的算法相比，在` Allstate、Flight Delay、LETOR、KDD10 和 KDD12 数据集`上分别加速了 21 倍、6 倍、1.6 倍、14 倍和 13 倍。由于 `xgb_his` 很消耗内存，它无法在 `KDD10` 和 `KDD12` 数据集上成功运行，因为内存溢出。\n\n在其余的数据集上，`LightGBM` 都更快，最高达 9 倍的加速。加速是基于每次迭代训练时间计算的。由于所有算法在相似数量的迭代中收敛，我们还展示了基于 `Flight Delay` 和 `LETOR 数据集` 墙时钟时间的训练曲线（见图1）6。\n\n- 表4：在不同采样比下，`GOSS` 和 `SGB` 在`LETOR 数据集`上的准确度比较。我们通过使用大量迭代和早期停止来确保所有实验达到收敛点。不同设置下的标准差较小。`GOSS` 的参数 a 和 b 设置可以在附加材料中找到。\n\n| 采样比 | 0.1    | 0.15   | 0.2    | 0.25   | 0.3    | 0.35   | 0.4    |\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| SGB    | 0.5182 | 0.5216 | 0.5239 | 0.5249 | 0.5252 | 0.5263 | 0.5267 |\n| GOSS   | 0.5224 | 0.5256 | 0.5275 | 0.5284 | 0.5289 | 0.5293 | 0.5296 |\n\n为了节省空间，我们将其余数据集的训练曲线放在附加材料中。\n\n在所有数据集上，`LightGBM` 可以达到与基准几乎相同的测试准确度。这表明 GOSS 和 EFB 不会影响准确度，同时带来显著的加速。这与我们在第 3.2 节和第 4 节中的理论分析一致。\n\n`LightGBM` 在这些数据集上实现了完全不同的加速比。总体加速来自 `GOSS` 和 `EFB` 的结合，我们将在接下来的部分中详细讨论 GOSS 和 EFB 的贡献以及它们的有效性。\n\n## GOSS分析\n首先，我们研究 `GOSS` 的加速能力。从 `LightGBM` 和 `EFB_only`（表2中的 `LightGBM` 未使用 `GOSS`）比较中可以看出，`GOSS` 自身可以通过使用 10% - 20% 的数据加速近 2 倍。`GOSS` 可以仅通过使用采样数据来学习树。然而，它仍然保留了一些在全数据集上的计算，比如进行预测和计算梯度。因此，我们可以发现整体加速与采样数据的比例并不完全相关，但 `GOSS` 带来的加速仍然是非常显著的，而且这种技术对不同数据集普遍适用。\n\n其次，我们通过与`随机梯度提升`（SGB）[20] 比较来评估 `GOSS` 的准确性。在不失一般性的情况下，我们使用 `LETOR 数据集`进行测试。我们通过选择不同的 a 和 b 来调节采样比例，并为 SGB 使用相同的整体采样比例。我们在这些设置下运行，直到使用早期停止达到收敛。结果如表4所示。我们可以看到，在使用相同的采样比例时，`GOSS` 的准确性始终优于 `SGB`。这些结果与我们在第 3.2 节中的讨论一致。所有实验都表明，`GOSS` 是一种比随机采样更有效的采样方法。\n\n## EFB分析\n我们通过将 `lgb_baseline` 与 `EFB_only` 进行比较，来检查 `EFB` 对加速的贡献。结果如表2所示。我们不允许在捆绑查找过程中出现冲突（即 $\\gamma = 0$）。我们发现，EFB 可以帮助在这些大规模数据集上实现显著的加速。\n\n请注意，`lgb_baseline` 已针对稀疏特征进行了优化，而 `EFB` 仍然能够加速训练过程。其原因在于 `EFB` 将许多稀疏特征（包括一热编码特征和隐式排他特征）合并为更少的特征。基本的稀疏特征优化已包含在捆绑过程中。另一方面，EFB 不需要在训练过程中为每个特征维护非零数据表。更重要的是，以前各自独立的特征现在被捆绑在一起，这有助于提高缓存命中率并显著提升效率。因此，整体的训练效率提升非常显著。通过进一步分析，EFB 是一种非常有效的算法，它能够在基于直方图的算法中利用稀疏特征，并且能在 `GBDT` 训练过程中带来显著加速。\n\n# 结论\n在本文中，我们提出了一种新型的 `GBDT 算法`，称为 `LightGBM`，该算法包含两种新技术：`基于梯度的单边采样`（Gradient-based One-Side Sampling）和`排他性特征捆绑`（Exclusive Feature Bundling），分别用于`处理大规模数据实例`和`大规模特征`。\n\n我们在这两项技术上进行了理论分析和实验研究。实验结果与理论一致，表明在 `GOSS` 和 `EFB` 的帮助下，`LightGBM` 在计算速度和内存消耗方面显著超越了 `XGBoost` 和 `SGB`。未来的工作将研究基于梯度的单边采样中 a 和 b 的最优选择，并继续改进`排他性特征捆绑`的性能，以处理大量特征，无论这些特征是否稀疏。\n\n# 支撑材料\n\n在这里下载：[https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Supplemental.zip](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Supplemental.zip)。\n\n# 参考文献\n\n1. Jerome H. Friedman. Greedy function approximation: a gradient boosting machine. *Annals of statistics*, pages 1189–1232, 2001.\n2. Ping Li. Robust logitboost and adaptive base class (abc) logitboost. *arXiv preprint arXiv:1203.3491*, 2012.\n3. Matthew Richardson, Ewa Dominowska, and Robert Ragno. Predicting clicks: estimating the click-through rate for new ads. *Proceedings of the 16th international conference on World Wide Web*, pages 521–530. ACM, 2007.\n4. Christopher JC Burges. From ranking to lambdamart: An overview. *Learning*, 11(23-581):81, 2010.\n5. Jerome Friedman, Trevor Hastie, Robert Tibshirani, et al. Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). *The annals of statistics*, 28(2):337–407, 2000.\n6. Charles Dubout and François Fleuret. Boosting with maximum adaptive sampling. In *Advances in Neural Information Processing Systems*, pages 1332–1340, 2011.\n7. Ron Appel, Thomas J Fuchs, Piotr Dollár, and Pietro Perona. Quickly boosting decision trees-pruning underachieving features early. In *ICML (3)*, pages 594–602, 2013.\n8. Manish Mehta, Rakesh Agrawal, and Jorma Rissanen. Sliq: A fast scalable classifier for data mining. In *International Conference on Extending Database Technology*, pages 18–32. Springer, 1996.\n9. John Shafer, Rakesh Agrawal, and Manish Mehta. Sprint: A scalable parallel classifier for data mining. In *Proc. 1996 Int. Conf. Very Large Data Bases*, pages 544–555. Citeseer, 1996.\n10. Sanjay Ranka and V Singh. Clouds: A decision tree classifier for large datasets. In *Proceedings of the 4th Knowledge Discovery and Data Mining Conference*, pages 2–8, 1998.\n11. Ruoming Jin and Gagan Agrawal. Communication and memory efficient parallel decision tree construction. In *Proceedings of the 2003 SIAM International Conference on Data Mining*, pages 119–129. SIAM, 2003.\n12. Ping Li, Christopher JC Burges, Qiang Wu, JC Platt, D Koller, Y Singer, and S Roweis. Mcrank: Learning to rank using multiple classification and gradient boosting. In *NIPS*, volume 7, pages 845–852, 2007.\n13. Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In *Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, pages 785–794. ACM, 2016.\n14. Stephen Tyree, Kilian Q Weinberger, Lanul Agrawal, and Jennifer Paykin. Parallel boosted regression trees for web search ranking. In *Proceedings of the 20th international conference on World wide web*, pages 387–396. ACM, 2011.\n15. Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. *Journal of Machine Learning Research*, 12(Oct):2825–2830, 2011.\n16. Greg Ridgeway. Generalized boosted models: A guide to the gbm package. *Update*, 1(1):207, 2007.\n17. Huan Zhang, Si Si, and Cho-Jui Hsieh. Gpu-acceleration for large-scale tree boosting. *arXiv preprint arXiv:1706.08359*, 2017.\n18. Rory Mitchell and Eibe Frank. Accelerating the xgboost algorithm using gpu computing. *PeerJ Preprints*, 5:e2911v1, 2017.\n\n19. Qi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, and Tieyan Liu. A communication-efficient parallel algorithm for decision tree. In *Advances in Neural Information Processing Systems*, pages 1271–1279, 2016.\n\n20. Jerome H Friedman. Stochastic gradient boosting. *Computational Statistics & Data Analysis*, 38(4):367–378, 2002.\n\n21. Michael Collins, Robert E Schapire, and Yoram Singer. Logistic regression, adaboost and bregman distances. *Machine Learning*, 48(1-3):253–285, 2002.\n\n22. Ian Jolliffe. *Principal component analysis*. Wiley Online Library, 2002.\n\n23. Luis O Jimenez and David A Landgrebe. Hyperspectral data analysis and supervised feature reduction via projection pursuit. *IEEE Transactions on Geoscience and Remote Sensing*, 37(6):2653–2667, 1999.\n\n24. Zhi-Hua Zhou. *Ensemble methods: foundations and algorithms*. CRC press, 2012.\n\n25. Tommy R Jensen and Bjarne Toft. *Graph coloring problems*, volume 39. John Wiley & Sons, 2011.\n\n26. Tao Qin and Tie-Yan Liu. Introducing LETOR 4.0 datasets. *CoRR*, abs/1306.2597, 2013.\n\n27. Allstate claim data, https://www.kaggle.com/c/ClaimPredictionChallenge.\n\n28. Flight delay data, https://github.com/szilard/benchm-ml#data.\n\n29. Hsiang-Fu Yu, Hung-Yi Lo, Hsun-Ping Hsieh, Jing-Kai Lou, Todd G McKenzie, Jung-Wei Chou, Po-Han Chung, Chia-Hua Ho, Chun-Fu Chang, Yin-Hsuan Wei, et al. Feature engineering and classifier ensemble for kdd cup 2010. In *KDD Cup*, 2010.\n\n30. Kuan-Wei Wu, Chun-Sung Ferng, Chia-Hua Ho, An-Chun Liang, Chun-Heng Huang, Wei-Yuan Shen, Jyun-Yu Jiang, Ming-Hao Yang, Ting-Wei Lin, Ching-Pei Lee, et al. A two-stage ensemble of diverse models for advertisement ranking in kdd cup 2012. In *KDDCup*, 2012.\n\n31. Libsvm binary classification data, https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html.\n\n32. Haijian Shi. *Best-first decision tree learning*. PhD thesis, The University of Waikato, 2007.","categories":["小小知识"]},{"title":"群体遗传模拟","url":"/2025/02/16/1t5fpnpd/","content":"\n这里记录群体模拟的原理和方法。\n\n# 群体模拟\n\n## 参考数据\n\n我们需要两个参考数据集：`map.rds` 和 `LD_chr1.rds` 。\n\n这里使用欧洲人群的参考LD数据和基因频率数据 （ [European LD reference](https://figshare.com/articles/dataset/European_LD_reference/13034123?file=24928052) ）进行模拟。具体来说，这是一个关于欧洲人群的连锁不平衡 (LD, Linkage Disequilibrium) 参考数据集。\n\n该数据集 `LD_chr1.rds` 包含欧洲人群的基因组数据（这里只考虑1号染色体），包括：\n\n- 基因型数据（SNP信息）\n- LD矩阵，描述了不同SNP之间的关联程度\n\n通常用于基因组学研究，如基因-环境互动分析、全基因组关联研究（GWAS）等。\n\n此外我们还需要一个映射表 `map.rds` ，包含这些SNP的等位基因及其频率信息：\n\n`map.rds` 各列的解释：\n\n- **chr**：染色体编号。\n- **pos**：染色体上的位置。\n- **a0**：SNP的一个等位基因（A、G、C、T）。\n- **a1**：另一个等位基因。\n- **rsid**：参考SNP标识符（例如rs3131972）。\n- **af_UKBB**：在UK Biobank人群中的等位基因频率。\n- **ld**：连锁不平衡（LD）值，量化了两个遗传变异之间的相关性。\n- **pos_hg17、pos_hg18、pos_hg38**：SNP在不同版本的人类基因组参考中的位置（hg17、hg18、hg38）。\n\n## 模拟详解\n\n### 示例\n\n为了帮助更好地理解基因型模拟和表型模拟的数学过程，这里构建一个低维的示例。我将使用一个简化的案例，其中包含几个基本的步骤，模拟少量的样本和SNP（3个SNP和2个样本）。\n\n#### 步骤 1: 初始化等位基因频率 $P$\n\n假设有3个SNP，且它们的等位基因频率如下：\n$$\nP = [0.3, 0.5, 0.7]\n$$\n#### 步骤 2: 协方差矩阵 $COV$ 的计算\n\n假设我们有2个样本，且3个SNP之间的连锁不平衡（LD）矩阵如下（这是一个简化的例子）：\n$$\n\\text{LD} = \\begin{bmatrix} 1.0 & 0.5 & 0.2 \\\\ 0.5 & 1.0 & 0.3 \\\\ 0.2 & 0.3 & 1.0 \\end{bmatrix}\n$$\n接下来，我们计算协方差矩阵 $COV$。\n\n协方差矩阵 $COV$ 可以通过连锁不平衡矩阵 $LD$ 和等位基因频率矩阵 $P$ 来计算。具体来说，对于给定的连锁不平衡矩阵 $LD$，等位基因频率矩阵 $P$，我们可以使用以下公式来计算协方差矩阵 $COV$：\n$$\nCOV_{ij} = \\text{LD}_{ij} \\cdot \\sqrt{P_i \\cdot (1 - P_i) \\cdot P_j \\cdot (1 - P_j)}\n$$\n其中：\n\n- $COV_{ij}$ 是 $SNP_i$ 和 $SNP_j$ 之间的协方差；\n- $\\text{LD}_{ij}$ 是 $SNP_i$ 和 $SNP_j$ 之间的连锁不平衡（LD）系数；\n- $P_i$ 和 $P_j$ 分别是 $SNP_i$ 和 $SNP_j$ 的等位基因频率；\n- $P_i (1 - P_i)$ 表示 $SNP_i$ 的基因型的方差（即该SNP的变异性）。\n\n$COV_{11}$：SNP1与自身的协方差\n$$\nCOV_{11} = \\text{LD}_{11} \\cdot \\sqrt{P_1 \\cdot (1 - P_1) \\cdot P_1 \\cdot (1 - P_1)} = 1.0 \\cdot \\sqrt{0.3 \\cdot 0.7 \\cdot 0.3 \\cdot 0.7} = 0.1\n$$\n$COV_{12}$：SNP1与SNP2的协方差\n$$\nCOV_{12} = \\text{LD}_{12} \\cdot \\sqrt{P_1 \\cdot (1 - P_1) \\cdot P_2 \\cdot (1 - P_2)} = 0.5 \\cdot \\sqrt{0.3 \\cdot 0.7 \\cdot 0.5 \\cdot 0.5} = 0.05\n$$\n$COV_{13}$：SNP1与SNP3的协方差\n$$\nCOV_{13} = \\text{LD}_{13} \\cdot \\sqrt{P_1 \\cdot (1 - P_1) \\cdot P_3 \\cdot (1 - P_3)} = 0.2 \\cdot \\sqrt{0.3 \\cdot 0.7 \\cdot 0.7 \\cdot 0.3} = 0.02\n$$\n其余的类似计算。通过计算，协方差矩阵 $COV$ 给出：\n$$\nCOV = \\begin{bmatrix} 0.1 & 0.05 & 0.02 \\\\ 0.05 & 0.1 & 0.03 \\\\ 0.02 & 0.03 & 0.1 \\end{bmatrix}\n$$\n\n#### 步骤 3: 生成正态分布随机数 $z_i$\n\n我们已经知道了每个SNP的等位基因频率和它们之间的连锁不平衡（LD）。我们想要生成一个具有这些特征的基因型数据。\n\n为了做到这一点，我们需要从一个正态分布随机数（$z_i$）开始，且这些随机数需要被转化为符合我们期望的协方差结构的基因型数据。因为协方差矩阵 $COV$ 描述了不同SNP之间的相关性，而我们希望生成的数据能够遵循这种相关性。\n\n对于每个样本，我们生成一个标准正态分布的随机数向量。假设我们有2个样本，生成的正态分布随机数如下：\n$$\nz_1 = [z_{11}, z_{12}, z_{13}] = [0.7, -1.2, 0.5]\n$$\n\n$$\nz_2 = [z_{21}, z_{22}, z_{23}] = [-0.4, 0.8, -0.3]\n$$\n\n#### 步骤 4: 使用下三角矩阵 $L$（ Cholesky 分解） 进行变换\n\n我们用下三角矩阵 $L$ 对正态分布随机数进行线性变换，是为了确保生成的基因型数据 $y_i$ 满足以下两个条件：\n\n1. **基因型数据之间的相关性（协方差）**：$L$ 是协方差矩阵 $COV$ 的 Cholesky 分解结果，因此通过对随机数 $z_i$ 进行线性变换，能够确保生成的基因型数据之间的协方差结构符合我们设定的目标协方差矩阵 $COV$。也就是说，$L$ 通过调整样本之间的关系，确保SNP之间的相关性被正确模拟。\n2. **标准化**：因为基因型数据应该满足特定的方差（通常是 $0$、$1$ 或 $2$），而每个SNP的基因型是离散的（即0、1、2表示不同的基因型类型），我们希望将生成的基因型数据进行标准化处理，使它们符合目标分布的形状。通过线性变换，$L$ 可以帮助调整基因型的分布，使得每个样本的基因型数据具有期望的统计特性。\n\n协方差矩阵 $COV$ 需要进行Cholesky分解来得到下三角矩阵 $L$。\n\nCholesky分解是将一个对称正定矩阵分解为一个下三角矩阵 $L$ 和它的转置矩阵 $L^T$ 的乘积。换句话说，对于一个对称正定矩阵 $COV$，我们可以通过如下的分解方式得到：\n\n$$\nCOV = L \\cdot L^T\n$$\n其中，$L$ 是下三角矩阵，假设协方差矩阵 $COV$ 为：\n\n$$\nCOV = \\begin{bmatrix}  0.1 & 0.05 & 0.02 \\\\  0.05 & 0.1 & 0.03 \\\\  0.02 & 0.03 & 0.1  \\end{bmatrix}\n$$\n\n我们需要找到下三角矩阵 $L$：\n\n$$\nL = \\begin{bmatrix}  l_{11} & 0 & 0 \\\\  l_{21} & l_{22} & 0 \\\\  l_{31} & l_{32} & l_{33}  \\end{bmatrix}\n$$\n\n根据Cholesky分解的定义，$COV = L \\cdot L^T$，即：\n\n$$\n\\begin{bmatrix}  0.1 & 0.05 & 0.02 \\\\  0.05 & 0.1 & 0.03 \\\\  0.02 & 0.03 & 0.1  \\end{bmatrix}  = \\begin{bmatrix}  l_{11} & 0 & 0 \\\\  l_{21} & l_{22} & 0 \\\\  l_{31} & l_{32} & l_{33}  \\end{bmatrix} \\begin{bmatrix}  l_{11} & l_{21} & l_{31} \\\\  0 & l_{22} & l_{32} \\\\  0 & 0 & l_{33}  \\end{bmatrix}\n$$\n\n通过矩阵乘法，我们得到：\n\n$$\n\\begin{bmatrix}  0.1 & 0.05 & 0.02 \\\\  0.05 & 0.1 & 0.03 \\\\  0.02 & 0.03 & 0.1  \\end{bmatrix}  = \\begin{bmatrix}  l_{11}^2 & l_{11}l_{21} & l_{11}l_{31} \\\\  l_{11}l_{21} & l_{21}^2 + l_{22}^2 & l_{21}l_{31} + l_{22}l_{32} \\\\  l_{11}l_{31} & l_{21}l_{31} + l_{22}l_{32} & l_{31}^2 + l_{32}^2 + l_{33}^2  \\end{bmatrix}\n$$\n\n我们通过对比矩阵的相应元素来求解下三角矩阵的元素。\n\n首先，根据 $COV$ 矩阵的第 (1, 1) 元素，我们得到：\n\n$$\nl_{11}^2 = 0.1 \\quad \\Rightarrow \\quad l_{11} = \\sqrt{0.1} = 0.316\n$$\n\n根据 $COV$ 矩阵的第 (2, 1) 元素，我们得到：\n\n$$\nl_{11} \\cdot l_{21} = 0.05 \\quad \\Rightarrow \\quad l_{21} = \\frac{0.05}{l_{11}} = \\frac{0.05}{0.316} = 0.158\n$$\n\n根据 $COV$ 矩阵的第 (2, 2) 元素，我们得到：\n\n$$\nl_{21}^2 + l_{22}^2 = 0.1\n$$\n$$\n\\Rightarrow \\quad l_{22} = \\sqrt{0.075} = 0.273\n$$\n其余元素的计算类似。最终得到的下三角矩阵 $L$ 是：\n\n$$\nL = \\begin{bmatrix}  0.316 & 0 & 0 \\\\  0.158 & 0.273 & 0 \\\\  0.063 & 0.109 & 0.285  \\end{bmatrix}\n$$\n\n这个矩阵就是协方差矩阵 $COV$ 的 Cholesky 分解结果。\n\n现在，我们用这个下三角矩阵 $L$ 对样本的正态分布随机数 $z_i$ 进行线性变换，得到标准化后的基因型数据 $y_i$。\n\n对于样本1：\n$$\ny_1 = L \\cdot z_1 =  \\begin{bmatrix} 0.316 & 0 & 0 \\\\ 0.158 & 0.273 & 0 \\\\ 0.063 & 0.109 & 0.285 \\end{bmatrix} \\cdot \\begin{bmatrix} 0.7 \\\\ -1.2 \\\\ 0.5 \\end{bmatrix} = \\begin{bmatrix} 0.221 \\\\ -0.063 \\\\ 0.169 \\end{bmatrix}\n$$\n对于样本2：\n$$\ny_2 = L \\cdot z_2 =  \\begin{bmatrix} 0.316 & 0 & 0 \\\\ 0.158 & 0.273 & 0 \\\\ 0.063 & 0.109 & 0.285 \\end{bmatrix} \\cdot \\begin{bmatrix} -0.4 \\\\ 0.8 \\\\ -0.3 \\end{bmatrix} = \\begin{bmatrix} -0.126 \\\\ 0.295 \\\\ -0.163 \\end{bmatrix}\n$$\n\n#### 步骤 5: 从标准化的基因型数据中生成基因型值\n\n在每个样本的标准化基因型数据生成后，根据每个SNP的等位基因频率（`P`）对基因型进行离散化。离散化的目标是将连续的基因型数据映射到 `0`、`1`或`2`（分别表示基因型AA、AB和BB）。\n\n**离散化过程的具体步骤：**\n\n1. **计算等位基因频率的阈值**：\n   - `p`：某个SNP的A等位基因频率。\n   - `q=1-p`：B等位基因的频率。\n   - `p²` 和 `2pq` 的阈值位置：`p²` 是AA基因型的频率，`2pq` 是AB基因型的频率。\n2. **排序标准化基因型**：将标准化后的基因型数据进行排序。\n3. **根据阈值离散化标准化基因型**：\n   - 将每个样本的标准化基因型与排序后的标准化基因型比较，基于阈值位置判断其属于哪种基因型。\n     - 如果标准化基因型小于等于`p²`阈值的位置，分配为基因型AA（0）。\n     - 如果标准化基因型在`p²`和`p² + 2pq`之间，分配为基因型AB（1）。\n     - 如果标准化基因型大于`p² + 2pq`，分配为基因型BB（2）。\n\n通过这种方法，标准化基因型被映射到AA、AB和BB基因型，同时考虑了不同等位基因频率的影响。\n\n这种离散化方法是基于等位基因频率来将连续数据划分为离散的基因型类别，模拟现实中基因型的分布特征。\n\n#### 步骤 6: 生成表型数据\n\n因果效应（Effect）是指某个特定SNP（单核苷酸多态性）对表型的影响。\n\n**因果效应是如何得到的？**\n\n因果效应的大小通常与表型的遗传率（heritability）相关。遗传率 $H_g^2$ 是指表型方差中由基因因素解释的部分。在模拟表型时，我们使用这种遗传率来控制因果效应的分布。\n\n因果效应 $\\text{Effect}_i$ 一般会从一个正态分布中抽取，分布的方差通常与遗传率、样本量以及SNP的数量有关。公式为：\n$$\n\\text{Effect}_i = \\mathcal{N}\\left( 0, \\frac{H_g^2}{n \\cdot p} \\right)\n$$\n其中：\n- $\\mathcal{N}(0, \\sigma^2)$ 是均值为零，方差为 $\\sigma^2$ 的正态分布；\n- $n$ 是SNP的数量；\n- $p$ 是有非零因果效应的SNP的比例；\n- $H_g^2$ 是遗传率，决定了表型中由基因效应解释的方差。\n\n**如何从分布中生成因果效应？**\n\n假设我们有3个SNP，且表型的遗传率 $H_g^2 = 0.5$，有80%的SNP是有因果效应的。我们可以从一个均值为0、标准差为 $\\frac{H_g^2}{n \\cdot p}$ 的正态分布中抽取因果效应值。\n\n假设我们的目标是模拟因果效应，并且我们知道：\n- $n = 3$（SNP的数量），\n- $p = 0.8$（80%的SNP有效应），\n- $H_g^2 = 0.5$（遗传率）。\n\n则每个SNP的因果效应可以从如下正态分布中抽取：\n$$\n\\text{Effect}_i \\sim \\mathcal{N}\\left( 0, \\frac{0.5}{3 \\times 0.8} \\right) = \\mathcal{N}(0, 0.2083)\n$$\n\n这意味着每个SNP的因果效应会从均值为0、方差为0.2083的正态分布中抽取。模拟结果可能是：\n- $\\text{Effect}_1 = 0.5$（从分布中抽取的正效应），\n- $\\text{Effect}_2 = -0.3$（从分布中抽取的负效应），\n- $\\text{Effect}_3 = 0.1$（从分布中抽取的小正效应）。\n\n假设遗传方差 $H_g^2 = 0.4$，噪声项 $\\epsilon_j$ 服从正态分布 $\\mathcal{N}(0, 1 - H_g^2)$。\n\n表型值 $y_j$ 是通过将每个SNP的标准化基因型 $Z_{j,i}$ 和该SNP的因果效应 $\\text{Effect}_i$ 进行线性组合得到的。再加上一个噪声项 $\\epsilon_j$：\n\n$$\ny_j = \\sum_{i=1}^{n} Z_{j,i} \\cdot \\text{Effect}_i + \\epsilon_j\n$$\n\n其中：\n- $\\text{Effect}_1 = 0.5$\n- $\\text{Effect}_2 = -0.3$\n- $\\text{Effect}_3 = 0.1$\n\n对于样本1，表型值 $y_1$ 的计算如下：\n\n$$\ny_1 = (1.732 \\times 0.5) + (-1.414 \\times -0.3) + (-2.309 \\times 0.1) + \\epsilon_1\n$$\n假设噪声项 $\\epsilon_1 = 0.2$，那么：\n\n$$\ny_1 = 0.866 + 0.424 - 0.231 + 0.2 = 1.259\n$$\n类似地，可以计算样本2的表型值。\n\n通过这个低维示例，演示了如何初始化等位基因频率，计算协方差矩阵，生成基因型数据，并最终模拟表型值。这个过程是基于正态分布、协方差矩阵、基因型效应以及噪声项的线性组合来模拟人群中的表型数据。\n\n在实际应用中，需要更多的SNP、样本以及更复杂的基因型和表型之间的关系。\n\n## 程序模拟\n\nR代码模拟：\n\n```R\n# 加载必需的R包\nlibrary(MASS)    # 包含许多统计和线性模型的函数\nlibrary(hapsim)  # 用于模拟基因型数据和生成单倍型数据\nlibrary(bigsnpr) # 处理大规模基因组数据，尤其是单核苷酸多态性（SNP）数据\nlibrary(bigreadr) # 用于处理大型数据集，帮助高效读取和处理数据\n\n#' 基于LD矩阵和等位基因频率模拟基因型数据\n#' @param snps_num 需要模拟的SNP数量\n#' @param sample_size 样本量\n#' @param chr 染色体号（默认：1）\n#' @return 包含模拟基因型数据及相关信息的列表\ngenotypeSim <- function(snps_num, sample_size, chr=1) {\n  # 加载参考数据\n  map_ldref <- readRDS(\"map.rds\")\n  LD_ref <- readRDS(\"LD_chr1.rds\")\n  \n  # 筛选指定染色体的数据\n  map_ldref <- map_ldref[map_ldref$chr == chr,]\n  \n  # 随机选择一段连续的SNP区域\n  start_sim <- max(1, as.integer(runif(1) * (dim(map_ldref)[1] - snps_num)))\n  end_sim <- start_sim + snps_num - 1\n  \n  \n  # 提取选定SNP的相关数据\n  map_sim <- map_ldref[seq(start_sim, end_sim),]\n  cor_sim <- LD_ref[seq(start_sim, end_sim), seq(start_sim, end_sim)]\n  \n  # 使用hapsim包计算协方差矩阵\n  N <- snps_num\n  C <- cor_sim\n  P <- map_sim$af_UKBB  # 等位基因频率\n  Q <- qnorm(P)\n  \n  # 使用hapsim的C函数计算协方差矩阵\n  # .C() 是一个允许R调用C语言函数的接口，它可以将R数据转换为C语言的数据格式，并将计算结果返回给R\n  vmat <- .C(\"covariance\", \n             as.integer(N), \n             as.double(C), \n             as.double(P), \n             as.double(Q), \n             rlt = as.double(as.matrix(rep(0, N*N))), \n             PACKAGE = \"hapsim\")$rlt\n  \n  V <- matrix(vmat, nrow = N, ncol = N)\n  if (!checkpd(V)) V <- makepd(V)  # 确保矩阵正定\n  \n  # 创建用于模拟的数据列表\n  x <- list(freqs = P, cor = C, cov = V)\n  \n  # 生成单倍型数据并转换为双倍型\n  y <- haplosim(sample_size, x)\n  y$data <- 2 - y$data - y$data[sample(seq(sample_size), sample_size),]\n  \n  return(y)\n}\n\n#' 模拟GWAS汇总统计量\n#' @param snps_num SNP数量\n#' @param sample_size 样本量\n#' @param filename 输出文件名前缀\n#' @param trait 性状类型（\"quantity\"数量性状或\"quality\"质量性状）\n#' @param Hg2 遗传力\n#' @param p 致病变异比例\n#' @param prevelence 疾病患病率（用于质量性状）\ngwasSummarySim <- function(snps_num, sample_size, filename=\"default\", \n                           trait=\"quantity\", Hg2=0.03, p=0.01, prevelence=0.1) {\n  # 生成基因型数据\n  y <- genotypeSim(snps_num, sample_size)\n  \n  # 使用稀疏模型生成因果效应\n  causal_effect <- rnorm(snps_num, 0, sqrt(Hg2/(snps_num*p)))\n  causal_effect[runif(snps_num, 0, 1) > p] <- 0  # 将非致病变异效应设为0\n  \n  # 标准化基因型\n  X <- t((t(y$data) - 2 * y$freqs)/(sqrt(2 * y$freqs*(1 - y$freqs))))\n  \n  # 生成表型得分\n  phenotype_score <- colSums(apply(y$data, MARGIN=1, \n                                   FUN=function(X){return(X * causal_effect)})) + \n    rnorm(sample_size, 0, sqrt(1-Hg2))\n  \n  # 将表型值和基因型数据合并\n  phenotype_data <- data.frame(phenotype = phenotype_score)\n  genotype_data <- as.data.frame(t(y$data))  # 转置基因型数据，以每行表示一个样本\n  \n  # 合并表型和基因型数据\n  combined_data <- cbind(phenotype_data, genotype_data)\n  \n  # 保存合并后的数据为CSV\n  write.csv(combined_data, paste0(filename, \"_genotype_phenotype.csv\"), row.names = FALSE)\n  \n  # 初始化结果数据框\n  gwas_summary <- data.frame(matrix(0, nrow=snps_num, ncol=4))\n  names(gwas_summary) <- c(\"BETA\", \"SE\", \"Zscore\", \"P\")\n  \n  if(trait == \"quantity\") {\n    # 数量性状分析\n    for(i in seq(snps_num)) {\n      relation <- lm(phenotype_score ~ y$data[,i])\n      gwas_summary[i,] <- summary(relation)$coefficients[2,]\n    }\n  } else {\n    # 质量性状分析\n    threshold <- quantile(phenotype_score, 1 - prevelence)\n    phenotype <- ifelse(phenotype_score > threshold[1], 1, 0)\n    \n    for(i in seq(snps_num)) {\n      relation <- glm(phenotype ~ y$data[,i], family=binomial())\n      gwas_summary[i,] <- summary(relation)$coefficients[2,]\n    }\n  }\n  \n  # 保存结果\n  write.csv(gwas_summary, paste0(filename, \"_gwasSummary.csv\"))\n  \n  # 记录关键信息并保存\n  heritability <- Hg2                      # 记录遗传力\n  disease_variants <- p                    # 记录致病变异比例\n  \n  # 创建包含关键信息的数据框\n  metadata <- data.frame(\n    heritability = heritability,\n    disease_variants = disease_variants,\n    causal_effect = paste(round(causal_effect, 4), collapse = \",\")  # 将因果效应存储为逗号分隔的字符串\n  )\n  \n  # 保存关键信息为CSV\n  write.csv(metadata, paste0(filename, \"_metadata.csv\"), row.names = FALSE)\n  \n  return(gwas_summary)\n}\n```\n\nJava模拟的代码已上传至 github ：\n\n[https://github.com/luoying2002/Genotype-Phenotype-Simulation](https://github.com/luoying2002/Genotype-Phenotype-Simulation)\n\n```java\npublic static void main(String[] args) throws IOException {\n\n        String basePath = \"/Users/yiguoshabi/Desktop/这是真研究/QuantTraitPredictor/resources/simulation/\";\n\n        String CCF_MAP = basePath + \"map.ccf\";\n        String LD_chr1 = basePath + \"LD_chr1.ccf\";\n\n        int CHR = 1;\n        int N = 100;\n        int snpsNum = 1000;\n        double modifyRate = 0.01;\n        double Hg2 = 0.6;\n        double p = 0.1;\n\n        GenotypeSim genotypeSim = new GenotypeSim(CCF_MAP, LD_chr1, CHR, N, snpsNum, modifyRate);\n\n        PhenotypeSim phenotypeSim  = new PhenotypeSim(genotypeSim, Hg2, p);\n\n        phenotypeSim.exportAll(basePath + \"simulation\");\n\n        phenotypeSim.gwasSummary2csv(basePath + \"simulation_gwas_summary.csv\");\n\n    }\n```\n\n运行此程序：\n![image-20250216172317151](/images/assets//image-20250216172317151.png)\n\n在R中，绘制QQ图检验模拟的好坏：\n\n```R\nlibrary(qqman)\ngwasSummary <- \"simulation_gwas_summary.csv\"\n# 读取 CSV 文件\ngwas_data <- read.csv(gwasSummary, fileEncoding = \"UTF-8\", stringsAsFactors = FALSE)\n# 查看数据\nhead(gwas_data)\nqq(gwas_data$P)\n```\n\n结果：\n![image-20250216173434058](/images/assets//image-20250216173434058.png)\n\n整体效果还是可以的。\n","categories":["医学遗传学"]},{"title":"递归算法的时间复杂度和空间复杂度分析","url":"/2025/02/10/r45xunj6/","content":"# 递归算法\n\n递归算法是一种通过`函数调用自身`来解决问题的方法。它将复杂问题分解为`相似的子问题`，直到达到一个可以直接求解的简单情况（称为“基线条件”）。递归的核心思想是**自我重复与逐层简化**，常见于树结构遍历、分治算法等场景。\n\n# 基础理论\n\n在分析递归算法的时间复杂度之前，我们需要知道几个基础理论，递归的求解路线本质上是一个树结构，可以化为一个树结构来分析递归深度和调用次数：\n\n1. 对于深度为 $d$ 的 $k$ 叉树（$d$ 从0开始，$k>1$），最多有$k^{d+1}-1$个节点数量；\n2. 对于问题规模n，每次k分递归（比如，二分递归），得到的树的深度为 $log_kn$（下文默认向下取整），深度为 $log_kn$ 的 $k$ 叉树，总节点数量$m = k^{log_kn + 1} - 1=kn-1$，也就是线性近似于 $n$；\n3. 递归函数代码中，出现 $k$ 个自调用函数，对应的递归树就是 $k$ 叉树；\n\n请注意，一般来说，一个节点对应一次递归调用，但是不同深度的节点对应的调用，时间复杂度不一定相同。\n\n# 时间复杂度\n\n我们写几个递归函数，来举例如何分析时间复杂度。\n\n首先，网上很多方法都会提到这个公式：**递归的时间复杂度 = 递归调用总次数 $\\times$ 单次调用函数中的时间复杂度**。\n\n这个公式在`不同深度的节点对应的调用的时间复杂度都一样`的情况下，没有问题，但是如果单次调用函数中的时间复杂度不同，那就会出问题，比如说，这个公式解释不了为什么`归并排序`的时间复杂度是$O(n~log_2n)$。\n\n本质上，这个公式只是个特例，即每次调用函数的时间复杂度完全相同。作为一般化方法，这里给出递归的通用时间复杂度计算公式：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} T(j)\n$$\n其中$D$为递归树的所有节点（即所有递归调用的集合），$d_i$为深度为 $i$ 的所有节点（即第$i$层树的所有节点的集合），$T(j)$表示某个节点 $j$ 的时间复杂度。\n\n这个公式的核心含义是：**计算递归树所有节点的时间复杂度之和**。\n\n在实际分析中，我们遵循以下步骤：\n\n1. `出`现了几个自调用函数？以决定递归树是几叉树；\n2. 递归树的`深`度是多少？\n3. `单`次调用的复杂度是多少？\n4. `总`时间复杂度是多少？\n\n## 斐波那契数列\n\n```c++\nclass Solution {\n  public:\n    int fib(int n) {\n      if (n < 2) return n;\n      return fib(n - 1) + fib(n - 2);\n    }\n};\n```\n\n这是斐波那契数列的递归算法实现，时间复杂度是多少呢？\n\n1. 首先看出现了几个自调用函数，显然是两个：`fib(n-1), fib(n-2)`，因此递归树是一个二叉树；\n2. 然后看递归树的深度，显然是 $n$；\n3. 所有节点对应的调用函数的时间复杂度都相同，均为$O(1)$；\n\n根据二叉树的性质，第 $i$ 层的节点数量为 $2^i$，根据公式求解：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{n}2^iO(1)=O(1)\\sum_{i=0}^{n}2^i\\simeq O(2^n)\n$$\n因此该算法的时间复杂度为$O(2^n)$。\n\n## 求x的n次方\n\n```c++\nint func1(int x, int n) {\n    int result = 1;\n    for (int i = 0; i < n; i++) {\n        result = result * x;\n    }\n    return result;\n}\n```\n\n求$x^n$，当然这里只是循环，不是递归，由于只有一个for循环，因此时间复杂度就是$O(n)$。\n\n第一种递归算法：\n\n```c++\nint func1(int x, int n) {\n    if (n == 0) {\n        return 1;\n    }\n    return func1(x, n - 1) * x;\n}\n```\n\n时间复杂度是多少呢？\n\n1. 首先看出现了几个自调用函数，显然是1个：`func1(x, n-1)`，因此递归树是一叉树（即链表结构）；\n2. 然后看递归树的深度，显然是 $n$；\n3. 单次调用函数中，时间复杂度为常数操作（一次乘法操作）。\n\n一叉树，每层节点数量固定为1，列公式：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{n}O(1)\\simeq O(n)\n$$\n因此该算法的时间复杂度为$O(n)$。\n\n这个复杂度是可以优化，比如：\n\n```c++\nint func2(int x, int n) {\n    if (n == 0) return 1;\n    if (n == 1) return x;\n\n    if (n % 2 == 1) {\n        return func2(x, n / 2) * func2(x, n / 2)*x;\n    }\n    return func2(x, n / 2) * func2(x, n / 2);\n}\n```\n\n这个算法的时间复杂度是多少呢？\n\n1. 首先看出现了几个自调用函数，显然是两个：`func2(x, n / 2)`（调用了两次），因此递归树是二叉树；\n2. 然后看递归树的深度，根据前面提到的基础理论，对于二分递归，递归树深度为 $log_2n$；\n3. 单次调用函数中，时间复杂度为常数操作。\n\n二叉树的性质，第 $i$ 层的节点数量为 $2^i$（ $i$ 从0开始），故\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{log_2n}2^iO(1)=O(1)\\sum_{i=0}^{log_2n}2^i= O(2n-1)\n$$\n因此该算法的时间复杂度为$O(2n-1) = O(n)$。\n\n当然这里只是展示复杂度的计算过程，这个算法明显是可以把`func2(x, n / 2)`提取出来只算一次的：\n\n```c++\nint func3(int x, int n) {\n    if (n == 0) return 1;\n    if (n == 1) return x;\n    int t = func3(x, n / 2);\t// 提取出来，只需要算一次\n    if (n % 2 == 1) {\n        return t * t * x;\n    }\n    return t * t;\n}\n```\n\n此时的时间复杂度是多少呢？\n\n1. 首先看出现了几个自调用函数，显然是1个：`func3(x, n / 2)`（调用了两次），因此递归树是一叉树；\n2. 然后看递归树的深度，递归树深度为 $log_2n$；\n\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{log_2n}O(1)\\simeq O(log_2n)\n$$\n\n因此该算法的时间复杂度为$O(log_2n)$。\n\n对于幂运算，最优的时间复杂度就是$O(log_2n)$，但是这个算法还是可以优化的，比如使用迭代代替递归，减少调用栈开销，用位运算代替等：\n\n```c++\nint func3_bit(int x, int n) {\n    int result = 1;\n    while (n > 0) {\n        if (n & 1) {           // 代替 n % 2 == 1\n            result *= x;\n        }\n        x *= x;\n        n >>= 1;              // 代替 n /= 2\n    }\n    return result;\n}\n```\n\n该算法的时间复杂度仍然为 $O(log_2n)$（因为迭代次数为 $log_2n$）。\n\n## 阶乘计算\n\n```c++\nint factorial(int n) {\n    if (n <= 1) return 1;\n    return n * factorial(n - 1);\n}\n```\n\n1. 出现了1次自调用，树结构为一叉树；\n2. 递归深度为 $n$；\n\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{n}O(1)\\simeq O(n)\n$$\n\n因此时间复杂度为：$O(n)$。\n\n## 二分查找\n\n```c++\nint binarySearch(int arr[], int l, int r, int x) {\n    if (l > r) return -1;\n    int mid = l + (r - l) / 2;\n    if (arr[mid] == x) return mid;\n    if (arr[mid] > x) \n        return binarySearch(arr, l, mid - 1, x);\n    return binarySearch(arr, mid + 1, r, x);\n}\n```\n\n1. 出现了1次自调用，树结构为一叉树；\n2. 递归深度为 $log_2n$；\n\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(1)=\\sum_{i=0}^{log_2n}O(1)\\simeq O(log_2n)\n$$\n\n时间复杂度：$O(log_2n$)。\n\n## 归并排序\n\n原理简单介绍一下：\n\n**第一步：分解（Divide）**\n\n```text\n原始数组：[8, 3, 2, 9, 7, 1, 5, 4]\n        ↓ 递归分解\n[8, 3, 2, 9]  [7, 1, 5, 4]\n    ↓              ↓\n[8, 3] [2, 9]  [7, 1] [5, 4]\n  ↓      ↓       ↓      ↓\n[8][3] [2][9]  [7][1] [5][4]\n\n```\n\n**第二步：合并（Merge）**\n\n```text\n[8][3] → [3, 8]    // 比较合并\n[2][9] → [2, 9]    // 比较合并\n[3,8] + [2,9] → [2, 3, 8, 9]  // 有序合并\n\n同理处理右半部分：\n[7][1] → [1, 7]\n[5][4] → [4, 5]\n[1,7] + [4,5] → [1, 4, 5, 7]\n\n最后合并：\n[2,3,8,9] + [1,4,5,7] → [1,2,3,4,5,7,8,9]\n```\n\n归并排序的巧妙之处在于`分治策略`让\"节点数增长\"和\"问题规模缩小\"完美平衡，最终得到 $O(n ~log_2 n)$ 的高效算法。递归算法实现：\n\n```c++\nvoid mergeSort(int arr[], int l, int r) {\n    if (l >= r) return;\n    int mid = l + (r - l) / 2;\n    mergeSort(arr, l, mid);      // T(n/2)\n    mergeSort(arr, mid + 1, r);  // T(n/2)\n    merge(arr, l, mid, r);       // O(n)\n}\n```\n\n其中：\n\n```c++\nvoid merge(int arr[], int l, int mid, int r) {\n    // 创建临时数组\n    vector<int> temp(r - l + 1);\n    int i = l, j = mid + 1, k = 0;\n    // 比较两个有序子数组，选择较小的元素\n    while (i <= mid && j <= r) {\n        if (arr[i] <= arr[j]) {\n            temp[k++] = arr[i++];\n        } else {\n            temp[k++] = arr[j++];\n        }\n    }\n    // 复制剩余元素\n    while (i <= mid) temp[k++] = arr[i++];\n    while (j <= r) temp[k++] = arr[j++];\n    \n    // 将临时数组复制回原数组\n    for (int p = 0; p < k; p++) {\n        arr[l + p] = temp[p];\n    }\n}\n```\n\n这里跟前面的算法不同的是，单次调用的函数体中，merge函数的复杂度为不再是$O(1)$，分析如下：\n\n1. 自调用次数为两次，递归树为二叉树；\n2. 递归深度为 $log_2n$；\n3. 对于第 $i$ 层树，单次调用函数的时间复杂度为 $O(\\dfrac{n}{2^i})$（即跟深度 $i$ 和数据规模 $n$ 有关系）；\n\n同样列公式：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(\\dfrac{n}{2^i})=\\sum_{i=0}^{log_2n}2^iO(\\dfrac{n}{2^i})=\\sum_{i=0}^{log_2n}O(n)\\simeq O(n ~log_2 n)\n$$\n这是归并排序时间复杂度为$O(n~log_2n)$的推导过程。\n\n## 快速排序\n\n来看看比较复杂的快速排序：\n\n```c++\nvoid quickSort(int arr[], int low, int high) {\n    if (low < high) {\n        int pi = partition(arr, low, high);  // O(n)\n        quickSort(arr, low, pi - 1);         // T(k)\n        quickSort(arr, pi + 1, high);        // T(n-k-1)\n    }\n}\n```\n\n**第一步：分区（Partition）**\n\n```text\n原始数组：[8, 3, 2, 9, 7, 1, 5, 4]\n选择基准：4（最后一个元素）\n\n第一次分区：\n小于等于4的元素：[3, 2, 1, 4]\n大于4的元素：[8, 9, 7, 5]\n→ [3, 2, 1, 4, 8, 9, 7, 5]\n基准位置：3（索引从0开始）\n\n递归分区左半部分：[3, 2, 1]\n选择基准：1\n→ [1, 2, 3]\n\n递归分区右半部分：[8, 9, 7, 5]\n选择基准：5\n→ [5, 9, 7, 8] → 继续分区\n```\n\n**第二步：递归排序**\n\n```text\n左子树：[3, 2, 1]\n    ↓ 基准：1\n[1] + [3, 2]\n        ↓ 基准：2\n    [2, 3]\n→ [1, 2, 3]\n\n右子树：[8, 9, 7, 5]\n    ↓ 基准：5\n[5] + [8, 9, 7]\n        ↓ 基准：7\n    [7] + [8, 9]\n            ↓ 基准：9\n        [8, 9]\n→ [5, 7, 8, 9]\n```\n\n**第三步：最终结果**\n\n```text\n左子树结果：[1, 2, 3]\n右子树结果：[5, 7, 8, 9]\n基准元素：4\n\n最终排序结果：[1, 2, 3, 4, 5, 7, 8, 9]\n```\n\n因此，`partition(arr, low, high)` 需要遍历一次元素集，时间复杂度为不再是$O(1)$，继续分析：\n\n1. 自调用次数为2，递归树为二叉树；\n2. 递归树的深度，如果每次都均匀对半分区，那么深度为$log_2n$，如果最差的情况，每次都以最大或者最小元素分区，那么深度接近$n$，此时二叉树退化为链表结构（一叉树）；\n3. 单次调用时间复杂度，如果每次都均匀对半分区，复杂度为$O(\\dfrac{n}{2^i})$（对于第 $i$ 层树），如果每次都以最大或者最小元素分区，复杂度接近$O(n-i)$；\n\n深度为$log_2n$的情况：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(\\dfrac{n}{2^i})=\\sum_{i=0}^{log_2n}2^iO(\\dfrac{n}{2^i})=\\sum_{i=0}^{log_2n}O(n)\\simeq O(n ~log_2 n)\n$$\n深度为$n$的情况：\n$$\nT(n) = \\sum_{d_i\\in D}\\sum_{j\\in d_i} O(n)=\\sum_{i=0}^nO(n-i)\\simeq O(n^2)\n$$\n这是`快速排序`平均时间复杂度为$O(n ~log_2 n)$，最差时间复杂度为$O(n^2)$的推导过程。\n\n## 二叉树遍历\n\n```c++\nvoid inorder(TreeNode* root) {\n    if (root == nullptr) return;\n    inorder(root->left);    // T(n₁)\n    cout << root->val;\n    inorder(root->right);   // T(n₂)\n}\n```\n\n1. 自调用次数为2，递归树为二叉树；\n2. 递归深度为 $n$；\n\n对于这种简单的情形，没必要次次列公式推导，就计算`树的所有节点的时间复杂度之和`就行。\n\n遍历二叉树的时间复杂度为$O(n)$。\n\n## 汉诺塔问题\n\n汉诺塔（Tower of Hanoi）是一个经典的**递归问题和数学谜题**，由法国数学家爱德华·卢卡斯在1883年发明。\n\n### 问题描述\n\n**游戏设置：**\n\n- 有3根柱子（A、B、C）\n- 在柱子A上有n个大小不同的圆盘，按**从上到下从小到大**的顺序叠放\n- 另外两根柱子B和C开始时为空\n\n**目标：**\n将**所有圆盘从柱子A移动到柱子C**\n\n**规则：**\n\n1. 每次只能移动**一个圆盘**\n2. 移动时只能移动**最上面的圆盘**\n3. **大盘不能放在小盘上面**\n\n这个问题的递归解法思路为：\n\n```text\n要将n个盘子从A移到C（借助B）：\n1. 将n-1个盘子从A移到B（借助C）\n2. 将最大的盘子从A移到C\n3. 将n-1个盘子从B移到C（借助A）\n```\n\n代码：\n\n```c++\nvoid hanoi(int n, char from, char to, char aux) {\n    if (n == 1) {\n        cout << \"Move disk 1 from \" << from << \" to \" << to << endl;\n        return;\n    }\n    hanoi(n - 1, from, aux, to);    // T(n-1)\n    cout << \"Move disk \" << n << \" from \" << from << \" to \" << to << endl;\n    hanoi(n - 1, aux, to, from);    // T(n-1)\n}\n```\n\n1. 自调用次数为2，递归树结构为二叉树；\n2. 最大深度为$n$；\n\n计算`树的所有节点的时间复杂度之和`，时间复杂度为$O(2^n)$。\n\n# 习题\n\n## 练习建议\n\n1. **画出递归树**：对于每个算法，尝试画出递归调用的树状结构\n2. **计算递归深度**：确定递归的最大深度\n3. **分析每层工作量**：计算递归树每层的时间复杂度\n\n## 数组求和\n\n```c++\nint arraySum(int arr[], int n) {\n    if (n <= 0) return 0;\n    return arr[n - 1] + arraySum(arr, n - 1);\n}\n```\n\n**时间复杂度分析：**\n- 单次递归调用\n- 递归深度：$n$\n- 时间复杂度：$O(n)$\n\n## 二叉树高度计算\n\n```c++\nint treeHeight(TreeNode* root) {\n    if (root == nullptr) return 0;\n    int leftHeight = treeHeight(root->left);\n    int rightHeight = treeHeight(root->right);\n    return max(leftHeight, rightHeight) + 1;\n}\n```\n\n**时间复杂度分析：**\n- 每个节点访问一次\n- 时间复杂度：$O(n)$ （$n$ 为节点数）\n\n## 全排列生成\n\n```c++\nvoid permute(vector<int>& nums, int start, vector<vector<int>>& result) {\n    if (start == nums.size()) {\n        result.push_back(nums);\n        return;\n    }\n    for (int i = start; i < nums.size(); i++) {\n        swap(nums[start], nums[i]);\n        permute(nums, start + 1, result);\n        swap(nums[start], nums[i]); // 回溯\n    }\n}\n```\n\n**时间复杂度分析：**\n- 递归深度：$n$\n- 每层分支数递减：$n, n-1, n-2, ..., 1$\n- 时间复杂度：$O(n!)$\n\n## 子集生成\n\n```c++\nvoid subsets(vector<int>& nums, int index, vector<int>& current, vector<vector<int>>& result) {\n    if (index == nums.size()) {\n        result.push_back(current);\n        return;\n    }\n    // 不包含当前元素\n    subsets(nums, index + 1, current, result);\n    // 包含当前元素\n    current.push_back(nums[index]);\n    subsets(nums, index + 1, current, result);\n    current.pop_back(); // 回溯\n}\n```\n\n**时间复杂度分析：**\n- 递归树为完全二叉树\n- 递归深度：$n$\n- 总节点数：$2^n$\n- 时间复杂度：$O(2^n)$\n\n## 快速幂计算\n\n```c++\ndouble power(double x, int n) {\n    if (n == 0) return 1;\n    if (n == 1) return x;\n    \n    double half = power(x, n / 2);\n    if (n % 2 == 0) {\n        return half * half;\n    } else {\n        return half * half * x;\n    }\n}\n```\n\n**时间复杂度分析：**\n- 每次递归问题规模减半\n- 递归深度：$log_2n$\n- 时间复杂度：$O(log_2n)$\n\n## 最大公约数（欧几里得算法）\n\n```c++\nint gcd(int a, int b) {\n    if (b == 0) return a;\n    return gcd(b, a % b);\n}\n```\n\n**时间复杂度分析：**\n- 每次递归参数至少减半\n- 递归深度：$O(log_2(min(a,b)))$\n- 时间复杂度：$O(log_2(min(a,b)))$\n","categories":["算法基础"]},{"title":"国产之光DeepSeek，比肩ChatGPT？","url":"/2025/01/05/r9y0mne6/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 国产之光DeepSeek，比肩ChatGPT？  https://mp.weixin.qq.com/s/RnX1pCYjf4VjlZPISWj_-Q /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"scGPT：利用生成式AI构建单细胞多组学基础模型","url":"/2024/12/16/vazgz0k2/","content":"\n# 文章链接\n\n> Cui, H., Wang, C., Maan, H., Pang, K., Luo, F., Duan, N., & Wang, B. (2024). scGPT: toward building a foundation model for single-cell multi-omics using generative AI. Nature Methods, 21,1470-1480. [https://doi.org/10.1038/s41592-024-02201-0](https://doi.org/10.1038/s41592-024-02201-0)\n\n# 简介\n\n`scGPT`：提出了一个利用`生成式AI`构建的单细胞多组学基础模型。\n\n# 摘要\n\n生成式预训练模型在语言和计算机视觉等多个领域取得了显著成功。具体而言，大规模多样化数据集与预训练`transformer`的结合已经成为开发基础模型的一种很有前景的方法。基于语言和细胞生物学之间的相似性（文本由词语组成；类似地，细胞由基因定义），我们的研究探索了基础模型在推进细胞生物学和遗传学研究方面的应用潜力。利用蓬勃发展的单细胞测序数据，我们基于生成式预训练`transformer`在超过`3300万`个细胞的数据库上构建了一个单细胞生物学基础模型`scGPT`。我们的研究表明，`scGPT`能有效提取关于基因和细胞的关键生物学见解。通过进一步采用迁移学习，`scGPT`可以针对各种下游应用进行优化以实现卓越性能。这包括细胞类型注释、多批次整合、多组学整合、扰动响应预测和基因网络推断等任务。\n\n# 创新点\n\n1. 首个单细胞组学领域的`基础模型`\n- 首次将大规模预训练`transformer`应用于单细胞组学数据分析\n- 在超过3300万个细胞的数据集上进行预训练\n- 可以通过微调适应多种下游任务\n\n2. 创新的模型架构\n- 设计了特殊的`注意力掩码机制`，可以处理`非序列`的基因表达数据 \n- 同时学习基因和细胞的嵌入表示\n- 支持通过`基因提示`和`细胞提示`进行生成式预测\n\n3. 多功能性和通用性\n- 在多个下游任务中实现了最先进的性能，包括:\n  - 细胞类型注释\n  - 基因扰动响应预测\n  - 多批次整合\n  - 多组学整合\n  - 基因网络推断\n- 展现了强大的`零样本`和`少样本`迁移学习能力\n\n4. 可解释性\n\n- 通过注意力机制学习`基因-基因相互`作用\n- 可以揭示特定细胞状态下的基因网络激活模式\n- 发现的基因调控关系与已知生物学知识高度吻合\n\n# 主要内容\n\n## 读前须知\n\n1. 论文解读尽可能的还原原文，若有不恰当之处，还请见谅；\n2. 排版上，插图会尽量贴近出处，而`补充图表`均在文末“`补充信息`”的下载链接中；\n3. 左边👈有目录，可自行跳转至想看的部分；\n4. 部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（`Receptive field`）。请注意，仅首次出现会标明；\n## 引言\n\n单细胞RNA测序（`scRNA-seq`）通过实现对不同细胞类型的精细表征并推进我们对疾病发病机制的理解，为细胞异质性探索、谱系追踪、致病机制阐明以及最终的个性化治疗策略铺平了道路。`scRNA-seq`的广泛应用产生了诸如人类细胞图谱等全面的数据图谱，现在已经包含数千万个细胞。测序技术的最新进展促进了数据模态的多样性，并将我们的认知从基因组学扩展到表观遗传学、转录组学和蛋白质组学，从而提供多模态的见解。这些突破也带来了新的研究问题，如`参考映射`、`扰动预测`和`多组学整合`。开发能够有效利用、增强和适应测序数据快速扩张的方法是至关重要的。\n\n> `参考映射（Reference Mapping）`：将测序数据比对到已知的参考基因组序列上的过程；\n>\n> `扰动预测（Perturbation Prediction）`：预测对生物系统施加干扰后可能产生的变化或响应；\n>\n> `多组学整合（Multi-omics Integration）`：将不同层面的组学数据（如基因组学、转录组学、蛋白组学等）进行综合分析，以获得系统性的认识。\n\n解决这一挑战的一个有前景的方法是生成式预训练基础模型。基础模型通常基于`self-attention transformer`架构构建，因其在学习数据表征方面的有效性而被广泛采用，这类模型在大规模、多样化数据集上进行预训练，可以轻松适应各种下游任务。此类模型最近在多个领域取得了空前的成功，典型例子包括`计算机视觉`和`自然语言生成`领域的`DALL-E 2`和`GPT-4`，以及最近用于生物应用的`Enformer`。\n\n> `生成式预训练模型（Generative Pre-trained Models）`：先在大规模数据上进行无监督预训练，再针对特定任务微调的人工智能模型，能够生成文本、图像等内容。典型代表如GPT、BERT等。这类模型通过\"预训练-微调\"的范式，可以学习到通用的知识表示，并应用于各种下游任务。\n\n更有趣的是，这些生成式`预训练模型`始终优于从头训练的特定任务模型。这表明这些模型在相应领域获得了与任务无关的知识理解，启发我们探索其在单细胞组学研究中的应用。然而，当前单细胞研究中的机器学习方法较为分散，具体模型仅专注于特定的分析任务。因此，每项研究使用的数据集在广度和规模上往往受限。为了应对这一局限性，需要一个在大规模数据上预训练的基础模型，能够理解不同组织中基因之间的复杂相互作用。\n\n为了增强单细胞测序数据的建模，我们从自然语言生成(`NLG`)中的自监督预训练工作流程获得灵感，其中`self-attention transformer`在建模输入词语标记方面表现出了强大的能力。正如文本由词语构成，细胞可以通过基因及其编码的蛋白质产物来表征。通过同时学习基因和细胞嵌入，我们可以更好地理解细胞特征。此外，`transformer`输入标记的灵活性使其能够轻松整合额外的特征和元信息。最近在`Geneformer`中也探索了这一方向，其中基于`transformer`的编码器通过按表达水平排序的基因进行训练，展示了细胞类型和基因功能预测的能力。在此基础上，我们认为有必要专门为`非序列组学数据`定制预训练工作流程，并扩展其在更广泛任务中的应用。\n\n在这项工作中，我们通过在超过`3300万`个细胞上进行预训练，提出了单细胞基础模型`scGPT`。我们建立了一个专门用于`非序列组学`数据的统一生成式预训练工作流程，并调整了`transformer`架构以同时学习细胞和基因表示。此外，我们提供了具有特定任务目标的微调流程，旨在促进预训练模型在各种不同任务中的应用。\n\n我们的模型`scGPT`通过以下三个关键方面展示了单细胞基础模型的变革性潜力：\n\n1. `scGPT`代表了一个大规模的生成式基础模型，能够跨多个下游任务进行`迁移学习`。通过在细胞类型注释、基因扰动预测、批次校正和多组学整合等任务上达到最先进的表现，我们展示了\"`普适预训练，按需微调`\"方法作为单细胞组学计算应用的通用解决方案的有效性。\n\n2. 通过比较微调和原始预训练模型的`基因嵌入`和`注意力权重`，`scGPT`揭示了关于基因-基因相互作用的宝贵生物学见解，这些相互作用与各种条件相关，如细胞类型和扰动状态。\n\n3. 我们的观察揭示了一个规模效应：更大的预训练数据量能产生更优的预训练嵌入，从而进一步提升下游任务的表现。这一发现强调了一个令人兴奋的前景：基础模型可以随着研究社群中可用测序数据的扩展而持续改进。\n\n\n基于这些发现，我们预见采用预训练基础模型将大大拓展我们对细胞生物学的理解，并为未来的发现奠定坚实基础。发布`scGPT`模型和工作流程的目的是赋能并加速这些领域及其他领域的研究。\n\n## 结果\n\n### 单细胞 transformer 基础模型概述\n\n单细胞转录组测序能够在单个细胞水平上分析分子特征。例如，`scRNA-seq`测量了`RNA`转录本的丰度，为理解细胞身份、发育阶段和功能提供了洞见。我们介绍了`scGPT`，一个采用生成式预训练方法的单细胞领域基础模型。核心模型包含带有多头注意力的`堆叠转换器层`，可以同时生成细胞和基因嵌入（方法部分）。\n\n`scGPT`包含两个训练阶段：首先在大型细胞图谱上进行通用预训练，然后在较小数据集上针对特定应用进行微调（图1a-c）。在预训练阶段，我们引入了专门设计的注意力掩码和生成式训练流程，以自监督的方式训练`scGPT`来联合优化细胞和基因表示（方法部分）。这种技术解决了基因表达的非顺序性质，以适应`NLG`框架的顺序预测。在训练过程中，模型逐渐学会基于细胞状态或基因表达线索来生成细胞的基因表达。在微调阶段，预训练模型可以适应新数据集和特定任务（方法部分）。我们提供了灵活的微调流程，适用于各种基本任务，包括带批次校正的`scRNA-seq`整合、细胞类型注释、多组学整合、扰动预测和基因调控网络（`GRN`）推断。\n\n![image-20241217213225509](/images/assets//image-20241217213225509.png)\n\n为了收集多样化和大量的测序数据用于`scGPT`的自监督预训练，我们从`CELLxGENE`收集库（[https://cellxgene.cziscience.com/](https://cellxgene.cziscience.com/)）组装了来自正常（非疾病）条件下3300万个人类细胞的`scRNA-seq`数据（图1d）。这个全面的数据集包含了来自51个器官或组织和441项研究的各种细胞类型，提供了人体中细胞异质性的丰富表示。\n\n预训练后，我们使用统一流形近似和投影（`UMAP`）可视化对3300万个细胞中10%的人类细胞的`scGPT`细胞嵌入（图1e）。产生的`UMAP`图展示出引人注目的清晰度，不同颜色代表的细胞类型准确地聚集在局部区域和簇中。考虑到数据集包含超过400项研究，这表明预训练具有提取生物变异的显著能力。\n\n> `UMAP (Uniform Manifold Approximation and Projection)`：一种`非线性降维算法`，通过构建高维数据的拓扑结构并将其映射到低维空间，能更好地保持数据的局部和全局结构。相比`t-SNE`运行更快，更适合处理大规模数据，在单细胞数据分析中应用广泛。\n\n### scGPT提高细胞类型注释的精确度\n\n为了针对细胞类型注释微调预训练的`scGPT`，一个神经网络分类器以`scGPT`转换器输出的细胞嵌入作为输入，并输出细胞类型的分类预测。整个模型在具有专家注释的参考数据集上使用交叉熵进行训练，然后用于预测保留的查询数据分区中的细胞类型。\n\n我们在多个数据集上进行了广泛的实验来评估`scGPT`在细胞类型注释方面的表现。首先，我们调整`scGPT`来预测人类胰腺数据集中的细胞类型。我们在图2a中可视化了预测结果。值得注意的是，`scGPT`对混淆矩阵中显示的大多数细胞类型都达到了较高的精确度（>0.8）（图2b），只有在参考分区中细胞数量极少的罕见细胞类型除外。例如，在10,600个参考集细胞中，肥大细胞和主要组织相容性（`MHC`）II类细胞类型的细胞数量少于50个。图2c可视化了微调后`scGPT`中的细胞嵌入，这些嵌入展示了高度的细胞类型内部相似性。\n\n![image-20241217213253221](/images/assets//image-20241217213253221.png)\n\n接下来，我们在一个多发性硬化症（`MS`）疾病数据集上测试了该模型。该模型在健康人类免疫细胞的参考分区上进行微调，并评估了对`MS`状态细胞的预测。微调后的模型与原始研究提供的细胞类型注释显示出强烈的一致性，并达到了约0.85的高准确度（图2f,g）。\n\n此外，我们将该模型应用于一个更具挑战性的情况，即使用`肿瘤浸润骨髓样细胞`数据集来进行跨疾病类型的泛化。该模型在参考数据分区的6种癌症类型上进行微调（方法部分），并在3种未见过的癌症类型的查询分区上进行评估（图2d）。结果显示在区分免疫细胞亚型方面具有高精确度（图2e,h），并且细胞嵌入在不同细胞类型之间表现出清晰的可分性（图2i）。最后，我们在这三个数据集上对微调的`scGPT`与其他两种最近的基于转换器的方法`TOSICA`和`scBERT`进行了基准测试（方法部分）。`scGPT`在所有分类指标中，包括准确度、精确度、召回率和宏观F1值，都持续优于其他方法（图2j）。\n\n除了细胞类型分类外，我们进一步探索了`scGPT`通过参考映射将未见过的查询细胞投影到参考数据集的能力（补充说明1和补充图11）。我们发现，仅使用预训练权重的`scGPT`就达到了与现有方法相当的性能。通过在参考数据集上进行微调可以进一步提高性能。\n\n### scGPT预测未见过的基因扰动响应\n\n近期测序和基因编辑技术的进展极大地促进了大规模扰动实验的开展，使得我们能够表征细胞对各种`基因扰动的响应`。这种方法在发现新的基因相互作用和推进再生医学方面具有巨大的潜力。然而，潜在基因扰动的巨大组合空间很快就会超出实验可行性的实际限制。\n\n为了克服这一限制，`scGPT`可以利用已知实验中获得的细胞响应知识，并将其外推以预测未知响应。在基因维度上使用`自注意力机制`，使得模型能够编码被扰动基因与其他基因响应之间的复杂相互作用。通过利用这种能力，`scGPT`可以有效地从现有实验数据中学习，并准确预测基因表达响应中未见过的扰动。\n\n#### 未见过的基因扰动预测\n\n对于扰动预测任务，我们使用三个白血病细胞系的`Perturb-seq`数据集来评估我们的模型：`Adamson`数据集包含87个单基因扰动，经过筛选的`Replogle`数据集包含1,823个单基因扰动，以及`Norman`数据集包含131个双基因扰动和105个单基因扰动。为了评估`scGPT`的扰动预测能力，我们在一部分扰动上微调模型，以根据输入的对照细胞状态和干预基因来预测扰动后的表达谱。\n\n接下来，模型在涉及未见过基因的扰动上进行测试（方法部分）。我们计算了`Pearson delta`指标，该指标衡量预测和观察到的扰动后表达变化之间的相关性。此外，我们还报告了每个扰动中前20个变化最显著的基因的这一指标，表示为差异表达基因上的`Pearson delta`。有关指标计算的详细信息，请参见补充说明12。我们对`scGPT`和其他两种方法`GEARS`和线性回归基准进行了性能比较（方法部分）。我们的结果表明，`scGPT`在所有三个数据集上都达到了最高分数（图3a和补充表6）。特别是，`scGPT`在预测扰动后的变化方面表现出色，持续超过其他方法5-20%的优势。此外，我们在图3b中可视化了`Adamson`数据集中两个示例扰动的预测，其中`scGPT`准确预测了所有前20个差异表达基因的表达变化趋势。\n\n![image-20241217213352057](/images/assets//image-20241217213352057.png)\n\n预测未见过的扰动响应的能力可以扩展扰动实验的范围，如图3c所示。为了探索预测的扰动响应的扩展空间，我们使用`Norman`数据集进行聚类分析，以验证生物相关的功能信号。原始的`Perturb-seq`研究涵盖了针对105个基因的236个扰动。\n\n然而，考虑到这些目标基因的所有可能组合，总共有5,565个潜在的扰动，这表明实验的`Perturb-seq`数据仅代表了整个扰动空间的5%。因此，我们使用经过微调的`scGPT`来扩展扰动体外预测，并在图3d中使用`UMAP`可视化了每个扰动的预测平均响应。使用原始研究中的注释，我们发现相同功能组的扰动条件聚集在相邻区域（补充图4）。\n\n接下来，我们使用`Leiden`对预测的表达进行聚类，并观察到这些簇与扰动组合中的\"主导基因\"具有高度关联。例如，与`KLF1`基因相关的圈出的簇表明，该簇中的数据点经历了涉及`KLF1`与另一个基因的组合扰动（即`KLF1 + X`）。以`KLF1`和`CNN1`簇为两个例子，我们进一步验证了相应的预测表达仅在这些区域高度表达（图3e），这与`Norman`数据集中`CRISPRa`（`CRISPR`介导的转录激活）`Perturb-seq`实验的预期结果一致。主导基因簇展示了`scGPT`揭示扰动组合之间关联的能力。\n\n> `Leiden聚类`：一种社区检测/聚类算法，是Louvain算法的改进版本，通常用于单细胞数据分析。它通过优化模块度（modularity）来识别网络中的社区结构，比Louvain算法更稳定，能够避免产生不连通的聚类，在保证聚类质量的同时提高运算效率。\n\n#### 体外逆向扰动预测\n\n`scGPT`还能够根据给定的导致的细胞状态预测基因扰动的`来源`，我们将其称为`体外逆向扰动预测`。一个理想的进行这种逆向预测的预测模型可以用于推断谱系发育的重要驱动基因，或者帮助发现潜在的治疗基因靶点。\n\n为了展示逆向扰动预测的有效性，我们使用了`Norman`数据集的一个子集，重点关注涉及20个基因的扰动（图3f）。这个组合空间总共包含210个单基因或双基因扰动组合。我们使用39个（18%）已知扰动（图3f中的训练组）来微调`scGPT`。然后，我们在未见过的扰动细胞状态的查询上测试模型，`scGPT`成功预测了（在排名靠前的预测中）能够产生观察结果的扰动来源。例如，`scGPT`将`CNN1 + MAPK1`基因的正确扰动排在一个测试示例的首位预测，另一个示例中将`FOSB + UBASH3B`基因的正确扰动排在第二位预测（图3f）。\n\n总体而言，`scGPT`在前1预测中识别了平均91.4%的相关扰动（7个中的6.4个）（图3g中的蓝色条），在前8预测中识别了65.7%的正确扰动（7个测试案例中的4.6个）（图3g中的粉色条），大幅优于`GEARS`和差异基因基准。我们设想这些预测可以用于通过最大化达到目标细胞状态的可能性来规划扰动实验。与随机尝试相比，在这个子集中210个可能的扰动中平均需要105.5次尝试，以较少的尝试次数找到正确的基因变化来源为加速发现重要基因驱动因子和优化扰动实验提供了有价值的工具。\n\n### scGPT实现多批次和多组学整合\n\n#### 多批次scRNA-seq整合\n\n整合来自不同批次的多个`scRNA-seq数据集`时，在保留整合数据的生物学变异的同时去除技术批次效应，这是一个独特的挑战。为了整合测序样本，我们采用自监督的方式对`scGPT`进行精调，通过学习统一的细胞表征来恢复被掩码的基因表达（参见`方法`）。\n\n> `批次效应（Batch Effect）`：由非生物学因素造成的系统性技术偏差，例如不同实验时间、不同操作人员、不同实验室或不同仪器设备等导致的数据变异。这种效应会影响数据分析的准确性，需要通过批次校正方法来消除或减少其影响。\n\n在我们的基准测试中，我们将`scGPT`与三种流行的整合方法进行比较：`scVI`、`Seurat`和`Harmony`。评估在三个整合数据集上进行，分别是`COVID-19`（18个批次）、`PBMC 10k`（2个批次）和大脑前嗜皮质(`perirhinal cortex`，2个批次）数据集。在PBMC 10k数据集中，scGPT成功区分了所有细胞类型（图4a）。scGPT出色的整合性能进一步得到了其较高生物学保留得分的支持，`AvgBIO`得分为0.821，比其他方法高出5-10%。`AvgBIO`得分汇总了三个细胞类型聚类指标：归一化互信息（`NMIcell`）、调整兰德指数（`ARIcell`）和平均轮廓宽度（`ASWcell`），详见补充说明12。\n\n> 指标解释：\n>\n> 1. `归一化互信息（NMIcell）`：\n> - 衡量两个聚类结果之间的相似度\n> - 值域在0-1之间，1表示完全一致\n> - 基于信息论，计算两种聚类方案之间共享的信息量\n>\n> 2. `调整兰德指数（ARIcell）`：\n> - 评估两个聚类结果的一致性\n> - 考虑随机聚类的影响，对原始兰德指数进行校正\n> - 值域在-1到1之间，1表示完全一致，0表示随机聚类水平\n>\n> 3. `平均轮廓宽度（ASWcell）`：\n> - 评估聚类的紧密度和分离度\n> - 计算每个样本与同类样本的相似度，与其他类样本的差异度\n> - 值域在-1到1之间，越接近1表示聚类效果越好\n>\n\n值得注意的是，即使没有精调，scGPT在整合`PBMC 10k数据集`时也表现出相当好的性能（补充图5），这突出了预训练的泛化能力。在近嗅皮层数据集（`perirhinal cortex dataset`）中，scGPT与所有其他方法相比保持竞争力（补充图6c）。这一发现突出表明，从全人类数据集学习到的特征可以很好地迁移到特定器官或组织如大脑。此外，scGPT在所有整合指标上始终保持竞争力的得分，并展现出对生物学信号的强大保留能力（补充表3和补充图6、7）。另外，我们还开发了策略来加速整合任务的精调过程，包括冻结特定模型层和排除无表达的基因，同时保持与原始方法相当的结果（补充说明3）。\n\n#### 单细胞多组学整合\n\n单细胞多组学（`scMultiomic`）数据结合了遗传调控的多个视角，如表观遗传、转录组和翻译活性，在聚合细胞表征的同时保留生物学信号方面提出了独特的挑战。scGPT通过有效提取跨不同组学数据集的整合细胞嵌入来解决这一挑战。在`10x Multiome PBMC`数据集（包括联合基因表达和染色质可及性测量）的案例中，我们将scGPT与两种最新的方法进行比较，即`scGLUE`和`Seurat`（v.4）。如图4b所示，scGPT是唯一成功为`CD8+ naive`细胞生成独特聚类的方法。\n\n![image-20241217213453682](/images/assets//image-20241217213453682.png)\n\n接下来，我们在来自骨髓单核细胞（`BMMCs`）的配对基因表达和蛋白质丰度数据集上测试了scGPT，如图4c所示。该数据集具有额外的复杂性，包括大量数据（90,000个细胞）、多个批次（12个供体）和细粒度的亚组注释（48种细胞类型）。scGPT比Seurat（v.4）呈现出更清晰的聚类结构，`AvgBIO`得分提高了9%。值得注意的是，scGPT能够将`CD4+ naive T`细胞和`CD4+ activated T`细胞分为两个不同的聚类。它还将整合β7+活化的CD4+ T细胞与其他CD4+ T细胞区分开来，这进一步证实了该模型能够捕捉免疫细胞亚群之间的微妙差异。\n\n在镶嵌数据整合设置中，测序样本共享一些（但不是全部）数据模态，这给整合方法带来了挑战。为了展示scGPT在这种情况下的能力，我们以`ATAC with select antigen profiling`（`ASAP`）人类PBMC数据集为例。该数据集由四个测序批次组成，包含三种数据模态。在与`scMoMat`的基准实验中，scGPT展示出优越的批次校正性能，如图4d所示，特别是在B细胞、骨髓细胞和自然杀伤（`NK`）细胞群中。\n\n总体而言，scGPT展示出优越的细胞类型聚类性能，并在各种基准生物学保留指标中表现出稳健性（补充表4）。\n\n### scGPT揭示特定细胞状态的基因网络\n\n转录因子、辅因子、增强子和靶基因之间的相互作用构成了基因调控网络（`GRN`），调控着重要的生物学过程。现有的`GRN推断方法`通常依赖于`静态基因表达的相关性`或`伪时间估计`作为因果图的代理。\n\n> 个人理解：研究者想知道哪个基因调控哪个基因（即因果关系），但直接观察这种调控关系很困难。所以退而求其次，主要用两种方法来推测：要么看基因表达量之间是否存在相关性（就像看到两个人总是同时出现，就推测他们可能有关系），要么通过重建细胞发育的时间顺序来推测（比如先发现A基因表达，过一会儿B基因才表达，就推测A可能调控B）。但这些都是间接的推测方法，可能并不能完全反映真实的调控关系，有点像是\"猜\"而不是\"看到\"。\n\nscGPT通过基因表达的生成式建模进行优化，在其`基因嵌入`和`注意力图`中隐式编码了这些关系。因此，我们提出通过探测来自预训练或精调模型的scGPT嵌入和注意力图来进行GRN推断。基因嵌入构建了一个相似性网络，表明数据集层面的基因-基因相互作用。注意力图进一步捕捉了不同细胞状态下独特的基因网络激活模式。\n\n在本研究中，我们将scGPT提取的基因网络与已知生物学进行验证，并探索其在基因程序发现中的应用。\n\nscGPT通过学习到的基因标记嵌入，展示了其对功能相关基因进行分组和区分功能不同基因的能力。在图5a中，我们使用预训练的scGPT模型可视化了人类白细胞抗原（`HLA`）蛋白的相似性网络进行基本验证。在这个零样本设置中，scGPT模型成功突出了对应于两个明确特征的HLA类别的两个聚类：HLA I类和HLA II类基因。这些类别编码抗原呈递蛋白，在免疫环境中发挥不同作用。\n\n例如，HLA I类蛋白（由`HLA-A`、`HLA-C`和`HLA-E`等基因编码）被`CD8+ T`细胞识别并介导细胞毒性效应，而HLA II类蛋白（由`HLA-DRB1`、`HLA-DRA`和`HLA-DPA1`编码）被`CD4+ T`细胞识别并触发更广泛的辅助功能。此外，我们在\"免疫人类\"数据集上对scGPT模型进行精调，并探索了该数据集中存在的免疫细胞类型特异的CD基因网络。我们使用与集成任务相同的精调策略（见`方法`）用于GRN分析。预训练的scGPT模型成功识别出了一组用于T细胞激活的T3复合物编码基因（`CD3E`、`CD3D`和`CD3G`）以及用于B细胞信号传导的`CD79A`和`CD79B`，以及作为HLA I类分子共受体的`CD8A`和`CD8B`（图5b）。此外，精调后的scGPT模型突出了`CD36`和`CD14`之间的联系（图5b）。\n\n![image-20241217213552997](/images/assets//image-20241217213552997.png)\n\nscGPT能够发现表现出细胞类型特异性激活的有意义的基因程序。基因程序随后使用来自scGPT的基因嵌入进行选择和聚类（见`方法`）。在图5c中，我们可视化了在\"免疫人类\"数据集的高变异基因（`HVGs`）上经过精调的scGPT模型提取的基因程序及其在不同细胞类型中的表达。我们观察到一组HLA II类基因被识别为第2组。类似地，参与T3复合物的CD3基因被识别为第3组，在T细胞中表现出最高表达。为了系统地验证提取的基因程序，我们对照Reactome数据库进行了通路富集分析，并使用严格的多重检验校正（见`方法`）确定了高置信度的\"通路命中\"。在图5d中，我们将scGPT的结果与共表达网络的结果进行比较。值得注意的是，scGPT在所有聚类分辨率下始终显示出显著更多的富集通路。\n\n此外，我们研究了scGPT和`共表达网络`之间识别的通路的异同，如图5e所示。两种方法识别出15条共同通路，包括与`细胞周期`和`免疫系统`相关的通路。scGPT独特地识别出额外的22条通路，其中14条与免疫相关。值得注意的是，scGPT特别突出了与适应性免疫系统、T细胞受体信号传导、`PD-1`信号传导和MHC II类呈递相关的通路。这与精调数据集中存在适应性免疫群体的事实相符。这些发现证明了scGPT在捕捉复杂的基因-基因连接和揭示更广泛生物学背景下特定机制的卓越能力。富集通路的详细列表在补充表5中提供。\n\n除了使用基因嵌入进行数据集层面的基因网络推断外，scGPT的注意力机制使其能够在单细胞层面捕捉基因-基因相互作用。scGPT通过`聚合注意力图`中的单细胞信号来提取细胞状态特异的网络激活数据。这为了解个别细胞内的上下文特异性基因调控相互作用提供了见解，这些相互作用可能在不同的细胞状态和条件下有所不同。\n\n例如，在一个扰动实验中，scGPT通过检查扰动前后基因网络激活的变化，来推断哪些基因最受每个被扰动基因的影响（图6a和方法）。在`Adamson CRISPR`干扰数据集中，scGPT识别出了受`DDIT3`（编码一个转录因子）抑制影响最大的前20个基因，这些基因在`ChIP-Atlas`数据库中均被发现是DDIT3的信号传导靶点（图6b）。此外，scGPT在对照与DDIT3敲除设置中捕捉到了在前100个最受影响基因中不同的通路激活模式。\n\n值得注意的是，在DDIT3敲除设置中识别出的`ATF6`转录因子通路已知可介导未折叠蛋白反应并调控细胞凋亡。类似地，在`BHLHE40`抑制的情况下，前20个最受影响的基因中有19个被发现是通过染色质免疫沉淀测序（`ChIP-seq`）预测的这个转录因子的靶点（图6c）。突出DNA合成和有丝分裂的通路激活模式反映了转录因子BHLHE40在细胞周期调控中的作用。这些基于注意力的发现进一步验证了scGPT在细胞状态水平上学习到的基因网络，为模型学习到的生物学提供了额外的`可解释性`。\n\n![image-20241217213726866](/images/assets//image-20241217213726866.png)\n\n### 迁移学习中的规模和上下文效应\n\n在前面的章节中，scGPT通过精调的方式展示了迁移学习的巨大潜力。我们通过将其与类似的、从头训练（无预训练）的`transformer模型`进行比较，进一步确认了使用基础模型的好处（表示为`scGPT (from scratch)`）。结果呈现在补充表2-4中，精调后的scGPT在整合和细胞类型注释等任务中始终表现出性能优势。鉴于基础模型对下游任务的贡献已被观察到，我们进一步关注影响迁移学习过程的因素。\n\n首先，我们深入研究`预训练数据规模与精调模型性能之间的关系`：对于某个特定的分析任务，在预训练的细胞图谱中添加更多测序数据能获得多少改进？我们使用相同参数数量但使用不同数据量（从30,000到3300万个测序的正常人类细胞）预训练了一系列scGPT模型。补充图13a展示了使用这些不同预训练模型在各种应用上精调的结果表现。我们观察到，随着预训练数据量的增加，精调模型的性能有所提升（补充说明4）。这些结果表明存在一个规模效应，即更大的预训练数据规模会带来更好的预训练嵌入，并提升下游任务的性能。值得注意的是，我们的发现也与自然语言模型中报告的规模定律相一致，突出了数据规模在模型性能中的重要作用。`预训练数据规模在精调结果中的关键作用表明了单细胞领域预训练模型的美好前景`。随着更大、更多样化的数据集的出现，我们可以预期模型性能会进一步提升，推进我们对细胞过程的理解。\n\n我们探索的第二个因素是`上下文特定预训练的影响`。这里，上下文使用是指scGPT模型在特定细胞类型上预训练，然后在类似细胞类型的下游任务上进行精调。为了探索这一因素的影响，我们在来自各个主要器官的正常人类细胞上预训练了七个器官特异性模型（图1d）和另一个泛癌症模型。我们通过可视化预训练数据的细胞嵌入来验证预训练的有效性：泛癌症模型的细胞嵌入准确地区分了不同的癌症类型（补充图2）。器官特异性模型能够揭示相应器官的细胞异质性（补充图3）。接下来，我们在`COVID-19`数据集上对各个模型进行微调，以检验预训练上下文的影响。我们的分析揭示了模型在预训练中所涉及的上下文相关性与其后续表现之间存在明显的关联（附录图8）。在数据整合任务中表现最好的是在`全人类`、`血液`和`肺部`数据集上预训练的模型，这与`COVID-19`数据集中存在的细胞类型高度一致。值得注意的是，尽管在`1320万`细胞的大规模数据集上进行了预训练，`大脑`预训练模型的性能仍比使用相似规模数据集训练的`血液`预训练模型低了`8%`。这强调了在预训练中保持细胞上下文与目标数据集一致的重要性，以获得更好的下游任务效果。但同时需要指出，虽然考虑细胞上下文很重要，但全人类预训练模型仍然是广泛应用场景下最可靠的选择。\n\n## 讨论\n\n我们介绍了`scGPT`，这是一个在大量单细胞数据上利用预训练`transformer`力量的基础模型。基于语言模型中自监督预训练的成功经验，我们在单细胞领域采用了类似的方法来揭示复杂的生物学相互作用。`scGPT`中`transformer`的使用使得基因和细胞嵌入的同步学习成为可能，这有助于对细胞过程的各个方面进行建模。通过利用`transformer`的注意力机制，`scGPT`能够在单细胞水平捕获基因间的相互作用，为模型提供了额外的可解释性层面。\n\n我们通过`零样本`和`微调环境`下的全面实验展示了预训练的优势。预训练模型在零样本实验中展现出强大的推广到未见数据集的能力，呈现出与细胞类型相一致的有意义的聚类模式。此外，所学习的基因网络在`scGPT`中表现出与已知功能组的强烈一致性。更进一步，预训练模型的知识可以通过微调迁移到多个下游任务。在细胞类型注释、扰动预测、多批次和多组学整合等各种任务中，经过微调的`scGPT`模型始终优于从头开始训练的模型。这展示了预训练模型对下游任务的价值，使得分析更加准确且具有生物学意义。值得注意的是，目前的预训练并不能从本质上缓解批次效应，因此模型在具有显著技术变异的数据集上的零样本表现可能会受到限制。评估模型也很复杂，因为经常缺乏明确的生物学真值，而且数据质量也存在差异（详见附录说明10）。\n\n对于未来的方向，我们计划在更大规模的数据集上进行预训练，包括`多组学数据`、`空间组学`和各种疾病条件。在预训练阶段`纳入扰动和时序数据`也很有趣，使模型能够学习因果关系，推断基因和细胞如何随时间响应变化。我们还旨在探索单细胞数据的上下文指令学习。这涉及开发使预训练模型能够在零样本环境下理解和适应不同任务和上下文的技术，而无需微调。通过使`scGPT`能够掌握不同分析的细微差别和具体要求，我们可以提高其在广泛研究场景中的实用性和适用性。我们设想预训练范式将很快被整合到单细胞研究中，并作为一个基础来利用来自指数增长的细胞图谱中的现有知识进行新的发现。\n\n## 在线内容\n任何方法、补充参考文献、《Nature Portfolio》报告摘要、源数据、扩展数据、补充信息、致谢、同行评议信息；作者贡献和竞争利益的详细信息；以及数据和代码可用性声明均可在 [https://doi.org/10.1038/s41592-024-02201-0](https://doi.org/10.1038/s41592-024-02201-0) 获取。\n\n## 方法\n\n### 输入嵌入\n\n单细胞测序数据被处理成一个细胞-基因矩阵，$X ∈ ℝ^{N×G}$，其中每个元素 $X_{i,j} ∈ ℝ^+$ 表示`scRNA-seq`数据的RNA分子读数或`scATAC-seq`数据的染色质可及性峰区域。具体来说，对于`scRNA-seq`数据，该元素表示细胞 $i ∈ \\{0,1,…,N\\}$ 中基因 $j ∈ \\{0,1,…,G\\}$ 的RNA丰度。在随后的章节中，我们将这个矩阵称为原始计数矩阵。`scGPT`的输入由三个主要组成部分：\n\n1. 基因（或峰）标记\n\n2. 表达值\n\n3. 条件标记\n\n对于每个建模任务，基因标记和表达值都是从原始计数矩阵`X`相应地`预处理`得到的。\n\n#### 基因标记\n\n在`scGPT`框架中，每个基因被视为类似于自然语言生成中词语的最小信息单位。因此，我们使用基因名称作为标记，并为每个基因 $\\text g_j$ 分配一个唯一的整数标识符 $\\text {id}(\\text g_j)$ 。这些标识符构成了`scGPT`中使用的标记词汇表。这种方法提供了极大的灵活性，可以协调具有不同基因集（即由不同测序技术或预处理流程生成）的多个研究。具体而言，不同基因标记集可以通过取所有研究中基因的并集来整合到一个共同的词汇表中。此外，我们在词汇表中还加入了特殊标记，如用于将所有基因聚合成细胞表示的`<cls>`和用于将输入填充到固定长度的`<pad>`。从概念上讲，我们将基因标记与自然语言生成中的词标记进行类比。因此，每个`细胞i`的输入基因标记由一个向量  $t^{(i)}_g ∈ ℕ^M$ 表示：\n$$\nt^{(i)}_g = [id(g^{(i)}_1), id(g^{(i)}_2), …, id(g^{(i)}_M)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(1)\n$$\n其中`M`是预定义的最大输入长度。\n\n#### 表达值\n\n在用于建模之前，基因表达矩阵X需要额外的处理。基因表达建模中的一个基本挑战是不同测序协议间绝对量值的变异性。测序深度的差异以及稀疏表达基因的存在导致了不同测序批次样本之间的数据尺度存在显著差异。这些差异不容易通过常见的预处理技术（如每百万转录本归一化和`log1p`转换）来缓解。即使经过这些转换，相同的绝对值在不同测序批次间也可能传达不同的\"语义\"含义。为了解决这种尺度差异，我们提出了值分箱技术，将所有表达计数转换为相对值。对于每个细胞中的每个非零表达计数，我们计算原始绝对值并将它们分成B个连续区间 $[b_k, b_{k+1}]$，其中 $k ∈ \\{1,2,…,B\\}$ 。每个区间代表所有表达基因的相等部分（`1/B`）。需要注意的是，每个细胞都会计算一组新的分箱边界，因此区间边界$b_k$可能在细胞间有所不同。`细胞i`的分箱表达值 $x^{(i)}_j$ 定义为：\n$$\nx^{(i)}_j = \\begin{cases} k, & \\text{if} ~~X_{i,j} > 0 \\text~{and}~ X_{i,j} ∈ [b_k, b_{k+1}], \\\\ 0, & \\text{if} ~~X_{i,j} = 0. \\end{cases}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(2)\n$$\n通过这种分箱技术，$x^{(i)}_j$ 的语义含义在来自各种测序批次的细胞间保持一致。例如，$x^{(i)}_j = B$ 始终表示基因中的最高表达。值得注意的是，对于微调任务，我们还在值分箱步骤之前执行了`log1p`转换和高变异基因选择。为了简化表示，我们使用 $X_{i,j}$ 来表示分箱前的原始和预处理数据矩阵。因此，`细胞i`的分箱表达值的最终输入向量表示为：\n\n$$\nx^{(i)} = [x^{(i)}_1, x^{(i)}_2,…,x^{(i)}_M]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(3)\n$$\n\n#### 条件标记\n\n条件标记包含了与各个基因相关的`多样化元信息`，比如扰动实验的改变（由扰动标记指示）。为了表示位置相关的条件标记，我们使用一个与输入基因具有相同维度的输入向量。该向量表示为：\n$$\nt^{(i)}_c = [t^{(i)}_{c,1},t^{(i)}_{c,2},…,t^{(i)}_{c,M}]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(4)\n$$\n其中 $t^{(i)}_{c,j}$ 表示对应于某个条件的整数索引。\n\n#### 嵌入层\n\n我们使用常规的嵌入层（即`PyTorch`嵌入层，[https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)）$\\text {emb}_g$ 和 $\\text {emb}_c$ 分别用于基因标记和条件标记，以便将每个标记映射到维度D的固定长度嵌入向量。我们使用全连接层（表示为 $\\text {emb}_x$ ）来处理分箱表达值以增强表达能力。这种选择使得对基因表达值的序数关系进行建模成为可能。因此，`细胞i`的最终嵌入$h^{(i)} ∈ ℝ^{M×D}$ 定义为：\n$$\nh^{(i)} = \\text {emb}_g(t^{(i)}_g) + \\text {emb}_x(x^{(i)}) + \\text {emb}_c(t^{(i)}_c)~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(5)\n$$\n\n### 细胞和基因表达建模的transformer\n\n#### scGPT transformer\n\n我们使用自注意力`transformer`来编码方程（5）中的完整输入嵌入 $h^{(i)}$。自注意力机制作用于M个嵌入向量序列，这使其特别适合捕获基因之间的相互作用。堆叠的`transformer`块的输出可以定义如下：\n$$\nh^{(i)}_0 = h^{(i)}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(6)\n$$\n$$\nh^{(i)}_l = \\text {transformer}\\_\\text {block}(h^{(i)}_{l-1}) ~~∀l ∈ [1,n]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(7)\n$$\n我们使用得到的表示 $h^{(i)}_n \\in R^{M,D}$ 来进行基因级别和细胞级别的任务。基因级别的微调目标直接应用。例如包括基因表达预测（`GEP`）目标和扰动表达预测任务（`perturb-GEP`）。对于细胞级别的任务，我们首先将 $h^{(i)}_n$ 整合成一个细胞嵌入向量。一个例子是细胞类型分配任务，其中细胞嵌入用于通过在细胞类型分类训练目标中添加的分类器来预测细胞类型标签。\n\n输入维度M可以达到数万个基因，这大大超过了自然语言生成中常用的传统`transformer`的输入长度。为了解决这个挑战并确保高效的自注意力机制，我们利用`FlashAttention`的加速自注意力实现。这种实现有效地提高了模型容量，并能够有效处理大输入维度。尽管我们采用了`FlashAttention`，但任何高效的`transformer`都可能用于`scGPT`，例如具有线性复杂度的`transformer`（`Linformer`）和`Kernelized Self-Attention`（`KSA`）。\n\n#### 细胞表示\n\n每个细胞类似于由基因组成的\"句子\"，其表示 $h^{(i)}_c ∈ ℝ^D$ 是通过聚合学习到的基因级别表示 $h^{(i)}_n$ 获得的。\n\n各种池化操作，如逐元素平均池化或加权池化，都可以在这种情况下轻松使用。\n\n在本研究中，我们选择使用特殊标记`<cls>`来获取细胞表示，使模型能够在`transformer`块内学习池化操作。`<cls>`标记被添加到输入标记的开头，这个位置的最终嵌入被提取作为细胞表示。因此，细胞嵌入 $h^{(i)}_c$ 可以通过从堆叠的最终层嵌入 $h^{(i)}_n[<cls>]$ 中提取相应行来获得，其中 $[<cls>]$ 操作检索`<cls>`标记位置的行。\n\n#### 批次和模态的表示\n\n我们使用额外的一组标记来表示不同的测序批次和测序模态（来自`RNA-seq`的基因、来自`ATAC-seq`的峰等），特别是对于`scRNA-seq`和`scMultiomic`整合任务。这类似于输入嵌入中介绍的条件标记，并且使用标准嵌入层以类似的方式实现。模态标记 $t^{(i)}_m$ 与个别输入特征 $g_j$ 相关联（例如，指示它是基因、区域还是蛋白质）。批次标记最初是在细胞水平上的，但也可以传播到单个细胞的所有特征。换句话说，相同的批次标记 $t^{(i)}_b$ 可以重复到单个`细胞i`的输入特征长度M：\n$$\nt^{(i)}_b = [t^{(i)}_{b,1},t^{(i)}_{b,2},…,t^{(i)}_{b,M}] = [t^{(i)}_b,t^{(i)}_b,…,t^{(i)}_b]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(8)\n$$\n和批次及模态表示的区别在于，这些批次和模态嵌入并不作为输入送入转换器模块。相反，它们在进入特定的微调目标之前，要么在特征层面或者细胞层面与转换器的输出进行拼接。这样做是为了防止转换器在同一模态的特征内放大注意力，同时低估不同模态之间的注意力。\n\n此外，在下游微调目标中了解模态和/或批次标识有助于基因表达建模。当模型学会基于模态和/或批次标识预测表达值时，这些偏差会从基因和细胞表示本身中被隐式地消除。这可以作为一种促进批次校正的技术。\n\n比如，在`scMultiomic`整合任务中，我们将转换器输出与批次和模态嵌入的和进行拼接。这作为下游微调目标的输入用于表达建模：\n\n$$\nh^{\\prime(i)}_n = \\text {concat}(h^{(i)}_n, \\text {emb}_b(t^{(i)}_b) + \\text {emb}_m(t^{(i)}_m))~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(9)\n$$\n其中 $\\text {emb}_b$ 和 $\\text {emb}_m$ 分别表示批次和模态嵌入层，$h^{(i)}_n$ 表示转换器层的输出（scGPT transformer）。\n\n另外，在`scRNA-seq`整合任务中，批次嵌入与细胞表示的拼接产生以下作为输入的表示：\n\n$$\nh^{\\prime(i)}_c = \\text {concat}(h^{(i)}_c, \\text {emb}_b(t^{(i)}_b))~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(10)\n$$\n其中 $t^{(i)}_b$ 表示`细胞i`的批次标识。$h^{(i)}_c$是原始细胞表示（微调目标）。需要注意的是，修改后的版本 $h^{\\prime(i)}_c$ 仅与表达建模目标相关，不适用于基于分类的目标，详见微调目标部分。\n\n### 生成式预训练\n\n#### 基础模型预训练\n\n基础模型被设计成一个可泛化的特征提取器，能够服务于多种下游任务。预训练中使用的标记词汇包含人类基因组中的全部基因集。在模型预训练之前，表达值被进行了分箱处理（输入嵌入）。为了加快训练速度，我们限制每个输入细胞只包含非零表达的基因。为了有效地训练模型以捕获基因-基因关系和基因-细胞关系，我们引入了一个带有特殊`注意力掩码`的生成式训练策略，具体将在下一节描述。\n\n#### 用于生成式预训练的注意力掩码\n\n自注意力机制已被广泛用于捕获标记之间的共现模式。在自然语言处理中，这主要通过两种方式实现：\n\n1. 掩码标记预测，用于`BERT`和`RoBERTa`等转换器编码器模型，其中输入序列中`随机掩码的标记`在模型输出中被预测；\n\n2. 在因果转换器解码器模型（如`OpenAI GPT`系列）中使用序列预测的`自回归生成`。\n\n`OpenAI GPT-3`和`GPT-4`中使用的生成式预训练采用了一个统一的框架，其中模型根据由已知输入标记组成的\"提示\"来预测最可能的下一个标记。这个框架在各种自然语言生成应用中提供了极大的灵活性，并在零样本和微调设置中展示了上下文感知等能力。我们相信生成式训练同样可以以类似的方式有益于单细胞模型。具体来说，我们对两个任务感兴趣：\n\n1. 基于已知的基因表达生成未知的基因表达值，即通过\"`基因提示`\"进行生成；\n\n2. 给定输入细胞类型条件生成全基因组表达，即通过\"`细胞提示`\"进行生成。\n\n尽管标记和提示的概念相似，但由于数据的非序列性质，对基因读数的建模本质上与自然语言不同。与句子中的单词不同，细胞内基因的顺序是可互换的，并且没有等效的\"下一个基因\"预测概念。这使得直接将`GPT`模型中的因果掩码公式应用于单细胞数据变得具有挑战性。为了解决这个挑战，我们为`scGPT`开发了一种特殊的注意力掩码机制，根据注意力分数定义预测顺序。\n\n注意力掩码通常可以应用在转换器模块中的自注意力图上：对于`M`个基因标记的输入（公式(1)），第 $l+1$ 个转换器模块对其输入 $h^{(i)}_l \\in \\mathbb{R}^{M\\times D}$ 的`M`个标记应用多头自注意力（公式(6,7)）。具体来说，每个自注意力操作计算如下：\n\n$$\nQ = h^{(i)}_l W_q,~~~ K = h^{(i)}_l W_k,~~~ V = h^{(i)}_l W_v,~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(11)\n$$\n\n$$\n\\text {Attention}(Q, K, V) = \\text {softmax}(\\frac{QK^T}{\\sqrt{d}} + A_{mask})V~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(12)\n$$\n\n其中 $Q, K, V \\in \\mathbb{R}^{M\\times d}$ 代表查询、键和值向量。$W_q, W_k, W_v \\in \\mathbb{R}^{D\\times d}$ 是可学习的权重矩阵。$d$ 是特征维度，作为 $\\dfrac{QK^T}{\\sqrt{d}}$ 中的缩放因子以维持数值稳定性。注意力掩码 $A_{mask} \\in \\{0, -\\inf\\}^{M\\times M}$ 通过修改查询和键之间的原始注意力权重 $\\dfrac{QK^T}{\\sqrt{d}}$ 来划定自注意力的范围。\n\n> `transformer`模型中的相关概念可参考这篇文章：\n>\n> {% postLinkCard skrzswes  \"auto\" %}\n\n具体来说，在矩阵中位置 $(i,j)$ 添加 `-inf` 会在 `softmax` 后使注意力权重归零，从而禁止第`i`个查询和第`j`个键之间的注意力。另一方面，添加0意味着注意力权重保持不变。这种注意力掩码技术允许模型专注于特定的上下文元素。\n\n我们专门设计了`scGPT`注意力掩码，以统一的方式支持基因提示和细胞提示生成。注意力掩码 $A_{mask} \\in \\{0, -\\inf\\}^{M\\times M}$ 在附图1a中进行了可视化，其中查询按行排列，键按列排列。如图底部注释所示，输入嵌入 $h^{(i)}_l$ 中的每个标记可以属于以下三组之一：\n\n（1）用于细胞嵌入的保留`<cls>`标记（在\"`细胞表示`\"小节中介绍）；\n\n（2）具有标记嵌入和表达值嵌入的已知基因；\n\n（3）需要预测表达值的未知基因。\n\n`scGPT`注意力掩码的基本规则是只允许`\"已知基因\"的嵌入`和`查询基因本身`之间的注意力计算。这通过使用 $A_{mask}$ 中的元素 $a_{i,j}$ 实现如下：\n$$\na_{i,j} = \\begin{cases}\n0, & \\text{如果 } j \\notin \\text{未知基因}, \\\\\n0, & \\text{如果 } i = j \\text{ 且 } j \\in \\text{未知基因}, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(13)\\\\\n-\\inf, & \\text{如果 } i \\neq j \\text{ 且 } j \\in \\text{未知基因}.\n\\end{cases}\n$$\n\n在每次生成迭代中，`scGPT`预测一组新基因的基因表达值，这些基因反过来在下一次迭代的注意力计算中成为\"已知基因\"。这种方法通过在非序列单细胞数据中进行顺序预测，反映了传统转换器解码器中带有下一个标记预测的因果掩码设计。\n\n如附图1a所示，在训练期间，我们随机选择一定比例的基因作为未知基因，以便在输入中省略其表达值。注意力仅在已知基因和查询未知基因本身之间应用，而不应用于其他未知基因的位置。\n\n例如，在`位置j`要预测的基因只与细胞嵌入、已知基因和它自身有注意力分数，而不与其他未知基因有注意力分数，如注意力掩码的最后一行所示。`scGPT`模型通过带有上述掩码注意力图的堆叠转换器模块来预测这些未知基因的表达。推理步骤如附图1b所示。在细胞提示生成的推理过程中，`scGPT`基于特定的细胞类型条件生成全基因组表达。在第一个位置输入代表细胞类型条件的训练好的细胞嵌入。数千个基因表达值的整个生成过程在`K`个迭代步骤中进行（例如，附图1b中的`K=3`步）。\n\n例如，在第 $i \\in \\{1,2,\\dots,K\\}$ 次迭代中，注意力掩码机制允许与前面 0 到 $i-1$ 次迭代中所有预测的基因进行注意力计算。在每次迭代中，`scGPT`从未知集合中选择预测置信度最高的前 $\\frac{1}{K}$ 个基因，作为下一次迭代 $i+1$ 的已知基因。\n\n直观地说，这个工作流以自回归方式简化了基因表达的生成，其中首先生成预测置信度最高的基因表达值，并用于帮助后续的生成轮次。基因提示生成以类似的迭代方式工作。不同之处在于，它从一组具有观察到的表达值的已知基因开始，而不是从细胞嵌入开始。\n\n`scGPT`注意力掩码统一了已知基因的编码过程和未知基因的生成。它也是首批针对非序列数据进行自回归生成的转换器方案之一。\n\n#### 学习目标和预训练\n\n我们使用了一个基因表达预测目标来优化模型，以预测未知基因的表达值。具体来说，我们使用`多层感知机`网络（`MLP`）来估计未知表达值并计算均方损失$\\mathcal{L}$：\n$$\n\\mathcal{L} = \\frac{1}{|U_{unk}|} \\sum_{j\\in U_{unk}} (\\text {MLP}(h^{(i)}_n) - x^{(i)}_j)^2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(14)\n$$\n\n其中 $U_{unk}$ 表示未知基因的输出位置集合，$x^{(i)}_j$是待预测的实际基因表达值。$|\\cdot|$操作获取集合中元素的数量。\n\n如\"用于生成式预训练的注意力掩码\"小节中所述，支持基因提示和细胞提示两种生成模式。在训练过程中，这两种模式连续进行。在一个给定细胞的输入基因标记中，选择一定比例的基因作为\"未知\"基因，并省略它们的表达值。首先，在基因提示步骤中，模型的输入包含`<cls>`标记嵌入、已知基因嵌入和未知基因嵌入。使用模型的输出计算损失（公式(14)）。其次，在细胞提示步骤中，上一步的输出细胞嵌入（即\"细胞表示\"中的 $h^{(i)}_c$ ）用于替换`<cls>`位置的嵌入。其他计算保持不变。最后，将这两个步骤的损失值加在一起，用于计算梯度以优化模型参数。\n\n### 微调目标\n\n`scGPT`利用各种微调目标来促进对细胞和基因的生物学有效表示的学习，以及用于`批次校正`等正则化目的。\n\n#### 基因表达预测\n\n为了促进`基因-基因互作`的学习，`scGPT`包含了基因表达预测（`GEP`）。这个微调目标的工作方式与预训练中的目标（\"学习目标和预训练\"）类似，但应用于掩码位置。具体来说，对于每个输入细胞，随机掩码一部分基因标记及其对应的表达值 $x^{(i)}$。`scGPT`被优化以准确预测掩码位置的表达值。这个微调目标有助于模型有效编码数据集中基因之间的共表达。该目标最小化掩码位置（表示为$\\mathcal{M}_{mask}$）的均方误差。`GEP`的工作方式如下：\n$$\n\\tilde{x}^{(i)} = \\text {MLP}(h^{(i)}_n)~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(15)\n$$\n\n$$\n\\mathcal{L}_{GEP} = \\frac{1}{|\\mathcal{M}_{mask}|} \\sum_{j\\in \\mathcal{M}_{mask}} (\\tilde{x}^{(i)}_j - x^{(i)}_j)^2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(16)\n$$\n\n这里，$\\tilde{x}^{(i)} \\in \\mathbb{N}^M$表示`细胞i`的表达估计行。值得注意的是，如果提供了测序批次或模态条件，我们使用公式(9)中的 $h^{\\prime(i)}_n$ 而不是 $h^{(i)}_n$。\n\n`GEP`提供了一个通用的自监督微调目标，旨在预测基因表达值。在某些下游任务中，例如扰动预测，模型需要预测扰动后的基因表达值而不是原始值。我们将这种变体称为`perturb-GEP`。我们保留公式(15)和公式(16)中的`MLP`估计器，但使用扰动后的基因表达作为目标 $x^{(i)}_j$。在`perturb-GEP`中，模型应该预测所有输入基因的扰动后表达。\n\n#### 用于细胞建模的基因表达预测\n\n这个微调目标的操作方式与`GEP`类似，但基于细胞表示 $h^{(i)}_c$ 预测基因表达值，以明确促进细胞表示学习。对于输入`细胞i`中的每个`基因j`，我们创建一个查询向量 $q_j$，并使用 $q_j$ 和细胞表示 $h^{(i)}_c$ 的参数化内积作为预测的表达值：\n$$\n\\mathbf q_j = \\text {MLP}(\\text {emb}_g(t^{(i)}_g))~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(17)\n$$\n\n$$\n\\tilde{x}^{(i)}_j = \\mathbf q_j \\cdot \\mathbf {Wh}^{(i)}_c~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(18)\n$$\n\n$$\n\\mathcal{L}_{\\text{GEPC}} = \\frac{1}{|\\mathcal{M}_{mask}|} \\sum_{j\\in \\mathcal{M}_{mask}} (\\tilde{x}^{(i)}_j - x^{(i)}_j)^2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(19)\n$$\n\n用于细胞建模的`GEP`（`GEPC`）继承了公式(5)中的基因标记嵌入 $emb_g(t^{(i)}_g)$。在整合任务中，我们使用公式(10)中的 $h_c^{\\prime(i)}$ 而不是 $h^{(i)}_c$。在我们的实验中，我们观察到将`GEP`和`GEPC`结合使用与单独使用任一方法相比，性能有显著提升。\n\n#### 弹性细胞相似度\n\n这个微调目标通过使用`相似度学习损失`来增强细胞表示：\n$$\n\\mathcal{L}_{\\text {ECS}} = -(\\text {sim}(\\mathbf h^{(i)}_c, \\mathbf h^{(i')}_c) - \\beta)^2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(20)\n$$\n\n其中 $\\text {sim}$ 表示余弦相似度函数，而 $i$ 和 $i'$ 指的是小批量内的两个细胞。此外，$β$ 表示预定义的阈值，$\\text {ECS}$ 是弹性细胞相似度。这种方法的基本思想是增强相似度值高于 $β$ 的配对之间的相似性，从而使它们更加相似。相反，不相似的配对则被鼓励进一步分开。\n\n#### 通过反向反向传播进行域适应\n\n由于测序技术引入的非生物学批次差异导致的批次效应，会妨碍细胞表示的学习。为了缓解这个问题，我们使用一个独特的`MLP`分类器来预测每个输入细胞的测序批次（基于它们的细胞表示 $h^{(i)}_c$），并通过在模型内反转梯度来修改反向传播过程。这种方法借鉴了`Ganin`和`Lempitsky`提出的鲁棒域适应方法的见解。\n\n#### 细胞类型分类\n\n这个微调目标旨在利用学习到的细胞表示来注释单细胞。我们使用一个单独的`MLP`分类器从细胞表示 $h^{(i)}_c$ 中预测细胞类型。这个微调目标通过预测的细胞类型概率和真实标签之间的交叉熵损失`ce`进行优化。\n\n### 下游任务的微调\n\n#### 细胞类型注释\n\n对于`细胞类型注释`任务，我们在具有真实标签的参考集上对模型进行微调，并在保留的查询集上验证注释性能。保留预训练基础模型和参考集之间的共同基因标记集。在模型微调之前，基因表达值经过归一化、对数转换和分箱处理。除了输出细胞类型分类器（随机初始化）外，所有预训练模型权重都用于初始化微调模型。在训练中使用所有具有零和非零表达值的基因标记。使用细胞类型分类微调目标来最小化分类损失。\n\n#### 基因扰动响应预测\n\n为了针对扰动预测任务进行微调，我们在模型训练前选择了`高变异基因`并对表达值进行了预处理。嵌入层和`transformer层`的参数从预训练模型中初始化。在微调过程中，包含了所有零值和非零值表达的基因标记。针对扰动预测任务的输入进行了两个显著的改变：\n\n首先，我们使用了`log1p转换`后的表达值作为输入和目标值，而不是分箱值，以更好地预测扰动后的绝对表达；其次，我们在每个输入基因位置添加了二元条件标记，以指示该基因是否被扰动。\n\n我们采用了`perturb-GEP`微调目标，并对训练设置进行了进一步修改。不同于使用同一细胞的遮罩和未遮罩表达值作为输入和学习目标，我们使用对照细胞作为输入，扰动细胞作为目标。这是通过将每个扰动细胞与随机配对的非扰动对照细胞构建输入-目标对来实现的。输入值包含了对照细胞中所有基因的表达值。因此，模型学会了基于对照基因表达和扰动标记来预测扰动后的反应。\n\n#### 整合多个scRNA-seq数据集的批次校正\n\n当输入原始计数矩阵包含来自不同测序批次或技术的多个数据集时，批次效应可能是细胞类型聚类中的一个主要混淆因素。因此，在整合多个`scRNA-seq`数据集时，我们的目标是在保持生物学差异的同时校正批次效应。对于这个整合任务的微调，我们保留了预训练基础模型和当前数据集之间的共同基因标记集。我们进一步从共同集中选择了一部分`HVGs`作为输入。我们在模型训练前对表达值进行了预处理，类似于细胞类型注释任务。所有预训练模型权重都被用来初始化微调模型。默认情况下，训练中使用了所有具有零值和非零表达值的基因标记。除了`GEP`和`GEPC`之外，`ECS`、通过反向传播的域适应（`DAR`）和`DSBN`微调目标被同时优化，通过反向传播和特定域归一化来增强细胞对比学习和显式批次校正。\n\n#### scMultiomic数据的整合表示学习\n\n`scMultiomic`数据可能在实验批次间包含不同的测序模态。我们研究了`scMultiomic`数据的两种数据整合设置：配对设置（`paired`）和镶嵌设置（`mosaic`）。\n\n在`配对设置`中，所有样本（细胞）共享所有测序的数据模态。在`镶嵌设置`中，一些批次共享少数共同的数据模态，但不是全部。由于存在额外的`ATAC`（和/或）蛋白质标记，我们仅继承了RNA数据的训练基因嵌入，并从头开始训练额外的标记嵌入和模型的其余部分。如果数据集包含额外的蛋白质数据，训练中仅使用非零表达值的标记。否则，默认情况下使用零值和非零表达值。我们使用了一组额外的模态标记来指示每个标记的数据类型（即基因、区域或蛋白质），并促进`GEP`和`GEPC`微调目标中的掩蔽基因和值预测。默认情况下，模型使用`GEP`和`GEPC`微调目标进行优化。如果存在多个批次，则包含`DAR`以促进多模态批次校正。\n\n#### 基因调控网络推断\n\n对于图5中基于基因嵌入的`GRN`推断，在零样本设置中，我们基于`k-最近邻`从`scGPT`的预训练基因嵌入构建了基因相似性网络。在微调设置中，我们以类似的方式从在人类免疫数据集上微调的`scGPT`模型构建了基因相似性网络。我们进一步对相似性图进行了`Leiden`聚类，并从包含五个或更多基因的基因簇中提取基因程序。\n\n对于图6中基于注意力的目标基因选择，我们在Adamson扰动数据集上微调了`scGPT`血液模型，该数据集包含了在白血病细胞系上进行的`87个CRISPR`干扰实验。我们在图6a中展示了目标基因选择流程。对于每个感兴趣的扰动基因，我们首先通过分别输入扰动和对照细胞集，获得了两组注意力图谱（扰动组和对照组）。\n\n注意，原始注意力分数是从模型最后一个注意力层的所有8个注意力头中获得的。原始注意力分数随后经过两轮秩归一化，先按行后按列进行。然后对8个注意力头的秩归一化注意力分数进行平均，得到一个聚合注意力图谱。这就得到了用于最受影响基因选择的最终注意力图谱。对于每个感兴趣的扰动基因，我们通过对扰动基因所在列中的最终注意力图谱中的分数进行排序来选择其最受影响的基因。这反映了注意力图谱中的列表示感兴趣的基因对其他基因的影响程度这一直觉。我们提供了三种最受影响基因选择设置：来自对照注意力图谱的\"对照\"、来自扰动注意力图谱的\"扰动\"以及两者之差的\"差异\"。从对照注意力图谱选择的基因靶标应反映感兴趣基因参与的基础通路，而扰动注意力图谱则反映扰动后的效应。这两个注意力图谱之间的差异应突出显示从扰动前到扰动后基因网络中发生最大变化的边。\n\n同样地，对于涉及多个转录因子的扩展注意力基因相互作用预测（补充说明7），我们在`Replogle`数据子集上微调了`scGPT`血液模型，并报告了来自\"扰动\"设置的最受影响基因。\n\n### 数据集\n\n#### CELLxGENE scRNA-seq集合\n\n我们从`CELLxGENE`门户网站（[https://cellxgene.cziscience.com/](https://cellxgene.cziscience.com/)）使用`Census API`收集了用于整个人类基础模型预训练的数据（`Census API`可在 [https://chanzuckerberg.github.io/cellxgene-census/python-api.html](https://chanzuckerberg.github.io/cellxgene-census/python-api.html) 获取，它定期托管和更新在线数据发布。我们使用了2023年5月15日的发布版本）。我们包含了`scRNA-seq`和`snRNA-seq`的测序协议，并过滤出没有疾病状况的样本。这最终得到了`3300万`个细胞的测序数据。\n\n特别地，为了预训练`scGPT`血液模型，我们从`CELLxGENE`（[https://cellxgene.cziscience.com/](https://cellxgene.cziscience.com/)）获取了超过`1030万`个人类血液和骨髓`scRNA-seq`样本。通过对生物体（即`Homo sapiens`）、组织（即血液、骨髓）和疾病（即正常、`COVID-19`、流感）进行过滤，从`CELLxGENE`中总共收集了`65`个数据集。此外，我们收集了`570万`个各种癌症类型的细胞来训练泛癌症模型。\n\n#### 多发性硬化症\n\n`MS`数据集从`EMBL-EBI`（[https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-35](https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-35)）获取。数据集包含了9个健康对照样本和12个MS样本。我们将对照样本划分用于模型微调的参考集，并将MS样本作为查询集用于评估。这个设置作为分布外数据的示例。我们排除了三种细胞类型：`B细胞`、`T细胞`和`少突胶质前体细胞`，这些细胞类型仅存在于查询数据集中。最终的细胞数量在训练参考集中为`7,844`个，在查询集中为`13,468`个。使用原始发表文献中提供的细胞类型标签作为评估的真实标签。数据处理协议涉及选择`HVGs`以保留`3,000`个基因。\n\n#### 骨髓样细胞\n\n骨髓样数据集可从基因表达综合数据库（`GEO`）使用登录号 [GSE154763](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE154763) 获取。该数据集包含九种不同的癌症类型，但为了训练和评估模型，六种癌症类型被选作参考集用于训练，而三种癌症类型用作查询集。参考集包含骨髓癌症类型`UCEC`、`PAAD`、`THCA`、`LYM`、`cDC2`和`kidney`，而查询集包含`MYE`、`OV-FTC`和`ESCA`。数据集也进行了随机抽样。最终的细胞数量在参考集中为`9,748`个，在查询集中为`3,430`个。在数据处理过程中选择了`3,000`个`HVGs`。\n\n#### 人胰腺\n\n人胰腺数据集包含来自五个人胰腺细胞`scRNA-seq`研究的数据，这些数据由Chen$^{[31]}$等人重新处理用于细胞类型注释任务。这五个数据集按数据来源分为参考集和查询集。参考集包含来自两个数据源的数据，查询集包含其他三个数据源的数据。参考集和查询集都保留了`3,000`个基因和来自原始发表文献的真实注释。参考集包含`13`个细胞群的`10,600`个细胞（`alpha`、`beta`、`导管`、`腺泡`、`delta`、`胰腺星状`、`胰腺多肽`、`内皮`、`巨噬细胞`、`肥大细胞`、`epsilon`、`施旺细胞`和`T细胞`）。查询集包含`11`个细胞群的`4,218`个细胞（`alpha`、`beta`、`导管`、`胰腺多肽`、`腺泡`、`delta`、`胰腺星状`、`内皮`、`epsilon`、`肥大细胞`和`MHC II类`）。\n\n#### PBMC 10k\n\n`PBMC 10k`数据集包括来自一位健康供体的两批`scRNA-seq`人类外周血单个核细胞。该数据集由Gayoso$^{[41]}$等人重新处理，得到`3,346`个差异表达基因。第一批包含`7,982`个细胞，第二批包含`4,008`个细胞。使用`Seurat`$^{[39]}$注释的细胞群包括九个类别，即`B细胞`、`CD4+ T细胞`、`CD8+ T细胞`、`CD14+单核细胞`、`树突状细胞`、`NK细胞`、`FCGR3A+单核细胞`、`巨核细胞`和其他。\n\n#### 人类免疫\n\n人类免疫数据集包括五个`scRNA-seq`数据集：一个来自人类骨髓，四个来自人类外周血。使用了各种测序技术，包括`10x Genomics`、`10x Genomics (v.2)`、`10x Genomics (v.3)`和`Smart-seq2`。该数据集总共包含`33,506`个细胞和`12,303`个基因。根据供体来源定义了十个不同的批次。协调后的数据包含`16`个细胞群。我们使用了由Luecken$^{[50]}$等人重新处理的数据和注释。\n\n#### 近嗅皮层（Perirhinal cortex）\n\n近嗅皮层数据集包括两个不同的样本，取自Siletti$^{[42]}$等人的一项更大规模研究，该研究最初包含`606`个高质量样本，涵盖十个不同的脑区。从近嗅皮层数据集选取的两个批次都包含大量细胞，第一批包含`8,465`个细胞，第二批包含`9,070`个细胞。这些数据集包含了范围广泛的`59,357`个基因。我们使用了原始研究中提供的十种独特细胞类型的注释。\n\n#### COVID-19\n\n`COVID-19`数据集来源于Lotfollahi$^{[12]}$等人的工作，分为`18`个不同的批次，包含来自肺组织、`PBMCs`和骨髓的多样化细胞。该数据集最初包含`274,346`个细胞和`18,474`个基因，为了本研究的目的，已被抽样至总共`20,000`个细胞。我们使用了原始研究提供的注释。对于参考映射评估，我们随机选择了`12`个样本批次作为参考数据集，另外`6`个批次作为查询数据集。最终的参考数据集包含`15,997`个细胞，查询数据集包含`4,003`个细胞。\n\n#### Adamson\n\nAdamson扰动数据集包含通过`Perturb-seq`$^{[33]}$扰动的`K562`白血病细胞系的基因表达数据。该数据集包括`87`个独特的单基因`CRISPR`干扰扰动，每个扰动在大约`100`个细胞中重复。\n\n#### Norman\n\nNorman扰动数据集包含通过`Perturb-seq`$^{[35]}$扰动的`K562`白血病细胞系的基因表达数据。该数据集有`131`个双基因扰动和`105`个单基因扰动。每个扰动在约`300-700`个细胞中重复。\n\n#### Replogle\n\nReplogle扰动数据集包含对`K562`白血病细胞系进行`CRISPR`干扰$^{[34]}$的全基因组扰动。考虑到数据质量，我们保留了与原始研究中识别的`1,973`个具有强转录表型扰动相匹配的数据子集。我们还删除了`150`个在测序数据中没有扰动基因表达记录的扰动。我们进一步为每个扰动保留了`100`个样本和`2,500`个对照样本。处理后的完整数据集包括来自`1,823`个扰动的`171,542`个样本，其中`99`个是转录因子的扰动。测试集包括`456`个扰动，其中`25`个是转录因子的扰动。\n\n#### Multiome PBMC\n\n[10x Multiome PBMC](https://support.10xgenomics.com/single-cell-multiome-atac-gex/datasets/1.0.0/pbmc_granulocyte_sorted_10k) 数据集包含来自人类`PBMC`细胞的配对单细胞`RNA`和`ATAC`数据，这些数据是通过`10x Single Cell Multiome`协议测序获得的。在该数据集中，所有样本都来自同一位健康供体。每个细胞都具有基因表达和染色质可及性测量。处理后的数据$^{[13]}$来自`9,631`个细胞，包含来自`29,095`个基因和`107,194`个染色质区域的读数计数。注释包括`19`个细胞群（`CD14+单核细胞`、`CD16+单核细胞`、`CD4+初始`、`CD4+ TCM`、`CD4+ TEM`、`CD8+初始`、`CD8+ TEM 1`、`CD8+ TEM 2`、`HSPCs`、`中间B细胞`、`MAIT`、`记忆B细胞`、`NK`、`初始B细胞`、`浆细胞`、`Treg`、`cDC`、`gdT`和`pDC`）。\n\n#### BMMC\n\n`BMMC`数据集包含通过`CITE-seq`协议$^{[45]}$测序的`BMMCs`配对单细胞RNA和蛋白质丰度测量。这些细胞来自`12`位健康人类供体，在该数据集中构成`12`个批次。处理后的数据代表`90,261`个细胞，包含来自`13,953`个基因和`134`个表面蛋白的测量。注释包含`45`个详细的免疫细胞亚型。\n\n#### ASAP PBMC\n\n`ASAP PBMC`数据集包含四个测序批次，具有三种数据模态（基因表达、染色质可及性和蛋白质丰度）$^{[46]}$。四个批次分别包含`5,023`、`3,666`、`3,517`和`4,849`个细胞。在批次1和2中，所有样本都有来自`CITE-seq`的`4,768`个基因和`216`个蛋白质测量。在批次3和4中，所有样本都有`17,742`个区域和来自`ASAP-seq`的相同`216`个蛋白质测量。注释$^{[46]}$包含四个细胞群（`B细胞`、`髓样细胞`、`NK细胞`和`T细胞`）。\n\n#### Lung-Kim\n\n该数据集包括`14`个[原发性人类肺腺癌样本](https://www.weizmann.ac.il/sites/3CA/lung)，总共`32,493`个细胞。该数据集可通过策展癌症细胞图谱公开访问。对于我们的研究，我们将其分为十个样本的参考集和四个样本的查询集。最初，该数据集包括`11`个细胞群：`B细胞`、`树突状细胞`、`内皮细胞`、`上皮细胞`、`成纤维细胞`、`巨噬细胞`、`恶性细胞`、`肥大细胞`、`NK细胞`、`T细胞`和一个未确定类别。在预处理中，我们移除了未确定类别并选择了`3,000`个`HVGs`用于下游评估。最终数据集包含`30,472`个细胞。对于参考映射评估，我们随机选择了十个患者样本作为参考数据集，另外四个患者样本作为查询数据集。最终的参考数据集包含`24,746`个细胞，查询数据集包含`7,747`个细胞。\n\n### 基准测试实验设置\n\n#### 单细胞RNA测序细胞类型注释\n\n我们在骨髓、多发性硬化症和人类胰腺数据集上，将`scGPT`与两种最新的基于`transformer`的细胞类型注释方法（`scBERT`和`TOSICA`）进行了基准测试对比。对于每个数据集，如前文所述，我们使用参考数据划分进行模型训练和验证。对查询集预测的细胞类型标签用于评估。\n\n我们基于四个标准分类指标评估细胞类型分配的性能：`准确率`、`精确率`、`召回率`和`宏观F1值`。`准确率`、`精确率`和`召回率`是针对整体性能进行全局计算，而`宏观F1值`则是按类别平均以增加稀有细胞类型的权重。我们还报告了按细胞类型\"精确率\"的归一化混淆矩阵以提供更多细节。\n\n#### 单细胞RNA测序扰动\n\n我们将`scGPT`与最新的扰动预测方法`GEARS`和线性回归模型进行了比较。线性回归模型将对照细胞的基因表达值和每个基因的扰动状态二进制编码作为输入特征。该模型通过最小化回归误差，使用输入特征的线性组合来估计每个基因的扰动后表达。为确保一致性，我们遵循了Roohani等人在其基准测试中概述的预处理步骤。将`25%`的扰动划分为测试集，在训练期间保持未见。\n\n虽然`GEARS`研究报告`CPA`方法表现次优，我们在实验中证实了这些发现。然而，我们认为这种性能差距主要归因于实验设置的差异。`CPA`主要设计用于学习适用于未见细胞类型的共享扰动嵌入，这与我们专注于完全未见扰动的目标有所偏离。为确保公平的基准测试，我们将`CPA`从最终比较中排除。\n\n我们在相同的设置下训练了所有模型并报告评估结果。首先，使用所有基因的总计数对每个细胞的基因表达值进行标准化，并应用对数转换。随后，我们选择了`5,000`个高变异基因，并将任何最初未考虑的受扰动基因纳入基因集。在实验中，对于所有三个数据集中的单基因扰动，对扰动进行拆分以确保测试扰动在训练中未见过，即训练集中的细胞未经历过任何测试扰动。对于Norman等人数据集中的双基因扰动，训练-测试分割包括三个难度递增的场景：\n\n1. 训练集中两个基因都见过；\n\n2. 训练集中一个基因未见过；\n\n3. 训练集中两个基因都未见过。\n\n为评估扰动预测的准确性，我们检查了扰动后和对照细胞状态之间的表达变化（\"`delta`\"）。我们计算了预测和观察到的数据表达变化之间的皮尔逊相关性，表示为`Pearson delta`。我们还报告了这些皮尔逊指标在表达差异最大的前20个基因上的结果。因此，我们为差异表达条件提供了额外的评估指标，即差异表达基因上的`Pearson delta`。此外，我们测试了预测基因表达与真实表达值之间的皮尔逊相关性（`Pearson`）。在补充说明9中进行的比较分析表明，基于`delta`的评估比仅与真实表达水平的相关性能更真实地反映模型性能。\n\n对于基于聚类的生物学验证，我们首先从`scGPT`模型中获取了每个扰动条件的代表性基因表达谱。`scGPT`从单个样本对照基因表达向量（即大小为`1×M`基因）预测每个扰动条件的代表性扰动响应，该向量是通过对数据集中所有对照细胞的基因表达取平均值获得的。Norman等人的数据集包含`105`个独特的受扰动基因，这产生了总共`5,565`个独特的扰动组合需要预测。\n\n我们将高维预测扰动响应投影到二维`UMAP`上。我们首先将`UMAP`图与Norman等人原始论文中发现的功能组进行了比较，其中`236`个扰动实验是基于真实扰动响应进行聚类，并通过标记基因表达注释其功能角色。我们检查了`scGPT`预测的`UMAP`投影与原始论文中发现的功能分组之间的一致性。然后，我们分析了`scGPT`预测的`UMAP`中存在的亚聚类。使用`0.5`的`Leiden`聚类分辨率，在预测扰动响应的`UMAP`中识别出`54`个亚聚类。我们用最频繁出现的受扰动基因作为其主导基因来注释每个聚类。\n\n对于反向扰动预测任务，我们从Norman数据集中选择了`20`个基因来构建扰动用例，并微调和测试新的扰动模型。这个`20`个基因的子集是通过最大化基于`scGPT`训练-测试分割的训练和测试案例的真实扰动数据比例来选择的。该选定子空间在`210`个独特扰动组合中包含`39`个训练案例、`3`个验证案例和`7`个测试案例。其余为无实验结果的未见案例。\n\n反向扰动预测遵循`top-K`检索任务设置：我们使用所有`210`个扰动条件的预测响应作为参考数据，使用七个测试案例的真实响应作为查询集。目标是检索产生最相似响应的顶部扰动条件。对于参考数据，我们从`30`个随机采样的对照细胞获得预测响应，以增加多样性，而不是每个扰动条件只有一个代表性基因表达谱。这产生了包含`6,300`个预测后扰动基因表达谱的参考数据库。对于每个`X+Y`扰动的测试案例，我们使用所有经历过`X+Y`扰动的细胞的真实基因表达谱作为查询集。\n\n对于`top-K`检索，我们设计了一个包含两轮选择的集成投票策略。在第一轮中，每个单独的查询细胞通过欧氏距离从参考数据集中选择其最相似的`K`个表达谱。在第二轮中，我们根据所有查询细胞的投票数对候选扰动条件进行排名。我们报告第二轮集成投票后得票最多的`K`个扰动条件作为预测的源扰动条件。\n\n我们通过修改后的`top-K`准确率指标评估检索性能，包括正确检索（即精确匹配）和相关检索（即与实际扰动组合中至少匹配一个基因）。我们报告了`scGPT`在五次不同随机种子运行的平均分数。我们将`scGPT`的检索性能与`GEARS`和差异基因进行了基准对比。对于与`GEARS`的基准对比，我们使用`GEARS`预测的表达谱作为参考数据库，并报告相同的`top-K`检索指标。对于差异基因，我们通过Wilcoxon秩和检验在受扰动细胞和对照细胞之间识别每个测试扰动的前两个差异表达基因。我们将这两个差异表达最显著的基因视为预测的top-1双基因扰动组合。我们仅报告差异表达的top-1检索指标，因为随着差异表达基因列表的扩大，扰动组合变得模糊不清。\n\n#### 单细胞RNA测序批次整合\n\n在这项工作中，我们将`scGPT`的性能与其他三种方法进行了比较，即`Seurat`、`Harmony`和`scVI`。评估涵盖了三个整合数据集的批次校正和细胞类型聚类：`COVID-19`、`PBMC 10k`和`perirhinal cortex`（外周皮层）。`Harmony`和`scVI`在最近的整合基准测试中被强调为表现最佳的方法。为确保公平比较，所有方法都使用相同数量的`1,200`个高变异基因（`HVGs`）作为输入。通过考虑所有基因的总计数对每个细胞的基因表达值进行标准化，随后进行对数转换。训练完成后获得集成的细胞嵌入，用于评估。\n\n对集成的细胞嵌入的评估是使用生物学保守性指标进行的。这些指标包括`NMIcell`、`ARIcell`和`ASWcell`。这些分数用于衡量派生的细胞类型聚类与真实标签之间的一致性。为便于比较，我们还计算了这些指标的平均值，称为`AvgBIO`。\n\n此外，我们报告了批次校正指标来评估批次混合效果。批次校正性能通过批次聚类的平均轮廓宽度的倒数（表示为`ASWbatch`）和图连通性度量（表示为`GraphConn`）来量化。我们计算`ASWbatch`和`GraphConn`的平均值作为`AvgBATCH`，以总结批次混合性能。此外，我们引入了一个总体得分，它是`AvgBIO`和`AvgBATCH`的加权和，这与最近的基准研究中采用的方法一致。\n\n#### 单细胞多组学整合\n\n我们在两种整合设置（配对和镶嵌）中对`scGPT`进行了基准测试，与最近的单细胞多组学整合方法`Seurat (v.4)`、`scGLUE`和`scMoMat`进行比较。在配对数据整合实验中，我们首先使用`10x Multiome PBMC`数据集（包含RNA和`ATAC-seq`数据）对`scGPT`与`scGLUE`和`Seurat (v.4)`进行了基准比较。所有方法都使用相同的`1,200`个高变异基因和`4,000`个高变异峰值作为输入。\n\n我们进一步在`BMMC`数据集（包含配对的RNA和蛋白质数据）上将`scGPT`与`Seurat (v.4)`进行了基准比较。在这种情况下，我们没有对`scGLUE`进行基准测试，因为该方法并非专门设计用于建模蛋白质数据，这是为了公平比较。同样，使用相同的`1,200`个高变异基因和所有`134`个蛋白质作为输入。\n\n在镶嵌数据整合实验中，我们在`ASAP PBMC`数据集上将`scGPT`与`scMoMat`进行了基准比较。总共使用`1,200`个高变异基因、`4,000`个高变异峰值和所有`216`个蛋白质特征作为两种方法的输入。在保持输入特征集一致的同时，我们使用每种方法的自定义预处理流程来标准化表达值。训练完成后获取集成的细胞嵌入用于评估。\n\n在配对和镶嵌数据整合设置的所有三个数据集中，我们使用四个生物学保守性指标来评估细胞嵌入质量：`NMIcell`、`ARIcell`、`ASWcell`和`AvgBIO`。由于在这三个数据集中，`BMMC`（配对）和`ASAP PBMC`（镶嵌）包含多个批次，我们进一步使用三个批次校正指标评估了不同组学批次的混合情况：`ASWbatch`、`GraphConn`和`AvgBATCH`。在镶嵌整合实验中还报告了一个总体得分。\n\n#### 基因调控网络推断\n\n我们对`scGPT`基因嵌入相似性网络进行了验证，将其与已知的`HLA`和`CD`基因网络进行比较。\n\n对于每个网络，我们首先通过筛选具有特定前缀（即`HLA-`和`CD-`）的基因名称来定义相关基因集。然后，我们筛选了来自`Reactome 2022`数据库中免疫系统`R-HSA-168256`通路中涉及的基因。对于`CD`基因，我们使用了来自免疫人类数据集的高变异基因的共同基因集，以便于比较预训练和微调模型。\n\n我们从`scGPT`模型中提取这些选定基因的基因嵌入，并构建了一个k近邻相似性网络。通过选择`余弦相似度`大于特定阈值的边（即`HLA`网络为`0.5`，`CD`基因网络为`0.4`），我们突出显示了强连接的子网络。然后，我们将这些子网络与免疫系统中已知的功能群进行了比较。\n\n此外，我们通过通路富集分析验证了由`scGPT`模型提取的基因程序的质量。我们使用每个基因程序作为输入基因列表，并选择具有统计显著性的通路作为\"通路命中\"。P值阈值经过`Bonferroni`校正后设定为`0.05`（[https://mathworld.wolfram.com/BonferroniCorrection.html](https://mathworld.wolfram.com/BonferroniCorrection.html)），校正基于总测试次数，即基因程序数量乘以通路测试数量。我们报告了在`Reactome 2022`数据库（[https://reactome.org/](https://reactome.org/)）中的通路命中数。\n\n作为基准，我们将结果与从基线`共表达图`中提取的基因程序进行了比较。共表达图是通过免疫人类数据集中基因标准化表达的`Pearson`相关性定义的。为确保与`scGPT`网络具有相似的模块性，我们将该图稀疏化为k近邻相似性网络（`k=15`）。按照与`scGPT`相同的流程，我们通过`Leiden`聚类从基因集群中识别基因程序。\n\n作为敏感性分析，我们报告了`scGPT`和共表达方法在不同`Leiden`分辨率（`1`、`5`、`10`、`20`、`30`、`40`、`50`和`60`）下的通路命中情况。我们进一步在`Leiden`分辨率`40`下检查了每种方法识别的共同和独特通路，以深入了解性能差异。\n\n我们在`ChIP-Atlas`数据库中验证了基于`scGPT`注意力的最受影响基因选择方法，该数据库包含已知转录因子的实验验证基因靶点。我们首先通过将`Adamson`扰动数据集中的扰动基因列表与`ChIP-Atlas`交叉检查，选择了两个示例转录因子，它们由`DDIT3`和`BHLHE40`编码。对于每个转录因子，我们通过将\"差异\"设置下注意力选择的前`20`个最受影响基因与已验证的基因靶点进行比较来进行验证。需要注意的是，在\"差异\"设置下，前`20`个基因是基于扰动后变化通过检查扰动注意力图和对照注意力图之间的差异来选择的。\n\n真实的基因靶点列表是通过从`ChIP-Atlas`中筛选人类基因（`hg38`）获得的，这些基因的转录起始位点位于转录因子峰值调用区间的`10kb`距离内。我们报告了注意力选择的前`20`个基因靶点与真实靶点基因之间的重叠数量。\n\n随后，我们比较了三种最受影响基因选择方法（即对照组、扰动组和差异组）中前`100`个选定基因之间的重叠情况。这三组前`100`个基因集合的重叠和差异通过`Venn`图进行可视化。我们还在`Reactome`数据库中进一步验证了这些顶部基因与转录因子一起参与的通路。通路命中和基因重叠百分比通过热图进行可视化。\n\n我们进一步验证了功能相关转录因子组的最受影响基因选择分析。我们使用了由`Replogle`等人确定的两个示例扰动组，这些组分别与`mRNA`多聚腺苷化和组蛋白乙酰化相关。通过与`ChIP-Atlas`数据库交叉检验，我们从扰动基因列表中选择了转录因子。因此，我们得到了以下具有功能注释的转录因子基因组：\n\n1. 用于`mRNA`多聚腺苷化的`CPSF2`、`CPSF3`、`CPSF4`和`CSTF3`；\n\n2. 用于组蛋白乙酰化的`KAT8`、`MCRS1`和`YEATS4`。\n\n需要注意的是，`KANSL3`和`CPSF1`也被`Replogle`等人列入这两个功能组。然而，由于这些基因对应的转录因子在用于构建注意力图的`1,200`个`HVG`中有超过十个注释的基因靶点，因此在后续分析中将其排除。\n\n按照之前对单个转录因子的分析方法，我们首先使用\"扰动\"设置为每个转录因子选择前`20`个最受影响的基因，并在`ChIP-Atlas`数据库中验证基因靶点。对于每个功能组，我们随后报告了所有转录因子（连同转录因子本身）的前`100`个最受影响基因富集的`Reactome`通路。具体而言，对于`mRNA`多聚腺苷化，我们从`CPSF2`、`CPSF3`、`CPSF4`和`CSTF3`的前`25`个最受影响基因的并集中获得前`100`个最受影响基因；对于组蛋白乙酰化，则从`KAT8`、`MCRS`和`YEATS4`的前`33`个最受影响基因的并集中获得。\n\n为了验证，我们将富集的`Reactome`通路与`Replogle`等人的功能注释特定术语进行比较。我们还通过文献检索进一步验证了相关通路。如果满足以下两个标准之一，则认为某个术语是相关的：\n\n1. 它包含一个或多个转录因子；\n\n2. 其与功能注释的关联得到现有文献支持。\n\n### 实现细节\n\n预训练的基础模型具有`512`的嵌入大小，由`12`个堆叠的转换器块组成，每个块有`8`个注意力头。全连接层的隐藏层大小为`512`。在使用`3300`万个细胞的全人类模型预训练中，我们随机拆分数据，使用`99.7%`的数据用于训练，`0.3%`用于验证。对于其他模型（包括器官特异性模型和泛癌症模型）的预训练，我们随机拆分数据，使用`97%`的数据用于训练，`3%`用于验证。注意，在预训练中，只有非零表达的基因才会输入到模型中。我们设置最大输入长度为`1,200`。对于非零基因数量大于最大输入长度的细胞，会在每次迭代时随机采样`1,200`个输入基因。我们设置要生成的基因比率从`0.25`、`0.50`和`0.75`三个选项中均匀采样。模型使用`Adam`优化器进行优化，小批量大小为`32`，初始学习率为`0.0001`，每个周期后权重衰减`0.9`。模型总共训练了`6`个周期。\n\n对于`scRNA-seq`批次整合、细胞类型注释和扰动预测任务，我们使用了从预训练模型继承的相同模型层配置。在微调过程中，我们以`0.0001`的学习率开始，每个周期后衰减到`90%`。对于整合任务，`GEP`和`GEPC`的掩码比率设置为`0.4`，而`ECS`中的参数`β`设置为`0.6`。当与其他损失函数结合时，`ECS`被赋予权重`10`。为了将数据集划分为训练集和验证集，我们使用了`9:1`的比例。模型训练固定持续了`15`个周期，在每个周期后，在验证集上评估`GEP`损失值。报告的结果对应于具有最佳验证分数的模型。\n\n对于多组学整合任务，我们加载了预训练模型的基因嵌入，并对任何新的标记（即基因、`ATAC`峰值或蛋白质）使用相同的`512`嵌入大小。主模型设置为具有`4`个堆叠的转换器块，每个块有`8`个注意力头和`512`的隐藏层大小。除了预训练的嵌入权重外，所有层都重新初始化。每个数据集以`9:1`的比例分为训练集和评估集。我们对批次整合使用了`1.0`的`DAR`权重。我们使用`0.001`的初始学习率，每个周期后权重衰减`0.95`。我们以`16`的批量大小训练模型固定`25`个周期，并同样报告了最佳验证模型。\n\n我们使用`PyTorch`来实现`scGPT`神经网络模型。`Scanpy Python`库用于基因表达预处理，包括标准化、对数转换和`HVG`选择。我们在染色质可及性数据上使用`EpiScanpy Python`库进行高变异峰值选择。在`scRNA-seq`批次整合和`scMultiomic`整合任务中，使用`scib.metrics`中的实现计算评估指标。在细胞注释任务中，使用`scikit-learn`包实现评估指标。在`GRN`推断任务中，使用`Scanpy`库进行相似性图构建和`Leiden`聚类。使用`GSEApy`包实现通路富集分析。其他依赖项包括`torchtext 0.14.0`、`torch-geometric 2.3.0`、`flash-attn 1.0.1`、`pandas 1.3.5`、`cell-gears 0.0.1`、`umap-learn 0.5.3`、`leidenalg 0.8.10`和`wandb 0.12.3`。\n\n## 数据可用性\n\n所有使用的数据集来源都已在数据集部分中报告。预训练数据集可以从`CELLxGENE`普查数据库（`2023`年`5`月`15`日发布版本）获取：\n* [https://chanzuckerberg.github.io/cellxgene-census/python-api.html](https://chanzuckerberg.github.io/cellxgene-census/python-api.html)\n* [https://cellxgene.cziscience.com/](https://cellxgene.cziscience.com/)\n\n对于注释任务，`MS`数据集从：[https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-35](https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-35)获取。髓样细胞数据集可以通过`GEO`数据库访问号`GSE154763`公开获取。处理后的人类胰腺数据集从：[https://github.com/JackieHanLab/TOSICA](https://github.com/JackieHanLab/TOSICA) 获取。\n\n对于参考映射，`Lung-Kim`数据集可通过曲率癌细胞图谱公开获取：[https://www.weizmann.ac.il/sites/3CA/lung](https://www.weizmann.ac.il/sites/3CA/lung)。处理后的`COVID-19`数据集从：[https://github.com/theislab/scarches-reproducibility](https://github.com/theislab/scarches-reproducibility) 获取。对于扰动预测任务，`Norman`和`Adamson`数据集分别从：\n* [https://dataverse.harvard.edu/api/access/datafile/6154020](https://dataverse.harvard.edu/api/access/datafile/6154020)\n* [https://dataverse.harvard.edu/api/access/datafile/6154417](https://dataverse.harvard.edu/api/access/datafile/6154417)\n\n获取。`Replogle`数据集从：[https://gwps.wi.mit.edu/](https://gwps.wi.mit.edu/) 获取。\n\n对于批次整合任务，`PBMC 10k`数据集从`scVI tools`（ [https://scvi-tools.org/](https://scvi-tools.org/) ）获取，外周皮层数据集从`CELLxGENE`人类脑细胞图谱1.0版本获取：[https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443](https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443) 。\n\n对于多组学整合任务，`10x Multiome PBMC`数据集从：[https://scglue.readthedocs.io/en/latest/data.html](https://scglue.readthedocs.io/en/latest/data.html) 获取，`BMMC`数据集可通过`GEO`数据库访问号`GSE194122`获取，`ASAP PBMC`数据集从：[https://github.com/PeterZZQ/scMoMaT/tree/main/data/real/ASAP-PBMC](https://github.com/PeterZZQ/scMoMaT/tree/main/data/real/ASAP-PBMC) 获取。\n\n对于`GRN`分析，处理后的免疫人类数据集从：[https://doi.org/10.6084/m9.figshare.12420968.v8](https://doi.org/10.6084/m9.figshare.12420968.v8) 获取。所有处理后的数据集都可以从：\n* [https://github.com/bowang-lab/scGPT](https://github.com/bowang-lab/scGPT)\n* [https://doi.org/10.6084/m9.figshare.24954519.v1](https://doi.org/10.6084/m9.figshare.24954519.v1) \n\n获取。\n\n## 代码可用性\n\n`scGPT`的代码库在`GitHub`上公开可用（ [https://github.com/bowang-lab/scGPT](https://github.com/bowang-lab/scGPT) ），并在`Zenodo`存储库（ [https://doi.org/10.5281/zenodo.10466117](https://doi.org/10.5281/zenodo.10466117) ）中提供，采用`MIT`许可证。\n\n# 补充信息\n`补充信息1–12`，`表1–7`和`图1–13`请在这里查看：[41592_2024_2201_MOESM1_ESM.pdf](https://static-content.springer.com/esm/art%3A10.1038%2Fs41592-024-02201-0/MediaObjects/41592_2024_2201_MOESM1_ESM.pdf) 。\n\n# 参考文献\n\n1. Silverman, A. D., Karim, A. S. & Jewett, M. C. Cell-free gene expression: an expanded repertoire of applications. Nat. Rev. Genet. 21, 151-170 (2020).\n\n2. Preissl, S., Gaulton, K. J. & Ren, B. Characterizing cis-regulatory elements using single-cell epigenomics. Nat. Rev. Genet. 24, 21-43 (2022).\n\n3. Ding, J., Sharon, N. & Bar-Joseph, Z. Temporal modelling using single-cell transcriptomics. Nat. Rev. Genet. 23, 355-368 (2022).\n\n4. Wagner, D. E. & Klein, A. M. Lineage tracing meets single-cell omics: opportunities and challenges. Nat. Rev. Genet. 21, 410-427 (2020).\n\n5. Regev, A. Science Forum: the Human Cell Atlas. eLife 6, e27041 (2017).\n\n6. Han, X. Mapping the mouse cell atlas by Microwell-seq. Cell 172, 1091-1107 (2018).\n\n7. Angerer, P. et al. Single cells make big data: new challenges and opportunities in transcriptomics. Curr. Opin. Syst. Biol. 4, 85-91 (2017).\n\n8. Subramanian, I., Verma, S., Kumar, S., Jere, A. & Anamika, K. Multi-omics data integration, interpretation, and its application. Bioinform. Biol. Insights 14, 1177932219899051 (2020).\n\n9. Miao, Z., Humphreys, B. D., McMahon, A. P. & Kim, J. Multi-omics integration in the age of million single-cell data. Nat. Rev. Nephrol. 17, 710-724 (2021).\n\n10. Lotfollahi, M., Wolf, F. A. & Theis, F. J. scGen predicts single-cell perturbation responses. Nat. Methods 16, 715-721 (2019).\n\n11. Lotfollahi, M. Predicting cellular responses to complex perturbations in high-throughput screens. Mol. Syst. Biol. 19, e11517 (2023).\n\n12. Lotfollahi, M. Mapping single-cell data to reference atlases by transfer learning. Nat. Biotechnol. 40, 121-130 (2022).\n\n13. Cao, Z.-J. & Gao, G. Multi-omics single-cell data integration and regulatory inference with graph-linked embedding. Nat. Biotechnol. 40, 1458-1466 (2022).\n\n14. Zhang, Z. et al. scMoMat jointly performs single cell mosaic integration and multi-modal bio-marker detection. Nat. Commun. 14, 384 (2023).\n\n15. Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at https://doi.org/10.48550/arXiv.2108.07258 (2021).\n\n16. Moor, M. et al. Foundation models for generalist medical artificial intelligence. Nature 616, 259-265 (2023).\n\n17. Vaswani, A. et al. Attention is all you need. Adv. Neural Inf. Process. Syst. 6000-6010 (NeurIPS, 2017).\n\n18. Ramesh, A., Dhariwal, P., Nichol, A., Chu, C. & Chen, M. Hierarchical text-conditional image generation with CLIP latents. Preprint at https://doi.org/10.48550/arXiv.2204.06125 (2022).\n\n19. Brown, T. Language models are few-shot learners. Adv. Neural. Inf. Process. Syst. 1877-1901 (NeurIPS, 2020).\n\n20. OpenAI team. GPT-4 technical report. Preprint at https://doi.org/10.48550/arXiv.2303.08774 (2023).\n\n21. Avsec, Z. et al. Effective gene expression prediction from sequence by integrating long-range interactions. Nat. Methods 18, 1196-1203 (2021).\n\n22. Gururangan, S. et al. Don't stop pretraining: adapt language models to domains and tasks. In Proc. 58th Annual Meeting of the Association for Computational Linguistics 8342-8360 (ACL, 2020).\n\n23. Qiu, X. et al. Pre-trained models for natural language processing: a survey. Sci. China Technol. Sci. 63, 1872-1897 (2020).\n\n24. Liu, J., Fan, Z., Zhao, W. & Zhou, X. Machine intelligence in single-cell data analysis: advances and new challenges. Front. Genet. 12, 655536 (2021).\n\n\n25. Oller-Moreno, S., Kloiber, K., Machart, P. & Bonn, S. Algorithmic advances in machine learning for single-cell expression analysis. Curr. Opin. Syst. Biol. 25, 27-33 (2021).\n\n26. Ji, Y., Lotfollahi, M., Wolf, F. A. & Theis, F. J. Machine learning for perturbational single-cell omics. Cell Syst. 12, 522-537 (2021).\n\n27. Theodoris, C. V. et al. Transfer learning enables prediction in network biology. Nature 618, 616-624 (2023).\n\n28. McInnes, L., Healy, J. & Melville, J. UMAP: uniform manifold approximation and projection for dimension reduction. Preprint at https://doi.org/10.48550/arXiv.1802.03426 (2018).\n\n29. Schirmer, L. Neuronal vulnerability and multilineage diversity in multiple sclerosis. Nature 573, 75-82 (2019).\n\n30. Cheng, S. A pan-cancer single-cell transcriptional atlas of tumor infiltrating myeloid cells. Cell 184, 792-809 (2021).\n\n31. Chen, J. et al. Transformer for one stop interpretable cell type annotation. Nat. Commun. 14, 223 (2023).\n\n32. Yang, F. et al. scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data. Nat. Mach. Intell. 4, 852-866 (2022).\n\n33. Adamson, B. A multiplexed single-cell CRISPR screening platform enables systematic dissection of the unfolded protein response. Cell 167, 1867-1882 (2016).\n\n34. Replogle, J. M. Mapping information-rich genotype-phenotype landscapes with genome-scale Perturb-seq. Cell 185, 2559-2575 (2022).\n\n35. Norman, T. M. et al. Exploring genetic interaction manifolds constructed from rich single-cell phenotypes. Science 365, 786-793 (2019).\n\n36. Roohani, Y., Huang, K. & Leskovec, J. Predicting transcriptional outcomes of novel multigene perturbations with GEARS. Nat. Biotechnol. https://doi.org/10.1038/s41587-023-01905-6 (2023).\n\n37. Traag, V. A., Waltman, L. & Van Eck, N. J. From Louvain to Leiden: guaranteeing well-connected communities. Sci. Rep. 9, 5233 (2019).\n\n38. Lopez, R., Regier, J., Cole, M. B., Jordan, M. I. & Yosef, N. Deep generative modeling for single-cell transcriptomics. Nat. Methods 15, 1053-1058 (2018).\n\n39. Satija, R., Farrell, J. A., Gennert, D., Schier, A. F. & Regev, A. Spatial reconstruction of single-cell gene expression data. Nat. Biotechnol. 33, 495-502 (2015).\n\n40. Korsunsky, I. et al. Fast, sensitive and accurate integration of single-cell data with Harmony. Nat. Methods 16, 1289-1296 (2019).\n\n41. Gayoso, A. A Python library for probabilistic analysis of single-cell omics data. Nat. Biotechnol. 40, 163-166 (2022).\n\n42. Siletti, K. Transcriptomic diversity of cell types across the adult human brain. Science 382, eadd7046 (2023).\n\n\n43. PBMC from a healthy donor, single cell multiome ATAC gene expression demonstration data by Cell Ranger ARC 1.0.0. 10X Genomics https://support.10xgenomics.com/single-cell-multiome-atac-gex/datasets/1.0.0/pbmc_granulocyte_sorted_10k (2020).\n\n44. Hao, Y. Integrated analysis of multimodal single-cell data. Cell 184, 3573-3587 (2021).\n\n45. Luecken, M. et al. A sandbox for prediction and integration of DNA, RNA, and proteins in single cells. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 13 (NeurIPS, 2021).\n\n46. Mimitou, E. P. Scalable, multimodal profiling of chromatin accessibility, gene expression and protein levels in single cells. Nat. Biotechnol. 39, 1246-1258 (2021).\n\n47. Pratapa, A., Jalihal, A. P., Law, J. N., Bharadwaj, A. & Murali, T. M. Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data. Nat. Methods 17, 147-154 (2020).\n\n48. Choo, S. Y. The HLA system: genetics, immunology, clinical testing, and clinical implications. Yonsei Med. J. 48, 11-23 (2007).\n\n49. Norman, P. S. Immunobiology: the immune system in health and disease. J. Allergy Clin. Immunol. 96, 274 (1995).\n\n50. Luecken, M. D. Benchmarking atlas-level data integration in single-cell genomics. Nat. Methods 19, 41-50 (2022).\n\n51. Zou, Z., Ohta, T., Miura, F. & Oki, S. ChIP-Atlas 2021 update: a data-mining suite for exploring epigenomic landscapes by fully integrating ChIP-seq, ATAC-seq and Bisulfite-seq data. Nucleic Acids Res. 50, W175-W182 (2022).\n\n52. Yang, H., Niemeijer, M., van de Water, B. & Beltman, J. B. ATF6 is a critical determinant of CHOP dynamics during the unfolded protein response. iScience 23, 100860 (2020).\n\n53. Yoshida, H. et al. ATF6 activated by proteolysis binds in the presence of NF-Y (CBF) directly to the cis-acting element responsible for the mammalian unfolded protein response. Mol. Cell. Biol. 20, 6755-6767 (2000).\n\n54. Kaplan, J. et al. Scaling laws for neural language models. Preprint at https://doi.org/10.48550/arXiv.2001.08361 (2020).\n\n\n56. Haque, A., Engel, J., Teichmann, S. A. & Lönnberg, T. A practical guide to single-cell RNA-sequencing for biomedical research and clinical applications. Genome Med. 9, 1-12 (2017).\n\n57. Devlin, J., Chang, M. W., Lee, K. & Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. In Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics 4171-4186 (ACL, 2019).\n\n58. Dao, T., Fu, D., Ermon, S., Rudra, A. & Ré, C. FlashAttention: fast and memory-efficient exact attention with IO-Awareness. Adv. Neural. Inf. Process. Syst. 16344-16359 (NeurIPS, 2022).\n\n59. Wang, S., Li, B. Z., Khabsa, M., Fang, H. & Ma, H. Linformer: self-attention with linear complexity. Preprint at https://doi.org/10.48550/arXiv.2006.04768 (2020).\n\n60. Katharopoulos, A., Vyas, A., Pappas, N. & Fleuret, F. Transformers are RNNs: fast autoregressive transformers with linear attention. In Proc. 37th International Conference on Machine Learning 5156-5165 (PMLR, 2020).\n\n61. Liu, Y. RoBERTa: a robustly optimized BERT pretraining approach. Preprint at https://doi.org/10.48550/arXiv.1907.11692 (2019).\n\n62. Bubeck, S. et al. Sparks of artificial general intelligence: early experiments with GPT-4. Preprint at https://doi.org/10.48550/arXiv.2303.12712 (2023).\n\n63. Liu, C. et al. Guided similarity separation for image retrieval. Adv. Neural. Inf. Process. Syst. 1556-1566 (NeurIPS, 2019).\n\n64. Eisenstein, M. Single-cell RNA-seq analysis software providers scramble to offer solutions. Nat. Biotechnol. 38, 254-257 (2020).\n\n65. Tran, H. T. N. et al. A benchmark of batch-effect correction methods for single-cell RNA sequencing data. Genome Biol. 21, 12 (2020).\n\n66. Ganin, Y. & Lempitsky, V. Unsupervised domain adaptation by backpropagation. In Proc. 32nd International Conference on Machine Learning 1180-1189 (PMLR, 2015).\n\n67. Cecilia, N. Identification of transcriptional programs using dense vector representations defined by mutual information with GeneVector. Nat. Commun. 14, 4400 (2023).\n\n68. Kim, N. Single-cell RNA sequencing demonstrates the molecular and cellular reprogramming of metastatic lung adenocarcinoma. Nat. Commun. 11, 2285 (2020).\n\n69. Paszke, A. PyTorch: an imperative style, high-performance deep learning library. Adv. Neural Inf. Process. Sys. 1-12 (NeurIPS, 2019).\n\n70. Wolf, F. A., Angerer, P. & Theis, F. J. Scanpy: large-scale single-cell gene expression data analysis. Genome Biol. 19, 15 (2018).\n\n71. Danese, A. et al. EpiScanpy: integrated single-cell epigenomic analysis. Nat. Commun. 12, 5228 (2021).\n\n72. Fang, Z., Liu, X. & Peltz, G. GSEApy: a comprehensive package for performing gene set enrichment analysis in Python. Bioinformatics 39, btac757 (2023).\n\n73. Wang, C. Processed datasets used in the scGPT foundation model. Figshare https://doi.org/10.6084/m9.figshare.24954519.v1 (2024).\n\n\n74. Cui, H., Wang, C. & Pang, K. Codebase for scGPT: towards building a foundation model for single-cell multi-omics using generative AI. Zenodo https://doi.org/10.5281/zenodo.10466117 (2024).\n","categories":["论文解读"]},{"title":"Enformer：通过整合长程相互作用从序列中有效预测基因表达","url":"/2024/11/26/906k2592/","content":"\n# 文章链接\n\n> Avsec, Ž., Agarwal, V., Visentin, D., Ledsam, J. R., Grabska-Barwinska, A., Taylor, K. R., Assael, Y., Jumper, J., Kohli, P., & Kelley, D. R. (2021). Effective gene expression prediction from sequence by integrating long-range interactions. Nature Methods, 18, 1196–1203. [https://doi.org/10.1038/s41592-021-01252-x](https://doi.org/10.1038/s41592-021-01252-x)\n\n# 简介\n\n`Enformer`：一个用于预测基因表达的深度学习架构。\n\n# 摘要\n\n`非编码DNA`如何在不同细胞类型中决定基因表达是一个重大的未解之谜，而在人类遗传学中的许多重要下游应用都依赖于对这个问题的深入理解。在此，我们报告通过使用一种称为`Enformer`的深度学习架构，显著提高了从DNA序列预测基因表达的准确性。该架构能够整合基因组中的长程相互作用信息（距离可达`100kb`）。这种改进使得对自然遗传变异和通过`大规模平行报告基因检测`（`massively parallel reporter assays`）测量的饱和突变对基因表达的影响预测更加准确。此外，`Enformer`学会直接从DNA序列预测增强子-启动子相互作用，其准确度可与直接使用实验数据作为输入的方法相媲美。我们预计这些进展将有助于更有效地精确定位人类疾病的相关性，并为解释`顺式调控元件`（`cis-regulatory`）的进化提供一个理论框架。\n\n# 创新点\n\n1. 使用`transformer架构`替代传统的卷积神经网络，能够整合长距离(`最远100kb`)的DNA序列信息。这比之前的模型(如`Basenji2`)的`20kb`范围更大。\n2. 在基因表达预测方面取得显著提升:\n\n   - 皮尔逊相关系数从0.81提升至0.85\n\n   - 在不同组织和细胞类型的预测准确度都有提高\n\n\n3. 模型可以有效识别和使用调控元件:\n\n   - 能够识别增强子及其与启动子的相互作用\n\n   - 能够识别绝缘子元件和拓扑相关结构域(TAD)边界\n\n> `transformer架构`可参考这篇文章：{% postLinkCard skrzswes  \"auto\" %}\n\n# 主要内容\n\n## 读前须知\n\n1. 论文解读尽可能的还原原文，若有不恰当之处，还请见谅；\n2. 排版上，插图会尽量贴近出处，而扩展图之类的，会放置末尾处；\n3. 左边👈有目录，可自行跳转至想看的部分；\n4. 部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（`Receptive field`）。请注意，仅首次出现会标明；\n\n## 背景\n\n从DNA序列预测基因表达和染色质状态的模型，有望更好地理解转录调控以及它如何受到与人类疾病和性状相关的众多非编码遗传变异的影响。这些模型补充了基于人群的关联研究，后者通常仅限于常见变异，并且由于连锁不平衡（`LD`）而难以区分因果关系和关联性。此外，人类遗传变异的实验验证工作量大，且仅限于可在实验室中重现的细胞类型或组织，这使得在相关生物环境中测试所有感兴趣的变异变得不可行。虽然基于序列的计算模型原则上可以克服这些挑战，但它们的准确性仍然有限，使得从序列预测基因表达成为一个关键的未解决问题。\n\n> 连锁不平衡：基因组中相邻位置的遗传变异倾向于一起遗传的现象。即某些等位基因或遗传变异在群体中共同出现的频率高于随机预期。\n\n深度卷积神经网络（`CNNs`）在预测人类和小鼠基因组的基因表达方面达到了目前的最高水平。然而，这些模型在做出预测时，只能考虑距转录起始位点（`TSS`）最远`20kb`的序列元件，因为卷积的局部性限制了网络中远距离元件之间的信息流动。许多经过深入研究的调控元件，包括增强子、抑制子和绝缘子，都可以从超过`20kb`的距离影响基因表达。因此，增加远距离元件之间的信息流动是提高预测准确性的一个有希望的途径。\n\n> `增强子(Enhancer)`：可以增强基因转录的DNA序列；\n>\n> `抑制子(Repressor)`：能够降低或抑制基因表达的DNA序列；\n>\n> `绝缘子(Insulator)`：位于拓扑相关结构域(TAD)的边界，主要功能是阻隔/隔离不同调控区域之间的相互作用，防止增强子错误调控非目标基因；\n>\n> 这三种元件共同参与精确调控基因表达，形成复杂的调控网络。\n\n## 核心内容\n\n在这项工作中，我们引入了一种基于自注意力（`self-attention`）的神经网络架构来实现这一目标。我们将机器学习问题定义为在多任务设置下预测长DNA序列中的数千个表观遗传和转录数据集。在人类和小鼠基因组的大部分区域进行训练，并在保留的序列上进行测试，我们观察到相对于之前没有自注意力的最先进模型，预测与测量数据之间的相关性有所提高。我们证明了对长程信息的更有效利用，这一点通过`CRISPRi`增强子检测得到了验证。该模型还能产生更准确的突变效应预测，这一点通过直接突变检测和人群`eQTL`研究得到了验证。\n\n> `自注意力机制`：允许模型在处理序列时，让每个位置都能\"关注\"并整合来自所有其他位置的信息。在Enformer中，这使得模型能够将位于不同位置的调控元件(如`启动子`和`增强子`)的信息关联起来。\n>\n> `eQTL`：表达数量性状位点，指能影响基因表达水平的DNA序列变异。这些变异可以位于基因内部或调控区域，通过影响转录调控或其他机制来改变基因的表达量。\n>\n> `CRISPRi增强子检测`：利用CRISPR干扰（CRISPR interference, CRISPRi）技术研究增强子功能的一种方法。CRISPRi通过抑制特定基因组区域的活性，可以系统性地筛选和验证增强子对基因表达的调控作用。\n\n## 成果\n\n### Enformer 改进了基因表达预测\n\n我们开发了一个名为`Enformer`（`enhancer`和`transformer`的组合词）的新模型架构，用于预测人类和小鼠的基因表达和染色质状态（图1a和扩展数据图1）。\n\n![image-20241212153414424](/images/assets//image-20241212153414424.png)\n\n`Transformer`是一类在自然语言处理（`NLP`）中取得重大突破的深度学习模型，最近也被应用于建模短DNA序列。它们由注意力层组成，这些层通过计算所有其他位置表征的`加权和`来转换输入序列中的每个位置。注意力权重取决于它们当前表征向量的嵌入和位置之间的距离。这使得模型能够，例如，`通过收集所有相关区域（如调控该基因的增强子）的信息来完善在转录起始位点的预测`。由于每个位置直接关注序列中的所有其他位置，它们能够实现远距离元件之间更好的信息流动。相比之下，卷积层由于其局部感受野，需要许多连续层才能到达远距离元件。使用`transformer`层使我们能够显著增加感受野，从而接触到距离达`100kb`的远距离调控元件，而之前最先进的模型`Basenji2`或`ExPecto`只能达到`20kb`（扩展数据图1）。这种感受野的增加很重要，因为它大大扩展了模型可见的相关增强子数量，从`<20kb`的`47%`增加到`<100kb`的`84%`（根据高置信度增强子-基因对的比例估计）。\n\n`Enformer`在预测人类蛋白质编码基因转录起始位点的RNA表达（通过`CAGE`测量）方面显著优于之前最好的模型`Basenji2`，平均相关性从`0.81`提高到`0.85`（图1b左）。这种性能提升是`Basenji1`和`Basenji2`之间性能提升的两倍，并缩小了三分之一到实验水平精确度（估计为`0.94`）的差距（扩展数据图2）。基因表达预测也更好地捕捉到了组织或细胞类型特异性（图1b右），包括密切相关的样本（扩展数据图3）。这种性能改进在所有四种基因组广泛轨迹类型中都是一致的，包括在各种细胞类型和组织中测量转录活性的`CAGE`、组蛋白修饰、转录因子结合和DNA可及性（图1c）。对`CAGE`的性能改进最大，这可能是因为组织特异性基因表达强烈依赖于远距离元件。\n\n> `测量转录活性的CAGE`：CAGE（Cap Analysis of Gene Expression）是一种测量转录起始活性的方法。它通过捕获mRNA 5'端的帽结构（cap），结合高通量测序，能够精确定位转录起始位点（TSS），并定量转录本的表达水平。这种技术特别适合分析启动子活性、TSS使用的变化，以及基因表达调控。\n>\n> `组蛋白修饰`：发生在组蛋白特定氨基酸残基上的共价化学修饰，这些修饰通过改变染色质的包装状态（紧致或松散），影响转录因子的结合，从而动态调控基因的活性。\n>\n> `转录因子结合`：转录因子（Transcription Factors, TFs）与DNA特定序列（通常是启动子或增强子上的顺式作用元件）的结合过程，这是基因表达调控的关键步骤。\n>\n> `DNA可及性`：DNA在染色质中的暴露程度，它决定了转录因子、RNA聚合酶等调控蛋白能否结合到特定的DNA区域。DNA可及性是基因表达调控的关键因素，受染色质结构的动态调节影响。\n\n在可视化基因组的观察和预测轨迹时，预测准确性的提高也是显而易见的（图1d）。`Enformer`在预测由`RNA-seq`测量的基因表达水平方面也优于`ExPecto`，在跨基因（`Spearman r`为`0.850`对`0.812`）和跨组织（`Spearman r`为`0.451`对`0.368`）评估中都表现更好（扩展数据图4）。这些结果证实`Enformer`架构在从DNA序列预测表观遗传标记和基因表达方面都提高了预测准确性。\n\n![image-20241212153504435](/images/assets//image-20241212153504435.png)\n\n为了确定相比于`Basenji2`中使用的扩张卷积，注意力层的具体优势，我们用扩张卷积替换了注意力层，并调整了学习率以获得最佳性能。注意力层在所有模型大小、层数和训练数据点数量上都优于扩张卷积（扩展数据图5a）。更大的感受野确实至关重要，因为当我们通过用局部注意力层替换全局注意力层，将`Enformer`的感受野限制为与`Basenji2`相同时，我们观察到性能显著下降（扩展数据图5b）。我们注意到，增加参数数量改善了模型性能，这与自然语言处理领域的最新进展一致。\n\n`Enformer`在`transformer`层中使用自定义的相对位置基函数，以更容易区分近端和远端调控元件，并区分转录起始位点上游和下游的位置。这两个特性相比于自然语言处理文献中通常使用的相对基函数和绝对位置编码都提供了明显的性能改进（扩展数据图6a、b）。总的来说，这些结果证实`注意力层比扩张卷积更适合基因表达预测`。\n\n### Enformer 关注细胞类型特异性增强子\n\n为了更好地理解`Enformer`在进行预测时使用了哪些序列元件，我们为几个具有经`CRISPRi`验证的增强子的基因计算了两种不同的基因表达`贡献分数`——输入梯度（`梯度×输入`）和注意力权重（方法和补充图1）。贡献分数突出显示了对特定基因表达预测最重要的输入序列。`体内突变`和`梯度×输入`是组织或细胞类型特异的，因为它们是相对于特定输出`CAGE`样本（例如`K562`）计算的。相比之下，注意力权重是模型的内部特征，在所有组织和细胞类型的预测中共享。\n\n我们检查了几个基因的贡献分数，发现它们与组蛋白`H3`在`K27`位乙酰化（`H3K27ac`）相关，不仅突出了局部启动子区域，还突出了距离超过`20 kb`的远端增强子（图2a和补充图2、3）。相比之下，由于感受野有限，`Basenji2`的贡献分数在距转录起始位点`20kb`以外的序列为零，因此错过了几个增强子。这个例子表明，`Enformer`在进行预测时确实关注了生物学相关区域，如距离超过`20kb`的增强子，并且基因表达贡献分数可以用来优先考虑相关的增强子。\n\n![image-20241212233856817](/images/assets//image-20241212233856817.png)\n\n> `H3K27ac`：发生在组蛋白 H3 的第 27 位赖氨酸（lysine 27, K27）上的 **乙酰化修饰**。它是一种表观遗传标记，与基因表达活跃和增强子功能密切相关。\n>\n> `K562`：一种来源于人慢性髓性白血病的永生化细胞系，常用于研究血液相关疾病、基因表达调控和分化机制。\n\n将通过生化注释识别的候选增强子链接到靶基因（通俗说：就是找出**增强子和它实际调控的基因之间的关系**）是一个重要但尚未解决的问题。由于标记的噪声和类别不平衡的组合，计算模型历来产生的准确性较低。为了系统地评估贡献分数在确定特定基因相关增强子方面的能力，我们比较了在`K562`细胞系上进行的两个大规模`CRISPRi`研究中测试的所有增强子-基因对的几种贡献分数。在这些实验中，使用`CRISPRi`抑制了超过`10,000`个候选增强子的活性，并测量其对基因表达的影响。\n\n`Enformer`贡献分数在几乎所有相对距离和不同类型的贡献分数上，都比`Basenji2`贡献分数或随机分数更准确地优先考虑了经验证的增强子-基因对（图2b，`Enformer`对`Basenji2`对随机）。`Enformer`的性能可以与`ABC`评分（一种最近专门为增强子优先级提出的最先进方法）相媲美，在某些情况下甚至更好。这一点很显著，因为`ABC`评分依赖于实验数据作为输入，如基于`HiC`的相互作用频率和`H3K27ac`（图2b，蓝色对绿色，和扩展数据图7a），而`Enformer`只使用DNA序列作为输入，并且从未被明确训练来定位增强子。这使得`Enformer`也可以用于缺乏实验数据的任意序列变异。\n\n> ABC评分：用于评估和优先排序基因组中增强子的功能性及其潜在靶基因。它基于增强子和靶基因之间的**活性、可及性**和**三维接触**数据，提出的一种定量化的评分体系。\n\n![image-20241212233945214](/images/assets//image-20241212233945214.png)\n\n![image-20241212234057560](/images/assets//image-20241212234057560.png)\n\n细胞类型特异的贡献分数比细胞类型非特异的贡献分数产生了更高的优先级性能，表明该模型按预期在不同细胞类型中使用不同的增强子序列（扩展数据图7c）。因此，`Enformer`贡献分数是一种有效的策略，可以在用于模型训练的细胞类型中确定`候选增强子的优先级`。\n\n接下来，我们探讨了模型是否学习了另一类重要的调控元件：绝缘子元件。这些元件将两个拓扑相关结构域（`TAD`）分开，并最小化两者之间的增强子-启动子串扰。我们检查了序列中心位于`TAD`边界处的注意力矩阵（相比于输入梯度，这些矩阵计算更有效，因为输出目标较多），并将其与没有特定对齐的序列的注意力矩阵进行比较。从查询位置的角度来看，`Enformer`对`TAD`边界的注意力比对随机位置的注意力更多（垂直红色条纹，图2c），而对边界另一侧区域的注意力更少（对角线外的蓝色区块，图2c），这与生物学上观察到的`TAD`间相互作用减少的现象一致。在`1,500`个测试序列中，这两种模式都具有统计学显著性（图2d，\"跨TAD\"和\"TAD边界处的关键位置\"）。在`TAD`边界处，模型用于做出`DNase`和`CAGE`预测的关键基序之一是`CTCF`，这种基序被发现与正负贡献分数都有关（扩展数据图8）。总的来说，这些结果表明，该模型不仅学习了组织特异性增强子和启动子的作用，还学习了绝缘子元件及其在抑制基因组区室间信息流动中的作用。\n\n> `拓扑相关结构域`（TAD, Topologically Associating Domains）：染色质三维结构中的功能性单位，指的是基因组中形成相对独立的空间区域，区域内的 DNA 片段更倾向于彼此互作，而与区域外的片段的互作较少。这种分区结构在基因表达调控中扮演重要角色。\n>\n> `DNase（脱氧核糖核酸酶）`：一种酶，能够催化DNA分子的水解反应，将DNA切割成较小的片段。DNase常用于研究染色质的开放状态和基因调控区域，特别是在染色质免疫沉淀（ChIP-Seq）和DNase-seq技术中，帮助识别活跃的基因调控元件。\n>\n> `CTCF（CCCTC-binding factor）`：一种高度保守的转录因子，广泛存在于真核生物中，尤其在基因调控和染色质结构中扮演重要角色。CTCF主要通过结合DNA上的特定序列（CCCTC）来调控基因的表达。\n\n### Enformer改进了eQTL数据的变异效应预测\n\n这项研究的一个核心目标是预测遗传变异对细胞类型特异性基因表达的影响，以帮助解释从`全基因组关联研究`中发现的数千个与表型相关的非编码关联。计算模型可以处理不同的等位基因并比较预测来评分遗传变异。一个成功的模型应该能够在不需要测量数百到数千个个体基因表达谱的情况下，产生基因表达数量性状位点（`eQTL`）研究的结果。\n\n> `eQTL（表达数量性状位点）`：指在基因组中与基因表达水平变异相关的遗传区域。eQTL分析研究的是特定基因的表达水平如何受到基因组变异（如SNPs）的影响。通过这种分析，可以识别与某些疾病、性状或生物学过程相关的基因调控区域。\n\n因此，我们研究了`GTEx`项目在数十个人类组织中发现的`eQTL`来验证模型预测。这种验证的主要挑战在于所研究人群中变异的共现（即连锁不平衡）会将因果`eQTL`的效应转移到邻近共现变异的测量值上。有向连锁不平衡谱（`SLDP`）回归是一种技术，它可以在考虑连锁不平衡的情况下，测量有向变异注释（如我们的模型预测）和`GWAS`汇总统计数据（如`GTEx eQTL`）之间的全基因组统计一致性（见方法）。在`648`个`CAGE`数据集（提供转录本的定量信息）中，有`379`个（`59.4%`）数据集中，跨`GTEx`组织的最大`SLDP Z`得分（代表最可能的最接近样本匹配）在`Enformer`预测中相比`Basenji2`有所增加。相比`Basenji2`，有`228`个`Enformer`最大`Z`得分增加超过一个标准差，而只有`46`个减少超过一个标准差。最大`Z`得分平均从`6.3`增加到`6.9`（图3a）。\n\n> `GTEx（Genotype-Tissue Expression）项目`：一个旨在研究`基因型与基因表达之间关系`的大型国际合作项目。该项目的目标是通过收集来自不同组织的样本，分析基因型（遗传变异）如何影响基因的表达，并探索这些变异如何与健康和疾病相关。GTEx项目收集了来自数百名个体的多种人体组织样本（例如大脑、肝脏、心脏等），对其进行基因组学分析，构建了一个基因型与基因表达的关系数据库。\n\n![image-20241212235659534](/images/assets//image-20241212235659534.png)\n\n需要注意的是，我们并不期望没有相关`GTEx`组织匹配的`CAGE`样本会出现增加的`SLDP Z`得分。在研究`GTEx`骨骼肌和皮下脂肪组织的`SLDP`时，我们观察到生物学相关的`CAGE`数据集（显示为蓝色）在从`Basenji2`到`Enformer`的过程中有所改善（图3b、c）。我们还发现，`Enformer`对`DNase`超敏感性的变异效应预测与`GTEx`的`SLDP`一致性高于`DeepSEA Beluga`（在`ExPecto`中使用）的替代方法（扩展数据图9）。因此，`Enformer`对非编码变异活性的预测似乎主要在样本具有相似细胞类型组成时得到改善，这与我们观察到的对保留序列的组织和细胞类型特异性改善一致。\n\n虽然连锁不平衡通常导致`GTEx eQTL`关联只能归因于频繁共现的变异集，但最新的`GTEx`版本包括了许多具有简单连锁模式的位点中的数千个关联，这些位点已经被精细定位到单个高概率的因果变异。\n\n> 因果变异：直接引起特定生物学性状或疾病的遗传变异。这些变异不仅与性状或疾病相关联，而且在遗传上具有因果关系，即它们直接影响性状或疾病的发生或发展。\n\n为了评估`Enformer`预测在识别因果变异方面的效用，我们为每个组织定义了一个分类任务，以区分可能的因果变异（因果概率`>0.9`，由基于人群的精细定位模型`SuSiE`确定）和可能的假阳性`eQTL`（因果概率`<0.01`），这些变异在可能的情况下与`eGene`相匹配（见方法）。我们通过计算参考和替代等位基因之间的预测差异向量（即评估参考减去替代等位基因，在序列上求和）来表示每个变异，为所有`5,313`个人类数据集产生特征。我们训练随机森林分类器。`Enformer`的预测使得分类器在`48`个`GTEx`组织中的`47`个组织中更加准确（图3d），平均`auROC`从`0.729`增加到`0.747`。这种改进在所有与转录起始位点的距离上都是一致的（图3e），这表明该模型不仅能更好地表示可能重叠长程增强子的变异（通过更大的感受野实现），而且还能更有效地解析启动子和短程增强子。在这些精细定位的`eQTL`中，`Enformer`模型在预测表达变化方向方面也比`Basenji2`更准确（扩展数据图10）。\n\n![image-20241212235748414](/images/assets//image-20241212235748414.png)\n\n一个`Enformer eQTL`概率预测相对于`Basenji2`有所增加的变异示例是`rs11644125`，它位于`NLRC5`基因转录起始位点下游约`35kb`的内含子中，该基因参与病毒免疫和细胞因子反应（图3f）。该变异已经在统计学上被精细定位为可能导致单核细胞和淋巴细胞血细胞计数变化。根据`GTEx`的数据，相对于主要等位基因`C`，次要等位基因`T`降低了全血中`NLRC5`的基因表达。`Enformer`正确预测了许多相关`CAGE`样本（包括外周血单个核细胞）中上游转录起始位点的`NLRC5`表达降低。使用局部区域的体内突变（见方法），我们观察到变异`rs11644125`调节了转录因子`SP1`的已知基序。`Enformer`预测表明，在造血细胞中`SP1`结合的扰动改变了`NLRC5`表达，这是这些性状的一个机制。\n\n![image-20241212235902773](/images/assets//image-20241212235902773.png)\n\n### Enformer改进了MPRA变异效应预测\n\n> `MPRA（Massively Parallel Reporter Assays）`：一种用于高通量评估基因调控元件功能的实验技术。MPRA结合了报告基因系统和高通量测序技术，能够同时评估大量潜在的基因调控元件（如增强子、启动子等）的活动。\n\n最后，我们使用第二个独立的变异效应预测任务评估了`Enformer`的性能，这个任务使用了一个数据集，其中大规模平行报告基因检测（`MPRAs`）通过对几个增强子和启动子在各种细胞类型中进行饱和突变，直接测量了遗传变异的功能效应。我们使用了与`CAGI5`竞赛相同的训练和测试集，使我们能够直接将`Enformer`的性能与其他团队提交的结果进行基准比较。其他团队采用的方法包括多种不同的方法，从使用`deltaSVM`策略、`CADD`框架，到使用结合了保守性信息和来自`DeepBind`和`DeepSEA`的深度学习预测的特征的回归模型（第3组、第5组和第7组）。对于每个变异，我们通过计算参考和替代等位基因之间的预测差异来评估其效应，获得了`5,313`个特征。接下来，我们比较了两种方法：\n\n1. 我们使用这些特征在每个基因提供的训练集上训练`lasso`回归模型；\n2. 我们预先选择了与细胞类型匹配和细胞类型非特异的`CAGE`和`DNase`变化预测相对应的特征子集，并生成了特征的统计摘要（即无需额外训练）。\n\n在每个基因的测试集上评估这两种方法揭示，使用`Enformer`预测作为特征的`lasso`回归在所有位点中平均具有最佳相关性，超过了七种替代方法（图4a）。\n\n![image-20241213000110438](/images/assets//image-20241213000110438.png)\n\n此外，无需训练的`Enformer`预测直接用作评分时，其性能与经过`lasso`训练的模型相当，同时也优于其他提交的方法。这包括基于序列的预测器`deltaSVM`，该预测器是在来自匹配细胞类型的独立`DNase`和组蛋白`H3`在`K4`位单甲基化（`H3K4me1`）数据上训练的。经过`lasso`训练的`Enformer`超过了`CAGI5`获胜团队第3组的性能（`P=0.002`，配对、单侧`Mann-Whitney U`检验，图4b）。对不需要额外训练的预测进行可视化表明，`Enformer`忠实地捕捉到了`LDLR`位点中四个转录因子结合位点中的两个的效应（图4c）。\n\n`Enformer`突出显示了一个额外的结合位点，虽然它的效应大小较小，但仍显示出显著差异。相比之下，`deltaSVM`只成功预测了一个结合位点但错过了其他三个，总体上相对于`Enformer`表现出`50%`降低的`Pearson`和`Spearman`相关性。对于这个位点，细胞类型匹配的预测反映了细胞类型非特异的预测，表明检测到的结合位点可能对应于大多数细胞类型中存在的一般转录因子。\n\n![image-20241213000145412](/images/assets//image-20241213000145412.png)\n\n## 讨论\n\n监管基因组学中一个长期存在的问题是如何仅从DNA序列预测基因表达。通过一种新颖的`transformer`架构，我们通过大大扩展感受野并增加远距离元件之间的信息流动，取得了重要进展。通过这种方式，该模型可以更好地捕捉生物学现象，例如增强子调控启动子，即使两者之间存在较长的DNA序列距离。这导致组织和细胞类型特异性基因表达预测相关性显著提高，从`0.81`提高到`0.85`，向实验水平精确度`0.94`（从重复实验估计）迈进了三分之一的距离。\n\n这种预测准确性的提高转化为两个具有生物学相关性的关键问题的改进模型：增强子-启动子预测和非编码变异效应预测。我们观察到模型在做出基因表达预测时关注增强子并考虑绝缘子，这表明它已经学会了典型的远距离调控模式。使用`Enformer`模型，我们可以比以前的方法更准确地预测自然变异或`CRISPR`干扰的增强子是否会导致显著的表达变化。通过仅依赖DNA序列作为输入，`Enformer`相比替代的变异效应预测方法具有几个优势：\n\n1. 与大多数方法不同，它能够对激活或抑制性突变进行有向预测；\n2. 由于不明确依赖核苷酸保守性统计数据（大多数工具都依赖），其预测不限于保守的增强子，而保守的增强子仅占所有增强子的一小部分；\n3. 它可以对任意序列进行预测，这使得可以合成设计具有细胞类型特异性的增强子。\n\n总的来说，这些进展和优势为研究与疾病相关的遗传变异不断扩大的目录以及发育和进化中的增强子生物学开辟了令人兴奋的途径。\n\n有几条路径可以进一步提高模型准确性，这些路径看起来很有希望。机器学习的成功取决于训练数据，因此提高目标轨迹的分辨率和质量，以及收集来自其他生物体的数据，可能会提升性能。最近的工作表明，高度结构化的3D DNA接触（对长程基因调控有重大影响）可以从基础DNA序列预测。巧妙地将这些模型与我们的模型结合可能会改善`Enformer`对绝缘子和远距离调控的建模。\n\n当前方法的一个限制是我们只能为训练数据中的细胞类型和检测方法进行建模和预测，而无法推广到新的细胞类型或检测方法。并行研究已经开始通过细胞类型和检测方法的表征学习来解决这个缺点，并可能在未来使用`Enformer`架构。该模型对遗传变异的敏感性可以通过在越来越多的功能基因组数据集（如来自`CRISPR`干扰和大规模平行报告基因检测的数据集）上进行训练来进一步改善。目前，这些数据集的小规模限制了它们仅用于模型评估。最后，我们预计`transformer`模型最近在计算效率方面的改进以及更好的硬件将使我们能够进一步扩展模型规模。\n\n未来，`Enformer`可以被系统地应用于精细定位现有的`GWAS`研究，优先考虑罕见疾病中观察到的罕见或从头突变，并跨物种推断调控活性以研究顺式调控进化。为了促进这些下游应用，我们已经公开发布了预训练的`Enformer`模型，并提供了演示其使用方法的代码示例。此外，我们已经预先计算了`1000`个基因组数据集中所有常见变异的效应预测，并公开发布。我们希望我们的模型将促进对基因调控架构的更好理解，并推动改进用于基因起源疾病诊断工具的开发。\n\n## 方法\n\n### 模型架构\n`Enformer`架构由三个部分组成：\n\n- 带有池化的7个卷积块；\n- 11个`transformer`块；\n- 1个裁剪层，后跟最终的逐点卷积，分支成2个生物体特异的网络头（扩展数据图1）。\n\n`Enformer`接受长度为`196,608 bp`的独热编码DNA序列作为输入（`A = [1,0,0,0]`，`C = [0,1,0,0]`，`G = [0,0,1,0]`，`T = [0,0,0,1]`，`N = [0,0,0,0]`），预测人类基因组的`5,313`个基因组轨迹和小鼠基因组的`1,643`个轨迹，每个长度为`896`，对应于聚合成`128 bp`区块的`114,688 bp`。带有池化的卷积块首先将空间维度从`196,608 bp`减少到`1,536`，使得每个序列位置向量代表`128bp`（尽管卷积也观察相邻池化区域中的核苷酸）。\n\n`transformer`块然后捕获序列中的长程相互作用。裁剪层在每侧修剪`320`个位置，以避免在远端计算损失，因为这些区域处于不利地位，它们只能观察一侧（朝向序列中心）而不能观察另一侧（序列边界以外的区域）的调控元件。\n\n最后，两个输出头预测生物体特异的轨迹。`Enformer`架构与最先进的模型`Basenji2`类似。然而，以下改变帮助我们改进并超越了其性能：`Enformer`使用`transformer`块而不是扩张卷积，使用注意力池化而不是最大池化，使用两倍的通道数，以及1.5倍长的输入序列（`197kb`而不是`131kb`）。\n\n详细的模型架构，包括选定的超参数，如扩展数据图1所示。\n\n注意力池化通过以下方式总结输入序列 ${\\mathbf{x}}_{k:k + L_p}^{full} = {\\mathbf{x}} \\in R^{L_p \\times C}$ 在$L_p$个位置上的连续块，对于 $C$ 个通道中的每一个返回输出值 $h∈R^C$ ：\n\n$$\nh_j = \\frac{\\sum_i \\exp\\left( \\mathbf{x}_i \\cdot \\mathbf{w}_j \\right) x_{ij}}{\\sum_i \\exp\\left( \\mathbf{x}_i \\cdot \\mathbf{w}_j \\right)}\n$$\n其中 $i$ 索引池化窗口中的序列位置，由指数化的点积 $\\mathbf x_i ·\\mathbf w_j$ 加权，$\\boldsymbol{w} ∈ R^{C×K}$是学习的权重矩阵。我们对原始输入序列的连续块应用注意力池化，使用窗口大小 $L_p=2$ 和步长为2。我们将 $\\boldsymbol{w}$ 初始化为$2×\\mathbf 1$，其中$\\mathbf 1$是单位矩阵，以优先考虑较大的值，使该操作类似于最大池化。这种初始化比随机初始化或用零初始化（表示平均池化）的性能略好。\n\n我们使用多头注意力（`MHA`）层在序列中共享信息并模拟长程相互作用，例如启动子和增强子之间的相互作用。每个头都有一组独立的权重 $w^q∈R^{C×K}$、$w^k∈R^{C×K}$和$w^v∈R^{C×V}$，它们将输入序列 $x∈R^{L×C}$ 转换为查询$q_i=x_i w^q$、键$k_j=x_j w^k$和值$v_j=x_j w^v$。查询表示每个位置的当前信息，键表示每个位置将寻找的信息。它们的点积加上相对位置编码 $R_{ij}$ 形成注意力矩阵，计算如下：\n\n$$\na_{ij} = \\mathbf {softmax}(q_i k_j^T/\\sqrt{K} + R_{ij})\n$$\n其中条目 $a_{ij}$ 表示位置`i`处的查询对位置`j`处的键的权重。值表示每个位置将传播给关注它的位置的信息。每个单独的注意力头计算其输出为跨所有输入位置的加权和：$\\mathbf a_v$。这允许每个查询位置使用整个序列的信息。多个头使用独立的参数进行计算，我们将每个头的输出连接起来形成最终的层输出，然后是一个线性层来组合它们。我们的层使用8个头，值大小为192，键/查询大小为64。\n\n在自然语言处理中的`MHA`应用通常直接在输入序列上操作，将其标记为单词并嵌入到更丰富的嵌入空间中。`Enformer`模型中位于`MHA`之前的卷积塔用于执行类似的操作，即嵌入核苷酸片段，并为相邻核苷酸在基序中一起工作提供了令人信服的归纳偏置。我们选择在`128bp`分辨率下计算，因为它大致代表了一个包含几个基序的调控元件的研究长度，并且是聚合实验数据进行预测的适当区块大小。更精细的分辨率在数据支持时可能有潜在的好处，但会延长进入二次复杂度`MHA`的序列长度，使模型工程在当前可用的硬件上变得难以处理。\n\n为了注入位置信息，我们按照`Transformer-XL`论文中的公式，将相对位置编码 $\\mathbf R_{ij}$ 添加到 $\\mathbf q_i \\mathbf k_j^T$ 注意力项中。具体来说，我们使用：\n\n$$\n\\mathbf R_{ij} = \\mathbf q_i \\mathbf r_{i-j}^T + \\mathbf u \\mathbf k_j^T + \\mathbf v \\mathbf r_{i-j}^T\n$$\n其中 $\\mathbf r_{i-j} = \\mathbf w^\\mathbf R\\mathbf f(\\mathbf i-\\mathbf j)$ 是不同相对基函数 $\\mathbf f(\\mathbf i-\\mathbf j)$ 的线性函数，$\\mathbf u$ 和 $\\mathbf v$是用于评估对特定键（$\\mathbf u$）或相对距离（$\\mathbf v$）偏好的位置无关嵌入。我们使用三种不同的基函数类用于 $\\mathbf f(\\mathbf i-\\mathbf j)$ ，如扩展数据图5b所示。\n\n1. 指数函数：\n    $$\n    f_i^{\\text{exponential}}\\left( r \\right) = e^{ - \\log \\left( 2 \\right) \\frac{r}{r_{1/2,i}} }\n    $$\n    \n\n    其中 $r_{1/2,i}$ 在对数空间中在3和序列长度之间线性放置。\n\n2. 中心掩码函数：\n    $$\n    f_i^{\\text{central mask}}\\left( r \\right) = \n    \\left\\{ \n    \\begin{array}{l}\n    1, \\quad \\text{if } r \\le 2^i \\\\\n    0, \\quad \\text{otherwise}\n    \\end{array}\n    \\right.\n    $$\n    \n3. 伽马函数：\n    $$\n    f_i^{\\gamma}\\left( r \\right) = \\Gamma\\left( r \\mid \\alpha = \\frac{\\mu_i}{\\sigma^2}, \\beta = \\frac{\\mu_i^2}{\\sigma^2} \\right)\n    $$\n\n其中 $\\Gamma(r|α,\\mathbf β)$ 是伽马概率分布函数。$μ_i$ 在（序列长度/特征数量）到序列长度之间线性放置，$σ$=序列长度/（2 × 特征数量）。\n\n对于每个基函数，我们使用对称 $\\mathbf f(|\\mathbf x|)$ 和非对称 $\\mathbf {sign(x)} × \\mathbf f(|\\mathbf x|)$ 版本来引入方向性。我们使用与`MHA`的值大小相同数量的相对位置基函数（192）。这192个基函数在基函数类和对称与非对称版本之间平均分配。对于3个基函数类，每个基函数类提供64个位置特征（32个对称和32个非对称）。\n\n在`MHA`中，位置编码特征和最终注意力矩阵的丢弃率分别为0.01和0.05。所有其他丢弃率都在扩展数据图1a中注明。\n\n### 模型训练和评估\n\n模型在与`Basenji2`相同的目标、基因组区间和泊松负对数似然损失函数上进行训练、评估和测试。简而言之，跨物种训练/验证/测试集是通过以下程序构建的，以将同源序列划分到相同的集合中。首先，我们将人类和小鼠基因组分成`1Mb`区域。我们构建了一个二分图，其中顶点表示这些区域。接下来，如果两个区域在从`UCSC Genome Browser`下载的`hg38-mm10`同源网格格式对齐中具有超过`100kb`的对齐序列，我们就在它们之间放置边。最后，我们将二分图中的连通分量随机划分为训练集、验证集和测试集。\n\n数据集包含人类基因组的34021个训练序列、2213个验证序列和1937个测试序列，以及小鼠基因组的29295个训练序列、2209个验证序列和2017个测试序列。对于人类基因组，每个样本包含2131个转录因子（`TF`）染色质免疫沉淀测序（`ChIP-seq`）、1860个组蛋白修饰`ChIP-seq`、684个`DNase-seq`或`ATAC-seq`和638个`CAGE`轨迹（总计5313个，补充表`2`）。对于小鼠基因组，每个样本包含308个`TF ChIP-seq`、750个组蛋白修饰`ChIP-seq`、228个`DNase-seq`或`ATAC-seq`和357个`CAGE`轨迹（总计1643个，补充表`3`）。我们修改了`Basenji2`数据集，使用`hg38`参考基因组将输入序列从原来的`131072bp`扩展到`196608bp`。\n\n为了在人类和小鼠基因组上同时训练模型，我们在包含人类基因组数据的批次和包含小鼠基因组数据的批次之间交替。主要的`Enformer`模型具有1536个通道，使用`Sonnet v2`、`TensorFlow`（`v2.4.0`）实现，并在64个`TPU v3`核心上进行训练，批量大小为64（每核心1个），训练150000步（约3天），在每一步中使用全归约梯度聚合。批量归一化统计数据也使用`0.9`动量在多个副本之间聚合。我们使用来自`Sonnet v2`的`Adam`优化器，学习率为`0.0005`，其他超参数使用默认设置：$\\mathbf β_1=0.9、\\mathbf β_2=0.999、\\mathbf ε=1×10^{-8}$。\n\n通过网格搜索在验证集上获得最高性能来发现最佳学习率。我们在训练的前5000步中将学习率从0线性增加到目标值。我们将梯度裁剪到最大全局范数`0.2`。在训练期间，我们使用与`Basenji2`相同的数据增强，通过随机移动输入序列最多`3bp`并反向互补输入序列的同时反转目标。最后，我们使用较低的学习率`0.0001`在人类数据上对`Enformer`模型进行了30000步的微调。\n\n我们使用预训练的`Basenji2`模型进行所有主要的模型比较，并重新训练了一个等效模型用于消融实验和超参数扫描（如扩展数据图5所示）。在这些比较分析中，我们使用了768个通道（原始`Enformer`模型的`1/2`，在`MHA`中使用值大小96）、`131kb`输入序列，以及批量大小32在32个`TPU v3`核心上训练。我们没有在人类数据上对这些模型进行微调。\n\n对于使用扩张卷积而不是`transformer`块的模型，我们使用了更高的学习率`0.02`，且不进行学习率预热。与`Enformer`一样，最佳学习率是通过网格搜索在验证集上获得最高性能来确定的。所有模型都训练了500000步，每1000步在验证集上计算一次`CAGE TSS`基因表达的`Spearman`相关性（跨基因平均，跨实验平均），只保存具有最高相关性的模型。\n\n我们使用验证集进行超参数选择，使用测试集进行`Basenji2`比较。我们考虑了两个评估指标：\n\n1. 对于每个输出轨迹，在验证/测试集中所有`128bp`分箱基因组位置上计算的`Pearson`相关性；\n\n2. 验证/测试集中所有蛋白质编码基因的`CAGE`基因表达值（ $\\mathbf {log(1+x)}$ 转换并在每个实验的基因间标准化）的`Pearson`相关性，可以是每个`CAGE`实验跨基因计算（主要指标），也可以是跨`CAGE`实验为每个基因计算（如图`1b`所示）。\n\n观察到的和预测的基因表达值是通过在基因的所有唯一`TSS`位置上对观察到/预测的`CAGE`读数进行求和获得的。对于每个`TSS`位置，我们使用与`TSS`重叠的`128bp`分箱以及两个相邻分箱（总共`3`个分箱）。\n\n在模型评估期间，我们使用测试时增强：我们平均了8个随机增强序列的预测，增强方式与训练期间相同（`≤3bp`移位和反向互补）。我们仅在生成图1时在测试集上评估了模型性能一次，在模型开发期间未使用测试集。\n\n为了选择一个具有代表性的例子，我们将`Enformer`和`Basenji2`在\"跨`CAGE`实验\"指标上表现差异最大的前`10`个转录本可视化，该指标用于测量`33%`组织特异性最强的基因的组织特异性。我们选择了列表中的第六个转录本（`ENST00000524922`），因为它清晰地显示了所有三类基因组轨迹（`DNA`可及性、组蛋白修饰和基因表达）的差异。\n\n### 增强子优先级排序\n\n我们从两项研究中获得了一组增强子-基因对，这些研究使用`CRISPRi`测定方法扰动目标增强子并测量`K562`细胞中基因表达变化：`Gasperini`等人使用`scRNA-seq`测量表达变化，以及`Fulco`等人使用`Flow-FISH`。\n\n我们使用`UCSC liftOver`网络工具将增强子和基因坐标从`hg19`转换到`hg38`。每个增强子-基因对都包含一个标签，表明在`CRISPRi`处理后是否诱导了显著的表达变化。我们将所有增强子集合表示为\"候选\"增强子，将那些显示表达变化的增强子表示为\"验证\"增强子。\n\n我们使用精确度-召回曲线下面积（`auPRC`）评估不同方法对表现出显著表达变化的增强子-基因对进行分类或优先级排序的能力。\n\n要使用基于序列的模型对增强子-基因对进行优先级排序，我们计算了三种不同的得分：梯度×输入、注意力和体外突变（`ISM`）。对于每个增强子-基因对，我们通过取`Enformer`在`K562`中预测的最高`CAGE`值来确定基因的主要`TSS`。我们提取以主要`TSS`为中心的`DNA`序列，并计算以下不同的增强子-基因得分：\n\n1. `梯度×输入`：我们计算`CAGE`目标（使用`K562`特异性`CAGE`目标或所有`CAGE`目标，扩展数据图`7c`）在`TSS`处相对于输入参考序列核苷酸的梯度的绝对值。注意，由于我们的输入序列是独热编码的，取非零通道（参考核苷酸）的输入梯度，等同于计算梯度×输入归因。我们注意到\"`TSS`处的`CAGE`\"始终意味着从三个相邻分箱中求和绝对梯度值，这在基因聚焦的模型评估中也是如此。三个分箱包括与`TSS`重叠的分箱和两侧各一个相邻分箱。增强子-基因得分是通过在以增强子为中心的`2kb`窗口中求和绝对梯度×输入得分获得的。\n\n2. `注意力`：我们首先在所有头部和层之间平均`transformer`注意力矩阵。我们提取与位于`TSS`的查询索引对应的行，这样键就对应于不同的空间位置，注意力值指定模型在为`TSS`做预测时对这些位置的关注程度。我们仅为`Enformer`计算此贡献得分。增强子-基因得分是通过在以增强子为中心的`2kb`窗口中求和注意力得分获得的。\n\n3. `ISM`：体外突变增强子-基因得分是通过比较参考序列与修改序列（其中`2kb`增强子序列被随机序列替换）在`TSS`处的`K562 CAGE`预测来计算的：`|f(modified) – f(reference)|`。\n\n为了复现`Fulco`等人引入的`ABC`得分，我们从`ENCODE`获取了`K562`中的`H3K27ac ChIP-seq`数据（文件访问号`ENCFF779QTH`）和`DNase`数据（文件访问号`ENCFF413AHU`和`ENCFF936BDN`）的`BigWig`文件。我们对重复样本的归一化读数进行求和。对于每个轨迹和增强子，我们在以增强子为中心的固定`2kb`窗口中求和信号。与原始`ABC`得分使用的约`500 bp`可变窗口大小相比，这种固定且更宽的窗口产生了更好的性能（扩展数据图4a）。\n\n### GTEx SLDP\n\n我们通过使用参考等位基因和替代等位基因对模型进行正向传递，计算它们的差异，并在序列上求和以获得每个训练数据集的带符号得分，来预测遗传变异对各种注释的影响。我们对使用正向和反向互补序列以及向左和向右的小序列移动计算的得分进行平均。我们计算了所有`1000 Genomes SNP`的得分。\n\n我们使用`SLDP`来估计这些得分与`GTEx v7a`的48个组织的汇总统计数据之间的功能相关性，同时考虑了人群连锁不平衡结构（补充信息）。\n\n#### 精细定位的`GTEx`分类\n\n为了在不需要考虑`LD`的情况下研究特定的`eQTL`，我们使用`SuSiE`方法研究了`GTEx v8`的统计精细作图。我们关注在可信因果集合中后验包含概率（`PIP`）大于`0.9`的变异，从黑质的最少`166`个变异到胫骨神经的`2740`个变异不等。我们安排了一个分类任务，以区分这些阳性因果变异和匹配的阴性变异集。\n\n在可用时，我们为每个因果变异从同一基因中测试的`PIP<0.01`但|`Z-score`| > `4`的集合中选择匹配的阴性变异。当在同一基因中不可用时，我们从全基因组范围内`PIP<0.01`且|`Z-score`| > `6`的集合中选择。\n\n为了确定不同变异注释的信息量，我们为每个组织训练了单独的随机森林分类器，使用八折交叉验证来区分因果和非因果变异。我们选择了`scikit-learn 0.22`实现的默认超参数，因为修改它们后准确性提升可以忽略不计。然而，由于来自训练数据集的特征数量庞大，将每个决策树分裂时考虑的最大特征数设置为特征总数的`log2`大大提高了计算效率。我们进行了`100`次随机交叉验证洗牌和随机森林拟合迭代，以描绘模型准确性的低方差估计。我们通过比较`8×100`个不同测试集`auROC`来对两个不同模型特征集进行统计检验。\n\n对于带符号的`GTEx`分析，我们基于模型预测区分增加和降低基因表达的因果变异的能力来进行基准测试。在这个分析中，我们去除了对不同顺式基因的基因表达影响方向相反的变异。我们手动将`FANTOM5 CAGE`样本描述与`GTEx`组织匹配。我们跳过了具有超过三个可能匹配的情况。在有两个或三个可能匹配的情况下，我们选择了`Basenji2`和`Enformer`预测之间平均一致性最好的`CAGE`样本。我们通过根据该样本的带符号预测对因果变异进行排序来计算`auROC`统计量。\n\n#### 基于饱和突变数据对变异效应预测进行基准测试\n\n我们从`CAGI5`竞赛获得了训练集和测试集以及各参赛者的预测准确性（`M.Kircher`，个人通信，[https://genomeinterpretation.org/content/expression-variants](https://genomeinterpretation.org/content/expression-variants)）。对于每个变异和位点，我们将其效应评估为参考等位基因和替代等位基因之间的预测差异，在代表`512bp`的四个相邻分箱中求和，基于人类数据集生成`5313`个特征。\n\n在计算这个差异之前，所有`CAGE`特征都在添加伪计数`1`后进行对数转换。对于每个等位基因，我们对正向和反向互补序列的预测进行平均。我们使用训练集特征计算的缩放因子对测试集的特征进行缩放，使训练特征具有均值`0`和标准差`1`。遵循我们之前的工作，我们然后使用这些特征和相应的训练集为每个位点训练一个`lasso`回归模型。正则化强度由单个`λ`参数控制，使用`R`语言中`glmnet`库的`cv.glmnet`函数通过对每个训练集进行十折交叉验证来优化。\n\n对于我们的免训练比较，我们选择了对应于细胞类型匹配和细胞类型无关的`CAGE`和`DNase`变化预测的特征子集。对于细胞类型无关模型，我们使用了所有`638`个`CAGE`或`674`个`DNase`特征的子集（补充表`2`）。对于细胞类型匹配模型，我们还要求`CAGE/DNase`特征包含以下子字符串：\n\n- 对于`F9`、`LDLR`和`SORT1`使用\"`HepG2`\"；\n- 对于`GP1BB`、`HBB`、`HBG1`和`PKLR`使用\"`K562`\"；\n- 对于`HNF4A`、`MSMB`、`TERT`（在`HEK293T`细胞中进行）和`MYCrs6983267`使用\"`HEK293`\"；\n\n对于几个位点，并不存在完全匹配的`DNase`或`CAGE`样本。因此，我们根据以下子字符串选择最接近的匹配特征：\n\n- 对于`ZFAND3`使用\"胰腺\"；\n- 对于`TERT`（在`GBM`细胞中进行）使用\"胶质母细胞瘤\"；\n- 对于`IRF6`使用\"角质形成细胞\"；\n- 对于`IRF4`使用\"`SK-MEL`\"；\n\n对于每个位点，我们提取匹配上述子字符串的特征，并使用所示特征的第一主成分（`PC`）作为我们的汇总统计量，如果`PC`与特征均值负相关则反转其符号。\n\n# 数据可用性\n\n基因注释从[https://www.gencodegenes.org/](https://www.gencodegenes.org/)（`v32`）获取。`Basenji2`训练、验证和测试数据从[https://console.cloud.google.com/storage/browser/basenji_barnyard/data](https://console.cloud.google.com/storage/browser/basenji_barnyard/data)获取。\n\n`Fulco`等人`2019`的处理后的`CRISPRi`数据从补充材料获取，`Gasperini`等人`2019`的数据从`GEO`登录号`GSE120861`获取。用于图2分析的`K562`中的`H3K27ac ChIP-seq`数据从[https://www.encodeproject.org/](https://www.encodeproject.org/)获取，文件登录号为`ENCFF779QTH`，`DNase`数据的文件登录号为`ENCFF413AHU`和`ENCFF936BDN`。由`Fudenberg`等人2020处理的`TAD`边界从[https://console.cloud.google.com/storage/browser/basenji_hic/insulation](https://console.cloud.google.com/storage/browser/basenji_hic/insulation)获取。精细定位的`eQTL`可从`Wang`等人2021的补充材料获取，阴性集从[https://console.cloud.google.com/storage/browser/dm-enformer/data/gtex_fine](https://console.cloud.google.com/storage/browser/dm-enformer/data/gtex_fine)获取。我们从`CAGI5`竞赛获得了训练集和测试集以及各参赛者的预测准确性（`M.Kircher`个人通信，[https://genomeinterpretation.org/content/expression-variants](https://genomeinterpretation.org/content/expression-variants)）。为了与`ExPecto`进行比较，我们使用了来自[https://github.com/FunctionLab/ExPecto/tree/master/resources](https://github.com/FunctionLab/ExPecto/tree/master/resources)提供的数据。\n\n# 代码可用性\n\n我们的核心算法的所有组件，包括完整的模型架构和用于训练和评估模型的示例代码，均可在以下URL下以开源`Apache 2.0`许可证获取：[https://github.com/deepmind/deepmind-research/tree/master/enformer](https://github.com/deepmind/deepmind-research/tree/master/enformer)。该代码也已存档在`Zenodo`：[https://doi.org/10.5281/zenodo.5098375](https://doi.org/10.5281/zenodo.5098375)。此外，模型的层组件现在可在现有的生物序列深度学习`Basenji`代码库中获取：[https://github.com/calico/basenji](https://github.com/calico/basenji)，同样采用开源`Apache 2.0`许可证。\n\n预训练的`Enformer`模型可在`TF-Hub`上获取，使用者可以轻松地在新数据上运行它：[https://tfhub.dev/deepmind/enformer/1](https://tfhub.dev/deepmind/enformer/1)。我们还计划在`Kipoi`模型库中发布它。我们提供代码示例（`enformer-usage.ipynb`）说明如何使用该模型对遗传变异进行评分。\n\n最后，我们在这里提供了`1000`个基因组队列中所有常见变异（在任何人群中`MAF>0.5%`）的变异效应预测，采用开放的创作共用`CC-BY 4.0`许可证。为了使这些预测更易获取，我们使用`PCA`将`5313`个特征提炼为`20`个高度信息量的变异得分，以保持发布文件大小可控（总共`10M`个变异小于`1GB`，而不是`100GB`），同时保持较高的预测准确性（使用所有特征的`GTEx`精细定位分类`auROC`为`0.747`，而使用提炼后的特征为`0.743`）。\n\n# 扩展图\n\n## 扩展数据图1\n\n![image-20241213005757016](/images/assets//image-20241213005757016.png)\n\n## 扩展数据图2\n\n![image-20241213005824711](/images/assets//image-20241213005824711.png)\n\n## 扩展数据图3\n\n![image-20241213005929510](/images/assets//image-20241213005929510.png)\n\n## 扩展数据图4\n\n![image-20241213005951132](/images/assets//image-20241213005951132.png)\n\n## 扩展数据图5\n\n![image-20241213010020755](/images/assets//image-20241213010020755.png)\n\n## 扩展数据图6\n\n![image-20241213010050142](/images/assets//image-20241213010050142.png)\n\n## 扩展数据图7\n\n![image-20241213010123603](/images/assets//image-20241213010123603.png)\n\n## 扩展数据图8\n\n![image-20241213010205858](/images/assets//image-20241213010205858.png)\n\n## 扩展数据图9\n\n![image-20241213010222558](/images/assets//image-20241213010222558.png)\n\n## 扩展数据图10\n\n![image-20241213010242362](/images/assets//image-20241213010242362.png)\n\n# 参考文献\n\n1. Zhou, J. et al. Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk. Nat. Genet. 50, 1171-1179 (2018).\n2. Kelley, D. R. Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n3. Kelley, D. R. et al. Sequential regulatory activity prediction across chromosomes with convolutional neural networks. Genome Res. 28, 739-750 (2018).\n4. Agarwal, V. & Shendure, J. Predicting mRNA abundance directly from genomic sequence using deep convolutional neural networks. Cell Rep. 31, 107663 (2020).\n5. Gasperini, M., Tome, J. M. & Shendure, J. Towards a comprehensive catalogue of validated and target-linked human enhancers. Nat. Rev. Genet. 21, 292-310 (2020).\n6. Vaswani, A. et al. Attention is all you need, in Advances in Neural Information Processing Systems 5998-6008 (2017).\n7. Brown, T. B. et al. Language models are few-shot learners. in Advances in Neural Information Processing Systems (2020).\n8. Ji, Y., Zhou, Z., Liu, H. & Davuluri, R. V. DNABERT: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome. Bioinformatics [https://doi.org/10.1093/bioinformatics/btab083](https://doi.org/10.1093/bioinformatics/btab083) (2021).\n9. Gasperini, M. et al. A genome-wide framework for mapping gene regulation via cellular genetic screens. Cell 176, 377-390 (2019).\n10. FANTOM Consortium and the RIKEN PMI and CLST (DGT). A promoter-level mammalian expression atlas. Nature 507, 462-470 (2014).\n11. Heinz, S., Romanoski, C. E., Benner, C. & Glass, C. K. The selection and function of cell type-specific enhancers. Nat. Rev. Mol. Cell Biol. 16, 144-154 (2015).\n12. Shrikumar, A., Greenside, P. & Kundaje, A. Learning important features through propagating activation differences. in International Conference on Machine Learning 3145-3153 (PMLR, 2017).\n\n13. Fulco, C. P. et al. Activity-by-contact model of enhancer-promoter regulation from thousands of CRISPR perturbations. Nat. Genet. 51, 1664-1669 (2019).\n14. Eraslan, G., Avsec, Ž., Gagneur, J. & Theis, F. J. Deep learning: new computational modelling techniques for genomics. Nat. Rev. Genet. 20, 389-403 (2019).\n15. Avsec, Ž. et al. Base-resolution models of transcription-factor binding reveal soft motif syntax. Nat. Genet. [https://doi.org/10.1038/s41588-021-00782-6](https://doi.org/10.1038/s41588-021-00782-6) (2021).\n16. ENCODE Project Consortium et al. Expanded encyclopaedias of DNA elements in the human and mouse genomes. Nature 583, 699-710 (2020).\n17. Ghandi, M. et al. gkmSVM: an R package for gapped-kmer SVM. Bioinformatics 32, 2205-2207 (2016).\n18. Zhou, J. & Troyanskaya, O. G. Predicting effects of noncoding variants with deep learning-based sequence model. Nat. Methods 12, 931-934 (2015).\n19. Kelley, D. R., Snoek, J. & Rinn, J. L. Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks. Genome Res. 26, 990-999 (2016).\n20. Consortium, T. G., The GTEx Consortium. The GTEx Consortium atlas of genetic regulatory effects across human tissues. Science 369, 1318-1330 (2020).\n21. Reshef, Y. A. et al. Detecting genome-wide directional effects of transcription factor binding on polygenic disease risk. Nat. Genet. 50, 1483-1493 (2018).\n22. Wang, Q. S. et al. Leveraging supervised learning for functionally informed fine-mapping of cis-eQTLs identifies an additional 20,913 putative causal eQTLs. Nat. Commun. 12, 3394 (2021).\n23. Wang, G., Sarkar, A., Carbonetto, P. & Stephens, M. A simple new approach to variable selection in regression, with application to genetic fine mapping. J. R. Stat. Soc. 82, 1273-1300 (2020).\n24. Weissbrod, O. et al. Functionally informed fine-mapping and polygenic localization of complex trait heritability. Nat. Genet. 52, 1355-1363 (2020).\n25. Kircher, M., Xiong, C., Martin, B. & Schubach, M. Saturation mutagenesis of twenty disease-associated regulatory elements at single base-pair resolution. Nature 10, 3583 (2019).\n\n26. Shigaki, D. et al. Integration of multiple epigenomic marks improves prediction of variant impact in saturation mutagenesis reporter assay. Hum. Mutat. 40, 1280-1291 (2019).\n27. Lee, D. et al. A method to predict the impact of regulatory variants from DNA sequence. Nat. Genet. 47, 955-961 (2015).\n28. Rentzsch, P., Witten, D., Cooper, G. M., Shendure, J. & Kircher, M. CADD: predicting the deleteriousness of variants throughout the human genome. Nucleic Acids Res. 47, D886-D894 (2019).\n29. Alipanahi, B., Delong, A., Weirauch, M. T. & Frey, B. J. Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning. Nat. Biotechnol. 33, 831-838 (2015).\n30. Villar, D. et al. Enhancer evolution across 20 mammalian species. Cell 160, 554 (2015).\n31. Linder, J. et al. A generative neural network for maximizing fitness and diversity of synthetic DNA and protein sequences. Cell Syst. 11, 49-62 (2020).\n32. Fudenberg, G., Kelley, D. R. & Pollard, K. S. Predicting 3D genome folding from DNA sequence with Akita. Nat. Methods 17, 1111-1117 (2020).\n33. Schwessinger, R. et al. DeepC: predicting 3D genome folding using megabase-scale transfer learning. Nat. Methods 17, 1118-1124 (2020).\n34. Schreiber, J., Durham, T., Bilmes, J. & Noble, W. S. Avocado: a multi-scale deep tensor factorization method learns a latent representation of the human epigenome. Genome Biol. 21, 81 (2020).\n35. Nair, S., Kim, D. S., Perricone, J. & Kundaje, A. Integrating regulatory DNA sequence and gene expression to predict genome-wide chromatin accessibility across cellular contexts. Bioinformatics 35, i108-i116 (2019).\n36. Tay, Y., Dehghani, M., Bahri, D. & Metzler, D. Efficient transformers: a survey. Preprint at [https://arxiv.org/abs/2009.06732](https://arxiv.org/abs/2009.06732) (2020).\n37. Richter, F. et al. Genomic analyses implicate noncoding de novo variants in congenital heart disease. Nat. Genet. 52, 769-777 (2020).\n38. Zhou, J. et al. Whole-genome deep-learning analysis identifies contribution of noncoding mutations to autism risk. Nat. Genet. 51, 973-980 (2019).\n39. Gupta, S., Stamatoyannpoulos, J. A., Bailey, T. L. & Noble, W. Quantifying similarity between motifs. Genome Biology 8, R24 (2007).\n\n40. Shaw, P., Uszkoreit, J. & Vaswani, A. Self-attention with relative position representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers) 464-468 (2018).\n41. Dai, Z. et al. Transformer-XL: Attentive language models beyond a fixed-length context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics 2978-2988 (2019).\n42. Kent, W. J. The Human Genome Browser at UCSC. Genome Research 12, 996-1006 (2002).\n43. Reynolds, M. et al. Open sourcing Sonnet — a new library for constructing neural networks. [https://deepmind.com/blog/open-sourcing-sonnet](https://deepmind.com/blog/open-sourcing-sonnet) (2017).\n44. Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830 (2011).\n45. Klein, J. C. et al. A systematic evaluation of the design and context dependencies of massively parallel reporter assays. Nat. Methods 17, 1083-1091 (2020).\n46. Avsec, Žiga et al. Enformer (Version 3.0) (Zenodo, 2021); [https://doi.org/10.5281/zenodo.5098375](https://doi.org/10.5281/zenodo.5098375)\n\n47. Avsec, Ž. et al. The Kipoi repository accelerates community exchange and reuse of predictive models for genomics. Nat. Biotechnol. 37, 592-600 (2019).\n","categories":["论文解读"]},{"title":"最强AI+最强Prompt=？！！","url":"/2024/11/22/5ihfxsje/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 最强AI+最强Prompt=？！！ https://mp.weixin.qq.com/s/3CBFuQ8vmCp5x0iaVU9tww /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"Nucleotide-Transformer：构建和评估人类基因组学的稳健基础模型","url":"/2024/11/17/4x6a3fgp/","content":"\n# 文章链接\n\n> Dalla-Torre, H., Gonzalez, L., Mendoza-Revilla, J. et al. Nucleotide Transformer: building and evaluating robust foundation models for human genomics. Nat Methods (2024).  https://doi.org/10.1038/s41592-024-02523-z\n>\n\n# 简介\n\n`Nucleotide Transformer`：提出了一个构建和评估人类`基因组学`的稳健基础模型\n\n# 摘要\n\n从DNA序列`预测分子表型`一直是基因组学中的一个长期挑战，这主要受限于标注数据的数量以及在不同任务间迁移学习的困难。在此，我们展示了一项关于在DNA序列上预训练的基础模型（称为`Nucleotide Transformer`）的广泛研究。这些模型参数规模从`5000万`到`25亿`不等，整合了来自`3,202`个人类基因组和`850`个不同物种基因组的信息。这些转换器模型能够产生特定上下文的核苷酸序列表征，使其即使在低数据量情况下也能进行准确预测。我们展示了这些开发的模型可以以低成本微调来解决各种基因组学应用。尽管没有监督，这些模型学会了将注意力集中在关键基因组元件上，并可用于改进`遗传变异`的优先级排序。在基因组学中训练和应用基础模型为从DNA序列进行准确的分子表型预测提供了一种广泛适用的方法。\n\n> `分子表型`：基因表达在分子水平上的具体体现，包括细胞内的蛋白质、RNA、代谢物等分子及其相互作用网络所呈现的可测量特征，它是连接基因型和传统表型的桥梁，帮助我们理解基因如何通过分子机制影响生物体的性状表现。\n\n# 创新点\n\n1. **规模和多样性的突破**：\n- 构建了迄今为止最大的`DNA基础模型`之一，参数规模达到`25亿`\n- 使用了迄今最大规模和最多样化的训练数据集，包含`3,202`个人类基因组和`850`个不同物种的基因组数据\n\n2. **技术创新**：\n- 提出了`NT-v2`优化版本，通过架构改进实现了模型小型化（参数减少`50`倍）的同时保持或提升性能 \n- 创新性地采用了参数高效的微调技术（`IA3`），仅需调整`0.1%`的参数就能实现高性能\n\n3. **应用创新**：\n\n- 无需监督即可识别关键基因组元素\n- 提出了基于`零样本`的遗传变异评分方法\n- 在多个具有挑战性的基因组学任务上达到或超过了专门设计的监督学习模型的性能\n\n# 主要内容\n\n## 读前须知\n\n1. 论文解读尽可能的还原原文，若有不恰当之处，还请见谅；\n2. 排版上，插图会尽量贴近出处，而`补充图表`均在文末“`补充信息`”的下载链接中；\n3. 左边👈有目录，可自行跳转至想看的部分；\n4. 部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（`Receptive field`）。请注意，仅首次出现会标明；\n\n## 引言\n\n`人工智能`(AI)中的基础模型的特点是其大规模性质，包含数百万经过大量数据集训练的参数。这些模型可以适应广泛的后续预测任务，并且已经深刻地改变了AI领域。自然语言处理(NLP)中的著名例子包括所谓的语言模型(LM)`BERT`和`GPT`。近年来LM变得越来越受欢迎，这要归功于它们能够在`未标记的数据`上进行训练，从而创建能够解决下游任务的通用表示。它们实现全面语言理解的一个方法是通过解决数十亿次完形测试，在这些测试中它们预测给定句子中空白处的正确单词。这种方法被称为掩码语言建模。\n\n> `掩码`：深度学习中是一种二进制标记机制，通常用0和1表示需要忽略或保留的数据。它可以用于处理缺失值、控制注意力机制的关注范围、实现序列填充对齐等任务。在Transformer中，掩码尤其重要，它既可以防止模型在预测时看到未来信息(自回归掩码)，也可以帮助处理不等长序列(填充掩码)。\n\n早期将这一目标应用于生物学的`基础模型`涉及在`蛋白质序列`上训练LM，它们的任务是在大型蛋白质序列数据集中预测被掩码的氨基酸。这些蛋白质LM在应用于下游任务时通过迁移学习，展示了与之前的方法竞争甚至超越之前方法的能力，例如预测蛋白质结构和功能，即使在数据稀缺的情况下也是如此。\n\n除了蛋白质序列之外，`DNA序列`中编码的依赖模式在理解基因组过程中起着基础性作用，从表征调控区域到评估单个变异在其单倍型环境中的影响。在这种情况下，专门的深度学习(DL)模型已经被训练来揭示DNA中有意义的模式。例如，DL模型已被用于从DNA序列预测基因表达，最近的进展将卷积神经网络和`transformer架构`相结合，能够编码位于上游`100`千碱基(kb)的调控元件。\n\n现代基因组学研究产生的大量数据既是机遇也是挑战。一方面，物种和群体之间的自然变异复杂模式可以轻易获得；另一方面，需要强大的DL方法来处理大规模数据，以便从未标记的数据集中准确提取信号。在基因组学中训练的大型基础模型似乎是值得探索的方法来应对这一挑战。\n\n在这里，我们构建了用于编码基因组序列的`稳健基础模型`，称为`Nucleotide Transformer`(NT)，并提供了系统性研究和基准测试来评估其性能。我们通过构建四个不同大小的LM开始研究，从`5亿`到`25亿`参数不等。这些模型在三个不同数据集上进行预训练，包括人类参考基因组、`3,202`个多样化人类基因组的集合，以及来自各种物种的`850`个基因组。\n\n训练之后，我们以两种方式利用每个模型的表示(嵌入)。为了评估`NT`在适应各种任务时的性能稳定性，我们在一组18个精选的基因组预测任务上训练了每个模型，并将它们与三个替代的`DNA基础模型`以及一个最先进的非基础模型进行比较，使用系统的`十折交叉验证`程序。\n\n> `十折交叉验证`：一种数据集划分方法，将数据集平均分成10份，每次用9份作为训练集，剩下1份作为验证集，轮流进行10次，最终取10次评估结果的平均值作为模型性能的估计。\n\n此外，为了扩大我们的评估，我们将我们表现最好的模型与三个针对特定任务优化的最先进的监督基线模型进行了比较。为了破译在预训练期间学习的序列特征，我们探索了模型的注意力图和复杂度（`perplexity`），并对其嵌入进行了数据降维。\n\n此外，我们还评估了嵌入对人类功能重要遗传变异影响进行建模的能力，通过零样本评分。基于初始实验的发现，我们开发了第二组四个`LM`，参数从`5亿`减少到`5千万`，以研究这类模型的缩放规律。我们成功构建了一个模型，仅用十分之一的参数就达到了之前最佳模型的性能，同时将感受野大小翻了一番。\n\n> `感受野`：神经网络中某一层的神经元能够\"看到\"的输入区域范围。\n\n## 结果\n\n###  `Nucleotide Transformer`模型准确预测基因组学任务\n\n我们开发了一系列基于`transformer`的DNA语言模型(NT)，它们从`6`kb未注释的基因组数据中学习了通用的核苷酸序列表示（图1a和方法）。受`NLP`中的趋势启发，即更大的训练数据集和模型规模已经显示出改进的性能，我们构建了具有不同参数规模和数据集的`transformer模型`：\n\n1. 在人类参考基因组序列上训练的`5亿`参数模型（\"`Human ref 500M`\"）\n\n2. 一个`5亿`参数模型（\"`1000G 500M`\"）\n\n3. 一个`25亿`参数模型（\"`1000G 2.5B`\"）（它们都在`3,202`个遗传多样性的人类基因组上训练）\n\n4. 一个`25亿`参数模型，包含来自不同门类的`850`个物种（\"`Multispecies 2.5B`\"），其中包括11个模式生物（图1c和补充表1-4）。\n\n![image-20241216164728681](/images/assets//image-20241216164728681.png)\n\n为了评估这些模型在预测各种`分子表型`方面的效果，我们从公开可获得的资源中整理了18个基因组数据集，包括剪接位点预测任务（`GENCODE`）、启动子任务（`Eukaryotic Promoter Database`）以及组蛋白修饰和增强子任务（`ENCODE`），每个数据集的大小都经过合理设计，以实现快速和严格的交叉验证程序（图1d，补充表5和方法）。\n\n虽然对监督模型来说有更大的数据集可用，但这18个基因组数据集的编译提供了`多样化`和`稳健`的选择，用于严格检验模型在各种任务中的适应性，并与其他DNA自监督基础模型进行比较。这些数据集被处理成`标准化格式`以方便实验并确保在评估大型语言模型性能时的可重复性（方法）。我们通过两种不同的技术评估了我们的`transformer模型`：探测和微调（图1b）。\n\n**探测**是指使用学习到的语言模型DNA序列嵌入作为输入特征，输入到更简单的模型中来预测基因组标签。具体来说，我们使用逻辑回归或一个最多包含两个隐藏层的小型多层感知器(MLP)，探测了语言模型的十个任意选择的层。在**微调**的情况下，语言模型的头部被替换为分类或回归头部，并使用参数高效的技术进行再训练（方法）。为了确保不同模型之间的公平和准确比较，我们实施了`十折交叉验证`策略。\n\n为了将我们的预训练基础模型方案与该领域的标准监督方法进行比较，我们从头开始在18个任务中的每一个上训练了不同版本的`BPNet`卷积架构（方法）。`BPNet`架构在基因组学中得到了广泛应用，代表了一个非常强大的默认架构，用于通过监督学习从头开始建模小型数据集。我们观察到原始`BPNet`模型在各个任务中都表现出强劲的性能（平均`Matthews`相关系数(MCC)为`0.665`），通过将其规模增加到`2800万`参数，我们可以将其提高（平均MCC为`0.683`），这证实了直接监督的卷积架构在基因组学任务中表现得非常好（图2a，b）。接下来，我们评估了`NT模型`的`探测`和`微调`与我们基准数据集上的这些监督基线模型相比如何。如果所得的两个标准差重叠或优于报告的基线值，我们认为这些模型是等同于或优于其他模型的。\n\n> `BPNet`：一个用于预测`DNA序列与蛋白质结合`的深度学习架构，它结合了扩张卷积网络和基于峰值的损失函数。该网络首先使用多尺度的扩张卷积来捕获DNA序列特征，然后通过解码器预测结合位点的概率分布，最后采用特殊的损失函数来优化对结合峰值的预测。`BPNet`的一个重要特点是可以生成`序列重要性分数`，帮助解释模型的`预测结果`。\n\n使用这个标准，`NT模型`仅通过`探测`就在5个任务中匹配基线`BPNet`模型，并在18个任务中的8个任务中超越了它们（补充图1和补充表6），并显著优于来自原始标记的探测。与最近的工作一致，我们观察到最佳性能既取决于模型也取决于层（补充表8）。我们还注意到，最高的模型性能从来不是通过使用最后一层的嵌入获得的，这与早期工作一致。例如，在增强子类型预测任务中，我们观察到性能最高和最低的层之间的相对差异高达`38%`，表明在各层之间学习到的表示有显著差异（补充图3）。与我们的探测策略相比，我们的微调模型在18个基线模型中要么匹配（n=6）要么超越（n=12）（图2a，b和补充表7和9）。值得注意的是，微调的NT模型优于探测模型，而且更大和更多样化的模型持续优于较小的模型。这些结果支持了有必要针对特定任务微调`NT基础模型`以实现更好的性能。\n\n我们的结果还表明，在多样化数据集上训练的`Multispecies 2.5B`模型在几个基于人类测试的任务上优于或匹配`1000G 2.5B`模型（图2a，b）。这意味着增加序列多样性的策略，而不仅仅是增加模型规模，可能会带来更好的预测性能，特别是在计算资源有限的情况下。\n\n![image-20241216164810595](/images/assets//image-20241216164810595.png)\n\n`微调`在之前的工作中没有被广泛探索，可能是由于其计算需求较高。我们通过采用最新的参数高效微调技术克服了这一限制，该技术仅需要总模型参数的`0.1%`（图1b和方法）。这种方法允许在`单个GPU`上更快地进行微调，比所有微调参数减少了`1,000`倍的存储需求，同时仍能提供相当的性能。在实践中，我们观察到即使使用简单的下游模型对嵌入进行探测，严格的探测也比微调更慢且计算强度更大。这种差异源于诸如层的选择、下游模型选择和超参数对性能的重要影响。此外，微调表现出更小的性能方差，增强了该方法的稳健性。总的来说，这种通用方法是多功能的，无需调整模型架构或超参数即可适应各种任务。这与监督模型形成鲜明对比，后者通常具有不同的架构，并且需要为每个任务从头开始训练。\n\n最后，我们旨在评估`大型DNA语言模型`与使用大量数据集训练并优化架构的稳健基线进行竞争的潜力。为此，我们将`Multispecies 2.5B`模型应用于另外三个基因组预测任务，这些任务包括：\n\n1. **对来自多样化人类细胞和组织的`919`个染色质谱的分类**\n2. **预测整个人类基因组中的规范剪接受体和供体位点**\n3. **预测来自果蝇`S2`细胞的发育和管家增强子活性（见方法）**\n\n> `剪接位点`：真核生物基因中内含子和外显子连接处的特定序列，主要包括5'剪接位点(供体位点)和3'剪接位点(受体位点)。在RNA前体剪接过程中，剪接体通过识别这些保守序列位点来确定剪接位置，将内含子去除并将外显子连接起来。准确的剪接位点识别对于`正确的基因表达和蛋白质合成`至关重要。\n\n值得注意的是，尽管没有对其原始微调架构进行额外的更改或优化，`Multispecies 2.5B`模型达到了与专门化`DL模型`紧密一致的性能水平。例如，在分类染色质特征谱的情况下，我们获得的曲线下面积(`AUC`)值平均仅比`DeepSEA`实现的值低约`~1%`（图2c）。\n\n关于预测`pre-mRNA`转录本中的每个位置是否是剪接供体、剪接受体或都不是，我们调整了NT模型以提供核苷酸级别的剪接位点预测，并实现了`95%`的`top-k`准确率和`0.98`的精确率-召回率`AUC`（图2d）。值得注意的是，我们的`2.5B` `6-kb`上下文模型与最先进的`SpliceAI-10k`的性能相匹配，后者在`15-kb`输入序列上训练，此外还优于其他剪接基线；并且在测试`6-kb`输入序列时优于`SpliceAI`。\n\n最后，在管家和发育增强子预测的情况下，我们的模型略微超过（`1%`）和获得较低（`4%`）的相关值（图2e），与`DeepSTARR`相比。在这三个不同任务中，我们还对我们的参数`高效微调`和`全模型微调`（训练模型的所有参数以优化其在特定任务或数据集上的性能）进行了比较。\n\n值得注意的是，在染色质和剪接预测方面我们没有观察到显著改进，在增强子活性预测方面仅有适度的3%提升（补充图2），支持我们使用高效微调方法。总的来说，我们广泛的基准测试和结果展示了NT作为一种通用方法在处理许多不同基因组学任务时的灵活性和高准确性。\n\n### 基因组学基础模型的基准测试\n\n我们将`NT模型`与其他基因组学基础模型进行了比较：`DNABERT-2`、`HyenaDNA`（`1-kb`和`32-kb`上下文长度）和`Enformer`（将其用作预训练模型的替代架构）（图2a，b和方法）。我们将`DNABERT-1`排除在这个比较之外，因为它只能处理最大`512` bp的输入长度，因此不能用于大多数任务。为确保公平比较，所有模型都使用相同的协议在18个下游任务中进行微调和评估（方法）。\n\n与`DNABERT-2`、`HyenaDNA-32-kb`和`Enformer`相比，我们的`Multispecies 2.5B`模型在所有任务中达到了最高的总体性能（图2a，b和表9）。尽管如此，`Enformer`在增强子预测和一些染色质任务中取得了最佳性能，证明它可以成为一个强大的DNA基础模型。我们的模型在所有启动子和剪接任务中都表现优于其他每个模型。值得注意的是，尽管`HyenaDNA`在人类参考基因组上进行预训练，我们的`Multispecies 2.5B`模型在所有18个任务中要么匹配（n=7）要么超越（n=11）它，突显了在多样化基因组序列集上预训练的优势。我们建立了一个包含所有模型在每个任务上结果的交互式排行榜（[https://huggingface.co/spaces/InstaDeepAI/nucleotide_transformer_benchmark](https://huggingface.co/spaces/InstaDeepAI/nucleotide_transformer_benchmark)）以方便比较。这代表了基因组学基础模型的广泛基准测试，应该作为进一步发展基因组学中语言模型的参考（图1c）。\n\n### 以无监督的方式检测已知的基因组元件\n\n为了深入了解`NT`模型的可解释性，并理解这些模型在进行预测时使用的序列元素类型，我们探索了它们架构的不同方面。首先，我们评估了这些嵌入在多大程度上可以捕获与五种`基因组元件`相关的序列信息（补充表7和10）。我们观察到，`NT`模型在没有任何监督的情况下，学会了区分具有独特注释的基因组序列，包括基因间区、内含子、编码区和非翻译区（`UTRs`），尽管在不同层次上的熟练程度不同（图3a、补充图7和方法）。特别是，`500M`大小的模型和那些在较少多样性序列上训练的模型，在基因组区域之间表现出较低的区分度，这再次证实了最大的模型在自监督训练期间更能捕获相关基因组模式的能力。\n\n在`Multispecies 2.5B`模型的情况下，第1层观察到基因间和基因区域之间最强的区分，其次是第5层的`5'UTR`区域，以及第21层大多数区域之间的区分（图3a）。`3'UTR`区域与其他元素的有限区分表明，该模型尚未完全学会区分这种类型的元素，或者如先前研究所建议的，这些区域中可能有许多注释错误。与这些观察结果一致，我们的监督探测策略展示了对这些元素的高分类性能，特别是在更深层次，准确率值超过`0.78`（图3b）。这证明了`NT`模型已经以无监督的方式学会在其嵌入中检测已知的基因组元素，这可以被用于高效的下游基因组任务预测。\n\n![image-20241216164914266](/images/assets//image-20241216164914266.png)\n\n接下来，我们通过`注意力机制`的视角对模型进行分析，以理解`注意力层`捕获和使用了哪些序列区域。我们计算了每个模型头和层对包含九种不同类型基因组元素（与`基因结构`和`调控特征`相关）的序列的注意力百分比（图3c）。\n\n> `注意力机制`：一种让模型能够`动态关注输入中重要部分`的计算方法。它通过计算查询(query)与键值对(key-value pairs)的相关性来`分配权重`，从而让模型对重要信息给予更多\"关注\"。在Transformer中，自注意力机制让序列中的每个位置都能与其他位置进行交互，`捕获长距离依赖关系`，已成为现代深度学习的核心组件之一。\n>\n> `transformer`模型中的相关概念可参考这篇文章：\n>\n> {% postLinkCard skrzswes  \"auto\" %}\n\n从形式上讲，当注意力头的注意力百分比显著超过该元素在预训练数据集中自然出现的频率时，就认为该注意力头识别出了特定元素（方法）。例如，`50%`的比例意味着，在人类基因组中平均而言，该特定头部`50%`的注意力指向了感兴趣的元素类型。通过将这种方法应用于在`6kb`序列中不同位置可能出现的每种类型元素（约10,000个不同序列，其中元素占序列的`2-11%`；补充表10），我们发现注意力在其不同的头部和层中明显聚焦于特定类型的基因组元素（图3d和补充图8-16）。\n\n跨层的显著注意力头数量在不同模型间有显著差异，其中`Multispecies 2.5B`模型对内含子（`640`个头中的`117`个）、外显子（`n=72`）和转录因子（`TF`）结合位点（`n=74`）表现出最多的显著注意力头（补充图8、9和补充表12），尽管包含外显子和`TF`基序的序列比例相对较小。关于增强子，最大模型的最大注意力百分比最高，例如`1000G 2.5B`模型实现了接近`100%`的注意力（补充图15）。对于其他基因组元素，如`3'UTR`、启动子和`TF`结合位点，也观察到类似的模式，其中`1000G 2.5B`模型在首层展示了具有高度注意力的高度专门化头部（补充图8-16）。\n\n为了更深入地了解预训练的`NT Multispecies 2.5B`模型在更高分辨率下的表现（关注更局部的序列特征），我们研究了不同类型基因组元素的`token`概率，作为模型学习的序列约束和重要性的度量。具体来说，我们计算了22号染色体上每个`6kb`窗口中的六聚体`token`概率（基于每次屏蔽一个`token`）。我们的发现显示，除了被模型很好重建的重复元素外，预训练模型还学习了各种基因结构和调控元素。这些包括受体和供体剪接位点、`polyA`信号、`CTCF`结合位点和其他基因组元素（补充图17a-d）。\n\n> `polyA信号`：真核生物mRNA 3'端的保守序列(通常是AAUAAA)，它指导mRNA的切割和多聚腺苷酸化过程，对mRNA的稳定性和成熟至关重要。\n>\n> `CTCF结合位点`：CTCF蛋白在基因组上的特异性结合序列，作为绝缘子和染色质结构调控因子，参与基因调控、染色质构象组织和转录绝缘等功能，在基因组三维结构形成中起重要作用。\n\n此外，我们将我们的`token`预测与`MST1R`基因外显子11的实验饱和突变剪接实验进行了比较（数据来自Braun等人）。这个分析揭示了实验突变效应与`Multispecies 2.5B`模型做出的`token`预测之间存在显著相关性（`皮尔逊相关系数（PCC）= 0.44`；补充图17e）。该模型不仅捕获了不同剪接位点的约束，还识别出第二个内含子中间对该外显子剪接至关重要的区域。这些结果有力地验证了`NT`模型在无监督预训练期间获得的生物学知识。\n\n最后，对于在`DeepSTARR`增强子活性数据上完全微调的`Multispecies 2.5B`模型，我们检查了它是否特别学习了与增强子活性相关的`TF`基序及其相对重要性。我们使用了一个数据集，其中包含了数百个增强子序列中五种不同`TF`基序类型的数百个单独实例的实验突变，并评估了模型在预测这些突变效应方面的准确性。\n\n与最先进的增强子活性`DeepSTARR`模型相比，我们的模型在四个`TF`基序上达到了相似的性能，并在`Dref`基序上展示了更优的性能（补充图18）。总的来说，这些结果说明了`NT`模型已经获得了恢复基因结构和基因组序列功能特性的能力，并直接将它们整合到其注意力机制中。这种编码的信息应该有助于评估遗传变异的重要性。\n\n### 预训练的嵌入预测突变的影响\n\n此外，我们评估了`NT模型`在评估各种`遗传变异`的严重程度和优先排序具有功能意义的变异方面的能力。我们首先研究了零样本评分的使用，这些评分用于预测模型在训练期间未见过的类别。\n\n具体来说，我们使用`嵌入空间`中不同方面的向量距离以及从损失函数中得出的评分来计算零样本评分，并比较它们在严重程度不同的十种遗传变异类型中的分布情况（图4a和方法）。令人鼓舞的是，一些零样本评分在模型间表现出与严重程度的中等相关性（补充图19）。这说明了仅通过无监督训练就捕获了与遗传突变潜在严重程度相关的信息，并突出了评估不同评分方法的重要性。评分之间的高度相关性变异也表明，嵌入空间的不同方面可能更有效地捕获与严重程度相关的信息。\n\n在这些评分中，余弦相似度在各个模型中表现出与严重程度最高的相关性，$r^2$ 值范围从`-0.35`到`-0.3`（$P < 6.55 × 10^{-186}$；补充图19）。在所有模型中，最低的`余弦相似度评分`被分配给影响蛋白质功能的遗传变异，如终止获得变异，以及同义和错义变异（图4b）。相反，我们注意到较高的评分被分配给潜在功能重要性较低的变异，如基因间变异，突出了其在捕获遗传变异严重程度影响方面的潜在用途。\n\n![image-20241216164949510](/images/assets//image-20241216164949510.png)\n\n接下来，我们还探索了`零样本评分`在优先考虑`功能变异`以及具有`致病效应变异`方面的潜力。具体来说，我们评估了模型对影响基因表达调控的遗传变异（表达量性状位点，`eQTLs`）、与`DNA甲基化`变异相关的遗传变异（甲基化量性状位点，`meQTLs`）、在`ClinVar`数据库中注释为致病性的遗传变异以及在人类基因突变数据库（`HGMD`）中报告的遗传变异进行分类的能力。零样本评分表现出高分类性能，在四个任务中的最高`AUC`值范围从`0.7`到`0.8`（图4c）。在`ClinVar`变异中获得的最高性能（`Multispecies 2.5B`模型的`AUC`为`0.80`）表明，至少对于高度致病性变异，零样本评分可能可以直接应用。\n\n最后，为了更正式地评估这些模型的有效性，我们还基于`微调模型`进行预测，并将其性能与多种方法进行了比较。这些方法包括那些测量基因组保守性的方法，以及从在功能特征上训练的模型中获得的评分。值得注意的是，微调模型或略微超过或紧密匹配了其他模型的性能（图4d和补充图20）。\n\n对于优先排序分子表型（`eQTLs`和`meQTLs`）表现最好的模型是那些在人类序列上训练的模型，而对于优先排序致病性变异表现最好的模型则是基于多物种序列的模型。考虑到最严重的致病性变异往往由于氨基酸改变而影响基因功能，多物种模型可能利用了跨物种的序列变异来学习位点的保守程度。\n\n我们的结果还表明，对于非编码变异（如`eQTLs`和`meQTLs`）的更高预测能力，可以通过从增加的人类遗传变异性中更好地学习序列变异来实现。此外，与零样本评分相比，点积在`eQTLs`和`meQTLs`上分别产生了`0.73`和`0.71`的`AUC`值，略微超过或匹配了通过微调模型获得的值。鉴于这些遗传变异往往位于调控区域内，这可能表明这些模型在没有任何监督的情况下，已经学会了区分与基因表达和甲基化变异相关的相关调控基因组特征。这与在层和头部之间观察到的注意力水平一致，特别是对于相关的`调控序列`，如增强子（图3a）和启动子（补充图13），这些序列已被证明在`meQTLs`和`eQTLs`中富集。总的来说，这些结果说明了基于`DNA`的转换器模型如何能帮助揭示和有助于理解与分子表型和疾病相关的变异的潜在生物学意义。\n\n### 基因组学中成本效益预测的模型优化\n\n最后，我们探索了通过整合当代架构进展并延长训练时间来优化我们表现最好的模型的可能性。我们开发了四个新的`NT`模型（`NT-v2`），参数数量从`5千万`到`5亿`不等，并引入了一系列架构改进（补充表1和方法）。这些改进包括引入旋转嵌入、实施`swiGLU`激活，以及消除`MLP`偏差和丢弃机制，这与最新的研究相一致。\n\n此外，我们将上下文长度扩展到`12kb`以容纳更长的序列并捕获更远距离的基因组相互作用。我们将`250M`和`500M`参数模型的训练时间延长至包含`1万亿`个`token`，这与最近文献中的建议相一致（图5a）。在同一个多物种数据集上预训练后，所有四个`NT-v2`模型都经过了微调，并在相同的18个下游任务上进行评估，其结果与四个初始`NT`模型进行了比较（图5b和补充表7、9）。\n\n![image-20241216165021903](/images/assets//image-20241216165021903.png)\n\n我们观察到`50M参数`的`NT-v2模型`实现了与我们两个`NT 500M参数模型`以及在`1000基因组数据集`上训练的`2.5B参数模型`相近的性能。这表明，通过优质的预训练数据集，结合训练技术和架构的进步，可以在显著提高性能的同时实现模型参数数量惊人的50倍减少（图5c）。\n\n事实上，`NT-v2 250M参数`和`500M参数模型`在保持参数数量显著较少的同时，成功实现了超越`2.5B参数多物种模型`的性能，并且将感受野加倍。特别值得注意的是，`NT-v2 250M参数模型`在我们的基准测试中取得了最佳性能（平均`MCC`为`0.769`），同时其参数量仅为`2.5B参数模型`的十分之一（图5c）。\n\n为了进一步了解更长时间预训练的必要性，我们对`NT-v2模型`在预训练期间看到的标记数量与性能之间的关系进行了系统性评估（图5b）。这显示了`250M参数模型`仅在训练达到`9000亿个标记`后才略微超过`500M模型`。总的来说，配备了`12kb`上下文长度的`NT-v2模型`由于其紧凑的尺寸而适合在经济型加速器上部署。因此，对于希望在下游应用中利用最先进基础模型的用户来说，它们提供了一个经济可行且实用的选择。\n\n作为一个相关的应用案例，在确立了一个表现良好的模型后，我们通过在`SpliceAI`剪接任务上评估`500M模型`来评估`NT-v2模型`更长上下文长度的优势。我们评估了`500M模型`，因为该模型在剪接相关任务上表现最好（补充表7和9）。我们调整了分类头以预测每个核苷酸位点是剪接供体、受体还是无剪接的概率（图5d和方法）。与`NT 6kb模型`相比，我们的`NT-v2 500M 12kb模型`将表现提高了1%，达到了`96%`的`top-k准确率`和`0.98`的`精确率-召回率AUC`（图5e）。这一性能超过了最先进的`SpliceAI-10k`模型，后者是在`15kb`输入序列上训练的。\n\n值得注意的是，我们并没有试图专门针对剪接预测任务优化我们的模型架构；相反，我们采用了与其他下游任务类似的`微调方法`，仅在分类头上进行调整以产生核苷酸级别的预测。针对特定任务（如剪接）的进一步架构优化很可能会提高性能。总之，这些结果证实了`NT v1`和`v2模型`在广泛的基因组学任务中的实用性和有效性，只需要最小的修改和计算能力就能实现高准确率。\n\n## 讨论\n\n本研究尝试研究在`DNA序列`上预训练相同规模的`transformer模型`时，使用不同数据集的影响。基于不同的基因组预测任务的结果表明，种内（在单一物种的多个基因组上训练）和种间（在不同物种的基因组上）变异都显著影响任务的准确性（图1c和2a）。\n\n在考虑的大多数人类预测任务中，在不同物种基因组上训练的模型表现优于仅在人类序列上训练的模型。这表明在不同物种上训练的`transformer模型`已经学会捕捉到在物种间具有功能重要性的基因组特征，从而能够更好地泛化到各种人类相关的预测任务中。\n\n基于这一发现，我们预计未来的研究可能会受益于利用跨物种的遗传变异性，包括确定采样这种变异性的最佳方式。另一个有趣的研究方向是探索编码种内变异性的不同方法。我们混合所有个体基因组序列的方法只带来了有限的改进，这表明当大多数序列是共享的时候，利用来自不同个体的基因组可能并不那么简单。\n\n本研究中训练的`transformer模型`参数范围从`5000万`到`25亿`，比`DNABERT-2`大20倍，比`Enformer`骨干模型大10倍。正如之前在自然语言处理研究中所证明的，我们在18个基因组预测任务上的结果证实，增加模型规模会持续改善性能。为了训练具有最大参数规模的模型，我们在16个计算节点上使用了总共128个GPU，持续28天。\n\n在工程方面投入了大量工作以开发高效的训练程序，充分利用基础设施，这凸显了专门的基础设施和专用软件解决方案的重要性。然而，一旦训练完成，这些模型可以以相对较低的成本进行推理，我们提供了可以将这些模型应用于任何下游任务的笔记本，从而促进进一步的研究。\n\n之前的工作主要基于在生物数据（主要是蛋白质序列）上训练的语言模型，主要通过探测最后一个`transformer层`来评估下游性能。这种选择可能是由于其`使用方便`、`性能相对较好`以及`计算复杂度低`。在本研究中，我们的目标是通过对不同`transformer层`、`下游模型`和`超参数`进行计算密集型和全面的探测来评估下游准确性。我们观察到最佳探测性能是在中间的`transformer层`上实现的（补充图1），这与计算生物学领域的最新工作和自然语言处理中的常见实践一致。仅通过探测，`Multispecies 2.5B模型`在18个任务中的8个任务上超过了`BPNet`基线模型。\n\n此外，我们探索了一种最新的`下游微调技术`，该技术在`transformer`中引入少量可训练权重。这种方法提供了一个相对快速且资源高效的微调程序，与全模型微调（`IA3`）相比差异很小。值得注意的是，这种微调方法只需要总参数数量的0.1%，使得即使是我们最大的模型也能在单个GPU上在15分钟内完成微调。与大量的探测实验相比，这种技术在使用更少计算资源的同时产生了更好的结果，证实了下游模型工程可以带来性能改进。从操作角度来看，这种技术使得微调在训练和推理方面都能与探测相竞争，同时还能实现更好的性能。\n\n虽然在大型数据集上进行广泛训练的优化架构的监督模型继续展现出优越的性能，但DNA语言方法在包括组蛋白修饰、剪接位点和调控元件表征等多个领域的各种任务中仍具有竞争力。\n\n此外，`NT模型`代表了一种通用方法，可以无缝地适应人类和非人类物种的各种任务。当处理较小的数据集时，我们的无监督预训练方法的价值变得尤为明显，因为从头开始训练监督模型通常只能产生有限的结果。认识到基础基因组学模型在该领域的关键作用，我们进行了广泛的比较和基准测试研究，将我们的模型与四个具有不同架构的预训练模型进行评估：`DNABERT-2`、`HyenaDNA-1kb`、`HyenaDNA-32kb`和`Enformer`。这个健全的基准测试将作为未来基因组学领域语言模型发展的参考点。\n\n通过对`transformer`架构的各种分析，我们已经证明这些模型不仅获得了`重建遗传变异`的能力（补充说明），还能识别关键的`调控基因组元件`。这一特性在注意力图、嵌入空间、标记重建和概率分布的分析中得到了证实。所有模型在多个头部和层中都能一致地检测到控制基因表达的关键调控元件，如增强子和启动子。此外，我们观察到每个模型至少包含一层，能产生清晰区分我们分析的五种基因组元件的嵌入。鉴于自监督训练促进了这些元件的检测，我们预计这种方法在未来的研究中可以用于表征或发现新的基因组元件。\n\n我们已经证明，`transformer模型`可以匹配甚至超越其他用于`预测变异效应`和`致病性`的方法。除了开发监督型`transformer模型`，我们还展示了零样本（`zero-shot`）分数的实用性，特别是在预测非编码变异效应方面。考虑到这些基于零样本的分数仅可从基因组序列中推导出来，我们鼓励将其应用于功能注释有限的非人类生物。\n\n最后，我们已经证明通过增强模型架构可以实现降低模型规模和提高性能的双重收益。我们后续的`NT-v2系列模型`具有`12kb`的上下文长度。为了说明这一点，这个长度分别是`DNABERT-1`（`500bp`）和`DNABERT-2`（`3kb`）平均上下文长度的24倍和4倍。这些改进的模型不仅展示了更好的下游性能，而且由于其紧凑的尺寸，结合我们引入的高效微调技术，适合在经济型硬件上执行和微调，这是一个额外的优势。\n\n虽然我们的模型仍然具有有限的注意力范围，但最近开发的`Enformer模型`表明，将感知域增加到`200kb`对于捕捉人类基因组中的长程依赖关系是必要的。作者认为，这些长程依赖关系对于准确预测基因表达是必需的，因为基因表达受远端调控元件控制，这些元件通常位于转录起始位点`10-20kb`以外的位置。由于自注意力机制相对于序列长度的二次方缩放，使用标准`transformer架构`处理如此大的输入是不可行的。`Enformer模型`通过在到达`transformer层`之前通过卷积层传递序列来减少输入维度以解决这个问题。然而，这种选择降低了其在语言建模中的有效性。另一方面，最近的`HyenaDNA模型`训练时的感知域达到了`100万bp`，但我们的下游任务基准分析表明，当训练过程中使用的感知域增加时，这些模型的性能会快速下降。\n\n> Enformer模型可参考：{% postLinkCard 906k2592  \"auto\" %}\n>\n\n基于我们的结果，我们建议开发能够`处理长输入同时保持对短输入高性能`的`transformer模型`是该领域一个有前景的方向。在多组学数据快速扩展的时代，我们最终预计本文提供的方法，以及可用的基准测试和代码，将促进基因组学中大型基础语言模型的采用、开发和改进。\n\n## 方法\n\n### 模型\n\n语言模型（`LM`）主要在自然语言处理（`NLP`）领域开发，用于模拟口语。语言模型是一个在`token序列`（通常是词）上的概率分布，给定任何词序列，语言模型都会返回该句子存在的概率。语言模型因其能够利用大规模未标记数据集来生成通用表示而广受欢迎，这些表示即使在监督数据较少的情况下也能解决下游任务。训练语言模型的一种技术是预测序列中被遮蔽位置最可能出现的`token`，这通常被称为遮蔽语言建模（`MLM`）。\n\n受蛋白质研究领域`MLM`成果的启发，该领域将蛋白质视为句子，氨基酸视为单词，我们将`MLM`应用于基因组学的转换器训练，将核苷酸序列视为句子，将`k-mers`（k=6）视为单词。转换器是一类在机器学习领域取得突破性进展的深度学习模型，包括`NLP`和计算机视觉。它们由一个初始嵌入层组成，该层将输入序列中的位置转换为嵌入向量，随后是一堆自注意力层，这些层依次细化这些嵌入。\n\n用`MLM`训练语言模型转换器的主要技术称为双向编码器表示转换器（`BERT`）。在`BERT`中，序列中的所有位置都可以相互关注，允许信息双向流动，这在DNA序列的上下文中是必不可少的。在训练过程中，网络的最终嵌入被送入语言模型头，将其转换为输入序列上的概率分布。\n\n#### 架构\n\n我们所有的模型都遵循仅编码器的转换器架构。嵌入层将`token序列`转换为`嵌入序列`。然后将位置编码添加到序列中的每个嵌入中，以向模型提供位置信息。我们使用可学习的位置编码层，最多可接受`1000个token`。\n\n我们使用六聚体`token`作为序列长度（最多6kb）和嵌入大小之间的权衡，并且与其他`token`长度相比，它实现了最高的性能。然后`token`嵌入由转换器层堆栈处理。每个转换器层通过层归一化层和多头自注意力层转换其输入。自注意力层的输出通过跳跃连接与转换器层输入相加。该操作的结果随后通过新的层归一化层和具有`GELU`激活的两层感知器传递。\n\n每个模型的头的数量、嵌入维度、感知器隐藏层中的神经元数量和层的总数可以在补充表1中找到。在自监督训练期间，堆栈最终层返回的嵌入由语言模型头转换为序列中每个位置上现有`token`的概率分布。\n\n我们的第二版`NT-v2`模型包含一系列经证实更高效的架构变化：我们使用旋转嵌入而不是学习位置嵌入，这些嵌入在每个注意力层中使用；我们使用带有`swish`激活的门控线性单元，没有偏置，使`NLP`更有效。这些改进的模型还接受最多2048个`token`的序列，导致更长的上下文窗口为12kb。\n\n#### 训练\n\n模型按照`BERT`方法进行训练。在每个训练步骤中，采样一批`tokenized序列`。批量大小根据可用硬件和模型大小进行调整。我们在`A100 GPU`集群上进行了所有实验，并采用了大小为14和2个序列的批次来训练\"500M\"和\"2.5B\"参数模型。\n\n在序列中，15%的`token`子集中有80%被替换为特殊的遮蔽（\"MASK\"）token。对于人类参考基因组和多物种数据集的训练运行，15%子集中额外10%的`token`被替换为随机选择的标准`token`（任何不同于类（\"CLS\"）、填充（\"PAD\"）或`MASK token `的`token`），就像在`BERT`中那样。\n\n对于1000G数据集的训练运行，我们跳过了这种额外的数据增强，因为添加的噪声大于人类基因组中存在的自然突变频率。对于每个批次，损失函数计算为在每个选定位置上预测`token`概率与真实`token`之间的`交叉熵损失之和`。梯度被累积以达到每批100万个`token`的有效批大小。\n\n我们使用`Adam`优化器，学习率计划和标准的指数衰减率和 $\\epsilon$ 常数，$β_1=0.9$，$β_2=0.999$ 和 $ϵ=1×10^{-8}$。在第一个预热期间，学习率在16,000步内在 $5×10^{-5}$ 和 $1×10^{-4}$ 之间线性增加，然后按照平方根衰减直到训练结束。\n\n我们对`NT-v2`模型的超参数进行了细微调整：优化器和学习率计划保持不变；但是，我们将批量大小增加到512（每批100万个`token`）。受`Chinchilla`缩放定律的启发，与其他深度学习模型相比，我们还对`NT-v2`模型进行了更长时间的训练。具体来说，我们对`NT-v2 50M`和`250M`参数模型预训练了3000亿个`token`，而我们的\"250M\"和\"500M\"参数模型训练了高达1万亿个`token`，以了解相关的缩放定律。相比之下，`NT-v1 2.5B`参数模型训练了3000亿个`token`，而其500M对应模型训练了500亿个`token`。最后，我们使用以下`NT-v2`模型检查点：3000亿个`token`检查点用于\"50M\"和\"100M\"模型，8000亿个`token`检查点用于\"250M\"模型，以及9000亿个`token`检查点用于\"500M\"模型。\n\n#### 探测\n\n我们将**探测**称为**评估模型嵌入解决下游任务的质量**。\n\n训练后，对于每个任务，我们探测模型的每一层，并比较几种下游方法，以深入评估表示的能力。换句话说，给定下游任务的核苷酸序列数据集，我们计算并存储模型十个层返回的嵌入。然后，使用每个单独层的嵌入作为输入，我们训练了几个下游模型来解决下游任务。\n\n我们测试了来自`scikit-learn`的默认超参数的逻辑回归和多层感知器（`MLP`）。由于我们观察到`超参数`的选择（如学习率、激活函数和每个隐藏层的层数）会影响最终性能，我们还对每个下游模型运行了超参数扫描。我们使用十折验证方案，其中训练数据集被分成十次训练和验证集，包含初始集的90%和10%的不同洗牌。\n\n对于给定的超参数集，在十个分割上训练十个模型，并平均其验证性能。这个程序使用`Tree-structured Parzen Estimator`求解器引导超参数空间的搜索运行100次，然后在测试集上评估表现最好的模型组。因此，对于每个下游任务，对于每个预训练模型的十个层，在超参数搜索结束时记录测试集上的性能。表现最好的探测在预训练模型和其层之间的超参数在补充表8中报告。这种探测策略导致训练了76万个下游模型，这为训练和使用语言模型的各个方面提供了详细分析，例如不同层对下游任务性能的作用。\n\n作为基线，我们评估了以`tokenized序列`作为输入的`逻辑回归模型`的性能，在通过转换器层传递`token`之前。使用原始`tokenized序列`作为输入比使用`token ids`被`one-hot编码`并通过`池化层`传递（在序列长度轴上求和或平均）的向量产生了更好的性能。\n\n#### 微调\n\n除了通过在各个层中`提取嵌入`来探测我们的模型外，我们还通过`IA3`技术执行了参数高效的微调。使用此策略，根据任务需求将语言模型头替换为分类或回归头。\n\n转换器层和嵌入层的权重被冻结，并引入了新的可学习权重。对于每个转换器层，我们引入了三个学习向量$l_k∈ℝ^{d_k}$，$l_v∈ℝ^{d_v}$和$l_f∈ℝ^{d_f}$，它们在自注意力机制中被引入为：\n$$\n\\text {softmax}(\\frac{Q(l_k)⊙K^T}{\\sqrt{d_k}})(l_v⊙V)\n$$\n\n并在位置前馈网络中被引入为 $(l_f⊙γ(W_1x))W_2$，其中$γ$是前馈网络的非线性，$⊙$ 表示逐元素乘法。这总共增加了$L(d_k+d_v+d_f)$个新参数，其中$L$是转换器层的数量。我们将这些可学习的权重称为重缩放权重。\n\n直觉是在微调期间，这些权重将对转换器层进行`加权`，以改善模型在下游任务上的最终表示，使得分类/回归头能够更准确地解决问题。由于我们在探测期间观察到层专门化，我们推测这种微调技术将同样选择对特定任务具有更大预测能力的层。\n\n实际上，重缩放权重和分类/回归头权重引入的额外参数数量约占模型总权重的0.1%。这加快了微调速度，因为只需要更新一小部分参数。同样，它也减轻了存储要求，每个下游任务只需要为500万和25亿个参数创建0.1%的新参数空间，而不是使用传统微调。例如，对于25亿参数模型，权重为9.5GB。考虑到18个下游任务，传统的微调将需要9.5×18=171GB，而参数高效的微调只需要171MB。\n\n与探测方案类似，训练数据集被分成`十次训练`和`验证集`，包含初始集的90%和10%的不同洗牌。对于每个分割，模型微调10,000步，然后使用产生最高验证分数的参数在测试集上评估模型。我们使用批量大小为8和`Adam`优化器，学习率为$3×10^{-3}$。其他优化器参数保持与训练方案相同。每个模型对每个任务微调10,000步。这些超参数是根据`NLP`领域的成功经验选择的。我们的实验表明，偏离这些超参数选择并未带来显著的收益。我们还将这种方法与从随机初始化的检查点进行微调进行了比较。\n\n#### 与监督`BPNet`基线的比较\n\n作为`基线监督模型`，我们从头开始在18个任务中的每一个上训练了不同变体的`BPNet`卷积架构。我们测试了原始架构（`121,000`个参数）、一个大型架构（`2800万`个参数）和一个特大型架构（`1.13亿`个参数）。对于每一个，超参数都经过手动调整以在验证集上获得最佳性能。我们实施了`十折交叉验证`策略来衡量每种架构的18个模型的性能。\n\n#### 与已发布的预训练基因组学模型的比较\n\n我们将`NT`模型在18个下游任务上的微调性能与三个不同的预训练模型进行了比较：`DNABERT-2`、`HyenaDNA`（1kb和32kb上下文长度）和`Enformer`。我们排除了`DNABERT-1`，因为它最多只能处理512bp的输入长度，因此不能用于大多数任务。我们将每个模型的架构和训练权重移植到我们的代码框架中，并对每个模型的转换器部分进行如上所述的参数高效微调，使用相同的交叉验证方案进行公平比较。所有结果都可以在交互式排行榜上查看（[https://huggingface.co/spaces/InstaDeepAI/nucleotide_transformer_benchmark](https://huggingface.co/spaces/InstaDeepAI/nucleotide_transformer_benchmark)）。只有对于`HyenaDNA`，由于我们的参数高效微调方法与模型架构不兼容，我们执行了完整的微调。\n\n需要注意的是，`Enformer`最初是在监督方式下训练的，用于解决染色质和基因表达任务。为了进行基准测试，我们重用了提供的模型主干作为我们基准的预训练模型，这不是原始论文的预期和推荐用法；然而，我们认为这种比较很有趣，因为它突出了自监督和监督学习在预训练方面的差异，并观察到`Enformer`确实是一个非常有竞争力的基线，即使对于与基因表达不同的任务。不过，我们注意到`Enformer`最初使用不同的数据分割进行预训练，因此其在我们的基准评估中的表现可能由于潜在的数据泄露而被夸大。\n\n### 预训练数据集\n\n#### 人类参考基因组数据集\n\n人类参考数据集通过考虑参考组装`GRCh38/hg38`([https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.26](https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.26))中所有常染色体和性染色体序列而构建，总计达到了`32亿`个核苷酸。\n\n#### 千人基因组(1000G)数据集\n\n为了让模型学习人类中自然存在的`遗传多样性`，我们构建了一个包含来自`不同人群遗传变异`的训练数据集。具体来说，我们从千人基因组(1000G)计划下载了变异调用格式(`VCF`)文件([20201028_3202_phased](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20201028_3202_phased/))，该计划旨在记录人类群体中频率至少为1%的遗传变异。\n\n该数据集包含`3,202`个高覆盖度人类基因组，来自27个地理结构化的非洲、美洲、东亚和欧洲血统人群，详见附表2，总计达`20.5万亿`个核苷酸。这种多样性使数据集能够更好地表示人类遗传变异。为了允许从`VCF文件`中重建`FASTA格式`的单倍型，我们考虑了数据的相位版本，其中包含总计`1.25亿`个突变，其中`1.11亿`个和`1400万`个分别是单核苷酸多态性(`SNPs`)和插入缺失(`indels`)。\n\n#### 多物种数据集\n\n多物种数据集的选择主要基于两个因素：\n\n1. 现有参考基因组的质量和\n\n2. 所使用物种间的多样性\n\n本数据集中选择的基因组来自NCBI参考序列(`RefSeq`)集合([https://www.ncbi.nlm.nih.gov/](https://www.ncbi.nlm.nih.gov/))。为确保基因组集的多样性，我们从`RefSeq`中每个主要分组(古菌、真菌、脊椎动物、哺乳动物、脊椎动物、其他等)在属级水平上随机选择了一个基因组。然而，由于细菌基因组数量众多，我们选择只包含其随机子集。未考虑植物和病毒基因组，因为它们的调控元件与本研究关注的不同。最终筛选得到的基因组集合下采样至总计`850`个物种，其基因组加起来达`1740亿`个核苷酸。如附表3所示，数据集中每个类别在总核苷酸数中的最终贡献与从NCBI解析的原始集合中的相同。最后，我们通过选择一些在文献中被广泛研究的基因组来丰富这个数据集(附表4)。\n\n### 数据准备\n\n在收集每个基因组/个体的`FASTA文件`后，它们被组装成每个数据集一个唯一的`FASTA文件`，然后在训练前进行预处理。在数据处理阶段，所有`非A、T、C、G`的核苷酸都被替换为`N`。使用分词器将字母串转换为标记序列。分词器使用的字母表包含通过组合`A、T、C、G`得到的 $4^6 = 4,096$ 种可能的六聚体组合，以及代表独立`A、T、C、G和N`的五个额外标记。它还包括三个特殊标记，即`填充（PAD）`、`掩码（MASK`）和`序列开始`（也称为类别（CLS））标记。这样总共构成了`4,104`个标记的词汇表。要对输入序列进行分词，分词器将从类别标记开始，然后从左侧开始转换序列，在可能的情况下匹配六聚体标记，或在需要时（例如出现字母N时或序列长度不是6的倍数时）回退使用独立标记。\n\n对于多物种和人类参考数据集，基因组被分割成`6,100`个核苷酸的重叠片段，每个片段分别与前一个和后一个片段共享前后`50`个核苷酸。作为数据增强练习，对于每个训练周期和片段，在0到100之间随机采样一个起始核苷酸索引，然后从这个核苷酸开始对序列进行分词，直到达到`1,000`个标记。根据数据集确定训练周期数，以使模型在训练期间总共处理`3000亿`个标记。\n\n在每一步，随机从训练周期集中采样一批`序列输入模型`。对于1000G数据集，在每一步采样人类参考基因组的序列批次（按上述方式准备）。然后，对于每个采样的片段，随机选择1000G数据集中的一个个体，如果该个体在对应于该片段的位置和染色体上携带突变，则将这些突变引入序列并替换相应的标记。这种数据处理技术确保了在训练期间对基因组和个体的均匀采样，并且使我们能够仅高效存储每个个体的突变，而不是完整的基因组。\n\n#### 硬件设施\n\n所有模型都在配备有16个节点的`Cambridge-1 Nvidia超级计算机`系统上训练，每个节点配备`8`个`A100 GPU`，总共使用了128个`A100 GPU`。在训练期间，模型权重在每个GPU上复制，而批次则在GPU间分片。在每个分片上计算梯度并累积，然后在设备间平均后反向传播。我们依赖Jax库([https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html](https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html))，该库使用NCCL协议([https://developer.nvidia.com/nccl](https://developer.nvidia.com/nccl))处理节点和设备之间的通信，观察到训练时间随可用GPU数量几乎呈线性下降。`500M`参数模型在单个节点上训练一天，而`2.5B`参数模型需要整个集群训练`28`天。具有从`5000万`到`5亿`参数不等的`NT-v2模型`同样在单个节点上训练一天。所有微调运行都在配备8个`A100 GPU`的单个节点上执行。与训练运行一样，模型权重被复制，批次在`GPU`间分布。由于我们在微调时使用了8的批次大小，每个GPU在平均梯度并应用之前处理一个样本。平均而言，`500M参数模型`的微调运行持续20分钟，`2.5B参数模型`持续50分钟。\n\n对于探测实验，所有`嵌入`（所有下游任务中所有序列的所有选定层）都在配备8个`A100 GPU`的单个节点上计算和存储，需要2天时间计算。然后，在一个由3000个CPU组成的集群上拟合76万个下游模型，需要2.5天。\n\n### Nucleotide Transformer下游任务\n\n#### 表观遗传标记预测\n\n从`ENCODE数据库`获取了人类`K562细胞系`中10个组蛋白`ChIP-seq`数据。我们下载了以下标识符的`bed narrowPeak`文件：`H3K4me3` (ENCFF706WUF)、`H3K27ac` (ENCFF544LXB)、`H3K27me3` (ENCFF323WOT)、`H3K4me1` (ENCFF135ZLM)、`H3K36me3` (ENCFF561OUZ)、`H3K9me3` (ENCFF963GZJ)、`H3K9ac` (ENCFF891CHI)、`H3K4me2` (ENCFF749KLQ)、`H4K20me1` (ENCFF909RKY)和`H2AFZ` (ENCFF213OTI)。对于每个数据集，我们选择包含峰值的`1kb基因组序列`作为正例，所有不与峰值重叠的`1kb序列`作为负例。\n\n#### 启动子序列预测\n\n我们构建了一个`启动子序列`数据集来评估模型识别启动子基序的能力。我们从真核生物启动子数据库下载了所有人类启动子，跨越转录起始位点上游`49bp`和下游`10bp`([Hs_EPDnew_006_hg38.bed](https://epd.expasy.org/ftp/epdnew/H_sapiens/006/Hs_EPDnew_006_hg38.bed))。这产生了`29,598`个启动子区域，其中`3,065`个是TATA盒启动子（使用[promoter_motifs.txt](https://epd.expasy.org/ftp/epdnew/H_sapiens/006/db/promoter_motifs.txt)的基序注释）。我们选择包含启动子的`300bp`基因组序列作为正例，所有不与启动子重叠的`300bp`序列作为负例。这些正例和负例用于创建三个不同的二元分类任务：存在任何启动子元件（所有启动子）、具有TATA盒基序的启动子（TATA启动子）或不具有TATA盒基序的启动子（非TATA启动子）。\n\n#### 增强子序列预测\n\n从`ENCODE`的`SCREEN数据库`获取了人类增强子元件。远端和近端增强子被合并。基于Meuleman等人的词汇表，增强子被分为组织特异性和组织不变性。与组织不变性区域重叠的增强子被定义为该类型，而所有其他增强子被定义为组织特异性。\n\n我们选择包含增强子的`400bp`基因组序列作为正例，所有不与增强子重叠的`400bp`序列作为负例。我们创建了一个用于预测序列中是否存在增强子元件的二元分类任务（增强子）和一个多标签预测任务，标签为组织特异性增强子、组织不变性增强子或无（增强子类型）。\n\n#### 剪接位点预测\n\n我们从`GENCODE V44基因注释`获取了所有人类注释的剪接位点。排除了`level-3转录本`（自动化注释）的注释，以使所有训练数据都由人工注释。我们使用`HISAT2`的`extract_splice_sites.py`来提取相应的剪接位点注释。我们选择中心包含剪接受体或供体位点的`600bp`基因组序列作为正例，所有不与剪接位点重叠的`600bp`序列作为负例。我们使用这些序列创建三个不同的任务来评估`剪接预测`：标签为受体、供体或无的多标签预测任务（所有剪接位点）；预测剪接受体的二元分类任务（剪接受体）；以及预测剪接供体的二元分类任务（剪接供体）。\n\n### 数据集分割和性能评估\n\n在人类基因组的不同`染色体集`上进行模型训练和性能评估。具体来说，染色体`20`和`21`的序列用于测试，其余用于训练不同的模型。删除了含有N的序列。我们通过对负例进行下采样至与正例相同数量来平衡每个数据集。为了获得可以快速基准测试任何新设计选择或模型的小型数据集，我们进一步随机对样本进行下采样，训练集最多`30,000`个，验证和测试集最多`3,000`个（详见附表5）。\n\n我们使用`十折交叉验证`方案来评估每个模型，其中训练集被分成十份，每次使用其中九份进行训练，保留十分之一用于验证和选择最终检查点。我们对每个模型重复此程序十次，每次保留不同的十分之一用于验证，并在相同的保留测试集上评估最终性能。我们使用十折中的中位数性能作为每个模型在给定任务上的最终性能度量。\n\n为了在任务间进行一致的性能评估，我们使用二元或多类`MCC`（Matthews相关系数）作为度量标准，因为它对不均衡的标签比例具有鲁棒性。为了最终比较模型之间的性能，我们计算了每个模型在三个不同任务类别（染色质谱系、调控元件和剪接）中的平均MCC，其中每个类别我们使用任务间的中位数MCC。\n\n### 其他下游任务\n\n#### 染色质谱系预测\n\n我们使用了Zhou等人编制的`DeepSEA数据集`进行染色质谱系预测。该数据集由`240万`个序列组成，每个序列大小为1000个核苷酸，并与919个染色质特征相关联。这些包括690个转录因子、125个`DNase`和104个`组蛋白特征`。如原始出版物所述，我们的模型同时在919个分类任务上进行训练，有919个独立的分类头，损失函数取为交叉熵损失的平均值。由于每个标签都高度不平衡，主要由负样本组成，因此与正样本相关的损失被放大了8倍。与`DeepSEA方法`不同的是，后者独立训练了两个模型，一个在正向序列上，一个在相应的反向互补序列上，并评估它们预测的平均值，而这里展示的模型仅在正向序列上训练。\n\n#### SpliceAI基准测试\n\n我们使用`Illumina Basespace平台`上可用的脚本来复现`SpliceAI`中展示的训练数据集。简而言之，这个训练数据集使用`GENCODE V24lift37注释`和来自`GTEx队列的RNA-seq数据`构建，仅关注主要转录本的剪接位点注释。\n\n训练数据集包括位于染色体`2`、`4`、`6`、`8`和`10-22`以及`X`和`Y`染色体上的基因的注释，而剩余染色体上非旁系同源基因的注释构成了测试数据集。这个流程产生的每个序列长度为`15,000bp`，中心`5,000bp`包含要预测的位点。关于训练数据集构建的更多细节可在原始出版物中找到。我们调整了这个原始SpliceAI数据集以运行我们的模型，方法是将序列长度减少到`6,000bp`（对于NT-v1模型）和`12,000bp`（对于NT-v2模型），减少了侧翼上下文但保持中心`5,000bp`。我们还删除了包含N的序列。在与第一个数据集上的SpliceAI进行比较时（我们称之为SpliceAI-6k），我们附加了`9,000`个\"N\"核苷酸作为侧翼序列，因为SpliceAI基于具有`15,000bp`输入的模型。在与第二个数据集上的SpliceAI进行比较时，我们报告了原始出版物中呈现的性能，与本数据集相比，包括`15,000bp`而不是`12,000bp`的序列长度。\n\n这个任务是一个类似于`SpliceAI`的多标签分类任务，针对输入序列的每个核苷酸（图5d）。对于transformer模型输出的每个嵌入，一个头部为该标记嵌入所代表的六个核苷酸中的每一个预测三个标签概率：剪接受体、剪接供体或无。该头部是一个简单的分类层，预测18个类别（六个核苷酸中的每一个都有三个标签）。为确保每个嵌入都与一个六聚体相关联，序列被切割以使其长度能被6整除。\n\n此外，从训练和测试集中删除了所有包含N的序列，这仅占数据的很少一部分。值得注意的是，如果我们使用字节对编码分词器（如`DNABERT-2`），每个嵌入所代表的核苷酸数量会变化，这会使核苷酸级别的预测任务变得更加困难。\n\n#### 增强子活性预测\n\n我们使用了de Almeida等人发布的`DeepSTARR增强子活性数据集`。该数据集由484,052个大小为249个核苷酸的DNA序列组成，每个序列都测量了它们对发育型或管家型启动子的定量增强子活性。\n\n我们在模型中添加了两个独立的`回归头`以同时预测这两种增强子活性。遵循先前工作的方法，我们选择将这个回归任务作为`多标签分类问题`处理。\n\n具体来说，每个标签$y$被离散化为一组50个值 $(b_i)_{i∈[1,50]}$，在最小值和最大值之间均匀分布。对于每个标签，模型预测归一化权重 $(w_i)_{i∈[1,50]}$，使得：\n$$\ny = \\sum_{i=1}^{50} w_ib_i\n$$\n\n### 其他性能分析\n#### t-SNE嵌入投影\n\n使用 t-分布随机邻域嵌入（`t-SNE`）将`NT`内部嵌入降维到二维向量，以可视化不同基因组元件的分离情况。在几个`transformer层`输出计算了每个基因组元件的`NT嵌入`，并计算对应于该元件的序列位置的平均嵌入。然后将这些平均嵌入作为输入传递到带有默认参数的`sklearn Python`包中的`t-SNE降维对象`。\n\n#### 重构准确率和复杂度（perplexity）\n\n我们研究了预训练模型如何重构被掩码的标记。我们考虑一个带参数 $θ$ 的训练好的语言模型。在一个感兴趣的核苷酸序列 $s$ 内，我们使用两种策略之一来掩码标记（我们用掩码（`MASK`）标记替换这些位置的标记）。\n\n我们要么只掩码序列的中心标记，要么随机掩码序列内`15%`的标记。然后将掩码序列输入模型，并检索每个掩码位置的标记概率。损失函数 $l(θ,s)$ 和准确率 $acc(θ,s)$ 定义如下：\n$$\n\\begin{cases}\nl(θ,s) = \\sum_{i∈masked} \\sum_{tok∈\\mathcal{V}} \\log p(θ,i,tok) \\cdot 1(tok=s(i)) \\\\\nacc(θ,s) = \\frac{1}{|masked|} \\sum_{i∈masked} 1(\\arg\\max_{tok∈\\mathcal{V}}(\\log p(θ,i,tok))=s(i))\n\\end{cases}\n$$\n\n其中 $\\text {masked}$ 是掩码位置的集合，$\\mathcal{V}$ 是词汇表（所有现有标记的集合）。\n\n`复杂度`通常在自回归生成模型的上下文中定义。这里，我们依赖Rives提出的另一种定义，将其定义为在掩码位置上计算的损失函数的指数：\n$$\nperplexity(θ,s) = 2^{l(θ,s)}\n$$\n\n`复杂度衡量模型重构掩码位置的能力`，比准确率更精细，因为它也考虑了幅度。与准确率相反，较低的复杂度表示更好的重构能力，因此性能更好。\n\n#### 不同基因组元素中的标记重构\n\n我们还在整个`22号染色体`上对 6kb 窗口执行了这种标记重构方法。我们只保留没有N的窗口。对于每个窗口，每次掩码一个标记，恢复序列中原始标记的预测概率。\n\n我们在`WashU表观基因组浏览器`会话中显示这些分数（[https://shorturl.at/jov28](https://shorturl.at/jov28)）。为了获得不同类型基因组元素的平均标记概率，我们从`Ensembl`（外显子、内含子、剪接受体和供体、5'UTR、3'UTR、转录起始位点和转录终止位点）（[https://www.ensembl.org/info/data/ftp/index.html](https://www.ensembl.org/info/data/ftp/index.html)）、GENCODE的polyA信号位点（[https://www.gencodegenes.org/human/](https://www.gencodegenes.org/human/)）和`ENCODE`的调控元件（来自`SCREEN数据库`的增强子、启动子和CTCF结合位点）（[https://api.wenglab.org/screen_v13/fdownloads/GRCh38-ccREs.bed](https://api.wenglab.org/screen_v13/fdownloads/GRCh38-ccREs.bed)）检索基因注释区域。\n\n#### 功能变异优先级排序\n\n为了获得具有`不同严重程度`的遗传变异，我们使用了变异效应预测（`VEP`）软件并对整个人类基因组的序列进行注释。\n\n具体来说，我们在整个人类基因组中随机采样序列，并保留了注释为以下任何类别的序列中的遗传变异：`\"内含子变异\"、\"基因间变异\"、\"调控区域变异\"、\"错义变异\"、\"3'UTR变异\"、\"同义变异\"、\"`TF`结合位点变异\"、\"5'UTR变异\"、\"剪接区域变异\"和\"终止获得变异\"`。\n\n在只保留`SNP`并过滤掉注释为多个结果的变异（例如那些注释为终止获得和剪接变异的变异）后，我们获得了每个类别920个遗传变异的最终数据集。\n\n作为功能性遗传变异的正集，我们从四个不同来源编制了`SNP`。我们使用来自`GRASP`数据库的与基因表达（`eQTL`）和`meQTL`相关的`SNP`，$p$ 值 <$10^{-12}$，来自`ClinVar`的带有\"可能致病\"注释的`SNP`以及`HGMD`（公共v.2020.4）中报告的`SNP`。\n\n经过这些过滤，我们分别保留了`eQTL`、`meQTL`、`ClinVar`和`HGMD SNP`数据集的总计80,590、11,734、70,224和14,626个遗传变异。对于这四个数据集中的每一个，我们然后基于来自1000G项目的`SNP`构建了一组阴性变异，这些`SNP`的次要等位基因频率>5%，与测试数据集中报告的任何变异都不重叠，并且在相关变异的100 kb内，从而产生四个平衡数据集。\n\n对于给定的感兴趣位点，要计算基于零样本的分数，我们执行以下操作：对于每个`SNP`，我们基于人类参考基因组获得以`SNP`为中心的6,000 bp序列。然后我们创建两个序列，一个携带`SNP`位置的参考等位基因，另一个携带替代等位基因。然后我们计算几个零样本分数，这些分数捕获这两个序列之间嵌入空间中的矢量距离的不同方面，即：\n\n- L1距离（曼哈顿距离）\n\n- L2距离（欧几里得距离）\n\n- 余弦相似度\n\n- 点积（未归一化的余弦相似度）\n\n我们还计算了`替代等位基因`的损失以及携带替代和参考等位基因的序列之间的损失差异，作为另外两个零样本分数。在功能性变异的情况下，除了零样本分数外，我们还微调了`transformer模型`来分类阳性和阴性变异。我们采用了类似于先前描述的策略，主要区别在于训练集和测试集按染色体划分，并严格保持不重叠。\n\n具体来说，我们将22个染色体分为五组，依次使用每组作为测试集，其他四组作为训练集。通过微调训练集，我们可以得出测试集中每个序列作为阳性变异的概率。我们使用这些概率作为每个`SNP`的分数。\n\n为了将这些预测与其他方法进行比较，我们从四个数据集中的每一个随机抽样10,000个阳性和阴性`SNP`。然后我们使用组合注释依赖性消减工具（`v.GRCh38-v1.6`）来计算`CADD`、`GERP`、`phastCons`和`phyloP`分数。`DeepSEA`分数是使用 [https://hb.flatironinstitute.org/sei/](https://hb.flatironinstitute.org/sei/) 提供的`Beluga模型`计算的。考虑的分数是报告给每个`SNP`的\"疾病影响分数\"。\n\n#### 注意力图分析\n\n我们分析了从预训练模型收集的`注意力图`如何捕获关键`基因组元素`。我们遵循先前工作中提出的方法。对于基因组元素，我们定义了标记上的指示函数 $f(i)$，如果标记 $i$ 内的一个或多个核苷酸属于该元素，则等于1，否则等于0。\n\n我们计算了在一个注意力头中，在核苷酸序列数据集 $X$ 上聚合的、集中在该基因组元素上的注意力的平均比例：\n$$\np_α(f) = \\frac{1}{|X|} \\sum_{x∈X} \\frac{\\sum_i\\sum_j f(i)1(α(i,j)>μ)}{\\sum_i\\sum_j 1(α(i,j)>μ)}\n$$\n\n其中 $α(i,j)$ 是标记 $i$ 和标记 $j$ 之间的注意力系数，定义为 $\\sum_i α_{i,j}=1$，$μ$ 是置信度阈值。\n\n我们计算了所有模型的所有头和所有层的 $p_α(f)$值，并考虑了九个元素（`\"5'UTR\"、\"3'UTR\"、\"外显子\"、\"内含子\"、\"增强子\"、\"启动子\"、\"CTCF结合位点\"、\"开放染色质\"和\"转录因子结合位点\"`）。\n\n我们在一个由90,000个序列组成的数据集上执行这些分析，每个特征10,000个，长度为6 kb，从人类参考基因组中提取。每个元素所属标记的平均比例可以在补充表10中找到。对于每个序列，在数据集创建期间均匀采样特征在序列中的位置。如先前工作所建议，我们为所有实验选择了置信度阈值 $μ=0.3$。\n\n如果 $p_α(f)$ 的数量显著大于该特征在数据集中的自然出现频率（补充表10），我们认为该特征被注意力头捕获。为了验证这一点，我们进行了两个比例的`z检验`，零假设为特征的自然频率，备择假设为 $p_α(f)$。使用每个模型的总头数作为 0.05 显著性水平 $α$ 的`Bonferroni校正`。我们为每个模型中的每个头部对每个基因组元素计算`z分数`和相关的`P值`，如下所示：\n\n$$\nZ = \\frac{\\hat{p}_1-\\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1}+\\frac{1}{n_2})}}\n$$\n\n其中 $\\hat{p}_1$ 表示与每个基因组元素相关的高于 $μ$ 的注意力的比例，$\\hat{p}_2$ 表示序列中被该基因组元素占据的比例，$n_1$ 是注意力高于 $μ$ 的序列位置总数，$n_2$ 是序列位置总数。`P值`低于`Bonferroni校正显著性水平`的注意力头被认为是显著的。\n\n#### 预测`DeepSTARR`数据中重要的TF基序实例\n\n我们从`DeepSTARR`数据集中检索实验突变数据，其中单个`TF`基序实例被突变，并测量它们对发育和管家增强子活性的影响。我们评估了完全微调的`NT 2.5B Multispecies`模型（因为它是测试集性能最高的模型）通过预测野生型和相应基序突变序列的活性并计算它们的 $\\text {log}_2$ 倍数变化来预测每个`TF`基序实例贡献的性能。我们将我们预测的突变效应与原始方法`DeepSTARR`预测的效应和实验得到的 $\\text {log}_2$ 倍数变化进行了比较。\n\n### 数据可用性\nNT预训练序列来自公开可用的资源。1000G序列从[1000G项目数据库](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage)获得，人类和多物种参考基因组从[NCBI RefSeq数据库](https://ftp.ncbi.nlm.nih.gov/genomes/refseq/)获得。基因注释从[GENCODE](https://www.gencodegenes.org/)和[Ensembl数据库](https://www.ensembl.org)获得。使用[Ensembl的VEP API](https://www.ensembl.org/info/docs/tools/vep/index.html)获得变异效应预测。致病性和调控变异从[ClinVar](https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/)、[GRASP](https://grasp.nhlbi.nih.gov)和`HGMD`（公共v.2020.4）通过`Ensembl Biomart`提取。NT下游任务是从以下公开可用资源中整理的：[ENCODE](https://www.encodeproject.org/)、[SCREEN](https://screen.wenglab.org/)和[DHSIndex](https://www.meuleman.org/research/dhsindex/)、[真核生物启动子数据库](https://epd.expasy.org/epd/)和[GENCODE](https://www.gencodegenes.org/)（补充表5）。我们在`HuggingFace`上提供了我们的多物种和人类预训练数据集版本（[NT models集合](https://huggingface.co/collections/InstaDeepAI/nucleotide-transformer-65099cdde13ff96230f2e592)）以及我们的下游任务基准测试（[NT下游任务集](https://huggingface.co/datasets/InstaDeepAI/nucleotide_transformer_downstream_tasks_revised)）。我们建立了一个[交互式排行榜](https://huggingface.co/spaces/InstaDeepAI/nucleotide_transformer_benchmark)，其中包含所有模型在每个任务上的结果，以便于比较。我们还在`WashU`表观基因组浏览器上创建了一个[交互式浏览器会话](https://shorturl.at/jov28)，显示整个22号染色体上预训练模型的标记概率。\n\n### 代码可用性\n预训练transformer模型的代码和权重以及`Jax`中的推理代码可在[NT GitHub仓库](https://github.com/instadeepai/nucleotide-transformer)获得用于研究目的。`PyTorch`中模型的`HuggingFace`版本可在[NT HuggingFace集合](https://huggingface.co/collections/InstaDeepAI/nucleotide-transformer-65099cdde13ff96230f2e592)找到。示例笔记本可在`HuggingFace`的[PyTorch生物示例页面](https://huggingface.co/docs/transformers/notebooks#pytorch-bio)获得。\n\n# 补充信息\n\n补充说明，补充表1-12和补充图1-20。请在[这里](https://static-content.springer.com/esm/art%3A10.1038%2Fs41592-024-02523-z/MediaObjects/41592_2024_2523_MOESM1_ESM.pdf)下载。\n\n# 参考文献\n\n1. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. Bert: pre-training of deep bidirectional transformers for language understanding. Preprint at [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805) (2018).\n\n2. Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. (2020).\n\n3. Jumper, J. et al. Highly accurate protein structure prediction with alphafold. Nature 596, 583-589 (2021).\n\n4. Rives, A. et al. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proc. Natl Acad. Sci. USA 118, e2016239118 (2021).\n\n5. Elnaggar, A. et al. ProtTrans: towards cracking the language of life's code through self-supervised deep learning and high performance computing. IEEE Trans. Pattern Anal. Mach. Intell. 44, 7112-7127 (2022).\n\n6. Littmann, M., Heinzinger, M., Dallago, C., Olenyi, T. & Rost, B. Embeddings from deep learning transfer go annotations beyond homology. Sci. Rep. 11, 1-14 (2021).\n\n\n7. Marquet, C. et al. Embeddings from protein language models predict conservation and variant effects. Hum. Genet. 141, 1629-1647 (2022).\n\n8. Littmann, M., Heinzinger, M., Dallago, C., Weissenow, K. & Rost, B. Protein embeddings and deep learning predict binding residues for various ligand classes. Sci. Rep. 11, 23916 (2021).\n\n9. Avsec, Ž. et al. Base-resolution models of transcription-factor binding reveal soft motif syntax. Nat. Genet. 53, 354-366 (2021).\n\n10. Zhou, J. & Troyanskaya, O. G. Predicting effects of noncoding variants with deep learning-based sequence model. Nat. Methods 12, 931-934 (2015).\n\n11. Mateo, L. J., Sinnott-Armstrong, N. & Boettiger, A. N. Tracing dna paths and rna profiles in cultured cells and tissues with orca. Nat. Protoc. 16, 1647-1713 (2021).\n\n12. de Almeida, B. P., Reiter, F., Pagani, M. & Stark, A. DeepSTARR predicts enhancer activity from dna sequence and enables the de novo design of synthetic enhancers. Nat. Genet. 54, 613-624 (2022).\n\n13. Eraslan, G., Avsec, Ž., Gagneur, J. & Theis, F. J. Deep learning: new computational modelling techniques for genomics. Nat. Rev. Genet. 20, 389-403 (2019).\n\n14. Zhou, J. et al. Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk. Nat. Genet. 50, 1171-1179 (2018).\n\n15. Kelley, D. R. Cross-species regulatory sequence activity prediction. PLOS Comput. Biol. 16, e1008050 (2020).\n\n\n16. Kelley, D. R. et al. Sequential regulatory activity prediction across chromosomes with convolutional neural networks. Genome Res. 28, 739-750 (2018).\n\n17. Agarwal, V. & Shendure, J. Predicting mRNA abundance directly from genomic sequence using deep convolutional neural networks. Cell Rep. 31, 107663 (2020).\n\n18. Chen, K. M., Wong, A. K., Troyanskaya, O. G. & Zhou, J. A sequence-based global map of regulatory activity for deciphering human genetics. Nat. Genet. 54, 940-949 (2022).\n\n19. Avsec, Ž. et al. Effective gene expression prediction from sequence by integrating long-range interactions. Nat. Methods 18, 1196-1203 (2021).\n\n20. Ji, Y., Zhou, Z., Liu, H. & Davuluri, R. V. Dnabert: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome. Bioinformatics 37, 2112-2120 (2021).\n\n21. Zvyagin, M. T. et al. Genslms: genome-scale language models reveal SARS-CoV-2 evolutionary dynamics. Preprint at bioRXiv [https://doi.org/10.1101/2022.10.10.511571](https://doi.org/10.1101/2022.10.10.511571) (2022).\n\n22. Oute, J. C. & Deane, C. M. Protein language embeddings provide strong signals for protein engineering. Nat. Mach. Intell. 6, 170-179 (2024).\n\n23. Zhou, Z. et al. Dnabert-2: efficient foundation model and benchmark for multi-species genome. in Proceedings of the Twelfth International Conference on Learning Representations [https://openreview.net/pdf?id=oMLQB4EZE1](https://openreview.net/pdf?id=oMLQB4EZE1) (ICLR, 2024).\n\n24. Fishman, V. et al. Gena-lm: A family of open-source foundational models for long dna sequences. Preprint at bioRXiv [https://doi.org/10.1101/2023.06.12.544594](https://doi.org/10.1101/2023.06.12.544594) (2023).\n\n25. Nguyen, E. et al. Hyenadna: Long-range genomic sequence modeling at single nucleotide resolution. in 37th Conference on Neural Information Processing Systems [https://openreview.net/pdf?id=ubzNoJjOKj](https://openreview.net/pdf?id=ubzNoJjOKj) (NeurIPS, 2023).\n\n\n26. Mendoza-Revilla, J. et al. A foundational large language model for edible plant genomes. Commun. Biol. 7, 835 (2024).\n\n27. Rae, J. W. et al. Scaling language models: methods, analysis & insights from training gopher. Preprint at [https://arxiv.org/abs/2112.11446](https://arxiv.org/abs/2112.11446) (2021).\n\n28. Consortium, G. P. et al. A global reference for human genetic variation. Nature 526, 68 (2015).\n\n\n29. Harrow, J. et al. GENCODE: the reference human genome annotation for the encode project. Genome Res. 22, 1760-1774 (2012).\n\n30. Meylan, P., Dreos, R., Ambrosini, G., Groux, R. & Bucher, P. Epd in 2020: enhanced data visualization and extension to ncRNA promoters. Nucleic Acids Res. 48, D65-D69 (2020).\n\n31. ENCODE. An integrated encyclopedia of dna elements in the human genome. Nature 489, 57-74 (2012).\n\n32. The ENCODE Project Consortium. Expanded encyclopaedias of dna elements in the human and mouse genomes. Nature 583, 699-710 (2020).\n\n33. Meuleman, W. et al. Index and biological spectrum of human DNase I hypersensitive sites. Nature 584, 244-251 (2020).\n\n34. Li, F.-Z., Amini, A. P., Yang, K. K. & Lu, A. X. Pretrained protein language model transfer learning: is the final layer representation what we want? in Machine Learning for Structural Biology Workshop (NeurIPS, 2022).\n\n35. Liu, H. et al. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. in 36th Conference on Neural Information Processing Systems (NeurIPS, 2022).\n\n36. Jaganathan, K. et al. Predicting splicing from primary sequence with deep learning. Cell 176, 535-548 (2019).\n\n37. Benegas, G., Batra, S. S. & Song, Y. S. DNA language models are powerful zero-shot predictors of non-coding variant effects. Proc. Natl Acad. Sci. USA 120, e2311219120 (2023).\n\n38. Vig, J. et al. BERTology meets biology: Interpreting attention in protein language models. in Proceedings of the International Conference on Learning Representations 2021 [https://openreview.net/pdf?id=YWtLZvLmud7](https://openreview.net/pdf?id=YWtLZvLmud7) (ICLR, 2021).\n\n39. Braun, S. et al. Decoding a cancer-relevant splicing decision in the ron proto-oncogene using high-throughput mutagenesis. Nat. Commun. 9, 3315 (2018).\n\n\n40. McLaren, W. et al. The Ensembl variant effect predictor. Genome Biol. 17, 1-14 (2016).\n\n41. Lappalainen, T. et al. Transcriptome and genome sequencing uncovers functional variation in humans. Nature 501, 506-511 (2013).\n\n42. Consortium, G. The gtex consortium atlas of genetic regulatory effects across human tissues. Science 369, 1318-1330 (2020).\n\n\n43. Võsa, U. et al. Large-scale cis-and trans-eqtl analyses identify thousands of genetic loci and polygenic scores that regulate blood gene expression. Nat. Genetics 53, 1300-1310 (2021).\n\n44. Chowdhery, A. et al. PaLM: scaling language modeling with pathways. J. Mach. Learn. Technol. 24, 11324-11436 (2021).\n\n45. Hoffmann, J. et al. Training compute-optimal large language models. in 36th Conference on Neural Information Processing Systems [https://proceedings.neurips.cc/paper_files/paper/2022/file/c1e2faff6f58887093f114ebe04a3e5-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/c1e2faff6f58887093f114ebe04a3e5-Paper-Conference.pdf) (NeurIPS, 2022).\n\n46. Rogers, A., Kovaleva, O. & Rumshisky, A. A primer in BERTology: what we know about how bert works. Trans. Assoc. Comput. Linguist. 8, 842-866 (2020).\n\n47. Stärk, H., Dallago, C., Heinzinger, M. & Rost, B. Light attention predicts protein location from the language of life. Bioinform. Adv. 1, vbab035 (2021).\n\n48. Zou, J. et al. A primer on deep learning in genomics. Nat. Genetics 51, 12-18 (2019).\n\n\n49. Wang, A. et al. Superglue: a stickier benchmark for general-purpose language understanding systems. in 33rd Conference on Neural Information Processing Systems [https://papers.nips.cc/paper_files/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf](https://papers.nips.cc/paper_files/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf) (NeurIPS, 2019).\n\n50. Hendrycks, D. & Gimpel, K. Gaussian error linear units (gelus). Preprint at [https://arxiv.org/abs/1606.08415](https://arxiv.org/abs/1606.08415) (2016).\n\n51. Su, J. et al. Roformer: enhanced transformer with rotary position embedding. Neurocomputing 568, 127063 (2024).\n\n52. Kingma, D. P. & Ba, J. Adam: a method for stochastic optimization. Preprint at [https://arxiv.org/abs/1412.6980v5](https://arxiv.org/abs/1412.6980v5) (2015).\n\n53. Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830 (2011).\n\n54. Bergstra, J., Bardenet, R., Bengio, Y. & Kégl, B. Algorithms for hyper-parameter optimization. in Advances in Neural Information Processing Systems 24 [https://papers.nips.cc/paper_files/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf](https://papers.nips.cc/paper_files/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf) (NeurIPS, 2011).\n\n\n55. Byrska-Bishop, M. et al. High-coverage whole-genome sequencing of the expanded 1000 genomes project cohort including 602 trios. Cell 185, 3426-3440 (2022).\n\n56. Kim, D., Paggi, J. M., Park, C., Bennett, C. & Salzberg, S. L. Graph-based genome alignment and genotyping with hisat2 and hisat-genotype. Nat. Biotechnol. 37, 907-905 (2019).\n\n57. Leslie, R., O'Donnell, C. J. & Johnson, A. D. GRASP: analysis of genotype-phenotype results from 1390 genome-wide association studies and corresponding open access database. Bioinformatics 30, i185-i194 (2014).\n\n58. Landrum, M. J. et al. Clinvar: improving access to variant interpretations and supporting evidence. Nucleic Acids Res. 46, D1062-D1067 (2018).\n\n59. Stenson, P. D. et al. The Human Gene Mutation Database (HGMD®): optimizing its use in a clinical diagnostic or research setting. Hum. Genet. 139, 1197-1207 (2020).\n","categories":["论文解读"]},{"title":"微信自动化工具v1.0，它来啦！","url":"/2024/11/16/rcvb4vct/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 微信自动化工具v1.0，它来啦！ https://mp.weixin.qq.com/s/LDPPkLHedotqSYscLE_E7A  /images/wechat.jpg %}","categories":["Java"]},{"title":"生信笔记---医学遗传学详述","url":"/2024/11/15/gom7w8w1/","content":"\n# 参考书籍\n\n> 《医学遗传学》第7版，左伋等主编。北京人民卫生出版社出版，2018，全国高等学校五年制本科临床医学专业第九轮规划教材，ISBN 978-7-117-26440-2。\n\n# 基于疾病的遗传学数据分析\n\n## 遗传数据库\n\n遗传数据库（genetic database）是储存在计算机内的、有组织的、可共享的`遗传数据`（genetic data）的集合。\n\n国际上最权威、最主要的三大`核酸序列数据库`，包括\n\n- 美国国家生物技术信息中心（National Center for Biotechnology Information，`NCBI`）维护的`GenBank`；\n- 欧洲分子生物学研究室（European Molecular Biology Laboratory，`EMBL`）下属的欧洲生物信息学研究所（European Bioinformatics Institute，`EBI`）维护的`EMBL-EBI`；\n- 日本国立遗传学研究所维护的`DDBJ`（DNA Data Bank of Japan）\n\n是目前最具有影响力的生命科学数据库。\n\n## 常用的人类基因组与遗传数据库\n\n| 序号 | 数据库(或网站)                                               | 网址                                                         |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 1    | OMIM：权威的遗传病分子医学百科全书和数据库                   | www.omim.org                                                 |\n| 2    | GeneTests：权威、常用的遗传病基因检测和基因诊断数据库        | www.genetests.org                                            |\n| 3    | HGMD：权威、完整的人类遗传病或与人类遗传病相关的核基因突变数据库 | www.hgmd.cf.ac.uk                                            |\n| 4    | GeneCards：信息量非常完整的人类基因综合数据库                | www.genecards.org                                            |\n| 5    | Ensembl：有关人类基因组和其他物种基因组的全面资源的综合性基因组数据库。由欧洲生物信息学会和Wellcome 基金会Sanger研究所共同维护 | www.ensembl.org                                              |\n| 6    | HGP相关资料数据库                                            | www.genome.gov/10001772 <br> http://genome.ucsc.edu/cgi-bin/hgGateway <br> www.ensembl.org/Homo_sapiens/Info/Index |\n| 7    | dbSNP和dbVar：NCBI旗下的SNP数据库和结构变异数据库，收录包括单核苷酸变异、微卫星DNA、indel和CNV等各种变异体 | www.ncbi.nlm.nih.gov/snp/ <br> www.ncbi.nlm.nih.gov/dbvar/   |\n| 8    | ClinVar：NCBI创建于2013年的与疾病相关的遗传变异数据库。内含超过十几万份独特突变的临床注释 | www.ncbi.nlm.nih.gov/clinvar                                 |\n| 9    | G1K计划(国际千人基因组计划)：对所有公众开放的包含几千个个体的基因组数据的数据库 | www.internationalgenome.org                                  |\n| 10   | Database of Genomic Variants(基因组变异体数据库)：收录人基因组的结构变异体。截至2012年的统计，总条目超过400 000个，其中CNV超过200 000种，倒位超过1000种，indel超过34 000种 | http://dgv.tcag.ca                                           |\n| 11   | JSNP：日本SNP数据库。由日本东京大学维护                      | http://snp.ims.u-tokyo.ac.jp/                                |\n| 12   | UCSC基因组生物信息学数据库：美国加州大学Santa Cruz分校创建和维护的权威的基因组浏览数据库 | http://genome.ucsc.edu/                                      |\n| 13   | HUGO(Human Genome Organization,人类基因组协会)               | www.hugo-international.org                                   |\n| 14   | HapMap计划：提供数百万个SNP，标志着人类基因组的研究\"从一个个体的基因组参考序列到人类基因组的多样性\"的重要里程碑 | www.hapmap.org <br> ftp://ftp.ncbi.nlm.nih.gov/hapmap/       |\n| 15   | G10K计划(英国万人基因组计划)                                 | www.genomicsengland.co.uk/the-100000-genomes-project/        |\n| 16   | ExAC：已收录超过6万例个体外显子组测序结果的数据库。利用ExAC数据库可以避免遗传性误诊 | http://exac.broadinstitute.org/                              |\n| 17   | EVS：已收录超过5000例个体的外显子组测序结果的数据库，旨在揭示心脏病、呼吸系统疾病、血液病的分子病因，从而进行精准诊治 | http://evs.gs.washington.edu/EVS/                            |\n| 18   | BROAD研究所：提供人类基因定位、测序、各种分析软件的信息      | www.broad.mit.edu                                            |\n| 19   | 预测基因变异体是否具有临床致病性的软件 <br> VEP <br> SIFT <br> POLYPHEN2 <br> ALIGNGVGD | www.ensembl.org/info/docs/tools/vep/ <br> http://sift.jcvi.org/ <br> http://genetics.bwh.harvard.edu/pph2/ <br> http://agvgd.hci.utah.edu/agvgd_input.php |\n| 20   | Decipher：\"Database of Chromosomal Imbalance and Phenotype in Humans using Ensembl Resources\"的缩写，收录了超过200家研究中心上传的10 000多例案例的信息，主要用于筛查比对CNV | http://decipher.sanger.ac.uk/                                |\n| 21   | MitoMap：最权威的人类线粒体参考基因序列库、相关基因突变与疾病数据库 | www.mitomap.org                                              |\n| 22   | London Medical Database Online(在线伦敦医疗数据库)：与Face2Gene公司合办，包含Winter-Baraitser畸形学数据库、Baraitser-Winter神经遗传学数据库和伦敦眼科遗传学数据库 | www.fdna.com/london-medical-databases-online                 |\n| 23   | GTR(Genetic Testing Registry)：NCBI收录有关遗传病基因检测信息数据库 | www.ncbi.nlm.nih.gov/gtr                                     |\n| 24   | GHR(Genetics Home Reference)：NIH旗下的美国国立医学图书馆(National Library of Medicine,NLM)创建和维护的医学遗传学网站 | http://ghr.nlm.nih.gov/                                      |\n| 25   | PharmGKB：药物遗传学和药物基因组学的权威数据库               | www.pharmgkb.org                                             |\n| 26   | ClinicalTrials.gov：NIH旗下的NLM维护的关于疾病的临床试验信息的数据库。截至2017年9月25日，收录了美国50个州和全球200个国家的255 652个临床试验研究资料 | http://clinicaltrials.gov/                                   |\n| 27   | The Journal of Gene Medicine Clinical Trial：收录了全球关于基因治疗的临床试验研究信息 | www.wiley.com/legacy/wileychi/genmed/clinical/               |\n| 28   | ELSI：人类基因组学的伦理、法律、社会问题/影响                | www.nhgri.nih.gov/PolicyEthics/                              |\n| 29   | Orphanet：提供罕见病和罕见病药物信息的开放门户网站，目的在于提高罕见病的诊断、护理和治疗效果 | www.orpha.net                                                |\n| 30   | Genetic Alliance UK：英国一家为罕患各种遗传病的患者及其亲属提供相关帮助的公益机构 | www.geneticalliance.org.uk                                   |\n| 31   | NORD：即\"National Organization for Rare Disorders\"的缩写，美国全国罕见病组织联合体。数据库中收录了1200多种遗传病 | http://rarediseases.org/                                     |\n\n注：`HCP = human genome project(人类基因组计划)`；`CNV = copy number variant(拷贝数变异体)`；`SNP = single nucleotide polymorphism(单核苷酸多态性)`\n\n## 常用遗传数据库介绍\n\n### OMIM\n\n`OMIM`包括所有已知的遗传病、遗传决定的性状及其基因，除了简略描述各种疾病的临床特征、诊断、鉴别诊断、治疗与预防外，还提供已知有关致病基因的连锁关系、染色体定位、基因的组成结构和功能、表型-基因型相关性、表型的系列信息、国际疾病分类号、动物模型等资料，并附有经过缜密筛选的相关参考文献。\n\nOMIM 制定的各种遗传病、性状、基因的编号，简称 OMIM 编号，其 6 位数字，为全世界所公认。有关疾病的报道必须冠以 OMIM 编号，以明确所讨论的是哪一种遗传病。因此，OMIM 是研究疾病与基因相关性的重要依据，为每一位医务工作者所必须掌握的核心资源。\n\n例如，呈常染色体显性遗传的表皮松解性掌跖角化症，其 OMIM 编号为\"`144200`\"。\n\nOMIM 编号中的有关含义如下：\n\n- 编号前有\"`*`\"：表示该条目（entry）是一个基因。\n\n- 编号前有\"`#`\"：表示该条目是一个描述性的条目，通常为一种表型（疾病或性状），而非一个特定的基因座。\n\n- 编号前有\"`+`\"：表示该条目包含了已知 DNA 序列的基因以及表型的相关描述。\n\n- 编号前有\"`%`\"：表示该条目描述了一种已经明确了的孟德尔表型或一个未知分子基础的表型基因座。\n\n- 编号前无任何符号：表示该条目尽管被怀疑为孟德尔性状，但是否为孟德尔遗传方式的表型信息尚未明确，或尚不能将该条目列为一个单独的条目。\n\n- 编号前有\"`^`\"：表示该条目现已不存在，或已从 OMIM 数据库中移除，或已被合并至其他条目中。\n\n- 编号为\"`100000～199999，200000～299999`\"的条目：表示为常染色体基因座或表型（创建于 1994年 5 月 15 日之前的相关条目）。\n\n- 编号为\"`300000～399999`\"的条目：表示为 X 染色体连锁基因座或表型。\n\n- 编号为\"`400000～499999`\"的条目：表示为 Y 染色体连锁基因座或表型。\n\n- 编号为\"`500000～599999`\"的条目：表示为线粒体遗传基因座或表型。\n\n- 编号为\"`600000～699999`\"的条目：表示为常染色体基因座或表型（创建于 1994 年 5 月 15 日之后的相关条目）。\n\n\n### GeneTests\n\n`GeneTests`（[www.genetests.org](www.genetests.org)）是最权威、最常用的有关遗传病基因检测和基因诊断的数据库。\n\nGeneTests 囊括了全球经标准化资质审核之后准许进行基因检测和基因诊断的所有遗传病、基因、医院、独立医学检验所、高校实验室、基因诊断公司等信息。\n\nGeneTests 数据库另一大亮点是其\"`GeneReviews`（基因综述）\"栏目。GeneReviews 是由一位或几位相关遗传病领域的专家撰写，并经同行审校的综述性论文，提供所描述的遗传病的概况、致病基因信息、突变检测手段、疾病的诊治方法和遗传咨询等应用的最新且权威的信息。\n\nGeneReviews 目前包含 694 篇综述，约 95% 的综述瞄准单基因病或基因，另有约 5% 的综述探讨的是耳聋、`Alzheimer病`等常见病。GeneReviews 每月增加数种，每篇综述 1～2 年内更新一次，并根据当今的遗传病研究进展随时进行修订。\n\n在 NCBI 网站上，GeneReviews 有专门的免费链接地址：\n\n[www.ncbi.nlm.nih.gov/books/NBK1116/](www.ncbi.nlm.nih.gov/books/NBK1116/)\n\n### HGMD\n\n`HGMD`（`Human Gene Mutation Database`）（[www.hgmd.cf.ac.uk](www.hgmd.cf.ac.uk)）即\"人类基因突变数据库\"，是由英国威尔士 Cardiff 大学医学遗传学研究所创建和维护的著名通用型数据库，全面收录了导致人类遗传病或与人类遗传病相关的核基因突变。\n\nHGMD 建立的初衷是用于基因突变机制的分析，但由于其收录最新的、完整的有关人类疾病基因突变谱的参考数据，包括单碱基置换（如基因编码序列中的错义突变、无义突变以及 DNA 调控和剪接区域中的点突变）、`微小缺失（micro-deletion）`、`微小插入（micro-insertion）`、`插缺（indel）`、重复序列扩增、大的基因损伤（大片段缺失、大片段插入和基因扩增）、复杂性基因重组等，因而具有很高的权威性声誉，一直为学者们广泛应用。\n\nHGMD 分为`免费公共版`和`专业版`两种。\n\n`免费公共版`提供给注册学术用户和非盈利用户的只是那些已收录了 3 年以上的数据，而更完整的、每 3 个月更新一次的专业版数据需要通过付费形式，从 HGMD 的商业合作伙伴 BIOBASE GmbH公司那里获得。\n\n显然，HGMD 专业版集实时更新、结果下载、高级检索等多项功能于一体：\n\n- 包含超过 179 000 份基因突变报告，涵盖突变所在的基因组位置、序列的详细信息，并可链接到参考文献及其他公共平台，如 `dbSNP`、`OMIM` 等；\n- 包含超过 6800 份总结报告，对给定基因的 6 种不同的致病变异进行描述，并罗列所有已知的遗传病的突变；\n- 高级搜索功能：可基于核酸/氨基酸的改变，或在特异序列、剪接位点、调控区域中的位置进行精确的突变检索；\n- 可视化的突变展示工具：为所比对的 DNA 序列或蛋白质序列提供图表描述，以不同的颜色区分突变核酸位点；\n- 可在第三方基因组分析工具中导出自定义的突变文件。\n\n因此，专业版可为从事基因组学、蛋白质组学、生物序列、人类疾病、基因突变等生物信息学研究的科研人员和医务工作者提供更便捷、全面的数据支持服务。\n\n# 基因突变\n\n## 基因突变的本质及其特性\n\n发生在体细胞中的基因突变，即`体细胞突变`，虽然不会传递给后代个体，但是却能够通过突变细胞的分裂增殖而在后代子细胞中进行传递，形成突变的`细胞克隆`，成为具有`体细胞遗传学特征`的`肿瘤病变`甚或`癌变`的细胞组织病理学基础。\n\n`基因是具有特定遗传效应的DNA序列片段`。 因此,无论是发生在生殖细胞中的基因突变，还是发生于体细胞中的基因突变，究其本质，实际上就是构成基因的DNA`碱基组成与序列结构`所发生的可遗传的变异，所以也具有一定的共同特性。\n\n### 多向性\n\n任何基因座上的基因，都有可能独立地发生多次不同的突变而形成其新的等位基因，这就是基因突变的多向性。\n\n### 重复性\n\n重复性是指已经发生突变的基因，在一定的条件下，还可能再次独立地发生突变而形成其另外一种新的等位基因形式。 \n\n亦即，对于任何一个基因来说，其突变并非仅囿于某一次或某几次的发生，而是会以一定的频率反复发生。 \n\n### 随机性\n\n基因突变不仅是生物界普遍存在的一种遗传事件，而且，对于任何一种生物，任何一个个体，任何一个细胞乃至任何一个基因来说，突变的发生也都是随机的。 只是不同的物种、不同的个体、不同的细胞或者基因，其各自发生基因突变的频率可能并不完全相同而已。 \n\n### 可逆性\n\n基因的突变是可逆的。 任何一种野生型基因都能够通过突变而形成其等位的突变型基因；反过来，突变型基因，也可以突变为其相应的野生型基因。 前者为正向突变，后者为回复突变。一般情况下，正向突变率总是远远高于回复突变率。\n### 有害性\n生物遗传性状的形成，是在长期的进化过程中与其赖以生存的自然环境相互作用、相互适应的结果，是自然选择的产物。而对这些性状具有决定性意义的基因一旦发生突变，通常都会对生物的生存带来`消极`或`不利`的影响，即`有害性`。 \n\n`生殖细胞`或`受精卵`中基因的突变是绝大多数人类遗传病发生的根本原因；`体细胞突变`则常常是`肿瘤`发生的病理遗传学基础。 然而，基因突变的有害性往往只是相对的，有条件的，也并非所有的基因突变都会对生物的生存及其种群繁衍带来不利或者有害的影响。 \n\n事实上，有些突变，往往只引起`非功能性DNA序列`组成的改变，却并不造成核酸和蛋白质正常功能的损害。\n\n## 基因突变的形式\n\n一般可归纳为`静态突变`和`动态突变`两种主要形式。\n\n### 静态突变\n\n`静态突变（static mutation）`是生物各世代中基因突变总是以一定的频率发生，并且能够使之随着世代的繁衍、交替而得以相对稳定地传递。\n\n#### 点突变\n\n`点突变（point mutation）`是 DNA 多核苷酸链中单个碱基或碱基对的改变。\n\n##### 碱基替换\n\n `碱基替换（base substitution）`是 DNA 分子多核苷酸链中原有的某一特定碱基或碱基对被其他碱基或碱基对置换、替代的突变形式。其具体表现为同类碱基或碱基对之间的替换及不同类碱基或碱基对之间的相互替换。同类碱基之间的替换，又被称之为`转换（transition）`，即一种嘌呤碱或相应的嘧啶-嘧啶碱基对被另外一种嘌呤碱或相应的嘌呤-嘧啶碱基对所取代；如果某种嘌呤碱或其相应的嘧啶-嘧啶碱基对被另外一种嘧啶碱或其相应的嘧啶-嘌呤碱基对所置换，则称之为`颠换（transvertion）`（图 2-6）。\n\n![image-20250116204659742](/images/assets//image-20250116204659742.png)\n\n碱基替换只是原有碱基性质的改变，而并不涉及碱基数目的变化与异常。这种突变会因其作用对象的不同而产生不同的遗传学效应。如果被替换的是构成特定三联密码子单位的碱基或碱基对，则会造成：\n\n- `同义突变`：由于存在遗传密码子的兼并现象，因此，替换的发生，尽管改变了原有三联遗传密码子的碱基组成，但是新、旧密码子所编码的氨基酸种类却依然保持不变。亦即新、旧密码子具有完全相同的编码意义（图 2-7），此为`同义突变（same sense mutation）`。同义突变并不产生相应的遗传表型突变效应。\n\n![image-20250116204721421](/images/assets//image-20250116204721421.png)\n\n- `无义突变`：由于碱基替换而使得编码某一种氨基酸的三联体遗传密码子，变成为不编码任何氨基酸的终止密码 UAA、UAG 或 UGA 的突变形式被称之为`无义突变（non-sense mutation）`。此种突变，会引起翻译时多肽链合成延伸的提前终止（图 2-8A），造成多肽链的组成结构残缺及蛋白质功能的异常或丧失，最终会体现为导致遗传表型改变的致病效应。\n\n![image-20250116204738000](/images/assets//image-20250116204738000.png)\n\n- `终止密码突变`：如果因为碱基替换的发生，而使得 DNA 分子中某一终止密码变成了具有氨基酸编码功能的遗传密码子，此种突变形式即为`终止密码突变（terminator codon mutation）`（图 2-8B）。与无义突变相反，终止密码突变造成的将会使本应终止延伸的多肽链合成，非正常地持续进行。其结果也必然形成功能异常的蛋白质结构分子。\n- `错义突变`：这是编码某种氨基酸的密码子经碱基替换后变成了另外一种氨基酸的密码子，从而在翻译时改变了多肽链中氨基酸的组成种类（图 2-9）。`错义突变（missense mutation）`的结果，必然地导致蛋白质多肽链原有功能的异常或丧失。人类的许多分子病和代谢病，就是因此而造成的。\n\n![image-20250116204759652](/images/assets//image-20250116204759652.png)\n\n此外，碱基替换如果发生在 DNA 分子的非密码子组成结构区域，引起的将可能是`调控序列或内含子与外显子剪接位点的突变`（图 2-10）。`调控序列突变`所产生的遗传学效应，通常可直接体现为蛋白质合成速率的降低或异常增高，进而影响细胞正常的代谢节律，以致引起疾病的发生。而`内含子与外显子剪接位点突变`，则往往会造成 RNA 编辑错误，以致不能形成正确的 mRNA 分子，这也势必会导致功能蛋白的合成障碍。\n\n![image-20250116204824166](/images/assets//image-20250116204824166.png)\n\n##### 移码突变\n\n`移码突变（frame-shift mutation）`是一种由于基因组DNA多核苷酸链中碱基对的插入或缺失，以致自插入或缺失点之后部分的、或所有的三联体遗传密码子组合发生改变的基因突变形式。移码突变直接的分子遗传学效应就是导致其所编码的蛋白质多肽链中的氨基酸组成种类和顺序的变化。\n\n碱基对插入或缺失的数目、位点不同，对其后密码子组合改变的影响也不尽相同（表2-1）。\n\n![image-20250116204945185](/images/assets//image-20250116204945185.png)\n\n- 一个或两个碱基对的插入或缺失。这将造成插入或缺失位点之后整个密码子碱基组合及其排列顺序的改变；\n- 整码突变或框内突变，即如果插入或缺失的碱基对是3或3的倍数，且插入或缺失位点亦恰好在两个相邻的遗传密码子之间，由此所引起的变化是在DNA双链的多核苷酸组成上额外地增加或减少1个或数个三联遗传密码子，但却并不造成`读码框（reading frame）`的改变；如果插入或缺失的3碱基对是在同1个三联密码子之内，那就只是造成该插入或缺失位点前、后各1个遗传密码的改变，而并不会改变其他密码子的碱基组成和编码顺序。\n- 当在某一位点插入或缺失1～2个碱基对之同时，又在该突变位点之后的某一位点相应地缺失或插入了同样数目的碱基对，那么，除引起前、后两个位点之间的密码组合改变外，其后其他的密码子组合仍可保持正常。\n\n\n移码突变不仅涉及DNA分子中碱基组成数目的改变，而且还伴随着特定的遗传密码组成性质与排列顺序的改变。因此，所引发的遗传学效应往往是比较严重的。它会导致一条或多条多肽链的合成障碍或功能缺陷，甚至完全丧失，进而危及到机体细胞正常的生命活动。\n\n#### 小片段的缺失、 插入与重排\n\nDNA分子中还可能发生小片段（涉及十几、数十或数百个碱基片段序列）的微小缺失、微小插入或重排。\n\n- `微小缺失`。微小缺失（micro-deletion）是由于在DNA复制或损伤的修复过程中，某一小片段没有被正常复制或未能得到修复所致。\n- `微小插入`。 在DNA的复制过程或损伤过程中，某一小片段插入到DNA链中，其结果造成新链中相应小片段的微小插入（micro-insertion）。\n\n- `重排` 。重排（rearrangement）发生的分子机制是当DNA分子发生两处以上的断裂后，所形成的断裂小片段两端颠倒重接，或者不同的断裂片段改变原来的结构顺序重新连接，从而形成了重排的片段突变形式。\n\n### 动态突变\n\n科学家们曾一度认为单基因遗传病主要是由遗传物质在分子水平上发生的点突变所引起，而且，这些突变一般都会在世代传递中保持相对的稳定状态，即上述的静态突变。\n\n直至20世纪80～90年代，随着对人类基因组DNA序列组成及结构特征分析研究的不断深入，才发现`某些单基因遗传性状的异常改变或疾病的发生，是由于DNA分子中某些短串联重复序列，尤其是基因编码序列或侧翼序列的三核苷酸串联重复扩增所引起`。\n\n因为这种串联三核苷酸的重复次数可随着世代交替的传递而呈现逐代递增的累加突变效应，故而被称之为`动态突变（dynamic mutation）`。把由动态突变所引起的疾病，统称为`三核苷酸重复扩增病（trinucleotide repeat expansion diseases，TREDs）`。\n\n# 遗传多态性\n\n## 遗传多态性的概念\n\n在同一种群中的某种遗传性状同时存在两种以上不连续的变异型，或同一基因座上两个以上等位基因共存的遗传现象。\n\n作为单一基因座等位基因`DNA多样性变异`在群体水平的体现，凡是在群体中出现频率大于1%的变异体，无论致病与否，均被称之为遗传多态型；而所有那些出现频率小于1%的变异体，则被称之为`稀有变异型`（rare variants）。\n\n遗传多态性现象十分普遍。多态性的形成，缘于基因的异变。发生于基因组`DNA非编码序列`（间隔序列或内含子序列）的变异，一般不会影响基因的结构与功能，也不会产生遗传的表型效应。只有那些位于编码序列和调控序列内的DNA变异，方可产生各种蛋白变异体，或者通过影响RNA的转录，从而导致各种明显的表型差异。对于一个体而言，基因多态性碱基组成序列终生不变，并按孟德尔规律世代相传。\n\n## 遗传多态性的表现形式\n\n遗传多态性不仅表现为个体水平上的表型遗传性状差异，亦可呈现为细胞水平上染色体遗传的多态性；分子水平上基因组DNA遗传的多态性和蛋白质与酶的多态性以及抗原的多态性等。\n\n### 个体水平上的表型性状遗传多态性\n表型性状遗传多态性是种群中不同个体之间同一遗传性状的表型差异，如人类头发、眼睛的颜色。表型遗传差异的多态性，决定于一组相应的复等位基因的作用。\n\n### 细胞水平上的染色体遗传多态性\n染色体多态性是在种群中经常可见的各种染色体形态的变异。其主要表现为同源染色体大小、形态或染色体带型的改变。此类改变，通常仅涉及染色体的结构异染色质区域，因此，并不表现出显著相关的表型效应。\n\n### 分子水平上的DNA遗传多态性\n\n人类基因组DNA呈现出多种多样的分子结构和组成形式。依据发现的时序和不同遗传多态性的分子遗传学特征，被分为\n\n- `限制性片段长度多态性`（restriction fragment length polymorphism，RFLP）；\n- `数目可变的串联重复`（variable number tandem repeat，VNTR）多态性；\n- `短串联重复序列`（short tandem repeat，STR）多态性；\n- `单核苷酸多态性`（single nucleotide polymorphism，SNP）。\n\n等多种类型。当前，被作为遗传标记而在人类遗传学和医学遗传学相关研究领域中得以广泛应用的主要有两大类。\n\n#### 单核苷酸多态性（SNP）\n\n由基因组DNA序列中单个碱基的转换或颠换所形成的变异；是最简单、最常见、分布最为广泛，也是多态性最为丰富的遗传多态类型之一。研究表明，人类基因组DNA平均约1000bp内就有一个SNP，占已知的人类基因组DNA多态性变异之90%以上。\n\n基因组DNA中任何碱基都有发生变异的可能。因此，SNP既可存在于基因的蛋白编码序列之内，亦可出现在非编码序列之中。存在于蛋白编码序列外显子中的SNP又被称之为`编码SNP`（coding SNP），简称`cSNP`。目前，发现的cSNP大约有100000个左右，其变异率仅及非编码序列的20%。就其对遗传性状的表型效应而言，cSNP又被区分为不改变编码蛋白氨基酸序列组成的同义cSNP和可改变氨基酸序列的非同义cSNP两种类别；两者所占比例各为50%。\n\n组成DNA的碱基虽然有4种，但是SNP一般只有2个\"等位\"成员，呈现为\"非此即彼\"的\"`双等位基因`\"（biallelic）多态性。基于SNP的自身特性，作为一种遗传标记，它常被用来进行对复杂性状与疾病的遗传分析和族群的基因识别以及遗传结构研究。\n\n#### 短串联重复序列多态性（STR）\n\n一类以1～6bp为重复单元，串联重复一到数十次；序列长度小于100bp的DNA结构片段。\n\nSTR散在于基因组中各个染色体上，但很少出现在编码DNA序列中。其主要表现为重复序列拷贝数的变异，具有较高的遗传多态性。\n\n# 基因突变的细胞分子生物学效应\n\n## 基因突变导致蛋白质功能异常\n\n基因突变对蛋白质结构和功能产生的影响主要表现在以下4个方面：\n\n① 直接影响相关功能蛋白质的生物合成；\n\n② 导致蛋白质产生异常的功能效应；\n\n③ 导致组织细胞中蛋白质表达类型的改变；\n\n④ 涉及蛋白质的`分子细胞生物学效应与相应临床表型`之间的关系。\n\n通过认识这些分子机制，将有助于从事医学遗传学研究与较为深入地理解基因突变导致遗传病发生的细胞分子生物学效应。\n\n### 基因突变导致异常蛋白的生成\n\n基因突变是蛋白质发生改变的根本原因，而`突变蛋白（mutant protein）`的形成则是基因突变的结果和表现形式。基因突变一般通过以下两种机制影响正常蛋白质的合成，导致细胞功能损害并引发疾病：\n\n- 突变影响、干扰了RNA的正常转录以及转录后的修饰、剪辑；或直接改变了由其编码的氨基酸的顺序或构成，从而使其丧失正常功能，即所谓的`原发性损害（primary abnormalities）`。\n- 突变并不直接影响或改变某一条多肽链的正常氨基酸组成，而是通过干扰该多肽链的翻译过程；或翻译后的修饰、加工；甚至通过对蛋白质各种辅助因子的影响，间接地导致某一蛋白质功能的异常。相对于原发性损害机制，后者被称之为`继发性损害（secondary abnormalities）`。\n\n### 基因突变导致蛋白质功能异常\n\n基因突变导致蛋白质功能异常的表现形式主要有以下几种：即丢失功能、 增强功能、 获得新性状、显性负效应以及异时或异地基因表达等。\n\n#### 丢失功能\n丢失功能是最常见的基因突变或基因缺失改变蛋白质功能的表现形式。 基因突变可发生在基因的编码区，也可发生在基因的调节区。 位于编码区的无义突变、移码突变等大多都会导致蛋白质正常功能的丧失，而部分错义突变等可使基因所编码的蛋白质保留部分功能。 \n\n#### 获得功能\n获得功能是最少见的基因突变改变蛋白质功能的表现形式。 对于一个特定的基因功能而言，并非越强越好。 如果破坏了机体的平衡，获得功能也会造成细胞正常生理功能的紊乱，并最终导致疾病的发生。 \n\n#### 获得新性状\n有的基因突变会使突变蛋白获得新性状，并赋予突变蛋白致病性。 \n\n#### 显性负效应\n在一对等位基因中，如果其中一个基因突变，另一个基因正常，即使突变基因的功能完全丧失，理论上仍应保留一半的功能，类似于显性遗传病的杂合子。 但在某种情况下，突变蛋白不仅自身没有生理功能，还会影响另一个正常蛋白质发挥其生理功能，这种由蛋白质相互作用产生的干涉现象称为显性负效应（dominant negative effect）。\n\n显性负效应通常通过蛋白质亚单位形成多聚体的形式实现的。\n\n#### 异时或异地基因表达\n有的基因突变影响基因调节区的序列导致该基因在不适当的时间或在不适当的细胞中表达，即所谓异时或异地基因表达。\n\n### 突变导致组织细胞蛋白表达类型的改变\n\n蛋白质通常可被划分为两类，即`持家蛋白（housekeeping protein）`和`奢侈蛋白（luxury protein）`。\n\n`持家蛋白`存在于几乎所有的组织细胞类型中，为细胞正常结构和最基本的生命活动的维系所必需。如核酸聚合酶蛋白、核糖体蛋白、细胞骨架蛋白等。\n\n`奢侈蛋白`则仅仅表达、存在于某些特定的组织细胞类型，是特异组织细胞类型分化及特殊生理功能的标志。如B淋巴细胞中的免疫球蛋白。\n\n基因突变往往导致正常组织细胞蛋白表达类型的改变，继而引起细胞功能的异常，甚至发生病理改变。\n\n### 突变蛋白的分子细胞病理学效应与临床表型之间的关系\n\n#### 同一基因的不同突变产生不同的临床表型\n同一基因的不同突变形式往往会导致不同的临床表现，这种现象称为等位基因异质性。 \n\n#### 同一基因的不同突变可改变疾病的遗传方式\n同一基因在不同位置发生基因突变有时会改变疾病的遗传方式。 \n\n#### 基因突变引发“无法预测”的临床效应\n\n遗传病的发生是在一定条件下基因有害突变的必然结果。 然而，在很多情况下却又无法估计和预测到某一基因突变是否能够、或者应该还是不应该引起这样或那样的生理生化异常及与之相应的临床表型效应。 \n\n## 基因突变引起性状改变的分子生物学机制\n\n`遗传中心法则`阐明了核酸、蛋白质之间的相互关系及细胞内遗传信息的传递、表达过程。\n\nDNA分子中储存的遗传信息，经过转录、翻译传递到肽链。而后者再进一步形成具有生物学功能活性的蛋白质，并最终表现为细胞的结构和功能性状。\n\n这种信息语言的转换和表达过程，不但是基因控制正常遗传性状发育最基本的分子生物学机制，也是基因突变引起各种性状异常和临床疾病发生的基本机制。\n\n### 基因突变引起酶分子的异常\n\n酶是生物体内具有特殊生物催化活性的催化剂。人体细胞中的每一步生化代谢反应，几乎都需要某种专一性酶的催化才能进行和完成。酶又是基因表达的产物，由结构基因突变所引起的酶分子组成与结构的改变，或由调节基因突变所导致的酶合成异常，都有可能造成相关代谢过程的障碍或代谢程序的紊乱。\n\n如果这种基因突变发生于生殖细胞或受精卵中，就有可能传递给后代，从而产生相应的`先天性代谢缺陷（inborn errors of metabolism）`或`遗传性酶病（hereditary enzymopathy）`。\n\n#### 结构基因突变引起的酶蛋白结构异常\n\n酶有`单体酶`与`复合酶`之分。前者仅由酶蛋白组成，后者，除酶蛋白外尚含有某种辅基或辅助因子。但无论是何种类型，其催化活性都是建立在与其催化功能相适应的特定三维空间构象基础之上的。\n\n所有结构基因突变，除同义突变一般不会引起酶蛋白结构异常外，其他突变形式都有可能造成酶分子特定立体构象不同程度的改变。空间构象变化引起的酶活性异常，主要表现为以下几种形式：\n\n- 酶的功能活性完全丧失；\n- 酶尚具有一定的功能活性，但其稳定性降低，极易被降解而失去活性；\n- 酶与其作用底物的亲和性降低，以致不能迅速、有效地与之结合，造成代谢反应的延滞；\n- 酶蛋白与辅助因子的亲和性下降，影响了酶的正常活性。\n\n#### 调节基因突变引起的酶蛋白合成异常\n\n基因是一个可调控的遗传功能表达单位。\n\n每一个结构基因的构成，除了其转录序列外，还含有侧翼的非转录调控序列。此类调控序列突变，或者使基因转录的启动发生障碍，不能进行mRNA的合成；或者造成转录速率下降，影响mRNA合成的产量。这些改变最终都导致酶蛋白的缺失，或酶蛋白合成量的不足而引发的代谢缺陷。\n\n### 酶分子异常引起的代谢缺陷\n\n人体细胞内的绝大多数生理活动都是建立在一系列相互联系的级联生化反应基础之上的。 而在这些级联反应中，每一步几乎都是在特定的酶或酶系的催化下实现和完成的。 因此，酶是实现机体细胞内各种生命活动过程最为直接、极其关键的重要因素之一。\n\n#### 酶与代谢反应的关系\n\n每一个代谢反应途径，以及由此所产生的各种中间代谢产物的最终去向，均和`参与催化该代谢反应的酶`密切相关。 换言之，即在一定条件下，`酶能够决定体内代谢反应的类型和反应的途径及去向`。\n\n在体内复杂的代谢反应过程中，参与代谢过程的各种物质，往往表现出作为反应底物和反应产物的双重属性，以及彼此之间互为底物与产物的交错关系。 而这种属性与相互关系，又构成了体内普遍存在的反馈调节机制的基础。\n\n#### 缺陷对代谢反应的影响\n\n1. `酶缺陷造成代谢底物缺乏`。绝大多数非脂溶性或极性的小分子物质（如葡萄糖、氨基酸等）都必须依赖于`膜转运酶`的作用才能进入细胞内作为某种代谢活动的原初反应底物而引发相应的代谢反应。一旦与之相关的膜转运酶缺陷或异常，就会造成代谢底物的缺乏而阻碍和影响整个代谢过程的发生，最终引发一系列的疾病症状。\n2. `酶缺陷导致代谢产物堆积`。酶缺陷导致的代谢产物堆积，可能造成两种情况的发生：`堆积产物对机体的直接危害`和`堆积底物或产物激发代谢旁路开放`。\n3. `酶缺陷导致代谢终产物缺乏`。在机体细胞内的物质代谢级联反应中，酶的缺陷出现在其整个过程的任何一个环节或步骤，都可能导致正常反应途径受阻或中断，造成某些必需代谢终产物的缺乏，并引发疾病。\n4. `酶缺失导致反馈调节失常`。在体内一系列级联反应中形成的某些代谢产物，往往会反过来影响、调节其初始的或前一反应步骤的进行以及反应速率，此即所谓的`反馈调节`。 某些酶的缺陷，若导致此类产物生成的减少或缺失，就可能造成这种自我反馈调节作用的失常，扰乱细胞代谢相对恒定、相互协调的运转秩序，从而引起机体疾病的发生。\n\n### 非酶蛋白分子缺陷导致的分子病\n\n基因突变除引起`酶蛋白分子缺陷`而导致`代谢性疾病`的发生之外，还可以通过影响`非酶蛋白分子`的结构和数量，从而改变机体细胞的生物学性状，并最终导致机体遗传性状的异常。 \n\n因此，一般将由`非酶蛋白分子结构和数量的异常`所引发的疾病，统称为`分子病`。比如由某些运输蛋白、免疫蛋白缺陷所引发的疾病，皆属此类。\n\n# 单基因病的遗传\n\n`单基因遗传病（monogenic disease, single-gene disorder）`，简称单基因病，是由一对等位基因控制而发生的遗传性疾病，这对等位基因称为`主基因（major gene）`。\n\n单基因遗传病的遗传可分为`核基因的遗传`和`线粒体基因的遗传`两种，后者属于`细胞质遗传`。\n\n核基因遗传的单基因遗传病在上下代之间的传递遵循孟德尔定律，因此也称为`孟德尔遗传病`，根据致病主基因所在染色体和等位基因间显隐关系的不同，包括五种遗传方式：\n\n- 常染色体显性遗传；\n- 常染色体隐性遗传；\n- X 连锁显性遗传；\n- X 连锁隐性遗传；\n- Y 连锁遗传；\n\n## 染色体显性遗传病的遗传\n\n如果一种遗传病的致病基因位于1 ~22号常染色体上，在杂合子的情况下可导致个体发病，即致病基因决定的是显性性状，这种遗传病就称为`常染色体显性（autosomal dominant, AD）遗传病`。\n\n常染色体完全显性遗传的特征：\n\n- 由于致病基因位于常染色体上，因而致病基因的遗传与性别无关，即`男女患病的机会均等`；\n- 患者双亲中必有一个为患者，致病基因由患病的亲代传来，此时患者的同胞有 1/2 的发病可能；双亲无病时，子女一般不会患病（除非发生新的基因突变）；\n- 患者的子代有 1/2 的发病可能；\n- 系谱中通常连续几代都可以看到患者，即存在`连续传递`的现象；\n\n根据这些特点，临床上可对常染色体显性遗传病进行发病风险的估计。例如，夫妇双方中有一人患病（杂合子），那么子女患病的可能性为 1/2；如果夫妇双方都是患者（均为杂合子），则子女患病的可能性为 3/4。\n\n**染色体显性遗传病**举例：\n\n| 疾病名称           | 主要症状                           | 发病率          |\n| ------------------ | ---------------------------------- | --------------- |\n| 软骨发育不全症     | 四肢短小，躯干正常                 | 1/15000-1/40000 |\n| 多指(趾)症         | 手指或脚趾数目过多                 | 1/500-1/1000    |\n| 亨廷顿舞蹈症       | 中年发病，运动和认知功能障碍       | 1/10000         |\n| 家族性高胆固醇血症 | 血液胆固醇异常升高，易患心血管疾病 | 1/500           |\n| 视网膜母细胞瘤     | 儿童眼部恶性肿瘤                   | 1/15000-1/20000 |\n\n## 染色体隐性遗传病的遗传\n\n一种遗传病的致病基因位于常染色体上,其遗传方式是隐性的，只有隐性致病基因的纯合子才会发病，称为`常染色体隐性（autosomal recessive, AR）遗传病`。 \n\n带有隐性致病基因的杂合子本身不发病，但可将隐性致病基因遗传给后代，称为`携带者`（carrier）。广义地说，携带者是指携带有某种致病基因或异常染色体，但本身并不表现出临床症状的个体，虽然携带者本身并不发病，但可能会将致病基因或异常染色体传递给后代，导致后代发病。\n\n一般认为，`常染色体隐性遗传`的典型系谱有如下特点：\n\n- 由于致病基因位于常染色体上，因而致病基因的遗传与性别无关，即男女患病的机会均等。\n\n- 患者的双亲表型往往正常，但都是致病基因的携带者；\n- 患者的同胞有`1/4`的发病风险，患者表型正常的同胞中有`2/3`的可能为携带者；患者的子女一般不发病，但肯定都是携带者；\n- 系谱中患者的分布往往是散发的，通常看不到连续传递现象，有时在整个系谱中甚至只有先证者一个患者；\n- `近亲婚配（consanguineous marriage）`时，后代的发病风险比随机婚配明显增高。这是由于他们有共同的祖先，可能会遗传到同一个隐性致病基因。\n\n**常染色体隐性遗传病**举例：\n\n| 疾病名称       | 主要症状                       | 发病率          |\n| -------------- | ------------------------------ | --------------- |\n| 白化病         | 黑色素缺乏，皮肤苍白，视力受损 | 1/20000         |\n| 镰状细胞贫血症 | 红细胞变形，贫血，易感染       | 1/500(非洲裔)   |\n| 苯丙酮尿症     | 苯丙氨酸代谢障碍，智力受损     | 1/10000-1/15000 |\n| 先天性耳聋     | 听力障碍                       | 1/1000-1/2000   |\n| 囊性纤维化     | 呼吸和消化系统受损             | 1/2500(白种人)  |\n| 地中海贫血     | 血红蛋白合成障碍，重度贫血     | 1/50000         |\n\n## X连锁显性遗传病的遗传\n\n由性染色体上的基因所决定的性状在群体分布上存在着明显的性别差异。如果决定一种遗传病的致病基因位于X染色体上，带有致病基因的`女性杂合子`即可发病，称为`X连锁显性（X-linked dominant，XD）遗传病`。\n\n男性只有一条X染色体，其X染色体上的基因不是成对存在的，在Y染色体上缺少相对应的等位基因，故称为`半合子（hemizygote）`，其X染色体上的基因都可表现出相应的性状或疾病。男性的X染色体及其连锁的基因只能从母亲传来，将来又只能传递给女儿，一般不存在男性→男性的传递，这种传递方式称为`交叉遗传（criss-cross inheritance）`。\n\n对于X连锁显性遗传病来说，女性有两条X染色体，其中任何一条X染色体上存在致病基因都会发病，而男性只有一条X染色体，所以女性发病率约为男性的2倍。然而男性患者病情较重，而女性患者由于X染色体的随机失活，病情较轻且常有变化。\n\nX连锁显性遗传的典型系谱有如下特点：\n\n- 人群中女性患者数目多于男性患者，在罕见的`XD遗传病`中，女性患者的数目约为男性患者的2倍，但女性患者病情通常较轻；\n- 患者双亲中一方患病；如果双亲无病，则来源于新生突变；\n- 由于`交叉遗传`，男性患者的女儿全部都为患者，儿子全部正常；女性杂合子患者的子女中有50%的可能性发病；\n- 系谱中常可看到`连续传递`现象，这点与常染色体显性遗传一致；\n\n**X染色体显性遗传病**举例：\n\n| 疾病名称          | 主要症状                              | 遗传特点                             | 发病率                |\n| ----------------- | ------------------------------------- | ------------------------------------ | --------------------- |\n| 维生素D抗性佝偻病 | 骨骼发育异常，血磷低，维生素D治疗无效 | 女性患者可生育，子代男女均可能发病   | 1/20000               |\n| 色素失禁症        | 皮肤色素沉着，中枢神经系统异常        | 男性胚胎常流产，存活女性表现完整症状 | 1/50000               |\n| 视网膜色素变性    | 夜盲，视野缩小，最终可致盲            | 男女均可发病，男性症状较重           | 1/3500                |\n| Rett综合征        | 智力发育迟缓，运动功能退化            | 男性胚胎期致死，仅女性患者存活       | 1/10000-1/15000(女性) |\n| 低磷性佝偻病      | 骨骼软化，生长发育迟缓                | 男女均可发病，但男性症状更严重       | 1/20000               |\n\n## X连锁隐性遗传病的遗传\n如果决定一种遗传病的致病基因位于X染色体上，且为隐性基因，即带有致病基因的女性杂合子不发病，称为`X连锁隐性（X-Iinked recessive,XR）遗传病`。\n\nX连锁隐性遗传的典型系谱有如下特点：\n\n- 人群中男性患者远多于女性患者，在一些罕见的`XR遗传病`中，往往只能看到男性患者；\n- 双亲无病时，儿子有1/2的可能发病，女儿则不会发病，表明致病基因是从母亲传来的；如果母亲不是携带者，则来源于新生突变；\n- 由于`交叉遗传`，男性患者的兄弟、舅父、姨表兄弟、外甥、外孙等也有可能是患者；患者的外祖父也可能是患者，这种情况下，患者的舅父一般不发病；\n- 系谱中常看到几代经过女性携带者传递，男性发病的现象；如果存在女性患者，其父亲一定是患者，母亲一定是携带者；\n\n**X染色体隐性遗传病**举例：\n\n| 疾病名称       | 主要症状                               | 遗传特点                     | 发病率               |\n| -------------- | -------------------------------------- | ---------------------------- | -------------------- |\n| 血友病A        | 凝血因子VIII缺乏，易出血，血液凝固障碍 | 男性发病，女性携带           | 1/5000(男性)         |\n| 血友病B        | 凝血因子IX缺乏，症状类似血友病A        | 男性发病，女性携带           | 1/30000(男性)        |\n| 红绿色盲       | 无法分辨红色和绿色                     | 男性多见，女性少见           | 8%(男性)，0.5%(女性) |\n| 杜氏肌营养不良 | 进行性肌肉萎缩，运动功能丧失           | 男孩3-7岁发病，女性携带      | 1/3500(男性)         |\n| G6PD缺乏症     | 溶血性贫血，对某些药物和食物过敏       | 男性症状明显，女性多为携带者 | 1/1000(男性)         |\n\n## Y连锁遗传病的遗传\n如果决定某种性状或疾病的基因位于Y染色体，随Y染色体而在上下代之间进行传递，称为`Y连锁遗传（Y-Iinked inheritance）`。\n\nY连锁遗传的传递规律比较简单，具有Y连锁基因者均为男性，这些基因将随Y染色体进行`父→子→孙`的传递，因此又称为`全男性遗传(holandric inheritance) `。\n\n目前已经定位在Y染色体上的基因有54个，其中主要的有`睾丸决定因子基因`（SRY，OMlM *480000）和`外耳道多毛症基因`（OMlM 425500）等。 \n\n## 从性遗传和限性遗传\n\n`从性遗传（sex-influenced inheritance）`是位于常染色体上的基因，由于受到性别的影响而显示出男女表型分布比例的差异或基因表达程度的差异。\n\n例如，雄激素性秃发1型属于常染色体显性遗传，群体中男性患者明显多于女性。男性杂合子（Aa）即会出现秃顶，表现为从头顶中心向周围扩展的进行性、弥漫性、对称性脱发，仅枕部及两侧颞部保留头发；而女性杂合子（Aa）仅表现为头发稀疏而不会表现秃顶症状。出现这种情况是因为`雄激素性秃发（AGIA）`基因的表达会受到体内雄性激素的影响。但携带有AGIA基因的女性杂合子，由于某种原因导致体内雄性激素水平升高也可出现秃顶的症状。\n\n`限性遗传（sex-limited inheritance）`则指位于常染色体上的基因，由于基因表达的性别限制，只在一种性别表现，而在另一种性别则完全不能表现，但这些基因均可传给下一代。限性遗传可能主要是由于男女性在解剖学结构上的差异所致，也可能受性激素分泌方面的性别差异限制，故只在某一性别中发病，如女性的子宫阴道闭水，男性的尿道下裂等。\n\n# 多基因病的遗传\n\n与单基因遗传疾病的罕见性不同，多基因疾病多为常见病且表型取决于相关的多个基因的共同作用。这些基因对疾病的表型贡献有大有小，因此可分为`主效基因（major effect gene）`和`微效基因（minor effect gene）`。\n\n主效基因可能存在显、隐性关系，但微效基因相互之间显隐之分并不明确，多互为共显性。多对微效基因的作用积累之后，可以形成一个明显的效应，这种现象称为`累加效应（additive effect）`；因而这些基因也被称作`累加基因（additive gene）`。\n\n近年来的研究发现，微效基因所发挥的作用或者说贡献率并不是等同的，可能存在一些起主要作用的所谓`主基因（major gene）`，主基因有可能存在显、隐性关系。由于多基因疾病参与的基因多，不仅基因之间遗传关系复杂，同时，这类疾病还往往明显受环境影响，因此，这类性状也称为复杂性状，这类疾病也就称为`复杂疾病`。\n\n## 数量性状的多基因遗传\n\n### 数量性状与质量性状\n\n在单基因遗传中，基因和表型之间的对应关系较为明显，因此基因改变而引起的性状的变异在群体中的分布往往是不连续的，可以明显地分为若干群，基本与其基因型相对应，且性状不易受环境影响，所以`单基因遗传`的性状也称为`质量性状`。\n\n![image-20250116215635321](/images/assets//image-20250116215635321.png)\n\n多基因遗传性状的变异在群体中的分布是连续的，只有一个峰，因此会有一个平均值。不同个体间的差异只是量的变异，临近的两个个体之间的差异很小，因此这类形状称为`数量性状（quantitative character）`。\n\n因此，数量性状是一种可测量的生理或生化数值指标，如身高、体重、血压、血清胆固醇浓度或体重指数等。群体中，每个个体在这些数量性状的数值上存在差别，呈现由低到高逐渐过渡。数值极高或极低的个体只占少数，大部分个体数量性状数值接近平均值。将此数量性状变异分布绘成曲线，该曲线往往表现出`正态分布`（图5-2）。这些性状在人群中呈常正态分布，而非\"有或无\"的遗传方式。\n\n### 数量性状的多基因遗传\n\n多基因遗传中，虽然性状的遗传规律不符合孟德尔定律，但每一对基因的遗传方式仍符合`孟德尔定律`，即`分离和自由组合`。\n\n对于某一个数量性状而言，每个个体的控制基因数量是基本相同的，但各型基因的比例是不同的，因而造成性状具有差异性。一般说来，决定数量性状的基因远不止3对，而且许多研究也显示每个基因的作用也并非相等。\n\n## 疾病的多基因遗传\n\n### 易患性与发病阈值\n\n在多基因遗传病中，遗传基础是由多基因构成的，它部分决定了个体发病的风险。这种由遗传基础决定一个个体患病的风险称为`易感性（susceptibility）`。由于环境对多基因遗传病产生较大影响，因此学术界将遗传因素和环境因素共同作用决定个体患某种遗传病的风险称为`易患性（liability）`，也就是说`易感性+环境因素=易患性`。\n\n在相同环境下不同个体产生的差异，可以认为是由不同的易感性造成的，也就是说是基因差异造成的。一般群体中，易患性很高或很低的个体都很少，大部分个体都接近平均值。因此，群体中的易患性变异也呈正态分布。但在一定的环境条件下，易感性高低可代表易患性高低。当一个个体易患性高到一定限度时，就可能发病。这种由易患性所导致的多基因遗传病发病最低限度称为`发病阈值（threshold）`。阈值将连续分布的易患性变异分为两部分：正常群体和患病群体（图5-4）。因此，多基因遗传病又属于阈值相关疾病，阈值是易患性变异的某一点，在一定条件下，阈值代表患病所必需的、最低的易患基因的数量。\n\n![image-20250116220149277](/images/assets//image-20250116220149277.png)\n\n一种多基因病的易患性的平均值与阈值越近，表明易患性高，阈值低，群体患病率高。相反，易患性的平均值与阈值越远，表明易患性低，阈值高，群体患病率低（图5-6）。\n\n![image-20250116220251862](/images/assets//image-20250116220251862.png)\n\n### 遗传率及其估算\n\n多基因遗传病是`遗传因素`和`环境因素`共同作用所致。\n\n这其中，遗传因素的作用大小可用`遗传率`来衡量。`遗传率（heritability）`又称遗传度，是在多基因疾病形成过程中，遗传因素的贡献大小。遗传率愈大，表明遗传因素的贡献愈大。\n\n如果一种疾病完全由遗传因素所决定，遗传率就是100%；如果完全由环境所决定，遗传率就是0，这两种极端情况是极少见的。某些疾病的遗传率较高，可达70%～80%，这表明在决定疾病易患性变异上，遗传因素发挥了较大的作用，相对环境因素的作用较小；某些疾病的遗传率较小，仅为30%～40%，这表明在决定疾病易患性变异上，环境因素发挥了较大作用，相对遗传因素的作用较小。\n\n一般说来，遗传率越低的性状或疾病，家族聚集现象越不明显。\n\n计算人类多基因遗传病遗传率的高低在临床实践上有重要意义，传统的计算方法主要有两种，即`Falconer公式`和`Holzinger公式`。\n\n#### Falconer公式\n\n`Falconer公式（Falconer method）`是根据先证者亲属的患病率与遗传率有关而建立的。亲属患病率越高，遗传率越大，所以可通过调查先证者亲属患病率和一般人群的患病率，算出遗传率（$h^2$或H）。\n\n$h^2=b/r$                  （式5-1）\n\n式5-1中，$h^2$为遗传率；$b$为亲属易患性对先证者易患性的回归系数；$r$为亲缘系数。\n\n当已知一般人群的患病率时，用式5-2计算回归系数：\n\n$b=\\frac{X_s-X_r}{a_g}$                  （式5-2）\n\n当缺乏一般人群的患病率时，可设立对照组，调查对照组亲属的患病率，用式5-3计算回归系数：\n\n$b=\\frac{p_c(X_s-X_r)}{ar}$                  （式5-3）\n\n在式5-2和式5-3中，$X_g$为一般群体易患性平均值与阈值之间的标准差数；$X_c$为对照组亲属中的易患性平均值与阈值之间的标准差数；$X_s$为先证者亲属易患性平均值与阈值之间的标准差数；$a_g$为一般群体易患性平均值与一般群体中患者易患性平均值之间的标准差数（图5-7）；$a_r$为先证者亲属易患性平均值与先证者亲属中患者易患性平均值之间的标准差数；$q_c$为一般群体患病率；$q_r$为对照亲属患病率，$p_c=1-q_c$；$q_s$为先证者亲属患病率。\n\n$X_g$、$X_s$、$a_g$和$a_r$均可由一般群体患病率、对照亲属患病率和先证者亲属患病率查Falconer表得到。\n\n![image-20250116220734569](/images/assets//image-20250116220734569.png)\n\n亲缘系数$r$是指两个个体从共同祖先获得某一特定等位基因的总体概率，可见Falconer表。\n\n在亲缘系数中，`一级亲属`指一个人与其双亲、子女和同胞之间，其基因有1/2的可能性是相同的；`二级亲属`指一个人与其叔、伯、姑、舅、姨、祖父母和外祖父母之间，其基因有1/4的可能性是相同的；`三级亲属`指一个人与其表兄妹、堂兄妹、曾祖父母之间，其基因有1/8的可能性是相同的。\n\n#### Falconer公式应用\n\n`先天性房间隔缺损`在一般群体中的患病率为1/1000（0.1%），在100个先证者的家系中调查，先证者的一级亲属共有669人（双亲200人，同胞279人，子女190人），其中有22人发病。\n\n依次求得先证者一级亲属的患病率为22/669×100%=3.3%（$q_s$），然后查Falconer表。按群体患病率查得$X_g$和$a_g$，再根据亲属患病率查得$X_s$和$a_r$，然后代入式5-2求出$b$值。\n\n将$b$值代入式5-1：\n\n$$\nb=\\frac{X_s-X_g}{a_g}=\\frac{3.090-1.838}{3.367}=0.37\n$$\n\n$$\nh^2=b/r=0.37/0.5=0.74=74\\%\n$$\n\n以上计算结果表明，遗传因素对先天性房间隔缺损发生的贡献为74%，经显著性检验该遗传率有统计学意义。\n\n在缺乏一般人群患病率数据时，可选择与病例组匹配的对照组，调查对照组亲属的患病率，用先证者亲属和对照亲属的患病率计算遗传率。\n\n对江苏启东肝癌的调查发现，肝癌患者一级亲属6591人中，有359人发病，其患病率为5.45%（$q_s$）；在年龄和性别均与患者相应的无病对照者的5227名一级亲属中，有54人患肝癌，患病率$q_c=0.0103=1.03\\%$。$p_c=1-q_c=0.9897$，分别查得$X_s$、$X_c$和$a_r$、$a_g$，然后代入式5-3求出$b$值。\n$$\nb=\\frac{p_c(X_s-X_r)}{a_r}=\\frac{0.9897(2.315-1.603)}{2.655}=0.2654\n$$\n将$b$值代入式5-1：\n\n$$\nh^2=b/r=0.2654/0.5=0.531=53.1\\%\n$$\n以上计算结果表明，遗传因素对肝癌发生的贡献超过50%，经显著性检验该遗传率有统计学意义。\n\n#### Holzinger公式\n\n`Holzinger公式（Holzinger formula）`（1929）是根据遗传率越高的疾病，单卵双生的患病一致率与二卵双生患病一致率相差越大而建立的。\n\n`单卵双生（monozygotic twin，MZ）`是由一个受精卵形成的一对双生子，他们的遗传基础理论上是完全相同的，其个体差异主要由环境决定；`二卵双生（dizygotic twin，DZ）`是由两个受精卵形成的一对双生子，相当于同胞，因此他们的个体差异由遗传基础和环境因素共同决定。\n\n所谓患病一致率是指双生子中一个患某种疾病，另一个也患同样疾病的频率。其中，$C_{MZ}$为单卵双生子的同病率；$C_{DZ}$为二卵双生子的同病率。\n\n$h^2=\\frac{C_{MZ}-C_{DZ}}{100-C_{DZ}}$                  （式5-4）\n\n#### Holzinger公式应用\n\n举个例子，对躁狂抑郁性精神病的调查表明，在15对单卵双生子中，共同患病的有10对；在40对二卵双生子中，共同患病的有2对。依此来计算单卵双生子的同病率为67%，二卵双生子的同病率为5%。代入式5-4：\n$$\nh^2=\\frac{C_{MZ}-C_{DZ}}{100-C_{DZ}}=\\frac{67-5}{100-5}=0.65=65\\%\n$$\n以上结果表明，在躁狂抑郁性精神病中，遗传因素的贡献为65%。\n\n#### 常见多基因遗传病的患病率和遗传率\n\n![image-20250116221400532](/images/assets//image-20250116221400532.png)\n\n# 群体遗传\n\n`群体（population）`又称种群，是属于一个物种，生活在同一地区，并且能够相互杂交的个体群。群体是物种的基本结构单位。群体中进行有性生殖的所有个体所拥有的基因型构成`基因库（gene pool）`。基因库即一个群体中所包含的全部遗传信息，含有特定位点的全部等位基因。\n\n`群体遗传学（population genetics）`研究群体的遗传变异分布，特别是等位基因频率和基因型频率在人群中的维持、变化及其规律。\n\n遗传病在不同种族或民族人群中的差异和变化规律，也属于群体遗传学研究的重要范畴。群体遗传学应用于医学，是要探讨遗传病或复杂性状在人群中的遗传方式、致病基因频率及其变化的规律，开发相应的遗传统计方法，故又称之为`遗传流行病学（genetic epidemiology）`。\n\n## 群体的遗传平衡\n\n### Hardy-Weinberg 平衡定律\n\n按照孟德尔遗传规律，某一性状由一对等位基因决定，可分别标识为 A 和 a，等位基因在人群中的分布频率，称为`等位基因频率（allele frequency）`。而这一对等位基因组成 3 种可能的基因型（`genotype`），分别为 AA、Aa 和 aa。对于人群中的任一个体，其基因型只能为 AA、Aa 和 aa 之一。基因型在人群中分布的频率，称为`基因型频率（genotype frequency）`。\n\n对于常染色体显性遗传病，纯合子 AA 和杂合子 Aa 显现相同的表型；而对于隐性遗传病，纯合子 AA 与杂合子 Aa 及纯合子 aa 呈现不同的表型。由于基因型无法直接进行观察，过去多用表型频率来推测基因型频率。但这需要满足 2 个条件：①单基因遗传；②不同的基因型与表型一一对应。有些性状虽然符合单基因遗传方式，但表型与基因型并不一一对应。例如，ABO 血型的每种表型对应几十甚至上百种基因型。随着 DNA 测序和基因分型方法的快速发展，基因型的获取已不存在困难。\n\n例如，在一个 747 人的人群中，某个 SNP 位点 AA 基因型的频率（假设为 D）是 31.2%，AG 基因型的频率（假设为 H）是 51.5%，GG 基因型（假设为 R）为 17.3%。则等位基因 A 的频率（设为 p）为 \n$$\n(747×0.312×2+747×0.515)/747×2=0.5695\n$$\n等位基因 G 的频率（设为 q）为 \n$$\n(747×0.173×2+747×0.515/747×2=0.4305\n$$\n即等位基因频率 p、q 与基因型频率 D、H、R 的关系为：\n$$\np=D+1/2H, q=R+1/2H\n$$\n对于一个群体，一个单基因遗传的性状，其表型由基因型频率决定。\n\n那么，这个群体的表型频率会怎样变化？等位基因频率和基因型频率的关系又是什么？\n\n群体遗传学的核心概念是`Hardy-Weinberg 平衡定律（Hardy-Weinberg law）`。该定律解释了等位基因频率与基因型频率的关系，并在一定条件下，群体的等位基因频率和基因型频率在向子代传递的过程中保持不变。\n\n一对等位基因 A 和 a，其等位基因频率分别为 p 和 q，$p+q=1$，则群体的基因型频率为 $(p+q)$ 的二项式展开：$(p+q)^2=p^2+2pq+q^2=1$。其中，$p^2$、$2pq$ 和 $q^2$ 分别为基因型 AA、Aa 和 aa 的频率。这就是 Hardy-Weinberg 定律的内涵。\n\n`Hardy-Weinberg 平衡`的成立必须满足以下几个条件：\n\n- 群体无限大；\n- 群体内的个体随机交配；\n- 没有自然或人工选择；\n- 没有突变；\n- 群体内没有大规模的个体迁移；\n\n可以说，没有完全满足 Hardy-Weinberg 平衡成立条件的群体，但一个足够大的群体在一定时间内应该近似地被看作一个遗传平衡群体。\n\n对于复等位基因，即多于 2 个等位基因的位点，Hardy-Weinberg 平衡依然成立。任何纯合子的频率等于等位基因频率的平方，而杂合子频率等于 2×等位基因频率之积。如 3 个等位基因（p、q、r）的位点：\n$$\n(p+q+r)^2=p^2+q^2+r^2+2pq+2pr+2qr=1\n$$\n由于男性只有一个 X 染色体，X 连锁是一个特例。男性的基因型频率=等位基因频率，而女性的基因型和等位基因频率与常染色体等位基因相同。\n\n### Hardy-Weinberg 定律的应用\n\n#### 遗传平衡群体的判定\n\n针对一个群体的某一特定位点，可以从`基因型频率`来判断该群体是否在该位点达到`遗传平衡`。\n\n首先，可以通过基因型频率（$p^2:2pq:q^2$）的观察值（O）计算出等位基因频率（p、q）；再由等位基因频率（p、q）按照 $p^2:2pq:q^2$ 计算出基因型频率的期望值（E）；再进行卡方检验：\n\n$\\chi^2 = \\sum \\frac{(O-E)^2}{E}$          （式 6-1）\n\n其中，O 和 E 分别为基因型频率的观察值和期望值。\n\n例如，在一个 730 个体的人群中，对一个 A/G 进行基因分型，得到 AA、AG 和 GG 基因型的人数分别为 22、216 和 492 例。因而观察到的基因型频率分别为 0.03、0.296 和 0.674。由此可计算出等位基因频率：\n$$\np=0.03+1/2×0.296=0.178；q=1/2×0.296+0.674=0.882\n$$\n则基因型的期望频率：\n$$\np^2=0.032、q^2=0.778、2pq=0.050\n$$\nAA、AG、GG 的期望值（E）：\n$$\n0.032×730=23.36、229.21、567.94\n$$\n代入式 6-1，则\n\n$$\n\\chi^2=(22-23.36)^2/23.36+(216-229.21)^2/229.21+(492-567.94)^2/567.94=10.99\n$$\n以自由度 n=1，得出 P=0.00049，此群体的等位基因频率和基因型频率分布不符合`Hardy-Weinberg 平衡`。\n\n一般来说，在一个正常的大群体中，人类基因组的任何位点都应该达到 Hardy-Weinberg 平衡，特别是此位点的等位基因 A 的频率高达 17.8%，因而该位点的基因分型很可能存在错误。\n\n虽然从理论上说，人类基因组任何位点都应该符合 Hardy-Weinberg 平衡，但有些位点存在强烈的自然选择（如`镰状细胞贫血症`），或小群体对大群体的等位基因频率有影响（如ABO血型），使得某些特别位点存在不符合 Hardy-Weinberg 平衡的现象。\n\n#### 基因频率的计算\n\n对于`单基因病`，当已知一个性状在某群体中的频率，根据 `Hardy-Weinberg 平衡`的等位基因频率和基因型频率的关系，即可确定等位基因频率和杂合子频率。\n\n> 例如，某常染色体隐性遗传病在某群体的发病率为 1/10000，该群体的致病基因携带者的频率是多少？\n\n由 $q^2=10^{-4}$，得出 $q=1/100$，$p=1-1/100=99/100$。\n\n故致病基因携带者的频率为：\n$$\n2pq=2×99/100×1/100≈1/50\n$$\n上述疾病患儿的双亲为肯定携带者。若他们离异后与群体中的任一个体再婚，假设新配偶的家族中无相同疾病的家族史，再生出患儿的风险=（肯定携带者的风险）×（新配偶为携带者的风险）×1/4=$1×1/50×1/4=1/200$。\n\n> 例如，`囊性纤维化（OMIM#219700）`是一种常染色体隐性遗传病，在欧洲白色人种中的发病率约为 1/2000，预测白色人种中囊性纤维化突变基因携带者是多少？\n\n$q^2=1/2000$，则 $q=0.022$，$p=1-0.022=0.978$。\n\n致病基因携带者的频率为：$2pq=2×0.978×0.022=0.043$。\n\n由于白色人种中约有 4% 为囊性纤维化致病基因携带者，这些携带者的生存和婚配是囊性纤维化致病基因传递下去的重要原因，该数据对囊性纤维化家族的遗传咨询十分重要。\n\n对于罕见的`隐性遗传病`（$q^2≤0.0001$），p 近似于 1，故杂合子频率（$2pq$）约为 $2q$，即杂合子频率是致病等位基因频率（q）的 2 倍；因此，群体中致病基因携带者的人数（$2q$）远高于患者（$q^2$）。随着隐性遗传病发病率（$q^2$）的下降，携带者和患者的比率明显升高，这对于制定隐性遗传病的筛查计划具有重要意义。\n\nX 连锁基因频率的估计不同于常染色体基因。因为男性为半合子，`男性发病率等于致病等位基因频率 q`。\n\n对于一种相对罕见的 X 连锁隐性遗传病（如`血友病 A`），其男性发病率为 1/5000，则该群体致病等位基因频率 $q=1/5000$；女性携带者频率 $2q=1/2500$，女性发病率为 $q^2$，因而男性患者远高于女性患者的发病率。\n\n相反，对于 X 连锁显性遗传病，男性发病率是女性发病率（$2q$）的 1/2。\n\n> 例如，X 连锁隐性遗传病`红绿色盲`在英国有 1/12 的男性受累。女性是携带者的比例是多少？受累女性的比例是多少？\n\n已知：$q=1/12，p=11/12$。\n\n女性致病等位基因携带者的频率：$2pq=2×1/12×11/12=22/144≈15\\%$。\n\n女性患者：$q^2=1/144≈0.7\\%$。\n\n## 影响遗传平衡的因素\n\n前已述及，`Hardy-Weinberg平衡`适用的条件包括群体无限大、随机婚配、无突变、无选择、无迁移等。 但是，真正的随机婚配和无限大群体并不存在。 群体越小，群体的等位基因频率受非随机婚配、选择、 迁移等的影响越明显。 下面就讨论群体遗传平衡的因素。\n\n### 非随机婚配\n\n在4代之内有共同的祖先者均属近亲，如果他们之间进行婚配就成为近亲婚配。亲属关系的远近可用`亲缘系数`表示，它是指`有亲缘关系的两个个体携带相同基因的概率`。 \n\n如父母与子女和同胞兄弟姐妹之间都各有1/2的基因相同，他们之间的亲缘系数为1/2，父母、兄弟姊妹也被称为一级亲属；与祖父母、 外祖父母、 叔、 姑、 舅、 姨、 侄、 甥的亲缘系数是1/4 ，为二级亲属；表兄妹、堂兄妹之间的亲缘系数是1/8，为三级亲属。\n\n如果发生近亲结婚，夫妇双方均有可能从共同祖先遗传到同一等位基因，并把该等位基因传递给他们的子女，使子女成为该基因的纯合子。 \n\n### 突变和选择\n\n突变是群体发生变异的根源。基因突变对于群体遗传组成的改变有 2 个重要的作用：\n\n- 突变本身改变了基因频率；\n- 突变又为选择提供了材料。\n\n突变和选择的交互作用，构成了生物进化的遗传学基础。\n\n选择主要是通过增加和减少个体的适合度来影响基因平衡。\n\n换言之，当一个群体的不同个体的适合度（`fitness`，`f`）不同时，选择就会发生作用。`自然选择（natural selection）`和`人工选择（artificial selection）`都是导致基因频率变化的重要因素。就人类而言，导致基因频率变化的主要选择因素是`自然选择`。\n\n### 遗传漂变\n\n小群体或隔离人群中基因频率的随机波动称为`遗传漂变（genetic drift）`。由于群体较小，故等位基因在传递过程中会使有的基因固定下来而传给子代，有的基因则丢失，最终使得该基因在群体中消失。遗传漂变的速率取决于群体的大小。群体越小，漂变的速率越快，常常在几代甚至一代后即可出现基因的固定和丢失。\n\n在一个大群体中，如果没有突变发生，则根据`Hardy-Weinberg`平衡定律，不同基因型的频率将会维持平衡状态。但在一个小群体中，由于与其他群体相隔离，不能够充分地随机交配，故小群体内的基因不能达到完全分离和自由组合，造成基因频率容易产生偏差，但这种偏差不是由于突变、选择等因素引起的。\n\n### 迁移和基因流\n迁移（migration）又称移居，即不同人群的流动和通婚，彼此渗入外来基因，导致基因流动，可改变原来群体的基因频率，这种影响称为`迁移压力`。 \n\n迁移压力的增强可使某些基因从一个群体有效地散布到另一个群体，称为`基因流（gene flow）`。\n\n### 注意点\n\n影响遗传平衡的因素并不是独立存在的，`群体越小，突变、选择、遗传漂变、非随机婚配的影响就越明显`。 影响遗传平衡的因素对规模较大的群体基因频率的影响较小，可以观察到的表型变化相对不明显。\n\n## 连锁不平衡及其应用\n\n在人类基因组中存在着大量的序列变异，其中在群体中能够以孟德尔遗传的方式传递到子代的变异称为`DNA多态`。这些变异以`单核苷酸多态性（SNP）`最为常见。这些多态性多数并不影响个体的表型。\n\n`连锁不平衡（linkage disequilibrium）`是指不同位点上各等位基因在群体中的非随机组合，即不同基因座上的各等位基因一起遗传到子代的频率明显高于其随机传递的频率。如图6-7所示，某致病突变发生之后，由于发生重组，离该致病位点越近的区域，越容易被一起传递到子代。经过多代之后，与致病基因位点一起传递下来的区域变得很小。由于该位点及其周围区域来源于若干代前的同一段染色体区域，这段区域的各个多态性位点之间即存在`连锁不平衡`。\n\n![image-20250116224405081](/images/assets//image-20250116224405081.png)\n\n例如，两个相邻的SNP位点，分别为A/G和G/T多态。由于这两个位点之间存在连锁不平衡，单倍型（haplotype）A-G总在一起被传递到子代。如果一旦在这两个位点之间发生重组，A-G的单体型就被破坏。\n\n两个位点之间的连锁不平衡程度常用D'或r²来度量，当D'和r²=1时为完全连锁不平衡，一般认为两个位点间r²>0.8时存在明确的连锁不平衡。\n\n一般来说，存在连锁不平衡的区域总是比较小的，在100kb以内。在特定人群中，某一段存在连锁不平衡的区域源于同一祖先。\n\n## 全基因组关联分析（genome wide association study，GWAS）\n\nGWAS，利用高通量的基因分型手段获得覆盖基因组的SNP基因型，从而进行基因型-表型的关联分析。\n\n对GWAS结果的解释需要注意以下几点：\n\n- 对疾病或性状存在显著关联的SNP位点并不代表功能上的联系，只是说明该SNP与致病基因位点间可能存在连锁不平衡（除非SNP本身就是致病突变，或与致病基因的表达有关）；\n- 要注意`多重检验的调整`，100万个SNP关联分析的显著性差异水平应该是`P<5×10⁻⁸（0.05/1×10⁶）`；\n- 对于复杂性状，每个易感基因位点的遗传相对风险（genetic relative risk，GRR）可能并不高，需要较大的样本量才能保证检验效能（power）。\n\n# 线粒体病的遗传\n\n## 人类线粒体基因组\n\n`mtDNA`是核基因组外的一独立的基因组。线粒体基因组的结构：\n\n![image-20250116224909574](/images/assets//image-20250116224909574.png)\n\n`mtDNA`可进行半保留复制。与核基因转录比较，`mtDNA的转录`有以下特点：\n\n- 两条链均有编码功能；\n- 两条链从D-环区的启动子处同时开始以相同速率转录，L链按顺时针方向转录，H链按逆时针方向转录；\n- `mtDNA`的基因之间无终止子，因此两条链各自产生一个巨大的多顺反子初级转录产物；\n- `mtDNA的遗传密码与核基因组（nDNA）不完全相同`：UGA编码色氨酸而非终止信号，AGA、AGG是终止信号而非精氨酸，AUA编码甲硫氨酸兼启动信号，而不是异亮氨酸的密码子；\n\n## 线粒体遗传系统的特点\n\n### 半自主性\n`mtDNA`能够独立地复制、 转录和翻译，但这种自主性有限。\n\n### 同质性和异质性\n\n线粒体`mtDNA`的多质性是区别于核DNA的重要特性。\n\n一个人体细胞内通常有数百个线粒体，每个线粒体内含2～10个mtDNA分子（例外的是血小板和未受精的卵子，它们中的每个线粒体内只含有一个拷贝的`mtDNA`），所以每个细胞有数千个`mtDNA分子`，这即为`mtDNA的多质性（polyplasmy）`。\n\n多质性是线粒体DNA遗传异质性和同质性的基础。\n\n- 细胞或组织中，如果所有`mtDNA分子`都是相同的，则称为`同质性（homoplasmy）`。\n- 由于`mtDNA`随机突变会产生部分突变型的`mtDNA`，导致同一个体不同组织、同一组织不同细胞、同一细胞的不同线粒体，甚至同一线粒体内有不同的`mtDNA`拷贝，这称为`异质性（heteroplasmy）`。\n\n### 不同的遗传密码\n在`mtDNA`遗传密码中，有4个密码子的含义与通用密码（nDNA的遗传密码）不同。\n\n### 母系遗传\n\n在精卵结合时，卵母细胞拥有上万万拷贝的`mtDNA`，而精子中只有很少的线粒体，受精时精子中的线粒体几乎不进入受精卵，因此，受精卵中的线粒体DNA几乎全都来自于卵子，这种受精过程中细胞质行为决定了线粒体遗传病的传递方式不符合孟德尔遗传，而是表现为`母系遗传（maternal inheritance）`，即母亲将mtDNA传递给她的子女，但只有女儿能将其mtDNA传递给下一代（图7-3）。\n\n![image-20250116225721173](/images/assets//image-20250116225721173.png)\n\n### 复制分离\n细胞分裂时，突变型和野生型`mtDNA`发生分离，随机地分配到子细胞中，使子细胞拥有不同比例的`突变型mtDNA分子`，称为复制分离。这种随机分配导致子细胞中`mtDNA`种类和比例变化，在连续的分裂过程中，子代细胞中`突变型mtDNA`和`野生型mtDNA`的比例会发生漂变，向纯质的方向发展。 \n\n### mtDNA突变率高\n`mtDNA`的结构特点决定了其`突变率高`的特点，`mtDNA`突变率比`nDNA`高10 ~20倍。 \n\n## 线粒体基因突变及相关疾病\n\n目前，已发现100多个与疾病相关的`mtDNA点突变`、200多种`mtDNA缺失和重排`。\n\n由于mtDNA基因突变可影响线粒体`氧化磷酸化功`能，使`ATP`合成减少，所以`mtDNA`突变导致的线粒体疾病多累及`能量需求旺盛的肌肉和中枢神经组织`，一旦线粒体不能提供足够的能量则可引起细胞退变甚至坏死，导致这些组织和器官功能的减退，出现相应的`临床症状`（图7-5）。\n\n![image-20250116230033066](/images/assets//image-20250116230033066.png)\n\n## 线粒体疾病的遗传特点\n\n### 母系遗传\n\n线粒体基因组存在于细胞质中，精卵结合形成的受精卵中细胞质来自卵母细胞，因此只有母亲的线粒体疾病可遗传给子女，而父亲的线粒体疾病不会遗传给后代，称为`母系遗传`（见图7-3）。但由于受精卵成熟过程中只有一小部分线粒体成熟并通过细胞分裂传给子细胞，加之细胞分裂过程中的复制分离和遗传漂变现象，所以并非女性患者的后代全部发病，而且发病年龄也不一致；甚至一些女性患者本身表型正常，但可将本病传给下一代。\n\n`线粒体疾病母系遗传与常染色体病的X连锁遗传不同`，前者只能由母亲传递给儿子和女儿，且只有女儿能传递给下一代，男性患者是不会传递给下一代的；而后者中男女患者都可以将疾病传递给下一代，且存在交叉遗传。\n\n### 阈值效应\n`mtDNA突变表型`由野生型与突变型mtDNA的`相对比例`以及`该组织对能量的依赖程度`决定的。\n\n通常突变的`mtDNA`达到一定数量时，才引起某种组织或器官的功能异常，这种能引起特定组织器官功能障碍的突变`mtDNA`的最小数量称为阈值。 \n\n### 核质协同性\n`线粒体疾病`受`线粒体基因组`和`核基因组`两套遗传系统共同控制，表现为`核质协同作用`的特点。\n\n# 人类染色体\n\n## 人类染色体的基本特征\n\n### 染色质和染色体\n\n`染色质（chromatin）和染色体实质上是同一物质在不同细胞周期、执行不同生理功能时不同的存在形式`。\n\n在细胞从间期到分裂期过程中，染色质通过螺旋化凝缩（condensation）成为`染色体`，而在细胞从分裂期到间期过程中，染色体又解螺旋舒展成为`染色质`。\n\n#### 染色质\n\n染色质是间期细胞核中伸展开的 `DNA 蛋白质纤维`。间期细胞核的染色质可根据其所含核蛋白分子螺旋化程度以及功能状态的不同，分为`常染色质（euchromatin）和异染色质（heterochromatin）`。\n\n1. `常染色质和异染色质`。`常染色质`在细胞间期螺旋化程度低，呈松散状，染色较浅而均匀，含有单一或重复序列的 DNA，具有转录活性，常位于间期细胞核的中央部位。`异染色质`在细胞间期螺旋化程度较高，呈凝集状态，而且染色较深，多分布在核膜内表面，其 DNA 复制较晚，含有重复 DNA 序列，很少进行转录或无转录活性，是间期核中不活跃的染色质。\n2. `性染色质`。 性染色质（sex chromatin）是性染色体（X 和 Y）在间期细胞核中显示出来的一种特殊结构，包括 X 染色质和 Y 染色质。\n\n#### 染色体\n\n`染色质`由无数个重复的`核小体`（nucleosome）单位构成。\n\n核小体则由 4 种`组蛋白`（`H2A、H2B、H3、H4各2个分子`）组成的`八聚体`核心表面围以长约 146bp 的 `DNA双螺旋` 所构成：\n\n![image-20250116231309060](/images/assets//image-20250116231309060.png)\n\n### 人类染色体的数目、 结构和形态\n\n不同物种生物的染色体数目、结构和形态各不相同，而同一物种的染色体数目、结构和形态则是相对恒定的。\n\n#### 人类染色体的数目\n\n在真核生物中，一个正常生殖细胞（配子）中所含的全套染色体称为一个染色体组，其所包含的全部基因称为一个`基因组（genome）`。\n\n具有一个染色体组的细胞称为`单倍体`（haploid），以 `n` 表示；具有两个染色体组的细胞称为二倍体（diploid），以 `2n` 表示。人类正常体细胞染色体数目是 46，即 `2n=46` 条，正常生殖细胞（精子或卵子）中染色体数为 23 条，即 `n=23` 条。\n\n#### 人类染色体的结构、形态\n\n每一中期染色体都具有两条染色单体（chromatid），互称为`姊妹染色单体`，它们各含有一条 DNA 双螺旋链。两条单体之间由着丝粒（centromere）相连接，着丝粒处凹陷缢窄为`初级缢痕`或`主缢痕`（primary constriction）。\n\n`着丝粒`是纺锤体附着的部位，在细胞分裂中与`染色体的运动`密切相关，失去着丝粒的染色体片段通常不能在分裂后期向两极移动而丢失。着丝粒将染色体划分为短臂（p）和长臂（q）两部分。`在短臂和长臂的末端分别有一特化部位，称为端粒（telomere）`。`端粒`起着维持染色体形态结构的稳定性和完整性的作用。\n\n![image-20250116231717358](/images/assets//image-20250116231717358.png)\n\n## 性别决定及性染色体\n\n人类性别是由细胞中的性染色体所决定的。\n\n在人类的体细胞中有23对染色体，其中22对染色体与性别无直接关系，称为`常染色体（autosome）`。\n\n常染色体中的每对同源染色体的形态、结构和大小都基本相同；而另外一对与性别决定有明显而直接关系的染色体称为`性染色体（sex chromosome）`，其中包括X染色体和Y染色体。\n\n两条性染色体的形态、结构和大小都有明显的差别。男性的性染色体组成为XY，而女性的性染色体组成为XX，即男性为异型性染色体，女性为同型性染色体。这种性别决定方式为`XY型性别决定`。人类的性别是精子和卵子在受精的瞬间决定的，确切地说是由精子决定的。在自然状态下，不同的精子与卵子的结合是随机的，因而人类的男女比例大致保持1:1。\n\n很显然，性别是由精子中带有的X染色体或Y染色体所决定的，而X染色体和Y染色体在人类性别决定中的作用并不相等。一个个体无论其有几条X染色体，只要有Y染色体就决定男性表型（睾丸女性化患者除外）。\n\n# 染色体畸变\n\n染色体畸变可分为`数目畸变(numerical aberration)`和`结构畸变(structural aberration)`两大类，其中染色体的`数目畸变`又可分为`整倍性改变`和`非整倍性改变`。\n\n无论数目畸变，还是结构畸变，其实质是涉及染色体或染色体节段上基因群的增减或位置的转移，使遗传物质发生了改变，结果都可以导致染色体异常综合征，或染色体病。\n\n## 染色体畸变发生的原因\n\n### 化学因素\n\n许多化学物质，如一些化学药品、农药、毒物和抗代谢药等，都可以引起染色体畸变。据调查，长期接触苯、甲苯等化学品的人群，出现染色体数目异常和发生染色体断裂的频率远高于一般人群。农药中的除草剂和杀虫的神经剂等都是一些染色体畸变的诱变剂。\n\n#### 药物\n某些药物可引起人类染色体畸变或产生畸形胚胎。已有研究证实，`环磷酰胺`、`氮芥`、`白消安（马利兰）`、`氮甲蝶啶`、`阿糖胞苷`等抗癌药物可导致染色体畸变；抗疟疾药物`采妥英钠`可引起人淋巴细胞多倍体细胞数增高。\n\n#### 农药\n许多化学合成的农药可以引起人类细胞染色体畸变。如某些有机磷农药可使染色体畸变率增高，如`美曲磷酯`类农药。\n\n#### 工业毒物\n工业毒物如苯、甲苯、铅、砷、二硫化碳、氯丁二烯、氯乙烯单体等，都可以导致染色体畸变。长期接触这些有害毒物的工人，其染色体的畸变率增高。\n\n#### 食品添加剂\n某些食品的防腐剂和色素等添加剂中所含的化学物质可以引起人类染色体发生畸变，如`硝基咪啶基糖酞胺AF-2`、`环己基糖精`等。\n\n### 物理因素\n\n细胞到电离辐射后，可引起细胞内染色体发生异常。畸变率随射线剂量的增高而增高；`最常见的畸变类型有染色体断裂、缺失、双着丝粒染色体、易位、核内复制、不分离`等，这些畸变都可使个体的性状出现异常。\n\n射线的作用包括对体细胞和生殖细胞两方面，如果一次照射大剂量的射线，可在短期内引起造血障碍而死亡。长期接受射线治疗或从事与放射线相关工作的人员，由于微小剂量的射线不断积累，会引起体细胞或生殖细胞染色体畸变。\n\n### 生物因素\n\n导致染色体畸变的生物因素包括两类：\n\n①由生物体产生的生物类毒素；\n\n②某些生物体如病毒本身可引起染色体畸变；\n\n`真菌毒素`具有一定的致癌作用，同时也可引起细胞内染色体畸变。如`朵色曲霉素`、`黄曲毒素`、`棒曲毒素`等均可引起染色体畸变；\n\n病毒也可引起宿主细胞染色体畸变，尤其是那些致癌病毒，其原因主要是影响DNA代谢。\n\n当人体感染某些病毒，如`风疹病毒`、`乙肝病毒`、`麻疹病毒`和`巨细胞病毒`时，就有可能引发染色体的畸变。如果用病毒感染离体培养的细胞将会出现各种类型的染色体异常。\n\n### 母亲年龄\n\n当母亲年龄增大时，其所生子女的体细胞中`某一序号染色体有3条的情况要多于一般人群`。\n\n母亲年龄越大（大于35岁），生育`Down综合征`患儿的危险性就越高。但母亲生育年龄只是环境致畸变因子在体内累积作用的表现形式，这与生殖细胞老化及合子早期所处的宫内环境有关。\n\n一般认为，生殖细胞在母体内停留的时间越长，受到各种因素影响的机会越多，在之后的减数分裂过程中，越容易产生染色体不分离而导致染色体数目异常。\n\n## 染色体数目异常及其产生机制\n\n人体正常生殖细胞精子和卵子所包含的全部染色体称为一个染色体组。\n\n因此，`精子和卵子为单倍体(haploid)`，以n表示，分别含有22条常染色体和1条性染色体。\n\n`受精卵则为二倍体(diploid)`，以2n表示，包括22对常染色体和1对性染色体。\n\n以人二倍体数目为标准，体细胞的染色体数目（整组或整条）的增加或减少，称为`染色体数目畸变`。包括整倍性改变和非整倍性改变两种形式。\n\n### 整倍性改变\n\n如果染色体的数目变化是单倍体n的整倍数，即以n为基数，成倍的增加或减少，则称为`整倍性(euploidy)`改变。\n\n在2n的基础上，增加一个染色体组n，则染色体数为3n，即`三倍体(triploid)`；若在2n的基础上增加2个n，则为4n，即`四倍体(tetraploid)`。\n\n`三倍体以上的又称为多倍体(polyploid)`。如果在2n的基础上减少一个染色体组，则称为`单倍体`。\n\n### 非整倍性改变\n\n一个体细胞的染色体数目增加或减少了一条或数条，称`非整倍性(aneuploidy)`改变，这是临床上最常见的染色体畸变类型。发生非整倍性改变后，会产生`亚二倍体(hypodiploid)`、`超二倍体(hyperdiploid)`等。\n\n#### 亚二倍体\n当体细胞中染色体数目少了1条或数条时，称为亚二倍体，可写作2n-m（其中m<n）。若果对染色体少了1条（2n-1），细胞染色体数目为45，即构成`单体型(monosomy)`。临床上常见的单体型有`21号、22号和X染色体的单体型`。\n\n#### 超二倍体\n当体细胞中染色体数目多了一条或数条时，称为超二倍体，可写作2n+m（其中m<n）。在超二倍体的细胞中某一同源染色体的数目不是2条，而是3条，4条……\n\n若某对染色体多了一条（2n+1），细胞内染色体数目为47，即构成该染色体的`三体型(trisomy)`，这是人类染色体数目畸变中最常见、种类最多的一类畸变。由于染色体的增加，特别是较大染色体的增加，将造成基因组的严重失衡而破坏或干扰了胚胎的正常发育，故绝大部分常染色体三体型核型只见于早期流产的胚胎。少数三体型病例可以存活至出生，但多数寿命不长，并伴有各种严重畸形。\n\n三体型以上的非整倍性统称为`多体型(polysomy)`，如四体型、五体型等。多体型常见于性染色体中。\n\n同时存在两种或两种以上核型的细胞系的个体称`嵌合体(mosaic)`。嵌合体可以是数目异常之间、结构异常之间以及数目和结构异常之间的嵌合。\n\n有时细胞中某些染色体的数目发生了异常，其中有的增加，有的减少，而增加和减少的染色体数目相等，结果是染色体总数不变，还是二倍体数（46条），但不是正常的二倍体核型，则称为`假二倍体(pseudodiploid)`。\n\n### 非整倍体的产生原因\n\n多数非整倍体的产生原因是在生殖细胞成熟过程或受精卵早期卵裂中，发生了染色体不分离或染色体丢失。\n\n#### 染色体不分离\n\n在细胞分裂进入中、后期时，如果某一对同源染色体或姐妹染色单体彼此没有分离，而是同时进入同一个子细胞，结果所形成的两个子细胞中，一个将因染色体数目增多而成为超二倍体，另一个则因染色体数目减少而成为亚二倍体，这个过程称为`染色体不分离（non-disjunction）`。\n\n染色体不分离可以发生在细胞的有丝分裂过程中，也可以发生在配子形成时的减数分裂过程。\n\n1. 染色体不分离发生在受精卵卵裂早期的有丝分裂过程 \n\n2. 减数分裂时发生染色体不分离  \n\n\n![image-20250116233710636](/images/assets//image-20250116233710636.png)\n\n#### 染色体丢失\n\n`染色体丢失（chromosome lose）`又称`染色体分裂后期滞带（anaphase lag）`，在细胞有丝分裂过程中，某一染色体未与纺锤丝相连，不能移向两极参与新细胞的形成，或者在移向两极时行动迟缓，滞留在细胞质中，造成该条染色体的丢失而形成亚二倍体。染色体丢失也是嵌合体形成的一种方式。\n\n### 染色体结构畸变及其产生机制\n\n临床上常见的染色体结构畸变有：`缺失、重复、易位、倒位、环状染色体和等臂染色体`等。染色体断裂及断裂片段的重接是各种染色体结构畸变产生的基本机制。\n\n#### 缺失\n\n`缺失（deletion）`是染色体片段的丢失，缺失使位于这个片段的基因也随之发生丢失。按染色体断点的数量和位置可分为末端缺失和中间缺失两类：\n\n1. `末端缺失（terminal deletion）`指染色体的臂发生断裂后，末发生重接，无着丝粒的片段不能与纺锤丝相连，在细胞分裂后期未能移至两极而丢失。如图9-3A所示，1号染色体长臂的2区1带发生断裂，其远侧段（q21→qter）丢失。这条染色体是由短臂的末端至长臂的2区1带所构成。\n\n2. `中间缺失（interstitial deletion）`指一条染色体的同一臂上发生了两次断裂，两个断点之间的无着丝粒片段丢失，其余的两个断片重接。如图9-3B所示，3号染色体长臂上的q21和q31发生断裂和重接，这两断点之间的片段丢失。\n\n\n![image-20250116234114034](/images/assets//image-20250116234114034.png)\n\n#### 重复\n\n`重复（duplication）`是一条染色体上某一片段增加了一份以上的现象，使这些片段的基因多了一份或几份。原因是同源染色体之间的不等交换或姐妹染色单体之间的不等交换以及染色体片段的插入等。\n\n#### 倒位\n\n`倒位（inversion）`是某一染色体发生两次断裂后，两断点之间的片段旋转180°后重接，造成染色体上基因顺序的重排。染色体的倒位可以发生在同一臂（长臂或短臂）内，也可以发生在两臂之间，分别称为臂内倒位和臂间倒位：\n\n1. `臂内倒位（paracentric inversion）`：一条染色体的某一臂上同时发生了两次断裂，两断点之间的片段旋转180°后重接。例如1号染色体p22和p34同时发生了断裂，两断点之间的片段倒转后重接，形成了一条臂内倒位的染色体（图9-4A）。\n\n2. `臂间倒位（pericentric inversion）`：一条染色体的长、短臂各发生了一次断裂，中间断片颠倒后重接，则形成了一条臂间倒位染色体。如2号染色体的p15和q21同时发生了断裂，两断点之间的片段倒转后重接，形成了一条臂间倒位染色体（图9-4B）。\n\n![image-20250116234036734](/images/assets//image-20250116234036734.png)\n\n#### 易位\n\n一条染色体的断片移接到另一条非同源染色体的臂上，这种结构畸变称为`易位（translocation）`。常见的易位方式有相互易位、罗伯逊易位和插入易位等。\n\n1. `相互易位（reciprocal translocation）`是两条染色体同时发生断裂，断片交换位置后重接，形成两条衍生染色体（derivative chromosome）。当相互易位仅涉及位置的改变而不造成染色体片段的增减时，称为平衡易位。如2号染色体长臂2区1带和5号染色体长臂3区1带同时发生了断裂，两断片交换位置后重接，形成两条衍生染色体（图9-5）。\n2. `罗伯逊易位（Robertsonian translocation）`又称`着丝粒融合（centric fusion）`。这是发生于近端着丝粒染色体的一种易位形式。当两个近端着丝粒染色体在着丝粒部位或着丝粒附近部位发生断裂后，两者的长臂在着丝粒处接合在一起，形成一条由两条染色体的长臂构成的衍生染色体；两个短臂则构成一个小染色体，小染色体往往在第一次分裂时丢失（图9-6）。\n3. `插入易位（insertional translocation）`，两条非同源染色体同时发生断裂，但只有其中一条染色体的片段插入到另一条染色体的非末端部位。只有发生了三次断裂时，才可能发生插入易位。\n\n![image-20250116234348391](/images/assets//image-20250116234348391.png)\n","categories":["医学遗传学"]},{"title":"DNABERT：针对基因组DNA语言的预训练双向编码器Transformers模型","url":"/2024/11/15/yete4apn/","content":"\n# 文章链接\n\n> Ji Y, Zhou Z, Liu H, Davuluri RV. DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome. Bioinformatics. 2021;37(15):2112-2120. [https://doi.org/10.1093/bioinformatics/btab083](https://doi.org/10.1093/bioinformatics/btab083)\n\n# 简介\n\n`DNABERT`：提出了一个针对基因组DNA语言的预训练双向编码器`Transformers`模型\n\n# 摘要\n\n**动机**：破译非编码DNA的语言是基因组研究中的一个基本问题。由于多义性和远距离语义关系的存在，基因调控密码高度复杂，而以往的信息学方法在数据稀缺的情况下往往难以捕捉这些特征。\n\n**结果**：为应对此挑战，我们开发了一种新型的预训练双向编码器表示模型，命名为`DNABERT`，基于上下游核苷酸上下文来捕获基因组DNA序列的全局和可迁移理解。我们将`DNABERT`与目前最广泛使用的基因组调控元件预测程序进行了比较，展示了其易用性、准确性和效率。我们证明，单个预训练的`transformers`模型在使用少量任务特定标记数据进行简单微调后，可以同时在启动子、剪接位点和转录因子结合位点的预测上达到最先进的性能。此外，`DNABERT`可以直接可视化输入序列中核苷酸级别的重要性和语义关系，从而提供更好的可解释性，并准确识别保守序列基序和功能性遗传变异候选。最后，我们展示了用人类基因组预训练的`DNABERT`甚至可以直接应用于其他生物体并取得出色的表现。我们预期预训练的`DNABERT`模型可以微调用于许多其他序列分析任务。\n\n**可用性和实现**：`DNABERT`的源代码、预训练模型和微调模型可在GitHub获取（[https://github.com/jerryji1993/DNABERT](https://github.com/jerryji1993/DNABERT)）。\n\n# 创新点\n\n1. 模型创新：\n- 首次将`BERT`架构应用于DNA序列分析，开发了名为`DNABERT`的预训练模型\n- 创新性地使用`k-mer`表示方法对DNA序列进行分词，更好地捕捉局部上下文信息\n- 开发了`DNABERT-XL`版本以处理超长序列\n\n2. 技术优势：\n- 通过注意力机制可以全局捕获序列上下文信息\n- 采用\"自上而下\"的方法，先通过自监督预训练理解DNA语言的一般特征，再应用于具体任务\n- 在数据稀缺的情况下仍能实现良好性能\n\n3. 应用创新：\n- 实现\"一个模型解决多个任务\"：同一个预训练模型可以通过简单微调应用于启动子、剪接位点和转录因子结合位点预测等多个任务\n- 开发了`DNABERT-viz`模块，提供了直观的可视化功能，增强了模型的可解释性\n- 能够识别功能性遗传变异\n\n这些创新使得`DNABERT`在DNA序列分析领域具有重要的理论价值和实际应用价值。\n\n# 主要内容\n\n## 读前须知\n\n1. 论文解读尽可能的还原原文，若有不恰当之处，还请见谅；\n2. 排版上，插图会尽量贴近出处，而`补充图表`均在文末“`支撑性材料`”的下载链接中；\n3. 左边👈有目录，可自行跳转至想看的部分；\n4. 部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（`Receptive field`）。请注意，仅首次出现会标明；\n\n## 引言\n\n破译DNA中隐藏的`指令语言`一直是生物研究中的主要目标之一。虽然解释DNA如何转译成蛋白质的遗传密码是通用的，但决定`基因何时以及如何表达`的调控密码却在不同的细胞类型和生物体中存在差异。相同的`顺式调控元件(CREs)`在不同的生物学环境中常常具有不同的功能和活性，而远距离分布的多个CREs可能会相互协作，导致在不同功能角色下对替代启动子的依赖性使用。这些观察结果表明序列编码中存在多义性和远距离语义关系，这些都是自然语言的关键特征。先前的语言学研究证实了DNA，尤其是非编码区域，确实表现出与人类语言极大的相似性，从字母和词汇到语法和语音学都有体现。然而，CREs的语义(即功能)如何随不同的上下文(上游和下游核苷酸序列)而变化仍然大部分未知。\n\n近年来，通过成功地将深度学习技术应用于基因组序列数据,已开发出许多计算工具来研究`顺式调控`景观的各个方面，包括DNA-蛋白质相互作用、染色质可及性、非编码变异等。大多数方法采用基于`卷积神经网络(CNN)`的架构。其他工具关注DNA的序列特征，试图通过应用基于`递归神经网络(RNN)`的模型来捕获状态之间的依赖关系，如`长短期记忆(LSTM)`和`门控循环单元(GRU)`网络。一些混合方法也被提出来整合这两种模型架构的优点。\n\n为了更好地将DNA建模为一种语言，理想的计算方法应该：\n\n1. 全局考虑所有上下文信息以区分多义CREs；\n\n2. 发展可转移到各种任务的通用理解；\n\n3. 在标记数据有限的情况下具有良好的泛化能力。\n\n然而，`CNN`和`RNN`架构都无法满足这些要求。`CNN`通常无法捕获长程上下文中的语义依赖关系，因为其提取局部特征的能力受限于过滤器大小。`RNN`模型(`LSTM`、`GRU`)虽然能够学习长期依赖关系，但当它顺序处理所有过去的状态并将上下文信息压缩到具有长输入序列的瓶颈时，大大受到梯度消失和低效率问题的影响。此外，大多数现有模型需要大量标记数据，导致在数据稀缺的情况下性能和适用性有限，而在这种情况下，获取高质量的标记数据是昂贵且耗时的。\n\n为了解决上述限制，我们采用了`双向编码器表示Transformers(BERT)`模型的理念，将其应用于基因组DNA领域，开发了一种称为`DNABERT`的深度学习方法。`DNABERT`应用`Transformer`，这是一种基于注意力的架构，在大多数自然语言处理任务中都取得了最先进的性能。我们证明`DNABERT`通过以下方式解决了上述挑战：\n\n1. 从纯未标记的人类基因组中发展出一般且可迁移的理解，并以\"一个模型解决所有问题\"的方式通用地解决各种序列相关任务；\n\n2. 通过注意力机制全局捕获整个输入序列的上下文信息；\n\n3. 在数据稀缺场景中取得出色的性能；\n\n4. 无需任何人工指导即可发现DNA序列中的重要子区域和不同顺式元件之间的潜在关系；\n\n5. 成功地以跨生物体的方式工作。\n\n由于`DNABERT`模型的预训练需要大量资源(在8个`NVIDIA 2080Ti GPUs`上约需25天)，作为本研究的主要贡献，我们在GitHub上提供了源代码和预训练模型供未来的学术研究使用。\n\n> `transformer架构`可参考这篇文章：{% postLinkCard skrzswes  \"auto\" %}\n\n## 模型与方法\n\n### DNABERT模型\n\n`BERT`是一种基于`transformer`的上下文化语言表示模型，在许多自然语言处理(`NLP`)任务中取得了超人的表现。它引入了预训练和微调的范式，首先从大量未标记的数据中发展通用理解，然后通过最小的架构修改使用特定任务的数据解决各种应用。`DNABERT`遵循与`BERT`相同的训练过程。\n\n![image-20241215205007485](/images/assets//image-20241215205007485.png)\n\n`DNABERT`首先将一组用`k-mer`标记表示的序列作为输入(图1b)。每个序列通过将每个标记嵌入到一个数值向量中而表示为一个矩阵M。从形式上讲，`DNABERT`通过对M执行多头自注意力机制来捕获上下文信息:\n$$\n\\text {MultiHead}(M) = \\text {Concat}(head_1,...,head_h)W^O\n$$\n其中：\n\n$$\n\\text {head}_i = \\text {softmax}(\\frac{MW^Q_i(MW^{K}_i)^T}{\\sqrt{d_k}})MW^V_i\n$$\n$W^O$ 和 ${W^Q_i, W^K_i, W^V_i}$ 是用于线性投影的学习参数。\n\n`head`通过首先计算每两个标记之间的注意力分数，然后利用它们作为权重来汇总 $MW^V_i$ 中的行，从而计算M的下一个隐藏状态。$\\text {MultiHead()}$ 将h个独立头部的结果与不同的 ${W^Q_i, W^K_i, W^V_i}$ 集合连接起来。整个过程执行L次，L为层数。\n\n与`BERT`类似，`DNABERT`也采用预训练-微调方案(图1c)。然而，我们通过删除下一句预测、调整序列长度以及强制模型预测连续k个标记来显著修改了预训练过程，以适应DNA场景。在预训练过程中，`DNABERT`通过自监督学习掌握DNA的基本语法和语义，基于从人类基因组中通过截断和采样提取的长度为10到510的序列。对于每个序列，我们随机掩盖构成序列15%的k个连续标记区域，让`DNABERT`基于剩余部分预测被掩盖的序列，确保充足的训练样本。我们使用交叉熵损失预训练`DNABERT`：\n$$\nL = \\sum_{i=0}^N y'_i log(y_i)\n$$\n这里，$y'_i$ 和 $y_i$ 分别是N个类别中每个类别的真实概率和预测概率。预训练的`DNABERT`模型可以用特定任务的训练数据进行微调，用于各种序列级和标记级预测任务的应用。我们将`DNABERT`模型在三个特定应用上进行了微调——启动子预测、转录因子结合位点(`TFBSs`)预测和剪接位点预测——并将训练好的模型与当前最先进的工具进行了基准比较。\n\n### DNABERT模型的训练\n\n#### 标记化\n\n与将每个碱基视为单个标记不同，我们使用`k-mer`表示法对DNA序列进行标记化，这是一种在分析DNA序列时被广泛使用的方法。`k-mer`表示通过将每个脱氧核苷酸碱基与其后续碱基连接起来，为其整合了更丰富的上下文信息。它们的连接被称为一个`k-mer`。例如，一个DNA序列\"`ATGGCT`\"可以被标记化为四个`3-mer`：{`ATG`, `TGG`, `GGC`, `GCT`}或两个`5-mer`：{`ATGGC`, `TGGCT`}。由于不同的k会导致DNA序列的不同标记化。在我们的实验中，我们分别将k设置为`3`、`4`、`5`和`6`，并训练了4个不同的模型：`DNABERT-3`、`DNABERT-4`、`DNABERT-5`、`DNABERT-6`。对于`DNABERT-k`，它的词汇表由所有`k-mer`的排列组合以及5个特殊标记组成：`[CLS]`代表分类标记；`[PAD]`代表填充标记，`[UNK]`代表未知标记，`[SEP]`代表分隔标记，`[MASK]`代表掩码标记。因此，在`DNABERT-k`的词汇表中有`4k+5`个标记。\n\n#### 预训练\n\n跟随之前的工作，`DNABERT`以最大长度为`512`的序列作为输入。如图1b所示，对于一个DNA序列，我们首先将其标记化为一系列`k-mers`，并在其开始处添加一个特殊的`[CLS]`标记(代表整个序列)，以及在末尾添加一个特殊的`[SEP]`标记(表示序列结束)。在预训练步骤中，我们掩盖了某些`k-mers`的连续k长度跨度(总计输入序列的15%)，考虑到一个标记可能会从紧邻的`k-mers`中被轻易推断出来，而在微调时，我们跳过掩码步骤，直接将标记化的序列输入到嵌入层。\n\n我们通过两种方法从人类基因组生成训练数据：直接非重叠分割和随机采样，序列长度在5到510之间。我们以2000的批量大小对`DNABERT`进行了120k步的预训练。在前100k步中，我们在每个序列中掩盖了15%的`k-mers`。在最后20k步中，我们将掩码率提高到20%。学习率在前10k步中从0线性增加(即预热)到$4\\times10^{-4}$，然后在200k步后线性降至`0`(补充图S1)。我们在`120k`步后停止训练过程，因为我们发现损失曲线出现了平稳的迹象。\n\n我们使用与`BERT base`相同的模型架构，它由12个`Transformer`层组成，每层有768个隐藏单元和12个注意力头，并在预训练期间对所有四个`DNABERT`模型使用相同的参数设置。我们在配备8个`Nvidia2080Ti GPUs`的机器上使用混合精度浮点运算训练每个`DNABERT`模型。\n\n#### 微调\n\n对于每个下游应用，我们从预训练参数开始，使用特定任务的数据对`DNABERT`进行微调。我们在所有应用中都使用了相同的训练技巧，即学习率首先线性预热到峰值，然后线性衰减到接近0。我们使用固定权重衰减的`AdamW`作为优化器，并对输出层采用了`dropout`。我们将训练数据分为训练集和开发集用于超参数调优。对于不同k值的`DNABERT`，我们稍微调整了峰值学习率。详细的超参数设置列在补充表S5中。\n\n对于长度超过512的序列，我们将它们分割成片段并连接它们的表示作为最终表示。这使得`DNABERT`能够处理超长序列(`DNABERT-XL`)。`k = 3`、`4`、`5`、`6`的`DNABERT`都取得了非常相似的性能，只有轻微波动。在所有实验中，我们报告`kmer=6`的结果，因为它取得了最佳性能。\n\n### 结果\n\n#### DNABERT-Prom能够有效预测近端和核心启动子区域\n\n预测基因启动子是生物信息学中最具挑战性的问题之一。我们首先评估了预训练模型在识别近端启动子区域方面的表现。为了公平地与具有不同序列长度设置的现有工具进行比较，我们使用来自`真核生物启动子数据库(EPDnew)`的长度为`10000bp`的人类`TATA`和非`TATA`启动子，对两个模型进行了微调，分别命名为`DNABERT-Prom-300`和`DNABERT-Prom-scan`。我们使用`TSS`周围从`-249`到`50bp`的序列作为正例，随机选择的`300bp`长度含`TATA`序列作为`TATA`负例，以及二核苷酸打乱的序列作为非`TATA`负例，将`DNABERT-Prom-300`与`DeePromoter`进行了比较。我们使用基于`10000bp`长序列的滑动窗口扫描，将`DNABERT-Prom-scan`与当前可用的方法进行了比较，包括最新的最先进方法`PromID`、`FPROM`和我们之前的软件`FirstEF`。为了适当地在相同设置下与`PromID`进行基准比较，我们使用了`1001bp`长的扫描，这超出了传统`BERT`模型的长度容量。因此，我们专门为此任务开发了`DNABERT-XL`。我们使用与`PromID`相同的评估标准，通过扫描序列并将预测与已知`TSS`的`-500`到`+500bp`重叠。与已知`TSS`的`-500`到`+500bp`重叠≥50%的`1001bp`序列被视为阳性，其余的被视为阴性。对于`PromID`和`FPROM`，测试集被直接输入进行评估。相比之下，`FirstEF`首先生成全基因组预测，然后将其与阳性序列对齐。\n\n`DNABERT-Prom`在不同设置下通过显著提高的准确性指标超越了所有其他模型(图2)。具体而言，对于`prom-300`设置下的`TATA`启动子，`DNABERT-Prom-300`在准确率和`MCC`指标上分别超过`DeePromoter` `0.335`和`0.554`(图2a)。同样，我们在非`TATA`和组合情况下也观察到`DNABERT-Prom`的性能显著提高(补充图S2)。同时，`prom-scan`设置本质上更加困难，因为类别高度不平衡，所以所有测试的基准模型表现都很差。在基准模型中，`FirstEF`取得了最好的性能，在`TATA`、非`TATA`和组合数据集的`F1`得分分别为`0.277`、`0.377`和`0.331`(图2b)。然而，`DNABERT-Prom-scan`取得的`F1`得分和`MCC`远超`FirstEF`。\n\n![image-20241215205652155](/images/assets//image-20241215205652155.png)\n\n接下来，我们评估了我们的模型在核心启动子上的预测性能，这是一个由于序列上下文大小减少而更具挑战性的问题。我们使用了以`TSS`为中心的`Prom-300`数据中的`70bp`，并与`CNN`、`CNN+LSTM`和`CNN+GRU`进行了比较。`DNABERT-Prom-core`在不同数据集上明显优于所有三个基准模型(图2c-g)，清楚地表明`DNABERT`可以被可靠地微调，仅依靠`TSS`区域附近的序列模式就能准确预测长的近端启动子和较短的核心启动子。为了进一步证明`DNABERT-XL`的有效性，我们还在`301bp`长序列和`2001bp`长序列上进行了实验。实验表明，该模型在预测`2001 bp`长序列时取得了更好的性能(补充表S7)。\n\n#### DNABERT-TF能准确识别转录因子结合位点\n\n第二代测序技术以前所未有的方式促进了基因组调控区域的全基因组鉴定，揭示了基因调控的复杂性。在分析体内基因组范围内结合相互作用数据时，一个重要步骤是预测目标顺式调控区域中的`转录因子结合位点(TFBS)`并整理得到的转录因子结合谱。因此，我们使用来自`ENCODE`数据库的`690`个`TF ChIP-seq`统一峰值谱来微调`DNABERT-TF`模型，以预测`ChIP-seq`富集区域中的`TFBS`，并与广泛使用的和之前发表的`TFBS`预测工具进行了比较，包括`DeepBind`、`DeepSEA`、`Basset`、`DeepSite`、`DanQ`和`DESSO`。\n\n`DNABERT-TF`是唯一一个平均和中位数准确率和`F1`值都超过`0.9`的方法（图3，`0.918`和`0.919`），大大超过第二好的竞争者（`DeepSEA`，`Wilcoxon`单侧符号秩检验，n=690，校正后P=$4.5×10^{-100}$和$1×10^{-98}$，对于平均值）。其他工具在某些实验中产生了许多假阳性（FP）和假阴性（FN）预测，导致在比较平均值时表现更不令人满意，这是由于分布的偏斜性。几个工具在使用高质量数据的实验中，在找到真阴性（TN）方面与`DNABERT`表现相当，但在低质量实验数据的预测中表现较差。相比之下，即使在低质量数据上，`DNABERT`也实现了显著高于其他工具的召回率（图3，中左）。同时，无论实验质量如何，`DNABERT-TF`产生的假阳性预测都比任何其他模型少得多（图3，右上）。这些结果在使用有限数量峰值的`ChIP-seq`谱的基准测试中得到进一步支持，其中`DNABERT-TF`始终优于其他方法（见补充图S3）。\n\n![image-20241215205846968](/images/assets//image-20241215205846968.png)\n\n为了评估我们的方法是否能有效区分多义的顺式调控元件，我们关注了`p53`家族蛋白（它们识别相同的基序），并研究了`TAp73-alpha`和`TAp73-beta`亚型之间结合特异性的上下文差异。我们将来自`GEO`数据集`GSE15780`的`p53`、`TAp73-alpha`和`TAp73-beta ChIP-seq`峰值与我们的`P53Scan`程序预测的结合位点重叠，并使用得到的`ChIP-seq`特征化`BS`（`35bp`）来微调我们的模型。`DNABERT-TF`在个别`TF`的二元分类上实现了接近完美的表现（`0.99`）（见补充表S2）。使用具有更宽上下文（`500bp`）的输入序列，`DNABERT-TF`能有效区分两种`TAp73`亚型，准确率达到`0.828`（见补充表S2）。总之，`DNABERT-TF`可以根据不同的上下文窗口准确识别甚至非常相似的`TFBS`。\n\n#### DNABERT-viz 实现重要区域、上下文和序列基序的可视化\n\n为了克服常见的\"黑箱\"问题，深度学习模型需要在与传统方法相比表现出色的同时保持可解释性。因此，为了总结和理解微调后的`DNABERT`模型基于哪些重要序列特征做出分类决策，我们开发了`DNABERT-viz`模块，用于直接可视化对模型决策有贡献的重要区域。我们证明，由于注意力机制的存在，`DNABERT`天生适合在`DNA`序列中找到重要模式并理解它们在上下文中的关系，从而确保了模型的可解释性。\n\n图4a显示了三个`TAp73-beta`响应元件的学习到的注意力图，其中`DNABERT-viz`以无监督的方式准确确定了`P53Scan`预测的`TFBS`的位置和得分。然后，我们汇总了所有热图，在`Prom-300`和`ENCODE 690 TF`的测试集上产生注意力景观。对于`TATA`启动子，`DNABERT`始终在`TSS`上游`-20`到`-30bp`区域（`TATA`框所在位置）表现出高度注意力，而对于大多数非`TATA`启动子，则观察到更分散的注意力模式（图4）。这种模式也在`TF-690`数据集中看到，每个峰值都显示出一组不同的高注意力区域，其中大多数分散在峰值中心周围（补充图S4）。我们特别关注了个别`ChIP-seq`实验的例子，以更好地理解注意力模式。大多数高质量实验都显示在`ChIP-seq`峰值中心或`TFBS`区域周围的注意力富集（图4和补充图S5）。相比之下，低质量实验倾向于具有分散的注意力，没有明显可观察到的模式，除了仅在序列开始处的高注意力，这可能是由于模型偏差造成的（图4d）。\n\n![image-20241215210956177](/images/assets//image-20241215210956177.png)\n\n接下来，我们扩展了`DNABERT-viz`，使其能够直接可视化任何输入序列内的上下文关系（图4e）。例如，最左边的图显示了`p53`数据集中一个输入序列的全局自注意力模式，其中来自大多数`k-mer`标记的各个注意力在所有头部中都正确地集中在二聚体`BS`的两个中心。通过观察哪些标记特别关注该位点，我们可以进一步推断`BS`与输入序列其他区域之间的相互依赖关系（图4e，右）。在注意力头部中，橙色的头部明显发现了上下文中隐藏的语义关系，因为它广泛突出了对这个重要标记`CTT`的注意力有贡献的各个短区域。此外，三个头部（绿色、紫色和粉色）成功地将这个标记与二聚体`BS`的下游一半相关联，展示了对输入序列的上下文理解。\n\n为了在许多输入序列中提取保守的基序模式，我们应用`DNABERT-viz`来寻找连续的高注意力区域，并通过超几何检验进行过滤（见补充方法）。然后将得到的显著基序实例对齐并合并，生成位置权重矩阵（`PWMs`）。通过在`ENCODE 690`数据集中发现的基序上应用`TOMTOM`程序并与`JASPAR 2018`数据库比较，我们发现发现的`1999`个基序中有`1595`个成功对齐到已验证的基序（补充图S6，q值<0.01）。通过与已记录基序的强烈相似性，说明识别的基序总体上质量很高（补充图S7）。\n\n最后，我们应用`DNABERT-viz`来理解区分`TAp73-alpha`和`beta`亚型结合位点的重要因素。注意力景观确实显示出两种亚型之间差异富集的许多短区域，其中`alpha`在中心具有更集中的高注意力，而`beta`则更分散在上下文中（补充图S8）。提取的许多强基序模式都没有对齐到`JASPAR`数据库，除了一些突出未知关系的模式（补充图S9）。重要的是，`c-Fos`、`c-Jun`和`TAp73-alpha/beta`亚型之间的差异性串扰对细胞凋亡平衡有贡献，而`DNABERT-viz`成功捕捉到了这种关系。总之，`DNABERT`可以以更直接的方式获得与基于`CNN`的模型相当的可解释性，同时在预测性能上大大超越它们。\n\n#### DNABERT-Splice准确识别经典和非经典剪接位点\n\n预测剪接位点对于揭示基因结构和理解选择性剪接机制至关重要。然而，既存在含有`GT-AG`的非剪接位点序列，又存在不含这些二核苷酸的非经典剪接位点，这给准确识别带来了困难。最近，`SpliceFinder`通过递归纳入先前误分类的假阳性序列来重建数据集，成功解决了这个问题。为了与`SpliceFinder`在相同基准数据上的性能进行比较，我们迭代重建了包含供体、受体和非剪接位点类别的相同数据集。我们还与多个基线模型进行了比较分析。\n\n正如预期的那样，由于任务过于简单化，所有模型在初始数据集上的表现都很好，尽管`DNABERT-Splice`仍然取得了最好的成绩（补充表S3）。然后，我们使用包含\"对抗样本\"的重建数据集将`DNABERT-Splice`与所有基线进行比较（图5a）。这一次，基线模型的预测性能大幅下降，而`DNABERT-Splice`仍然实现了`0.923`的最佳准确率、`0.919`的`F1`值和`0.871`的`MCC`，其`AUROC`和`AUPRC`显著优于其他模型（图5b和c），这也得到了`Mcnemar`精确检验的支持（补充图S10和S11）。此外，当在包含我们迭代训练过程中保留的滑动窗口扫描的独立测试集上进行预测时，`DNABERT-Splice`再次优于所有模型（补充表S4）。\n\n![image-20241215211144471](/images/assets//image-20241215211144471.png)\n\n我们还检查了注意力景观，以阐明模型如何做出分类决策（补充图S12）。令人惊讶的是，`DNABERT-Splice`在内含子区域（供体下游和受体上游）表现出全局一致的高注意力，突显了作为剪接`CREs`的各种内含子剪接增强子（`ISEs`）和抑制子（`ISSs`）的存在和功能重要性。\n\n#### 预训练显著提升性能并可推广到其他生物体\n\n最后，我们基于性能提升和可推广性研究了预训练的重要性。当在相同超参数下比较预训练的`DNABERT-prom-300`与随机初始化的训练损失时，预训练的`DNABERT`收敛到明显更低的损失，这表明没有预训练的随机初始化模型很快就陷入局部最小值，因为预训练通过捕获远距离上下文信息确保了对`DNA`逻辑的初步理解（图6d）。同样，随机初始化的`DNABERT-prom-core`模型要么完全无法训练，要么表现出次优性能。\n\n![image-20241215211346554](/images/assets//image-20241215211346554.png)\n\n对注意力图的检查揭示了对输入序列的逐步理解（图6e）。由于对不同生物体分别预训练`DNABERT`既耗时又需要大量资源，我们还评估了用人类基因组预训练的`DNABERT`是否也可以应用于其他哺乳动物生物体。具体来说，我们用`78`个小鼠`ENCODE ChIP-seq`数据集对用人类基因组预训练的`DNABERT`进行微调，并与`CNN`、`CNN+LSTM`、`CNN+GRU`和随机初始化的`DNABERT`进行比较。预训练的`DNABERT`显著优于所有基线模型（图6f），表明即使在不同基因组间`DNABERT`也具有稳健性和适用性。\n\n众所周知，虽然人类和小鼠基因组的蛋白质编码区域约有`85%`的同源性，但非编码区域仅显示约`50%`的全局相似性。由于`TFBS`主要位于非编码区域，`DNABERT`模型成功地将学习到的信息从一个基因组转移到一个相似度低得多的基因组，对这些差异具有很高的容忍度。这表明该模型正确捕获了不同生物体`DNA`序列中共同的深层语义。上述评估证明了预训练的必要性，并保证了预训练模型在不同生物体的众多序列预测任务中的高效应用的可扩展性。\n\n# 讨论\n\n基于`Transformers`的模型在各种自然语言处理任务、大规模电子健康记录备注和生物医学文档的生物医学和临床实体提取方面都取得了最先进的性能。之前的研究已经将`Transformers`应用于蛋白质序列和原核生物基因组。在这里，我们展示了`DNABERT`通过大大超越现有工具，在各种下游`DNA`序列预测任务中实现了卓越的性能。通过对输入序列创新性的全局上下文嵌入，`DNABERT`采用\"自上而下\"的方法来解决序列特异性预测问题，首先通过自监督预训练发展对`DNA`语言的普遍理解，然后将其应用于特定任务，这与使用特定任务数据的传统\"自下而上\"方法形成对比。\n\n`DNABERT`的这些特点确保它能更有效地从`DNA`上下文中学习，具有适应多种情况的巨大灵活性，并且在有限数据条件下性能得到提升。特别是，我们还观察到预训练的`DNABERT`在不同生物体之间具有很强的泛化能力，这确保了我们的方法无需单独预训练就能广泛应用。\n\n作为本研究的一部分发布的预训练`DNABERT`模型可以用于其他序列预测任务，例如，从`ATAC-seq`和`DAP-seq`确定`CREs`和增强子区域。此外，由于`RNA`序列与`DNA`序列仅相差一个碱基（胸腺嘧啶变成尿嘧啶），而语法和语义基本保持不变，我们提出的方法也可以应用于交联和免疫沉淀（`CLIP-seq`）数据，用于预测`RNA`结合蛋白（`RBPs`）的结合偏好。尽管对`DNA`的直接机器翻译尚不可能，但`DNABERT`的成功开发为这种可能性提供了启示。\n\n作为一个成功的语言模型，`DNABERT`正确捕获了`DNA`序列中隐藏的语法、语法规则和语义，一旦标记级标签可用，它应该在序列到序列（`Seq2seq`）翻译任务上表现同样出色。同时，`DNA`和人类语言在文本之外的其他相似方面（如选择性剪接和标点符号）突显了需要结合不同层次的数据来更恰当地破译`DNA`语言。总之，我们预期`DNABERT`通过将先进的语言建模视角带入基因调控分析，可以为生物信息学界带来新的进展和见解。\n\n# 支撑性材料\n\n本文的支撑性材料可在[这里](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/37/15/10.1093_bioinformatics_btab083/6/btab083_supplementary_data.zip?Expires=1737199066&Signature=Ei0ZDa86mUeYlE-aB7PSlBXjV70u7bWtd4u-N2Rk2psxNmFyLT83dh1Z6J8SLDl8MuEoOzycXI9uZvuzrBA0e3iX97BSKh3s1qyw7GG2ZqzZqTcoNowJM4Ue4xBRvecQVRY6FIUxxXwfTusFq-kcWRcCCfHzNVuyYyNXg3TvoWWNRrTytJnyl4f4opHe-vTHSENslUn4UNDKsxTtaVScJxEAkvLSjOufQ8qFgI7kWNe1yw3XMkUcSSpaoyTZ3XIww0hevUkIryG~QzhMakxQTydUjsoupJvcdvJQh08j7VvFh5-qXPLeZzZx5P-91xw3HjsRqcXmcnMjYQA5A11UQg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)获取。\n\n# 参考文献\n\n1. Andersson, R., Sandelin, A. (2020). Determinants of enhancer and promoter activities of regulatory elements.\n\n2. Nirenberg, M., Leder, P., Bernfield, M., Brimacombe, R., Trupin, J., Rottman, F., O'neal, C. (1965). RNA codewords and protein synthesis, VII. On the general nature of the RNA code.\n\n3. Davuluri, R.V., Suzuki, Y., Sugano, S., Plass, C., Huang, T.H.-M. (2008). The functional consequences of alternative promoter use in mammalian genomes.\n\n4. Gibcus, J.H., Dekker, J. (2012). The context of gene regulation.\n\n5. Ji, Y., Mishra, R.K., Claude, E., Moore, J.E., Lobos, C.M., Hoff, A.M., et al. (2020). Promoter-proximal pausing coordinates tissue-specific timing of gene expression.\n\n6. Vitting-Seerup, K., Sandelin, A. (2017). The landscape of isoform switches in human cancers.\n\n7. Brendel, V., Busse, H.G. (1984). Genome structure described by formal languages.\n\n8. Head, T. (1987). Formal language theory and DNA: An analysis of the generative capacity of specific recombinant behaviors.\n\n9. Ji, S. (1999). The linguistics of DNA: Words, sentences, grammar, phonetics, and semantics.\n\n10. Mantegna, R.N., Buldyrev, S.V., Goldberger, A.L., Havlin, S., Peng, C.-K., Simons, M., Stanley, H.E. (1994). Linguistic features of noncoding DNA sequences.\n\n11. Searls, D.B. (1992). The linguistics of DNA.\n\n12. Searls, D.B. (2002). The language of genes.\n\n13. Alipanahi, B., Delong, A., Weirauch, M.T., Frey, B.J. (2015). Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning.\n\n14. Kelley, D.R., Snoek, J., Rinn, J.L. (2016). Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks.\n\n15. Zhou, J., Troyanskaya, O.G. (2015). Predicting effects of noncoding variants with deep learning-based sequence model.\n\n16. Zou, J., Huss, M., Abid, A., Mohammadi, P., Torkamani, A., Telenti, A. (2019). A primer on deep learning in genomics.\n\n17. Hochreiter, S., Schmidhuber, J. (1997). Long short-term memory.\n\n18. Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.\n\n19. Hassanzadeh, H.R., Wang, M.D. (2016). DeeperBind: Enhancing prediction of sequence specificities of DNA binding proteins.\n\n20. Quang, D., Xie, X. (2016). DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences.\n\n21. Shen, Z., Bao, W., Huang, D.-S. (2018). Recurrent neural network for predicting transcription factor binding sites.\n\n22. Bengio, Y., Courville, A., Vincent, P. (2013). Representation learning: A review and new perspectives.\n\n23. LeCun, Y., Bengio, Y., Hinton, G. (2015). Deep learning.\n\n24. Devlin, J., Chang, M.-W., Lee, K., Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)\n\n25. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., et al. (2017). Attention is all you need.\n\n26. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., et al. (2019). RoBERTa: A robustly optimized BERT pretraining approach.\n\n27. Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R.R., Le, Q.V. (2019). XLNet: Generalized autoregressive pretraining for language understanding.\n\n28. Li, F., Chen, Y., Zhang, Z., Ouyang, J., Wang, Y., Meng, S., et al. (2019). Discriminating clinical phases of recovery from major depressive disorder using the dynamics of facial expression.\n\n29. Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C.H., Kang, J. (2020). BioBERT: a pre-trained biomedical language representation model for biomedical text mining.\n\n30. Clauwaert, J., Waegeman, W. (2020). Novel transformer networks for improved sequence labeling in genomics.\n\n31. Min, X., Zeng, W., Chen, S., Chen, N., Chen, T., Jiang, R. (2019). Predicting enhancers with deep convolutional neural networks.\n\n32. Gupta, S., Stamatoyannopoulos, J.A., Bailey, T.L., Noble, W.S. (2007). Quantifying similarity between motifs.\n\n33. Koeppel, M., van Heeringen, S.J., Kramer, D., Smeenk, L., Janssen-Megens, E., Hartmann, M., et al. (2011). Crosstalk between c-Jun and TAp73α/β contributes to the apoptosis-survival balance.\n\n34. Wang, Z., Burge, C.B. (2008). Splicing regulation: from a parts list of regulatory elements to an integrated splicing code.\n\n35. Buenrostro, J.D., Giresi, P.G., Zaba, L.C., Chang, H.Y., Greenleaf, W.J. (2013). Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position.\n\n36. Bartlett, A., O'malley, R.C., Huang, S.C., Galli, M., Nery, J.R., Gallavotti, A., Ecker, J.R. (2017). Mapping genome-wide transcription-factor binding sites using DAP-seq.\n\n37. Gerstberger, S., Hafner, M., Tuschl, T. (2014). A census of human RNA-binding proteins.\n\n38. Mouse Genome Sequencing Consortium (2002). Initial sequencing and comparative analysis of the mouse genome.\n\n39. Mouse ENCODE Consortium (2012). An encyclopedia of mouse DNA elements (Mouse ENCODE).\n","categories":["论文解读"]},{"title":"Transformer：Attention Is All You Need","url":"/2024/11/04/skrzswes/","content":"\n# 文章链接\n\n> Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30, 5998-6008. https://arxiv.org/pdf/1706.03762\n>\n\n# 简介\n\n提出`Transformer`模型架构，它完全基于注意力机制，摒弃了此前序列转导模型中普遍使用的循环神经网络(`RNN`)和卷积神经网络(`CNN`)结构。这是第一个完全依赖`自注意力机制`来计算输入输出表示的转导模型。\n\n# 摘要\n\n当前主流的`序列转导模型`都基于复杂的循环或卷积神经网络，包含编码器和解码器结构。性能最好的模型还通过`注意力机制（attention mechanism）`连接编码器和解码器。\n\n> `编码器和解码器`：编码器负责处理输入序列(比如源语言句子)，将其转换成一系列向量表示，这些向量编码了输入的语义和结构信息。解码器则基于这些编码向量，逐个生成输出序列(比如目标语言句子)。\n\n我们提出了一种新的简单网络架构`Transformer`，它完全基于注意力机制，彻底摒弃了循环和卷积结构。在两个机器翻译任务上的实验表明，这些模型在质量上具有优势，同时具有更好的并行性，所需训练时间大大减少。\n\n我们的模型在`WMT2014`英德翻译任务上获得了`28.4BLEU`分数，超过现有最佳结果（包括集成模型）`2个BLEU`以上。在`WMT2014`英法翻译任务上，我们的模型通过在`8个GPU`上训练`3.5天`，建立了新的单模型最高水平，达到了`41.8 BLEU`分数，仅用了文献中最佳模型训练成本的一小部分。我们还通过将其成功应用于英语句法解析任务，展示了`Transformer`具有良好的泛化能力，无论是在大规模还是受限训练数据的情况下都表现出色。\n\n> `WMT2014英德翻译`：机器翻译领域的一个重要基准测试。该数据集包含约450万个英语-德语的平行句子对作为训练数据，通常使用`newstest2014`作为测试集来评估模型性能。评估标准主要是BLEU分数，该分数越高表示机器翻译的质量越好。\n>\n> `BLEU (Bilingual Evaluation Understudy) `：一种评估机器翻译质量的指标，通过比较机器翻译结果和人工参考翻译的`n-gram重合度`来打分。分数范围是`0到1`，越接近1表示翻译质量越好。\n\n# 创新点\n\n- 提出了完全基于注意力机制的新架构，摒弃了`RNN`和`CNN`结构\n- 提出了多头注意力机制(`Multi-Head Attention`)，允许模型关注不同子空间的信息\n- 引入了位置编码(`Positional Encoding`)，使模型能够处理序列的顺序信息\n- 使用缩放点积注意力(`Scaled Dot-Product Attention`)，提高了计算效率\n- 采用残差连接(`Residual Connection`)和层归一化(`Layer Normalization`)，有利于深层网络训练\n- 具有更好的并行性能，训练速度快，效果好，在多个任务上达到了（当时的）最好水平\n\n# 主要内容\n\n## 读前须知\n\n1. 论文解读尽可能的还原原文，若有不恰当之处，还请见谅；\n2. 排版上，插图会尽量贴近出处，而扩展图之类的，会放置末尾处；\n3. 左边👈有目录，可自行跳转至想看的部分；\n4. 代码超过30行，会折叠，想浏览代码可点击右边按钮展开；\n5. 部分专业术语翻译成中文可能不太恰当，此时会用括号标明它的英文原文，如感受野（`Receptive field`）。请注意，仅首次出现会标明；\n\n## 介绍\n\n循环神经网络，特别是`长短期记忆网络（Long Short-Term Memory，LSTM）`和`门控循环神经网络（Gated Recurrent Neural Networks）`，已经在序列建模和转导问题（如语言建模和机器翻译）中牢固确立了最先进的地位。此后，众多研究工作持续推进循环语言模型和编码器-解码器架构的边界。\n\n> 长短期记忆网络：一种特殊的循环神经网络架构，设计用来解决普通RNN难以学习长期依赖关系的问题。它的核心是引入了一个记忆单元和三个控制门：输入门控制新信息进入记忆单元的程度，遗忘门决定丢弃多少旧信息，输出门控制记忆单元信息输出的多少。这种精细的门控机制让LSTM能够在长序列任务中表现出色。\n>\n> 门控循环神经网络：循环神经网络的一种改进版本，设计用来有效缓解传统RNN中的梯度消失问题，让网络能更好地处理长序列数据，捕捉长期依赖关系。它的典型代表是GRU（Gated Recurrent Unit），相比LSTM结构更简单但效果相当。\n\n循环模型通常沿着输入和输出序列的符号位置进行计算。将位置与计算时间步骤对齐，它们生成一系列隐藏状态 $\\mathbf h_t$，作为前一个隐藏状态 $\\mathbf h_{t-1}$ 和位置 $\\mathbf t$ 的输入的函数。这种本质上的`顺序特性`阻碍了训练样本内的并行化，这在序列较长时变得尤为关键，因为内存限制会限制跨样本的批处理。\n\n最近的工作通过分解技巧和条件计算在计算效率方面取得了显著改进，后者还改善了模型性能。然而，顺序计算的基本约束仍然存在。\n\n`注意力机制（attention mechanisms）`已经成为各种序列建模和转导模型中不可或缺的组成部分，使模型能够建立与输入或输出序列中距离无关的依赖关系。然而，除了少数情况外，这种注意力机制都是与循环网络结合使用的。\n\n在本工作中，我们提出了`Transformer`，这是一种`摒弃循环而完全依赖注意力机制`来捕获输入和输出之间全局依赖关系的模型架构。`Transformer`允许更多的并行化，在经过仅仅`12小时`的训练（使用`8个 P100 GPU`）后，就能在翻译质量上达到新的最高水平。\n\n## 背景\n\n减少顺序计算的目标也构成了`Extended Neural GPU`、`ByteNet`和`ConvS2S`的基础，这些模型都使用卷积神经网络作为基本构建模块，为所有输入和输出位置并行计算隐藏表示。\n\n在这些模型中，将两个任意输入或输出位置的信号关联起来所需的操作数会随着位置之间的距离而增长：对于`ConvS2S`是线性增长，对于`ByteNet`则是对数增长。这使得学习远距离位置之间的依赖关系变得更加困难。\n\n在`Transformer`中，这种操作数被减少到`常数级别`，尽管由于对注意力加权位置的平均化导致`有效分辨率降低`，但我们通过`多头注意力（Multi-Head Attention）`机制来抵消这种影响。\n\n`自注意力（Self-attention）`，有时也称为`内部注意力（intra-attention）`，是一种将单个序列的不同位置关联起来以计算序列表示的注意力机制。自注意力已经在多种任务中成功应用，包括阅读理解、摘要生成、文本蕴涵和学习任务无关的句子表示。\n\n基于循环注意力机制而非序列对齐循环的`端到端记忆网络（End-to-end memory networks）`已经被证明在简单语言问答和语言建模任务上表现良好。\n\n然而，据我们所知，`Transformer`是第一个完全依赖自注意力来计算其输入和输出表示的转导模型，无需使用序列对齐的`RNN`或`卷积`。在接下来的章节中，我们将描述`Transformer`，阐述选择自注意力的动机，并讨论它相比其他模型的优势。\n\n## 模型架构\n\n大多具有竞争力的神经序列转导模型都具有编码器-解码器结构。其中，编码器将符号表示的输入序列 $(x_1, ..., x_n)$ 映射为连续表示序列 $z = (z_1, ..., z_n)$。有了 $z$ 后，解码器再逐个生成输出序列的符号 $(y_1, ..., y_m)$。在每一步，模型都是自回归的，在生成下一个符号时将之前生成的符号作为额外输入。\n\n`Transformer`遵循这种整体架构，对编码器和解码器都使用堆叠的`自注意力`和`逐点全连接层`，如图1所示（分别在左半部分和右半部分）。\n\n<img src=\"/images/assets//image-20241214213436546.png\" width=\"400\">\n\n### 编码器与解码器\n\n**编码器**：编码器由 $\\text N = 6$ 个相同的层堆叠而成。每一层都有两个子层：\n\n1. 多头自注意力机制（multi-head self-attention mechanism）；\n\n2. 简单的、逐位置的全连接前馈网络；\n\n> `全连接前馈网络`：最基本的神经网络架构，由多个全连接层顺序堆叠而成。每一层的每个神经元都与上一层的所有神经元相连，通过权重矩阵和偏置项进行线性变换，再经过非线性激活函数（如ReLU）进行处理。\n\n我们在这两个子层的每一个周围都采用了残差连接，然后进行层标准化。即每个子层的输出是：\n$$\n\\text{LayerNorm}(x + \\text{Sublayer}(x))\n$$\n其中 $\\text{Sublayer}(x)$ 是由子层本身实现的函数。为了便于这些残差连接，模型中所有的子层以及嵌入层产生的输出维度都是 $d_{\\text{model}} = 512$。\n\n> `残差连接(Residual Connection)`：一种网络架构设计，通过在深层神经网络中添加\"捷径\"，让输入信息可以直接跳过某些层直达后面的层。这种设计有效缓解了深层网络的梯度消失问题，使得训练更深的网络成为可能，同时也能提升模型性能。\n\n**解码器**：解码器同样由 $\\text N = 6$ 个相同的层堆叠而成。除了编码器层中的两个子层外，解码器还插入了第三个子层，该层对解码器堆栈的输出执行多头注意力。\n\n与编码器类似，我们在每个子层周围使用残差连接，然后进行层标准化。我们还修改了解码器堆栈中的自注意力子层，以防止位置关注后续位置。这种遮蔽与输出嵌入偏移一个位置的事实相结合，确保对位置 $i$ 的预测只能依赖于位置小于 $i$ 处的已知输出。\n\n> `解码器堆栈`：由多个相同的解码器层叠加而成。每个解码器层包含三个主要部分：\n>\n> 1. 带掩码的自注意力层，确保当前位置只能看到之前生成的内容\n> 2. 交叉注意力层，允许解码器访问编码器的输出信息\n> 3. 前馈神经网络层，进行特征变换\n>\n> 通过这种堆叠结构，解码器能够逐个生成输出序列的每个元素。\n\n### 注意力\n\n注意力函数可以描述为将一个查询（`query`）和一组键值对（`key`-`value` pairs）映射到输出的过程，其中查询、键、值和输出都是`向量`。输出是`值的加权和`，其中分配给每个值的权重是通过查询和对应键的兼容函数计算得到的。\n\n#### 缩放点积注意力\n\n我们称我们特别使用的注意力为\"`缩放点积注意力`（`Scaled Dot-Product Attention`）\"。输入包含维度为 $d_k$ 的查询和键，以及维度为 $d_v$ 的值。我们计算查询和所有键的点积，将每个点积除以 $\\sqrt{d_k}$，然后应用`softmax`函数来获得值的权重。\n\n实践中，我们同时计算一组查询的注意力函数，将其打包成矩阵 $Q$ 。键和值也同样打包成矩阵 $K$ 和 $V$ 。于是我们得到以下输出矩阵：\n\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n$$\n最常用的两种注意力函数是`加性注意力`和`点积（乘性）注意力`。除了缩放因子 $\\frac{1}{\\sqrt{d_k}}$ 外，点积注意力与我们的算法相同。加性注意力使用`单隐层前馈网络`来计算兼容性函数。虽然这两种方法在理论复杂度上相似，但`点积注意力`在实践中更快、更节省空间，因为它可以使用`高度优化的矩阵乘法代码`来实现。\n\n当 $d_k$ 较小时，这两种机制表现相似。但对于较大的 $d_k$ 值，在未经缩放的情况下，点积的量级会增大，将`softmax`函数推入具有极小梯度的区域。为了抵消这种影响，我们将点积除以 $\\sqrt{d_k}$ 。\n\n#### 多头注意力\n\n我们发现，与使用 $d_{model}$ 维度的单个注意力函数相比，将查询、键和值分别用不同的、学习得到的线性映射到 $d_q$、$d_k$ 和 $d_v$ 维度上，并行计算注意力 $h$ 次会`更有益`。然后将这些注意力输出的 $d_v$ 维向量拼接起来，再经过一次线性映射得到最终输出，这种方式更有利。\n\n这允许模型共同关注来自不同位置的不同表示子空间的信息，如图2所示。使用单个注意力头，平均化会抑制这种效果。\n\n<img src=\"/images/assets//image-20241214214041382.png\" width=\"520\">\n\n多头注意力的计算公式如下：\n\n$$\n\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O\n$$\n其中 \n$$\n\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n$$\n\n\n这里，投影矩阵为\n$$\nW_i^Q \\in \\mathbb{R}^{d_{model} \\times d_q} ,~~\nW_i^K \\in \\mathbb{R}^{d_{model} \\times d_k} ,~~\nW_i^V \\in \\mathbb{R}^{d_{model} \\times d_v} ,~~\nW^O \\in \\mathbb{R}^{hd_v \\times d_{model}},~~\n$$\n在本工作中，我们采用了 $h=8$ 个并行注意力层（头）。对于每个注意力头，我们使用 $d_k = d_v = d_{model}/h = 64$ 维度。由于每个头的维度减小，总的计算成本与使用单个头的完整维度注意力相似。\n\n#### 基于位置的前馈网络\n\n除了注意力子层外，编码器和解码器中的每一层都包含一个完全连接的前馈网络，该网络独立且相同地应用于每个位置。这包含两个线性变换和一个`ReLU激活函数`：\n\n$$\n\\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n$$\n虽然不同位置的线性变换相同，但层与层之间使用不同的参数。这种操作也可以描述为两个卷积核大小为1的卷积。输入和输出的维度是 $d_{model} = 512$，内层的维度是 $d_{ff} = 2048$。\n\n#### 嵌入和Softmax\n\n> `嵌入(Embedding)`：将离散的符号（如单词、字符）转换为连续的密集向量表示的过程。这些向量具有语义意义，相似的符号在向量空间中距离较近。例如，\"猫\"和\"狗\"的嵌入向量会比\"猫\"和\"汽车\"的更接近。\n\n与其他序列转导模型类似，我们使用学习得到的`嵌入`将输入标记和输出标记转换为维度 $d_{model}$ 的向量。我们也使用普通的`线性变换`和`softmax函数`将`解码器输出`转换为预测的下一个标记概率。\n\n在我们的模型中，我们在两个嵌入层和`softmax`前的线性变换中共享相同的权重矩阵。在嵌入层中，我们将这些权重乘以 $\\sqrt{d_{model}}$。\n\n表1：不同层类型的`最大路径长度`、`每层复杂度`和`最小顺序操作数`。其中，`n`是序列长度，`d`是表示维度，`k`是卷积核大小，`r`是受限自注意力中的邻域大小。\n\n<img src=\"/images/assets//image-20241214222641650.png\" width=\"600\">\n\n#### 位置编码\n\n由于我们的模型不包含循环和卷积，为了让模型利用序列的顺序信息，我们必须注入一些关于标记在序列中相对或绝对位置的信息。为此，我们在编码器和解码器堆栈底部的输入嵌入中添加\"`位置编码`\"。位置编码的维度与嵌入维度相同（$d_{model}$），因此两者可以相加。\n\n这里有多种位置编码可供选择，学习得到的和固定的都可以。在本工作中，我们使用不同频率的正弦和余弦函数：\n$$\nPE_{(pos,2i)} = \\sin(\\dfrac {pos}{10000^{\\frac {2i}{d_{model}}}}),~~PE_{(pos,2i+1)} = \\cos(\\dfrac {pos}{10000^{\\frac {2i}{d_{model}}}})\n$$\n其中`pos`是位置，`i`是维度。也就是说，位置编码的每个维度对应于一个正弦曲线。波长形成从`2π`到`10000·2π`的几何级数。我们选择这个函数是因为我们假设它能让模型轻松学习通过相对位置来关注，因为对于任何固定`偏移量k`，$PE_{pos+k}$ 可以表示为 $PE_{pos}$ 的线性函数。\n\n我们还尝试了使用学习得到的位置嵌入，发现两种版本产生了几乎相同的结果（见表3）。我们选择正弦版本是因为它可能允许模型推断出比训练过程中遇到的序列长度更长的序列长度。\n\n## 为什么选择自注意力机制\n\n在本节中，我们将比较自`注意力层`与`循环层`和`卷积层`在不同方面的特点。这些层通常用于将一个`可变长度`的符号表示序列 $(x_1, ..., x_n)$ 映射到另一个等长序列 $(z_1, ..., z_n)$，其中 $x_i, z_i \\in \\mathbb{R}^d$，比如典型序列转换编码器或解码器中的隐藏层。为论证使用自注意力的合理性，我们考虑三个期望目标：\n\n1. 每层的总计算复杂度；\n2. 可并行计算的数量，用所需的最小顺序操作数来衡量。\n\n3. 网络中长距离依赖的路径长度。\n\n在许多序列转换任务中，`学习长距离依赖关系`是一个关键挑战。影响学习这种依赖关系能力的一个重要因素是信号在网络中前向和后向传播所必须经过的路径长度。输入和输出序列中任意位置之间的这些路径越短，就越容易学习长距离依赖关系。因此，我们还比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。\n\n如表1所示，自注意力层通过恒定数量的`顺序执行操作`就能连接所有位置，而循环层则需要 $O(n)$ 个顺序操作。在计算复杂度方面，当序列长度 `n` 小于表示维度 `d` 时，自注意力层比循环层更快，这在机器翻译中使用的句子表示（如词片段和字节对编码）的最新模型中经常出现。\n\n为了提高涉及超长序列任务的计算性能，可以将自注意力限制为仅考虑输入序列中以相应输出位置为中心的大小为 `r` 的邻域。这会将最大路径长度增加到 $O(n/r)$。我们计划在未来的工作中进一步研究这种方法。\n\n单个核宽度为 $k < n$ 的卷积层无法连接所有的输入和输出位置对。要实现这一点，在连续核的情况下需要 $O(n/k)$ 层卷积层堆叠，或在扩张卷积的情况下需要 $O(\\log_k(n))$ 层，这增加了网络中任意两个位置之间最长路径的长度。卷积层通常比循环层的计算开销更大，系数为 `k`。然而，可分离卷积能显著降低复杂度至 $O(k \\cdot n \\cdot d + n \\cdot d^2)$。即使在 $k = n$ 的情况下，可分离卷积的复杂度也等于自注意力层和逐点前馈层的组合，这正是我们在模型中采用的方法。\n\n作为附加好处，自注意力可能产生`更容易解释`的模型。我们检查了模型中的`注意力分布`，并在附录中展示和讨论了示例。不仅是各个注意力头明显学会执行不同的任务，许多注意力头似乎表现出与句子句法和语义结构相关的行为。\n\n## 训练\n\n本节描述了我们模型的训练方案。\n\n### 训练数据与批处理\n\n我们在标准的 `WMT 2014` 英德数据集上进行训练，该数据集包含约450万个句子对。句子使用字节对编码（`byte-pair encoding`）进行编码，共享源语言和目标语言的词表，包含约37000个词元。对于英法翻译，我们使用了明显更大的 `WMT 2014` 英法数据集，包含3600万个句子，并将词元分割成32000个词片（`word-piece`）词表。句子对按照近似序列长度进行批处理。每个训练批次包含一组句子对，大约包含25000个源语言词元和25000个目标语言词元。\n\n###  硬件与时间安排\n\n我们使用一台配备8块 `NVIDIA P100 GPU` 的机器训练模型。对于使用文中描述的超参数的基础模型，每个训练步骤大约需要0.4秒。我们总共训练了`100,000`步，即12小时。对于我们的大型模型（在表3的底部描述），每步用时1秒。大型模型训练了300,000步（3.5天）。\n\n###  优化器\n\n我们使用 `Adam` 优化器，参数设置为 $\\beta_1 = 0.9$，$\\beta_2 = 0.98$ 和 $\\epsilon = 10^{-9}$。在训练过程中，我们根据以下公式调整学习率：\n\n$$\n\\text {lrate} = d_{\\text {model}}^{-0.5} \\cdot \\min(\\text {step\\_num}^{-0.5}, \\text {step\\_num} \\cdot \\text {warmup\\_steps}^{-1.5})\n$$\n这相当于在前 `warmup_steps` 训练步骤中线性增加学习率，之后按步数的平方根的倒数比例降低学习率。我们使用 `warmup_steps=4000`。\n\n> 在Adam优化器中这三个参数的含义是：\n>\n> - $\\beta_1 = 0.9$ 是一阶动量的衰减率，控制历史梯度的影响程度。0.9意味着新的梯度占10%，过去的累积梯度占90%，使参数更新更平滑\n>\n> - $\\beta_2 = 0.98$ 是二阶动量的衰减率，用于控制学习率的自适应程度。0.98表示历史梯度平方的影响会更持久，让学习率调整更稳定\n>\n> - $\\epsilon = 10^{-9}$ 是一个很小的常数，添加到分母以防止除零，保证数值稳定性。通常取很小的值，对优化结果影响不大\n>\n> 这些是Adam常用的默认值，在实践中表现良好。\n\n### 正则化\n\n我们在训练期间采用三种类型的正则化：\n\n- **残差丢弃**：我们对每个子层的输出应用丢弃（`dropout`），然后再将其添加到子层输入并进行归一化。此外，我们对编码器和解码器堆栈中的嵌入和位置编码的和也应用丢弃。对于基础模型，我们使用 $P_{\\text drop} = 0.1$ 的丢弃率。\n\n- **标签平滑**：在训练期间，我们采用值为 $\\epsilon_{ls} = 0.1$ 的标签平滑。这会损害困惑度，因为模型学会了更加不确定，但能提高准确率和 `BLEU` 分数。\n\n表2：`Transformer`在英德和英法 `newstest2014` 测试中，以较少的训练成本达到了比之前最先进模型更好的 `BLEU` 分数。\n\n<img src=\"/images/assets//image-20241214220939993.png\" width=\"600\">\n\n## 结果\n\n### 机器翻译\n\n在 `WMT 2014` 英德翻译任务中，`Transformer` 大型模型（表2中的 `Transformer (big)`）比之前报告的最佳模型（包括集成模型）的表现高出超过2.0个 `BLEU` 分，创造了新的 `BLEU` 分数记录：28.4。该模型的配置列在表3的最后一行。训练在8块 `P100 GPU` 上用时3.5天。即使是我们的基础模型也超越了所有先前发表的模型和集成模型，而且训练成本只是竞争模型的一小部分。\n\n在 `WMT 2014` 英法翻译任务中，我们的大型模型达到了41.0的 `BLEU` 分数，超越了所有先前发表的单一模型，且训练成本不到之前最先进模型的四分之一。用于英法翻译的 `Transformer` 大型模型使用了 $P_{\\text drop} = 0.1$ 的丢弃率，而不是0.3。\n\n对于基础模型，我们使用了通过平均最后5个检查点获得的单一模型，这些检查点以10分钟的间隔写入。对于大型模型，我们平均了最后20个检查点。我们使用束搜索，束宽为4，长度惩罚 $\\alpha = 0.6$ 。这些超参数是在开发集上实验后选择的。我们在推理过程中将最大输出长度设置为输入长度加50，但在可能的情况下提前终止。\n\n表2总结了我们的结果，并将我们的翻译质量和训练成本与文献中的其他模型架构进行了比较。我们通过将训练时间、使用的 `GPU` 数量以及每个` GPU` 的估计单精度浮点持续计算能力相乘来估算训练模型所使用的浮点运算次数。\n\n### 模型变体\n\n为了评估 `Transformer` 不同组件的重要性，我们以不同方式改变了基础模型，在英德翻译的开发集（`newstest2013`）上测量性能变化。我们使用了如前一节所述的束搜索，但没有进行检查点平均。这些结果在表3中展示。\n\n表3：`Transformer` 架构的变体。未列出的值与基础模型相同。所有指标都基于英德翻译开发集 `newstest2013`。列出的困惑度是按照我们的字节对编码的每词片（`per-wordpiece`）计算的，不应与每词（`per-word`）困惑度进行比较。\n\n<img src=\"/images/assets//image-20241214220200245.png\" width=\"600\">\n\n在表3的（A）行中，我们改变了注意力头的数量以及注意力键值维度，同时保持计算量不变。虽然单头注意力比最佳设置低0.9 `BLEU`，但头数过多时质量也会下降。\n\n在表3的（B）行中，我们观察到减小注意力键的大小 $d_k$ 会损害模型质量。这表明确定兼容性并不容易，可能需要比点积更复杂的兼容性函数。我们在（C）和（D）行中进一步观察到，正如预期的那样，更大的模型效果更好，且丢弃对避免过拟合非常有帮助。在（E）行中，我们用学习的位置嵌入替换了正弦位置编码，观察到与基础模型几乎相同的结果。\n\n### 英语成分句法分析\n\n为了评估`Transformer`是否能够泛化到其他任务，我们在英语成分句法分析上进行了实验。这项任务具有特定的挑战：输出受到强结构约束，并且显著长于输入。此外，基于`RNN`的序列到序列模型在小数据条件下无法达到最优水平。\n\n我们在`Penn Treebank`（宾夕法尼亚树库）的`Wall Street Journal`（华尔街日报，简称`WSJ`）部分训练了一个4层的`transformer`模型，模型参数`dmodel=1024`，训练数据约4万句。我们还在半监督设置下进行了训练，使用了更大的高可信度语料库和`BerkleyParser`语料库，包含约1700万句。在仅使用`WSJ`的设置中，我们使用了16K词汇量，在半监督设置中使用了32K词汇量。\n\n我们仅在第22部分的开发集上进行了少量实验来选择`dropout`（包括注意力和残差部分）、学习率和束搜索大小，其他所有参数均保持与英德翻译基础模型相同。在推理过程中，我们将最大输出长度增加到输入长度`+300`。在`WSJ`单独训练和半监督设置中，我们都使用了束大小为`21`且`α=0.3`的设置。\n\n表4：`Transformer`在英语成分句法分析上的良好泛化性能（结果基于`WSJ`第`23`部分）\n\n<img src=\"/images/assets//image-20241214220853164.png\" width=\"600\">\n\n我们的结果如表`4`所示，尽管缺乏特定任务的调优，我们的模型表现出人意料地好，除了递归神经网络文法外，取得了优于所有先前报告模型的结果。\n\n与`RNN`序列到序列模型相比，即使仅在包含4万句的`WSJ`训练集上训练，`Transformer`的表现也优于`BerkeleyParser`。\n\n# 结论\n\n在这项工作中，我们提出了`Transformer`，这是第一个完全基于注意力机制的序列转换模型，它用多头自注意力机制取代了编码器-解码器架构中最常用的循环层。\n\n对于翻译任务，`Transformer`的训练速度明显快于基于循环层或卷积层的架构。在`WMT 2014`英德翻译和`WMT 2014`英法翻译任务上，我们都达到了新的最优水平。在前一个任务中，我们的最佳模型甚至超越了所有此前报告的集成模型的性能。\n\n我们对基于注意力模型的未来充满期待，并计划将其应用于其他任务。我们计划将`Transformer`扩展到涉及文本以外的输入和输出模态的问题，并研究局部的、受限制的注意力机制，以有效处理大规模输入和输出，如图像、音频和视频。使生成过程减少顺序依赖性也是我们的研究目标之一。\n\n我们用于训练和评估模型的代码可在 [https://github.com/tensorflow/tensor2tensor](https://github.com/tensorflow/tensor2tensor) 获取。\n\n致谢：我们感谢`Nal Kalchbrenner`和`Stephan Gouws`富有成效的评论、修正和启发。\n\n# 注意力可视化\n\n## 图3\n\n<img src=\"/images/assets//image-20241214221259460.png\" width=\"600\">\n\n图3：在编码器第5层（共6层）的自注意力机制中跟踪长距离依赖关系的示例。许多注意力头都关注动词\"making\"的远距离依赖，完成短语\"making...more difficult\"。此处仅显示针对单词\"making\"的注意力。不同颜色代表不同的注意力头。最佳以彩色查看。\n\n## 图4\n\n<img src=\"/images/assets//image-20241214221432239.png\" width=\"500\">\n\n图4：两个位于第5层（共6层）的注意力头，显然参与了回指消解。上图：第5个头的完整注意力分布。下图：仅展示来自单词\"its\"的注意力分布（注意力头5和6）。注意这个词的注意力分布非常清晰明确。\n\n## 图5\n\n<img src=\"/images/assets//image-20241214221551627.png\" width=\"500\">\n\n图5：许多注意力头表现出与句子结构相关的行为模式。我们在上面给出了两个这样的示例，来自编码器第5层（共6层）自注意力机制中的两个不同头。这些注意力头明显学会了执行不同的任务。\n\n# 参考文献\n\n1. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint [arXiv:1607.06450](https://arxiv.org/abs/1607.06450), 2016.\n2. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.\n3. Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n4. Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint [arXiv:1601.06733](https://arxiv.org/abs/1601.06733), 2016.\n5. Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n6. Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint [arXiv:1610.02357](https://arxiv.org/abs/1610.02357), 2016.\n7. Junyoung Chung, Çağlar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n8. Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In Proc. of NAACL, 2016.\n\n9. Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence to sequence learning. arXiv preprint [arXiv:1705.03122v2](https://arxiv.org/abs/1705.03122v2), 2017.\n10. Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint [arXiv:1308.0850](https://arxiv.org/abs/1308.0850), 2013.\n11. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770-778, 2016.\n12. Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001.\n13. Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780, 1997.\n14. Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 832-841. ACL, August 2009.\n15. Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint [arXiv:1602.02410](https://arxiv.org/abs/1602.02410), 2016.\n16. Lukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016.\n17. Lukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on Learning Representations (ICLR), 2016.\n18. Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint [arXiv:1610.10099v2](https://arxiv.org/abs/1610.10099v2), 2017.\n19. Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In International Conference on Learning Representations, 2017.\n20. Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n\n21. Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint [arXiv:1703.10722](https://arxiv.org/abs/1703.10722), 2017.\n\n22. Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint [arXiv:1703.03130](https://arxiv.org/abs/1703.03130), 2017.\n\n23. Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning. arXiv preprint [arXiv:1511.06114](https://arxiv.org/abs/1511.06114), 2015.\n\n24. Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. arXiv preprint [arXiv:1508.04025](https://arxiv.org/abs/1508.04025), 2015.\n\n25. Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313-330, 1993.\n\n26. David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152-159. ACL, June 2006.\n\n27. Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\n\n\n28. Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. arXiv preprint [arXiv:1705.04304](https://arxiv.org/abs/1705.04304), 2017.\n\n29. Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 433-440. ACL, July 2006.\n\n30. Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv preprint [arXiv:1608.05859](https://arxiv.org/abs/1608.05859), 2016.\n\n31. Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint [arXiv:1508.07909](https://arxiv.org/abs/1508.07909), 2015.\n\n32. Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint [arXiv:1701.06538](https://arxiv.org/abs/1701.06538), 2017.\n\n33. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929-1958, 2014.\n\n34. Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440-2448. Curran Associates, Inc., 2015.\n\n35. Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104-3112, 2014.\n\n\n36. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n\n37. Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n\n38. Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google's neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint [arXiv:1609.08144](https://arxiv.org/abs/1609.08144), 2016.\n\n39. Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n\n40. Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434-443. ACL, August 2013.\n\n# transformer发展\n\n## transformer模型变体\n\n自`2017` 年发表的这篇奠基性论文《`Attention is All You Need`》中提出的原始 `transformer` 架构之后，transformer的变体模型越来越多，同时适用的领域也越来越精细化，下表列出了近几年 `transformer` 的`变体模型`及其特点等信息：\n\n| 模型名称                      | 发表年份 | 特点                                                         | 优势                                                         | 劣势                                                 |\n| ----------------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------- |\n| **BERT**                      | 2018     | 双向编码预训练语言模型，使用遮掩语言模型（MLM）和下一句预测（NSP）任务 | 在多个NLP任务上取得了显著的性能提升                          | 预训练和微调需要大量计算资源，缺乏对生成任务的支持   |\n| **GPT**                       | 2018     | 基于Transformer的单向自回归语言模型                          | 在生成任务上表现出色，模型架构简单，易于扩展                 | 单向性限制了对上下文信息的完整捕捉                   |\n| **GPT-2**                     | 2019     | 扩大了GPT的规模，参数量增加，生成更长的文本                  | 文本生成更连贯，表现更佳                                     | 存在滥用风险，计算资源需求高                         |\n| **RoBERTa**                   | 2019     | 改进了BERT，取消NSP任务，增加训练数据和训练时间              | 在多项NLP任务上超过了BERT的性能                              | 训练成本高，依赖大量数据                             |\n| **ALBERT**                    | 2019     | 引入参数共享和因子化嵌入，减少模型参数量                     | 模型更小，训练速度更快，性能接近BERT                         | 参数共享可能限制模型的表达能力                       |\n| **XLNet**                     | 2019     | 结合自回归和自编码的预训练方法，使用Transformer-XL作为基础   | 超越了BERT在多个任务上的性能，能够捕捉双向上下文             | 模型更复杂，训练难度增加                             |\n| **T5**                        | 2019     | 将所有NLP任务统一为“文本到文本”的框架，进行大规模预训练      | 在多项任务上表现出色，统一的架构便于迁移学习                 | 模型体积庞大，训练和推理成本高                       |\n| **ELECTRA**                   | 2020     | 使用替换词检测作为预训练任务，提高训练效率                   | 在相同计算预算下，性能优于BERT                               | 训练过程更复杂，可能需要精细的超参数调节             |\n| **Reformer**                  | 2020     | 利用局部敏感哈希（LSH）和可逆残差网络，减少内存和计算需求    | 能处理长序列，降低计算复杂度和内存占用                       | 实现复杂度增加，可能在某些任务上不稳定               |\n| **Longformer**                | 2020     | 采用稀疏注意力机制，增强长序列处理能力                       | 能有效处理长文档，在长序列任务上性能优异                     | 对于短序列任务优势不明显，模型复杂度增加             |\n| **Performer**                 | 2020     | 使用随机特征映射近似软max注意力，实现线性计算复杂度          | 能够高效处理长序列，计算效率高                               | 近似可能导致性能下降，在某些任务上效果不如精确注意力 |\n| **Linformer**                 | 2020     | 通过低秩投影将注意力机制的复杂度降为线性                     | 大幅降低注意力的计算和内存需求，适用于长序列                 | 低秩近似可能损失部分信息，影响模型性能               |\n| **BigBird**                   | 2020     | 结合局部、随机和全局注意力机制，扩展到更长的序列             | 能处理非常长的序列，在长文本理解上表现良好                   | 模型结构更复杂，实现和调试难度增大                   |\n| **ViT（Vision Transformer）** | 2020     | 将Transformer应用于图像任务，将图像划分为patches进行处理     | 在图像分类任务上取得了优异性能，突破了传统CNN的限制          | 需要大量数据进行预训练，对小样本数据集表现较差       |\n| **Switch Transformer**        | 2021     | 基于专家混合（MoE）的稀疏激活模型，极大地扩大模型规模        | 增加模型容量的同时保持计算成本较低，在大规模预训练中表现出色 | 通信和负载均衡成为训练的瓶颈，模型复杂度高           |\n| **Swin Transformer**          | 2021     | 使用层次化的Transformer结构和滑动窗口机制，适用于视觉任务    | 在图像分类、目标检测等任务上性能优异，具有良好的扩展性       | 模型结构复杂，训练时间较长，需要更多资源             |\n| **GPT-3**                     | 2020     | 超大规模语言模型，拥有1750亿参数，具备强大的生成能力         | 具有卓越的零样本和少样本学习能力，可处理多种任务             | 参数规模庞大，训练和推理成本极高，存在偏见和不准确性 |\n| **GPT-4**                     | 2023     | 多模态模型，支持文本和图像输入，进一步提升推理能力           | 在广泛的任务上表现优异，更好的上下文理解和生成能力           | 模型巨大，推理成本高，仍存在生成错误信息的风险       |\n\n这些 `transformer` 变体各有特点，通过在模型结构、预训练任务和训练策略等方面的创新，不断提升了模型在各种任务上的性能。然而，随着模型规模的扩大，训练和推理的计算成本也显著增加，`如何在性能和效率之间取得平衡仍是一个重要的研究方向`。\n\n## 优化与创新方向\n\n细分看来，上述这些模型，主要在以下几个方向上进行了`优化和创新`：\n\n1. **`模型架构优化`**\n   - **稀疏注意力机制**：为了降低计算复杂度，提高对长序列的处理能力，一些模型引入了稀疏注意力机制。例如：\n     - **Longformer**：采用局部和全局的稀疏注意力模式，能够处理更长的文本。\n     - **BigBird**：结合局部、随机和全局注意力，扩展了模型的上下文范围。\n     - **Reformer**：利用局部敏感哈希（LSH）替代传统的点积注意力，减少了计算和内存开销。\n   \n   - **线性化注意力**：通过近似方法将注意力机制的计算复杂度从二次降为线性。例如：\n     - **Performer**：使用随机特征映射近似软max注意力，实现线性时间复杂度。\n     - **Linformer**：采用低秩矩阵分解技术，降低了注意力矩阵的维度。\n   \n   - **层次化结构**：在视觉领域，引入了层次化的特征表示，以更好地捕捉不同尺度的信息。例如：\n     - **Swin Transformer**：使用滑动窗口和金字塔结构，适用于图像和视频任务。\n   \n2. **`预训练任务和目标的改进`**\n   - **新的预训练任务**：为了更有效地学习语言表示，模型引入了新的预训练任务。\n     - **BERT**：使用了遮掩语言模型（MLM）和下一句预测（NSP）。\n     - **RoBERTa**：改进了预训练策略，取消了NSP任务，使用动态遮掩。\n     - **ELECTRA**：提出了替换词检测任务，训练一个判别器来区分真实词和生成的假词，提高了训练效率。\n   \n   - **自回归与自编码的结合**：\n     - **XLNet**：融合了自回归和自编码的预训练方法，通过掩码排列方式捕获双向上下文信息。\n   \n3. **`模型规模的扩展`**\n   - **参数规模的增加**：为了提升模型的表达能力，研究者们不断扩大模型的参数规模。\n     - **GPT-2**：参数量达到15亿，比GPT大了一个数量级。\n     - **GPT-3**：进一步扩展到1750亿参数，具备强大的生成和推理能力。\n     - **Switch Transformer**：采用专家混合（MoE）结构，实现了万亿级参数的模型。\n   \n   - **稀疏激活和专家模型**：\n     - **Switch Transformer**：在模型中引入了稀疏激活的专家层，每次只激活部分参数，减少计算成本。\n   \n4. **`参数高效化`**\n   - **参数共享和压缩**：为了减少模型参数量，提升训练和推理效率。\n     - **ALBERT**：使用跨层参数共享和因子化嵌入，将参数量大幅减少，同时保持性能。\n     - **DistilBERT**：通过蒸馏技术，从大型模型中学习，生成轻量级模型。\n   \n5. **`任务统一化`**\n   - **统一的框架处理多种任务**：\n     - **T5（Text-to-Text Transfer Transformer）**：将各种NLP任务统一建模为文本到文本的问题，方便了多任务学习和迁移学习。\n   \n6. **`跨模态扩展`**\n   - **将Transformer应用于视觉和多模态任务**：\n     - **ViT（Vision Transformer）**：将Transformer直接应用于图像分类任务，效果超过了一些经典的卷积神经网络。\n     - **GPT-4**：支持文本和图像输入的多模态模型，能够理解并生成跨模态的内容。\n   \n7. **`更好的长程依赖建模`**\n   - **相对位置编码和循环机制**：\n     - **Transformer-XL**：引入了递归机制和相对位置编码，改善了对长序列的依赖。\n     - **XLNet**：利用相对位置编码，增强了模型对长距离依赖的捕捉能力。\n   \n8. **`计算效率和内存优化`**\n   - **可逆网络和压缩技术**：\n     - **Reformer**：引入可逆残差网络，减少了模型的内存占用，因为可以在反向传播中无需存储中间激活值。\n   \n   - **低秩和近似计算**：\n     - **Linformer**：通过低秩近似，减少了注意力矩阵的尺寸，降低了计算量。\n     - **Performer**：用核方法近似softmax函数，提升了计算效率。\n   \n9. **`训练策略的改进`**\n   - **大规模数据和训练技巧**：\n     - **RoBERTa**：增加了训练数据量，延长了训练时间，并调整了超参数，取得了比BERT更好的性能。\n     - **DeepSpeed和Megatron-LM**：提供了高效的模型并行和数据并行策略，支持训练超大规模模型。\n   \n10. **`应用领域的拓展`**\n    - **领域特定的预训练**：\n      - **BioBERT、SciBERT**：针对生物医学和科学文献进行预训练，提升了在特定领域的性能。\n    \n    - **多语言和跨语言模型**：\n      - **mBERT、XLM-R**：在多语言数据上进行预训练，支持跨语言的理解和生成。\n\n综合上述内容，这些改进旨在提升模型的性能、效率和适用范围等等，以应对不同的任务需求和计算资源限制。\n\n## 如何在新任务上优化 transformer 架构？\n\n个人认为，可从以下几个方面考虑：\n\n- **`架构创新`**：通过改进注意力机制和引入新的网络结构，提升模型对长序列和复杂任务的处理能力。\n\n- **`预训练策略`**：设计新的预训练任务和目标，使模型能够更有效地学习新任务所需特征。\n\n- **`规模和效率`**：扩大模型规模以提高性能，同时引入参数共享、模型压缩和稀疏激活等技术，优化计算资源的利用。\n\n- **`任务和领域拓展`**：将Transformer应用于新的领域和任务，如基因组学数据分析、计算机视觉、多模态处理等等。\n\n- **`训练优化`**：改进训练算法和并行策略，以支持大规模模型的训练，降低训练时间和资源消耗。\n\n# transformer代码实现举例\n\n作为参考，这里的示例基于`Transformer`架构的语言模型实现，具体是一个`仅包含解码器`的变体，功能是`语言生成`。\n\n先来回顾一下transformer模型中的概念：\n\n- `嵌入层`：将词汇等源转换为密集向量表示\n- `位置编码`：为序列中的每个位置添加位置信息\n- `Transformer解码器`：核心计算单元\n- `输出层`：将结果映射回词汇等源大小的空间\n\n重要参数：\n\n- `vocab_size`: 词汇表等源大小\n- `embed_size`: 嵌入维度\n- `num_heads`: 注意力头数\n- `hidden_dim`: 前馈网络维度\n- `num_layers`: 解码器层数\n\n## 构建 transformer 模型\n\n```python\nimport torch\nfrom torch import nn\n\n# 定义一个仅包含解码器的transformer模型\nclass TransformerDecoderModel(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_heads, hidden_dim, num_layers):\n        # 调用基类的初始化函数\n        super(TransformerDecoderModel, self).__init__()  \n        # 创建嵌入层，将词索引转换为嵌入向量\n        self.embed = nn.Embedding(vocab_size, embed_size)\n        # 初始化位置编码，是一个可学习的参数\n        self.positional_encoding = nn.Parameter(torch.randn(embed_size).unsqueeze(0))\n        # 定义Transformer解码器层\n        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim)\n        # 堆叠多个解码器层构成完整的解码器\n        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n        # 定义输出层，将解码器输出转换回词汇空间\n        self.fc = nn.Linear(embed_size, vocab_size)\n\n    def forward(self, src):\n        # 嵌入输入并添加位置编码\n        src = self.embed(src) + self.positional_encoding\n        # 生成源序列的掩码，用于屏蔽未来的信息\n        src_mask = self.generate_square_subsequent_mask(src.size(0))\n        # 通过解码器传递源数据和掩码\n        output = self.transformer_decoder(src, src, src_mask)\n        # 应用线性层输出最终的预测结果\n        output = self.fc(output)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        # 上三角矩阵，用于序列生成中遮蔽未来位置的信息\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        # 将掩码的非零位置设为无穷大，零位置设为0\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n```\n\n## 训练数据集\n\ntransformer架构的模型，整体`训练成本`都非常高，这里仅作演示，我们极大`缩小训练量级`，将以下文本存为“`sentence.txt`”作为训练数据：\n\n```\n数学\n\n数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定义中建立起严谨推导出的定理。\n\n基础数学的知识与运用总是个人与团体生活中不可或缺的一环。对数学基本概念的完善，早在古埃及、美索不达米亚及古印度内的古代数学文本便可观见，而在古希腊那里有更为严谨的处理。从那时开始，数学的发展便持续不断地小幅进展，至16世纪的文艺复兴时期，因为新的科学发现和数学革新两者的交互，致使数学的加速发展，直至今日。数学并成为许多国家及地区的教育范畴中的一部分。\n\n今日，数学使用在不同的领域中，包括科学、工程、医学、经济学和金融学等。数学对这些领域的应用通常被称为应用数学，有时亦会激起新的数学发现，并导致全新学科的发展，例如物理学的实质性发展中建立的某些理论激发数学家对于某些问题的不同角度的思考。数学家也研究纯数学，就是数学本身的实质性内容，而不以任何实际应用为目标。虽然许多研究以纯数学开始，但其过程中也发现许多应用之处。\n\n西方语言中“数学”（）一词源自于古希腊语的（），其有“学习”、“学问”、“科学”，以及另外还有个较狭义且技术性的意思－「数学研究」，即使在其语源内。其形容词（），意思为\"和学习有关的\"或\"用功的\"，亦会被用来指\"数学的\"。其在英语中表面上的复数形式，及在法语中的表面复数形式'，可溯至拉丁文的中性复数'，由西塞罗译自希腊文复数（），此一希腊语被亚里士多德拿来指「万物皆数」的概念。\n\n汉字表示的「数学」一词大约产生于中国宋元时期。多指象数之学，但有时也含有今天上的数学意义，例如，秦九韶的《数学九章》（《永乐大典》记，即《数书九章》也被宋代周密所著的《癸辛杂识》记为《数学大略》）、《数学通轨》（明代柯尚迁著）、《数学钥》（清代杜知耕著）、《数学拾遗》（清代丁取忠撰）。直到1939年，经过中国数学名词审查委员会研究“算学”与“数学”两词的使用状况后，确认以“数学”表示今天意义上的数学含义。\n\n数学有着久远的历史。它被认为起源于人类早期的生产活动：中国古代的六艺之一就有「数」，数学一词在西方有希腊语词源（mathematikós），意思是“学问的基础”，源于（máthema，“科学，知识，学问”）。\n\n史前的人类就已尝试用自然的法则来衡量物质的多少、时间的长短等抽象的数量关系，比如时间单位有日、季节和年等。算术（加减乘除）也自然而然地产生了。古代的石碑及泥版亦证实了当时已有几何的知识。\n\n更进一步则需要写作或其他可记录数字的系统，如符木或于印加帝国内用来储存数据的奇普。历史上曾有过许多不同的记数系统。\n\n在最初有历史记录的时候，数学内的主要原理是为了做税务和贸易等相关计算，为了解数字间的关系，为了测量土地，以及为了预测天文事件而形成的。这些需要可以简单地被概括为数学对数量、结构、空间及时间方面的研究。\n\n到了16世纪，算术、初等代数以及三角学等初等数学已大体完备。17世纪变量概念的产生使人们开始研究变化中的量与量的互相关系和图形间的互相变换，微积分的概念也在此时形成。随着数学转向形式化，为研究数学基础而产生的集合论和数理逻辑等也开始发展。数学的重心从求解实际问题转变到对一般形式上的思考。\n\n从古至今，数学便一直不断地延展，且与科学有丰富的相互作用，两者的发展都受惠于彼此。在历史上有著许多数学发现，并且直至今日都不断地有新的发现。据Mikhail B. Sevryuk于2006年1月的期刊中所说，「存放于数学评论资料库中论文和书籍的数量自1940年（数学评论的创刊年份）现已超过了一百九十万份，而且每年还增加超过七万五千份。此一学海的绝大部份为新的数学定理及其证明。」\n\n每当有涉及数量、结构、空间及变化等方面的困难问题时，通常就需要用到数学工具去解决问题，而这往往也拓展了数学的研究范畴。一开始，数学的运用可见于贸易、土地测量及之后的天文学。今日，所有的科学都存在著值得数学家研究的问题，且数学本身亦给出了许多的问题。牛顿和莱布尼兹是微积分的发明者，费曼发明了费曼路径积分，这是推理及物理洞察二者的产物，而今日的弦理论亦引申出新的数学。一些数学只和生成它的领域有关，且用来解答此领域的更多问题。但一般被一领域生成的数学在其他许多领域内也十分有用，且可以成为一般的数学概念。即使是「最纯的」数学通常亦有实际的用途，此一非比寻常的事实，被1963年诺贝尔物理奖得主维格纳称为「数学在自然科学中不可想像的有效性」。\n\n如同大多数的研究领域，科学知识的爆发导致了数学的专业化。主要的分歧为纯数学和应用数学。在应用数学内，又被分成两大领域，并且变成了它们自身的学科——统计学和电脑科学。\n\n许多数学家谈论数学的\"优美\"，其内在的美学及美。「简单」和「一般化」即为美的一种。另外亦包括巧妙的证明，如欧几里得对存在无限多质数的证明；又或者是加快计算的数值方法，如快速傅立叶变换。高德菲·哈罗德·哈代在《一个数学家的自白》一书中表明他相信单单是美学上的意义，就已经足够作为纯数学研究的正当理由。\n\n我们现今所使用的大部分数学符号在16世纪后才被发明出来的。在此之前，数学以文字的形式书写出来，这种形式会限制了数学的发展。现今的符号使得数学对于专家而言更容易掌握，但初学者却常对此望而却步。它被极度的压缩：少量的符号包含著大量的讯息。如同音乐符号一般，现今的数学符号有明确的语法，并且有效地对讯息作编码，这是其他书写方式难以做到的。符号化和形式化使得数学迅速发展，并帮助各个科学领域建立基础支撑理论。\n\n数学语言亦对初学者而言感到困难。如“或”和“只”这些字有著比日常用语更精确的意思。亦困恼著初学者的，如“开放”和“域”等字在数学里有著特别的意思。数学术语亦包括如“同胚”及“可积性”等专有名词。但使用这些特别符号和专有术语是有其原因的：数学需要比日常用语更多的精确性。数学家将此对语言及逻辑精确性的要求称为「严谨」。但在现实应用中，舍弃一些严谨性往往会得到更好的结果。\n\n严谨是数学证明中很重要且基本的一部份。数学家希望他们的定理以系统化的推理依著公理被推论下去。这是为了避免依著不可靠的直观而推出错误的「定理」，而这情形在历史上曾出现过许多的例子。在数学中被期许的严谨程度因著时间而不同：希腊人期许著仔细的论证，但在牛顿的时代，所使用的方法则较不严谨。牛顿为了解决问题所做的定义，到了十九世纪才重新以小心的分析及正式的证明来处理。今日，数学家们则持续地在争论电脑辅助证明的严谨度。当大量的计算难以被验证时，其证明亦很难说是足够地严谨。\n\n公理在传统的思想中是「不证自明的真理」，但这种想法是有问题的。在形式上，公理只是一串符号，其只对可以由公理系统导出的公式之内容有意义。希尔伯特计划即是想将所有的数学放在坚固的公理基础上，但依据哥德尔不完备定理，每一相容且能蕴涵皮亚诺公理的公理系统必含有一不可决定的公式；因而所有数学的最终公理化是不可能的。尽管如此，数学常常被想像成只是某种公理化的集合论，在此意义下，所有数学叙述或证明都可以写成集合论的公式。\n\n卡尔·弗里德里希·高斯称数学为「科学的皇后」。在拉丁原文'，以及其德语'中，对应于「科学」的单字的意思皆为知识（领域）。而实际上，science一词在英语内本来就是这个意思，且无疑问地数学在此意义下确实是一门「科学」。将科学限定在自然科学则是在此之后的事。若认为科学是只指物理的世界时，则数学，或至少是纯数学，不会是一门科学。爱因斯坦曾如此描述：「数学定律越和现实有关，它们越不确定；若它们越是确定的话，它们和现实越不会有关。」\n\n许多哲学家相信数学在经验上不具可否证性，且因此不是卡尔·波普尔所定义的科学。但在1930年代时，在数理逻辑上的重大进展显示数学不能归并至逻辑内，且波普尔推断「大部份的数学定律，如物理及生物学一样，是假设演绎的：纯数学因此变得更接近其假设为猜测的自然科学，比它现在看起来更接近。」然而，其他的思想家，如较著名的拉卡托斯，便提供了一个关于数学本身的可否证性版本。\n\n另一观点则为某些科学领域（如理论物理）是其公理为尝试著符合现实的数学。而事实上，理论物理学家齐曼（John Ziman）即认为科学是一种公众知识，因此亦包含著数学。在任何的情况下，数学和物理科学的许多领域都有著很多相同的地方，尤其是从假设所得的逻辑推论之探索。直觉和实验在数学和科学的猜想建构上皆扮演著重要的角色。实验数学在数学中的重要性正持续地在增加，且计算和模拟在科学及数学中所扮演的角色也越来越加重，减轻了数学不使用科学方法的缺点。在史蒂芬·沃尔夫勒姆2002年的著作《一种新科学》中他提出，计算数学应被视为其自身的一科学领域来探索。\n\n数学家对此的态度并不一致。一些研究应用数学的数学家觉得他们是科学家，而那些研究纯数学的数学家则时常觉得他们是在一门较接近逻辑的领域内工作，且因此基本上是个哲学家。许多数学家认为称他们的工作是一种科学，是低估了其美学方面的重要性，以及其做为七大博雅教育之一的历史；另外亦有人认为若忽略其与科学之间的关联，是假装没看到数学和其在科学与工程之间的交互影响，进而促进了数学在许多科学上的发展此一事实。这两种观点之间的差异在哲学上产生了数学是「被创造」（如艺术）或是「被发现」（如科学）的争议。大学院系划分中常见「科学和数学系」，这指出了这两个领域被看作有紧密联系而非一样。实际上，数学家通常会在大体上与科学家合作，但在细节上却会分开。此争议亦是数学哲学众多议题的其中一个。\n\n如上所述，数学主要的学科最先产生于商业上计算的需要、了解数字间的关系、测量土地及预测天文事件。这四种需要大致地与数量、结构、空间及变化（即算术、代数、几何及分析）等数学上广泛的子领域相关连著。除了上述主要的关注之外，亦有用来探索由数学核心至其他领域上之间的连结的子领域：至逻辑、至集合论（基础）、至不同科学的经验上的数学（应用数学）、及较近代的至不确定性的严格研究。\n为了阐明数学基础，数学逻辑和集合论等领域被发展了出来。\n\n数学逻辑专注于将数学置在一坚固的公理架构上，并研究此一架构的结果。就数学逻辑本身而言，其为哥德尔第二不完备定理所属的领域，而这或许是逻辑中最广为流传的成果－总存在一不能被证明而又为真的定理。\n\n现代逻辑被分成递归论、模型论和证明论，且和理论电脑科学有著密切的关连性，千禧年大奖难题中的P/NP问题就是理论电脑科学中的著名问题。\n\n数量的研究起于数，一开始为熟悉的自然数及整数与被描述在算术内的自然数及整数的算术运算。整数更深的性质于数论中有详细的研究，此一理论包括了如费马最后定理等著名的结果。数论还包括两个被广为探讨的未解问题：孪生质数猜想及哥德巴赫猜想。\n\n当数系更进一步发展时，整数被视为有理数的子集，而有理数则包含于实数中，连续的量即是以实数来表示的。实数则可以被进一步广义化成复数。数的进一步广义化可以持续至包含四元数及八元数。从自然数亦可以推广到超限数，它形式化了计数至无限的这一概念。另一个研究的领域为大小，这个导致了基数和之后对无限的另外一种概念：阿列夫数，它允许无限集合之间的大小可以做有意义的比较。\n\n许多如数及函数的集合等数学物件都有著内含的结构。这些物件的结构性质被探讨于群、环、-{zh-cn:域;zh-tw:体}-等抽象系统中，该些物件事实上也就是这样的系统。此为代数的领域。在此有一个很重要的概念，即广义化至向量空间的向量，它于线性代数中被研究。向量的研究结合了数学的三个基本领域：数量、结构及空间。向量分析则将其扩展至第四个基本的领域内，即变化。\n\n创立于二十世纪三十年代的法国的布尔巴基学派认为：纯粹数学，是研究抽象结构的理论。\n结构，就是以初始概念和公理出发的演绎系统。\n布尔巴基学派认为，有三种基本的抽象结构：代数结构（群，环，域……），序结构（偏序，全序……），拓扑结构（邻域，极限，连通性，维数……）。\n\n空间的研究源自于几何－尤其是欧几里得几何。三角学则结合了空间及数，且包含有著名的勾股定理。现今对空间的研究更推广到了更高维的几何、非欧几里得几何（其在广义相对论中扮演著核心的角色）及拓扑学。数和空间在解析几何、微分几何和代数几何中都有著很重要的角色。在微分几何中有著纤维丛及流形上的微积分等概念。在代数几何中有著如多项式方程的解集等几何物件的描述，结合了数和空间的概念；亦有著拓扑群的研究，结合了结构与空间。李群被用来研究空间、结构及变化。在其许多分支中，拓扑学可能是二十世纪数学中有著最大进展的领域，并包含有存在已久的庞加莱猜想，以及有争议的四色定理。庞加莱猜想已在2006年确认由俄罗斯数学家格里戈里·佩雷尔曼证明，而四色定理已在1976年由凯尼斯·阿佩尔和沃夫冈·哈肯用电脑证明，而从来没有由人力来验证过。\n\n了解及描述变化在自然科学里是一普遍的议题，而微积分更为研究变化的有利工具。函数诞生于此，做为描述一变化的量的核心概念。对于实数及实变函数的严格研究为实分析，而复分析则为复数的等价领域。黎曼猜想－数学最基本的未决问题之一－便是以复分析来描述的。泛函分析注重在函数的（一般为无限维）空间上。泛函分析的众多应用之一为量子力学。许多的问题很自然地会导出一个量与其变化率之间的关系，而这在微分方程中被研究。在自然界中的许多现象可以被动力系统所描述；混沌理论则是对系统的既不可预测而又是决定的行为作明确的描述。\n离散数学是指对理论电脑科学最有用处的数学领域之总称，这包含有可计算理论、计算复杂性理论及资讯理论。可计算理论检验电脑的不同理论模型之极限，这包含现知最有力的模型－图灵机。复杂性理论研究可以由电脑做为较易处理的程度；有些问题即使理论是可以以电脑解出来，但却因为会花费太多的时间或空间而使得其解答仍然不为实际上可行的，尽管电脑硬体的快速进步。最后，资讯理论专注在可以储存在特定媒介内的资料总量，且因此有压缩及熵等概念。\n\n作为一相对较新的领域，离散数学有许多基本的未解问题。其中最有名的为P/NP问题－千禧年大奖难题之一。一般相信此问题的解答是否定的。\n\n应用数学思考将抽象的数学工具运用在解答科学、工商业及其他领域上之现实问题。应用数学中的一重要领域为统计学，它利用机率论为其工具并允许对含有机会成分的现象进行描述、分析与预测。大部份的实验、调查及观察研究需要统计对其资料的分析。（许多的统计学家并不认为他们是数学家，而比较觉得是合作团体的一份子。）数值分析研究有什么计算方法，可以有效地解决那些人力所限而算不出的数学问题；它亦包含了对计算中舍入误差或其他来源的误差之研究。\n\n数学奖通常和其他科学的奖项分开。数学上最有名的奖为菲尔兹奖，创立于1936年，每四年颁奖一次。它通常被认为是数学的诺贝尔奖。另一个国际上主要的奖项为阿贝尔奖，创立于2003年。两者都颁奖于特定的工作主题，包括数学新领域的创新或已成熟领域中未解决问题的解答。著名的23个问题，称为希尔伯特的23个问题，于1900年由德国数学家大卫·希尔伯特所提出。这一连串的问题在数学家之间有著极高的名望，且至少有九个问题已经被解答了出来。另一新的七个重要问题，称为千禧年大奖难题，发表于2000年。对其每一个问题的解答都有著一百万美元的奖金，而当中只有一个问题（黎曼猜想）和希尔伯特的问题重复。\n\n```\n\n定义`TextDataset`类：\n\n```python\nclass TextDataset(Dataset):\n    # 初始化函数，filepath为输入文件路径\n    def __init__(self, filepath):\n        words = []\n        with open(filepath, 'r') as file:\n            for line in file:\n                # 使用jieba库进行分词，并去除每行的首尾空白字符\n                words.extend(list(jieba.cut(line.strip())))\n\n        # 将所有单词转换为一个集合来去除重复，然后再转回列表形式，形成词汇表\n        self.vocab = list(set(words))\n        self.vocab_size = len(self.vocab)  # 计算词汇表的大小\n\n        # 创建从单词到整数的映射和从整数到单词的映射\n        self.word_to_int = {word: i for i, word in enumerate(self.vocab)}\n        self.int_to_word = {i: word for i, word in enumerate(self.vocab)}\n\n        # 将映射关系保存为JSON文件\n        with open('word_to_int.json', 'w') as f:\n            json.dump(self.word_to_int, f, ensure_ascii=False, indent=4)\n        with open('int_to_word.json', 'w') as f:\n            json.dump(self.int_to_word, f, ensure_ascii=False, indent=4)\n\n        # 将所有单词转换为对应的整数索引，形成数据列表\n        self.data = [self.word_to_int[word] for word in words]\n\n    # 返回数据集的长度减1，这通常是因为在机器学习中可能需要使用当前数据点预测下一个数据点\n    def __len__(self):\n        return len(self.data) - 1\n\n    # 根据索引idx返回数据，这里用于返回模型训练时的输入序列和目标输出\n    def __getitem__(self, idx):\n        # 固定序列长度为50\n        sequence_length = 50\n        # 获取输入序列\n        if idx < sequence_length:\n            # 如果idx小于序列长度，用0填充前面的部分\n            input_data = self.data[0:idx]\n            padding_length = sequence_length - len(input_data)\n            input_seq = torch.tensor([0] * padding_length + input_data, dtype=torch.long)\n        else:\n            # 如果idx大于等于序列长度，直接取前50个元素\n            input_seq = torch.tensor(self.data[idx - sequence_length:idx], dtype=torch.long)\n        # 确保输入序列长度为50\n        assert input_seq.size(0) == sequence_length\n        # 获取目标输出\n        target = torch.tensor(self.data[idx], dtype=torch.long)\n        return input_seq, target\n```\n\n通过以下方式`加载数据集`：\n\n```python\ndataset = TextDataset('sentence.txt')\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n```\n\n## 训练模型\n\n创建模型并发送：\n\n```python\nmodel = TransformerDecoderModel(vocab_size=dataset.vocab_size, embed_size=512, num_heads=8, hidden_dim=2048, num_layers=6)\n\n# 将模型传送到定义的设备上（例如GPU或CPU），以便进行训练\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n```\n\n模型`优化器`和`损失函数`设置：\n\n```python\n# 初始化优化器，这里使用Adam优化器，设置学习率，从模型中获取参数\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# 添加学习率调度器\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)\n# 初始化损失函数，这里使用交叉熵损失\ncriterion = nn.CrossEntropyLoss()\n```\n\n> 优化器和损失函数可参考这篇文章：{% postLinkCard nyeno8kr \"auto\" true %}\n\n开始训练：\n\n```python\n# 训练模式\nmodel.train()\n\n# 循环遍历所有的训练周期\nfor epoch in range(3):\n    # 循环遍历数据加载器中的每个批次\n    for i, (inputs, targets) in enumerate(dataloader):\n        # 将输入数据转置，以符合模型的期望输入维度\n        inputs = inputs.t()\n        # 在每次迭代前清空梯度\n        optimizer.zero_grad()\n        # 前向传播：计算模型对当前批次的输出\n        outputs = model(inputs)\n        # 选择输出的最后一个元素进行损失计算\n        outputs = outputs[-1]\n        # 计算损失值\n        loss = criterion(outputs, targets)\n        # 反向传播：计算损失的梯度\n        loss.backward()\n        # 更新模型的参数\n        optimizer.step()\n        # 每隔50步打印一次当前的训练状态\n        if i % 50 == 0:\n            print(f'Epoch [{epoch + 1}/{3}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item()}')\n\n# 保存模型到指定路径\ntorch.save(model, \"transformer_model.pth\")\nprint('模型已保存到', \"transformer_model.pth\")\n```\n\n仅用于演示，这里只训练了`3轮`，训练大致耗时几分钟，过程截图：\n\n![image-20241215144352531](/images/assets//image-20241215144352531.png)\n\n## 测试模型\n\n```python\nimport torch\nimport json\nimport jieba\n\ndef load_model(model_path):\n    # 加载模型到CPU\n    model = torch.load(model_path, map_location=torch.device('cpu'))\n    # 设置为评估模式\n    model.eval()\n    return model\n\ndef load_vocab(json_file):\n    # 读取词汇表文件\n    with open(json_file, 'r') as f:\n        vocab = json.load(f)\n    return vocab\n\ndef predict(model, initial_seq, max_len=10):\n    # 加载数字到单词的映射\n    int_to_word = load_vocab('int_to_word.json')\n    # 确保模型处于评估模式\n    model.eval()\n    # 关闭梯度计算\n    with torch.no_grad():\n        generated = initial_seq\n        # 生成最多max_len个词\n        for _ in range(max_len):\n            input_tensor = torch.tensor([generated], dtype=torch.long)\n            output = model(input_tensor)\n            predicted_idx = torch.argmax(output[:, -1], dim=-1).item()\n            generated.append(predicted_idx)\n            # 如果生成结束标记，则停止生成\n            if predicted_idx == len(int_to_word) - 1:\n                break\n        # 将生成的索引转换为单词\n        return [int_to_word[str(idx)] for idx in generated]\n\ndef generate(model, input_sentence, max_len=10):\n    # 使用结巴分词对输入句子进行分词\n    input_words = list(jieba.cut(input_sentence.strip()))\n    # 加载单词到数字的映射\n    word_to_int = load_vocab('word_to_int.json')\n    # 将单词转换为索引\n    input_seq = [word_to_int.get(word, len(word_to_int) - 1) for word in input_words]\n    # 生成文本\n    generated_text = predict(model, input_seq, max_len)\n    # 将生成的单词列表合并为字符串\n    return \"\".join(generated_text)\n\ndef main():\n    # 定义输入提示\n    prompt = \"介绍一下数学历史。\"\n    # 加载模型\n    model = load_model('transformer_model.pth')\n    # 生成文本\n    completion = generate(model, prompt)\n    # 打印生成的文本\n    print(prompt, completion)\n\nif __name__ == '__main__':\n    main()\n```\n\n效果如下：\n\n![image-20241215143828976](/images/assets//image-20241215143828976.png)\n\n不出意外的烂哈哈哈，如果要`提升质量`，就需要在增加`训练集量级`和`训练周期`的基础之上，`优化模型参数`了。\n","categories":["论文解读"]},{"title":"Latex数学公式符号汇总","url":"/2024/10/20/xf4572aq/","content":"\nTeX数学公式指南，仅供参考。\n\n# 基础环境\n\n## 公式环境类型\n\n| 类型       | 语法                                  | 说明             |\n| ---------- | ------------------------------------- | ---------------- |\n| 行内公式   | `$...$`                               | 嵌入文本中的公式 |\n| 行间公式   | `$$...$$`                             | 独立成行的公式   |\n| 编号公式   | `\\begin{equation}...\\end{equation}`   | 自动编号的公式   |\n| 无编号公式 | `\\begin{equation*}...\\end{equation*}` | 不编号的公式     |\n\n## 基本语法规则\n\n1. 公式必须在数学环境中书写\n2. 使用花括号 `{}` 进行分组\n3. 多个参数用 `\\` 开头的命令\n4. 下标用 `_`，上标用 `^`\n\n## 常见注意事项\n\n1. 行内公式中避免使用 `\\frac`，建议使用 `\\tfrac` 或斜线表示\n2. 复杂表达式应使用 `\\left` 和 `\\right` 自动调整括号大小\n3. 多行公式尽量使用 `align` 环境而不是 `eqnarray`\n4. 矩阵中使用 `&` 分隔列，使用 `\\\\` 换行\n5. 在需要输入大括号时，使用 `\\{` 和 `\\}`\n\n# 基础符号与运算\n\n## 基础运算符\n\n| 符号      | 代码      | 符号    | 代码    |\n| --------- | --------- | ------- | ------- |\n| $+$       | `+`       | $-$     | `-`     |\n| $\\times$  | `\\times`  | $\\div$  | `\\div`  |\n| $\\pm$     | `\\pm`     | $\\mp$   | `\\mp`   |\n| $\\cdot$   | `\\cdot`   | $\\ast$  | `\\ast`  |\n| $\\bullet$ | `\\bullet` | $\\circ$ | `\\circ` |\n| $\\propto$ | `\\propto` | $\\wr$   | `\\wr`   |\n\n## 比较符号\n\n| 符号      | 代码      | 符号     | 代码     |\n| --------- | --------- | -------- | -------- |\n| $=$       | `=`       | $\\neq$   | `\\neq`   |\n| $\\approx$ | `\\approx` | $\\equiv$ | `\\equiv` |\n| $\\sim$    | `\\sim`    | $\\simeq$ | `\\simeq` |\n| $>$       | `>`       | $<$      | `<`      |\n| $\\geq$    | `\\geq`    | $\\leq$   | `\\leq`   |\n| $\\gg$     | `\\gg`     | $\\ll$    | `\\ll`    |\n\n## 集合符号\n\n| 符号        | 代码        | 符号        | 代码        |\n| ----------- | ----------- | ----------- | ----------- |\n| $\\in$       | `\\in`       | $\\notin$    | `\\notin`    |\n| $\\subset$   | `\\subset`   | $\\subseteq$ | `\\subseteq` |\n| $\\supset$   | `\\supset`   | $\\supseteq$ | `\\supseteq` |\n| $\\cup$      | `\\cup`      | $\\cap$      | `\\cap`      |\n| $\\emptyset$ | `\\emptyset` | $\\forall$   | `\\forall`   |\n| $\\exists$   | `\\exists`   | $\\nexists$  | `\\nexists`  |\n\n## 上下标与分式\n\n### 上下标\n\n| 类型   | 代码     | 效果     |\n| ------ | -------- | -------- |\n| 上标   | `x^2`    | $x^2$    |\n| 下标   | `x_i`    | $x_i$    |\n| 组合   | `x_i^2`  | $x_i^2$  |\n| 多字符 | `x^{2n}` | $x^{2n}$ |\n\n### 分式\n\n| 类型     | 代码                  | 效果                  |\n| -------- | --------------------- | --------------------- |\n| 常规分数 | `\\frac{1}{1+e^{-x}}`  | $\\frac{1}{1+e^{-x}}$  |\n| 小型分数 | `\\tfrac{1}{1+e^{-x}}` | $\\tfrac{1}{1+e^{-x}}$ |\n| 大型分数 | `\\dfrac{1}{1+e^{-x}}` | $\\dfrac{1}{1+e^{-x}}$ |\n\n## 根式\n\n| 类型    | 代码          | 效果          |\n| ------- | ------------- | ------------- |\n| 平方根  | `\\sqrt{x}`    | $\\sqrt{x}$    |\n| n次方根 | `\\sqrt[n]{x}` | $\\sqrt[n]{x}$ |\n\n# 特殊函数与运算符\n\n## 极限、求和、积分\n\n```latex\n% 极限\n\\lim_{x \\to \\infty}\n\n% 求和\n\\sum_{i=1}^n\n\n% 积分\n\\int_{a}^{b}\n\n% 多重积分\n\\iint\n\\iiint\n```\n\n效果：\n$$\n% 极限\n\\lim_{x \\to \\infty}~~\n\n% 求和\n\\sum_{i=1}^n~~\n\n% 积分\n\\int_{a}^{b}~~\n\n% 多重积分\n\\iint~~\n\\iiint~~\n$$\n\n## 常用函数\n\n```latex\n\\sin x\n\\cos x\n\\tan x\n\\log x\n\\ln x\n\\exp x\n\\max(x,y)\n\\min(x,y)\n```\n\n$$\n\\sin x ~~\n\\cos x ~~\n\\tan x ~~\n\\log x ~~\n\\ln x ~~\n\\exp x ~~\n\\max(x,y) ~~\n\\min(x,y)\n$$\n\n# 矩阵与行列式\n\n## 基本矩阵\n\n```latex\n\\begin{matrix}\na & b \\\\\nc & d\n\\end{matrix}\n```\n\n效果：\n$$\n\\begin{matrix}\na & b \\\\\nc & d\n\\end{matrix}\n$$\n\n## 带括号的矩阵\n\n```latex\n% 小括号矩阵\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n\n% 中括号矩阵\n\\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\n% 大括号矩阵\n\\begin{Bmatrix}\na & b \\\\\nc & d\n\\end{Bmatrix}\n\n% 行列式\n\\begin{vmatrix}\na & b \\\\\nc & d\n\\end{vmatrix}\n```\n\n效果：\n$$\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n\\quad\n\\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\quad\n\\begin{Bmatrix}\na & b \\\\\nc & d\n\\end{Bmatrix}\n\\quad\n\\begin{vmatrix}\na & b \\\\\nc & d\n\\end{vmatrix}\n$$\n\n## 增广矩阵\n\n```latex\n\\left[\n\\begin{array}{cc|c}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\n\\right]\n```\n\n效果：\n$$\n\\left[\n\\begin{array}{cc|c}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\n\\right]\n$$\n\n# 多行公式与对齐\n\n## 多行公式排版\n\n```latex\n\\begin{array}{ll}\ny = x + 1 \\\\\ny = x^2 + 2x + 1 \\\\\ny = \\frac{x^2}{2}\n\\end{array}\n```\n\n效果：\n$$\n\\begin{array}{ll}\ny = x + 1 \\\\\ny = x^2 + 2x + 1 \\\\\ny = \\dfrac{x^2}{2}\n\\end{array}\n$$\n\n## 长等式对齐\n\n```latex\n\\begin{array}{ll}\ny &= x + 1 \\\\\n  &= (x + 2) - 1 \\\\\n  &= x + 2 - 1\n\\end{array}\n```\n\n效果：\n$$\n\\begin{array}{ll}\ny &= x + 1 \\\\\n  &= (x + 2) - 1 \\\\\n  &= x + 2 - 1\n\\end{array}\n$$\n\n## 分段函数\n\n```latex\nf(x)=\\begin{cases}\nx, & x > 0 \\\\\n0, & x = 0 \\\\\n-x, & x < 0\n\\end{cases}\n```\n\n效果：\n$$\nf(x)=\\begin{cases}\nx, & x > 0 \\\\\n0, & x = 0 \\\\\n-x, & x < 0\n\\end{cases}\n$$\n\n## 空格控制\n\n| 空格类型 | 代码     | 宽度 |\n| -------- | -------- | ---- |\n| 细空格   | `\\,`     | 3mu  |\n| 中等空格 | `\\:`     | 4mu  |\n| 大空格   | `\\;`     | 5mu  |\n| 负空格   | `\\!`     | -3mu |\n| 固定空格 | `\\quad`  | 1em  |\n| 双倍空格 | `\\qquad` | 2em  |\n\n# 高级数学符号\n\n## 微积分符号\n\n| 符号       | 代码       | 说明         |\n| ---------- | ---------- | ------------ |\n| $\\partial$ | `\\partial` | 偏导数       |\n| $\\nabla$   | `\\nabla`   | nabla算子    |\n| $\\prime$   | `\\prime`   | 导数         |\n| $\\oint$    | `\\oint`    | 闭合曲线积分 |\n| $\\oiint$   | `\\oiint`   | 闭合曲面积分 |\n| $\\oiiint$  | `\\oiiint`  | 闭合体积积分 |\n| $\\,dx$     | `\\,dx`     | 微分符号     |\n| $\\Delta$   | `\\Delta`   | 增量         |\n\n## 向量符号\n\n```latex\n% 向量表示\n\\vec{a}  % 箭头向量\n\\mathbf{a}  % 粗体向量\n\\overrightarrow{AB}  % 带箭头的线段\n```\n\n效果：\n$$\n\\vec{a} \\\\\n\\mathbf{a} \\\\\n\\overrightarrow{AB}\n$$\n\n## 集合与逻辑符号\n\n### 集合符号\n| 符号         | 代码         | 说明     |\n| ------------ | ------------ | -------- |\n| $\\mathbb{R}$ | `\\mathbb{R}` | 实数集   |\n| $\\mathbb{C}$ | `\\mathbb{C}` | 复数集   |\n| $\\mathbb{Z}$ | `\\mathbb{Z}` | 整数集   |\n| $\\mathbb{N}$ | `\\mathbb{N}` | 自然数集 |\n| $\\mathbb{Q}$ | `\\mathbb{Q}` | 有理数集 |\n\n### 逻辑符号\n| 符号       | 代码       | 说明     |\n| ---------- | ---------- | -------- |\n| $\\wedge$   | `\\wedge`   | 逻辑与   |\n| $\\vee$     | `\\vee`     | 逻辑或   |\n| $\\neg$     | `\\neg`     | 逻辑非   |\n| $\\implies$ | `\\implies` | 蕴含     |\n| $\\iff$     | `\\iff`     | 当且仅当 |\n\n# 复杂公式示例\n\n## 高等数学公式\n\n### 多重积分与极限\n```latex\n$$\n\\iiint\\limits_V \\mu(x,y,z)\\,dV = \\lim_{n \\to \\infty} \\sum_{i=1}^n \\mu(x_i,y_i,z_i)\\Delta V_i\n$$\n\n$$\n\\lim_{n \\to \\infty} \\left(1 + \\frac{x}{n}\\right)^n = \\sum_{n=0}^{\\infty} \\frac{x^n}{n!} = e^x\n$$\n```\n\n效果：\n$$\n\\iiint\\limits_V \\mu(x,y,z)\\,dV = \\lim_{n \\to \\infty} \\sum_{i=1}^n \\mu(x_i,y_i,z_i)\\Delta V_i\n$$\n\n$$\n\\lim_{n \\to \\infty} \\left(1 + \\frac{x}{n}\\right)^n = \\sum_{n=0}^{\\infty} \\frac{x^n}{n!} = e^x\n$$\n\n## 线性代数公式\n\n### 复杂行列式\n```latex\n$$\n\\det\\begin{vmatrix} \na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nn}\n\\end{vmatrix} = \\sum_{\\sigma \\in S_n} \\text{sgn}(\\sigma) \\prod_{i=1}^n a_{i\\sigma(i)}\n$$\n```\n\n效果：\n$$\n\\det\\begin{vmatrix} \na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nn}\n\\end{vmatrix} = \\sum_{\\sigma \\in S_n} \\text{sgn}(\\sigma) \\prod_{i=1}^n a_{i\\sigma(i)}\n$$\n\n## 物理公式\n\n### 麦克斯韦方程组\n```latex\n$$\n\\begin{array}{ll}\n\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0} \\\\\n\\nabla \\cdot \\mathbf{B} = 0 \\\\\n\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t} \\\\\n\\nabla \\times \\mathbf{B} = \\mu_0\\left(\\mathbf{J} + \\varepsilon_0\\frac{\\partial \\mathbf{E}}{\\partial t}\\right)\n\\end{array}\n$$\n```\n\n效果：\n$$\n\\begin{array}{ll}\n\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0} \\\\\n\\nabla \\cdot \\mathbf{B} = 0 \\\\\n\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t} \\\\\n\\nabla \\times \\mathbf{B} = \\mu_0\\left(\\mathbf{J} + \\varepsilon_0\\frac{\\partial \\mathbf{E}}{\\partial t}\\right)\n\\end{array}\n$$\n\n## 统计公式\n\n### 多元正态分布\n\n```latex\n$$\nf_X(x) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\Sigma|^{\\frac{1}{2}}} \ne^{\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)}\n$$\n```\n\n效果：\n$$\nf_X(x) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\Sigma|^{\\frac{1}{2}}} \ne^{\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)}\n$$\n\n# 排版技巧与实践\n\n## 括号大小控制\n\n1. 自适应括号：使用 `\\left` 和 `\\right`\n```latex\n\\left(\\frac{1}{1+x^2}\\right)\n```\n\n效果：\n$$\n\\left(\\frac{1}{1+x^2}\\right)\n$$\n\n\n2. 固定大小括号：使用 `\\big`、`\\Big`、`\\bigg`、`\\Bigg`\n\n```latex\n\\Bigg(\\bigg(\\Big(\\big((x)\\big)\\Big)\\bigg)\\Bigg)\n```\n\n效果：\n$$\n\\Bigg(\\bigg(\\Big(\\big((x)\\big)\\Big)\\bigg)\\Bigg)\n$$\n\n\n## 多行公式对齐技巧\n\n1. 使用 `align` 环境进行对齐\n2. 在对齐点使用 `&` 符号\n3. 使用 `\\\\` 换行\n4. 长公式可以使用 `split` 环境\n\n## 常见错误处理\n\n1. 下标和上标的顺序：先下标后上标（`x_{i}^{2}`）\n2. 在行内公式中避免使用大型分式\n3. 使用 `\\text{}` 在公式中插入文本\n4. 使用 `\\limits` 和 `\\nolimits` 控制上下限位置\n\n## 性能优化建议\n\n1. 复杂公式使用 `equation` 环境而不是 `$$`\n2. 多次使用的公式可以定义为宏\n3. 避免过度使用自适应大小的定界符\n4. 适当使用空格调整公式的美观度\n\n> 后续若有新使用到的语法，会持续更新。\n","categories":["小小知识"]},{"title":"超拟真AI语音合成工具【REECHO】初体验！","url":"/2024/10/17/dhfndcph/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 超拟真AI语音合成工具【REECHO】初体验！ https://mp.weixin.qq.com/s/l5pNhLpn13sondrcYcdvEQ /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"Linux系统目录","url":"/2024/10/13/9ikmkjbw/","content":"\n在 Linux 系统中，目录结构是遵循 **FHS（Filesystem Hierarchy Standard，文件系统层次结构标准）** 的，每个目录都有特定的用途和功能。以下是 Linux 系统主要目录的详细介绍，它们位于系统的根目录 `/` 下。\n\n---\n\n# **根目录（`/`）**\n\n- 根目录是 Linux 文件系统的起点，所有目录和文件都从这里开始。\n- 根目录本身通常只包含子目录，而不直接存放文件。\n- **注意**：确保根目录有足够的空间，因为它的损坏会导致系统无法启动。\n\n---\n\n# **主要子目录详解**\n\n## **`/bin`**\n- **作用**：存放基本的用户二进制可执行文件。\n- **内容**：普通用户和管理员都可以使用的常用命令，例如：\n  - `ls`、`cp`、`mv`、`rm`、`cat`、`echo`、`pwd`、`chmod` 等。\n- **特点**：在单用户模式下也可以使用这些命令，因为它们是系统启动和运行的必要工具。\n\n---\n\n## **`/sbin`**\n- **作用**：存放系统管理的二进制可执行文件，普通用户一般无权运行。\n- **内容**：系统管理员使用的命令，例如：\n  - `ifconfig`、`reboot`、`shutdown`、`mkfs`、`fsck` 等。\n- **特点**：与 `/bin` 类似，但主要用于系统管理。\n\n---\n\n## **`/boot`**\n- **作用**：存放与系统引导相关的文件。\n- **内容**：\n  - 内核文件（如 `vmlinuz`）、引导加载程序（如 GRUB 的配置文件）和启动所需的其他文件。\n- **特点**：系统启动时，BIOS/UEFI 会访问这个目录加载内核和引导程序。\n\n---\n\n## **`/dev`**\n- **作用**：存放系统中的设备文件。\n- **内容**：\n  - 所有硬件设备都被抽象为文件存放在这里，例如：\n    - 硬盘：`/dev/sda`、`/dev/sdb`\n    - 光驱：`/dev/cdrom`\n    - 终端设备：`/dev/tty1`\n    - 随机数设备：`/dev/random`\n- **特点**：通过这些文件可以直接与硬件交互。\n\n---\n\n## **`/etc`**\n- **作用**：存放系统的所有配置文件和子目录。\n- **内容**：\n  - 系统配置文件：`/etc/passwd`、`/etc/fstab`、`/etc/hosts` 等。\n  - 服务配置文件：`/etc/ssh/sshd_config`、`/etc/nginx/nginx.conf` 等。\n- **特点**：是系统配置的核心目录，建议备份。\n\n---\n\n## **`/home`**\n- **作用**：存放普通用户的主目录。\n- **内容**：\n  - 每个用户都有一个对应的子目录，例如：\n    - 用户 `alice` 的主目录是 `/home/alice`。\n    - 用户 `bob` 的主目录是 `/home/bob`。\n  - 用户的数据、配置文件等都存放在这里。\n- **特点**：如果系统重新安装，可以单独保留 `/home`，以免丢失用户数据。\n\n---\n\n## **`/lib`**\n- **作用**：存放系统运行所需的共享库（类似 Windows 的 DLL 文件）。\n- **内容**：\n  - 静态库和动态库文件，例如：\n    - `libc.so`（C 标准库）\n    - `libm.so`（数学库）\n- **特点**：这些库供 `/bin` 和 `/sbin` 的程序使用。\n\n---\n\n## **`/media`**\n- **作用**：挂载可移动媒体设备的临时目录。\n- **内容**：\n  - 当插入 U 盘、光盘等设备时，系统会自动将其挂载到 `/media` 下，例如：\n    - `/media/usb`、`/media/cdrom`。\n- **特点**：用户可以方便地访问这些设备。\n\n---\n\n## **`/mnt`**\n- **作用**：挂载临时文件系统的目录。\n- **内容**：\n  - 系统管理员可以手动将设备挂载到这里，例如：\n    - `mount /dev/sdb1 /mnt/test`\n- **特点**：与 `/media` 不同，通常需要手动挂载。\n\n---\n\n## **`/opt`**\n- **作用**：存放第三方软件的可选目录。\n- **内容**：\n  - 安装的第三方软件或应用程序会存放在这里，例如：\n    - `/opt/google/chrome`（Google Chrome 浏览器）\n    - `/opt/lampp`（XAMPP 软件包）\n- **特点**：与系统分离，便于管理。\n\n---\n\n## **`/proc`**\n- **作用**：存放内核和进程的虚拟文件系统。\n- **内容**：\n  - 虚拟文件，显示系统的运行时信息，例如：\n    - `/proc/cpuinfo`：CPU 信息。\n    - `/proc/meminfo`：内存信息。\n    - `/proc/<PID>`：每个进程的详细信息。\n- **特点**：动态生成，不实际占用磁盘空间。\n\n---\n\n## **`/root`**\n- **作用**：系统管理员（`root` 用户）的主目录。\n- **特点**：\n  - 类似于普通用户的主目录 `/home/username`。\n  - 默认位于 `/root` 而不是 `/home`。\n\n---\n\n## **`/run`**\n- **作用**：存放系统启动后临时生成的运行文件。\n- **内容**：\n  - 运行时的进程 ID 文件（如 `/run/sshd.pid`）。\n  - 套接字和其他运行时数据。\n- **特点**：数据在系统重启后会清空。\n\n---\n\n## **`/srv`**\n- **作用**：存放系统提供的服务数据。\n- **内容**：\n  - Web 服务数据：`/srv/www`。\n  - FTP 数据：`/srv/ftp`。\n- **特点**：用于存放服务器运行时需要的文件。\n\n---\n\n## **`/sys`**\n- **作用**：存放系统的设备和内核信息。\n- **内容**：\n  - 与 `/proc` 类似，提供系统硬件信息，例如：\n    - `/sys/class`：设备分类信息。\n    - `/sys/devices`：硬件设备信息。\n- **特点**：是内核设备模型的一部分。\n\n---\n\n## **`/tmp`**\n- **作用**：存放临时文件。\n- **特点**：\n  - 系统和应用程序运行时可能会在这里创建临时文件。\n  - 系统重启后会自动清空。\n\n---\n\n## **`/usr`**\n- **作用**：存放用户程序及相关文件。\n- **内容**：\n  - `/usr/bin`：用户可执行文件（非必要命令）。\n  - `/usr/sbin`：系统管理员命令。\n  - `/usr/lib`：共享库和模块。\n  - `/usr/share`：共享数据（如文档、图标等）。\n  - `/usr/local`：用户自己安装的软件。\n- **特点**：包含许多系统文件和工具，占用空间较大。\n\n---\n\n## **`/var`**\n- **作用**：存放可变数据文件。\n- **内容**：\n  - 日志文件：`/var/log`（如 `/var/log/syslog`）。\n  - 邮件：`/var/mail`。\n  - 缓存：`/var/cache`。\n  - 数据库：`/var/lib`（如 `/var/lib/mysql`）。\n  - 临时文件：`/var/tmp`。\n- **特点**：\n  - 数据会随着时间增长，例如日志文件。\n\n---\n\n# **Linux 目录结构图**\n\n以下是 Linux 目录结构的简化图示：\n\n```bash\n/\n├── bin       # 基本用户命令\n├── sbin      # 系统管理命令\n├── boot      # 启动相关文件\n├── dev       # 设备文件\n├── etc       # 配置文件\n├── home      # 用户主目录\n├── lib       # 基本共享库\n├── media     # 挂载点（自动）\n├── mnt       # 挂载点（手动）\n├── opt       # 第三方软件\n├── proc      # 内核和进程信息\n├── root      # root 用户主目录\n├── run       # 运行时文件\n├── srv       # 服务数据\n├── sys       # 系统信息\n├── tmp       # 临时文件\n├── usr       # 用户程序\n└── var       # 可变数据\n```\n\n---\n\n# **注意事项**\n\n1. **不要随意修改系统目录**：\n   - 像 `/bin`、`/sbin`、`/etc` 等目录中的文件是系统运行必需的，修改或删除可能导致系统无法正常工作。\n   \n2. **备份重要目录**：\n   - 例如 `/etc`（配置文件）、`/home`（用户数据）、`/var/log`（日志文件）等。\n\n3. **挂载分区**：\n   - 推荐将 `/home`、`/var` 等目录单独分区，以便系统升级或重装时，数据不会丢失。\n\n通过理解 Linux 的目录结构，可以更高效地管理系统资源和定位问题。\n","categories":["Linux"]},{"title":"生信笔记---医学遗传学概述","url":"/2024/10/11/2a5a43xe/","content":"\n# 参考书籍\n\n> 《医学遗传学》第7版，左伋等主编。北京人民卫生出版社出版，2018，全国高等学校五年制本科临床医学专业第九轮规划教材，ISBN 978-7-117-26440-2。\n\n# 医学遗传学概念\n\n在传统的观念上，遗传因素与环境因素在疾病发生、发展中的交互作用考虑得较少，所以比较局限。\n\n一般把`遗传因素`作为唯一或主要病因的疾病称为遗传病。相应地，`医学遗传学`就是用人类遗传学的理论和方法来研究这些遗传病`从亲代传递至子代`的特点和规律、起源和发生 、病理机制 、病变过程及其与临床关系（包括诊断、治疗和预防）的一门综合性学科。\n\n# 人类基因组计划\n\n促使`医学遗传学`发生革命性变化的是20世纪90年代开始的`人类基因组计划`。 \n\n该计划的研究目标是从整体上阐明人遗传信息的组成和表达。包括`遗传图绘制`、`物理图构建`、`测序`、`转录图绘制`和`基因鉴定`等方面的工作，为人类遗传多样性的研究提供基本数据，揭示上万种人类`单基因异常`和上百种严重危害人类健康的`多基因病`（例如心血管疾病、 糖尿病、 恶性肿瘤、 自身免疫性疾病等）的`致病基因`或`疾病易感基因`，建立对各种基因病新的诊治方法，实现精确医疗，从而推动整个生命科学和医学领域的发展。\n\n# 人类基因组介绍\n\n基因（gene）是细胞内遗传物质的结构和功能单位，以脱氧核糖核酸（DNA）的化学形式存在于染色体上。\n\n## 基因的化学本质\n组成DNA分子的基本单位是`脱氧核苷酸`。4种不同的脱氧核苷酸：\n\n- 脱氧腺嘌呤核苷酸 (dAMP, A)\n- 脱氧鸟嘌呤核苷酸 (dGMP, G)\n- 脱氧胞嘧啶核苷酸 (dCMP, C)\n- 脱氧胸腺嘧啶核苷酸 (dTMP, T)\n\n按一定顺序排列起来构成脱氧多核苷酸长链（`DNA单链`）。两条`反向平行`排列的脱氧多核苷酸单链通过`A与T`、`C与G`的碱基互补方式组成DNA双链。4种脱氧核苷酸（A, T, G, C）的排列顺序在不同的DNA分子中各不相同，蕴含着各种生物性状的遗传信息。\n\n## 基因的结构\n\n包括人类在内的`真核生物`的结构基因是`割裂基因`，由编码序列（`外显子`）和非编码序列（`内含子`）组成，两者相间排列。不同基因所含内含子的数目和大小各不相同。\n\n![image-20250116185454091](/images/assets//image-20250116185454091.png)\n\n割裂基因中的`内含子`和`外显子`的关系不是固定不变的，即在同一条 DNA 分子上的某一段 DNA 序列，在作为编码某一条多肽链的基因时是外显子；作为编码另一条多肽链的基因时是内含子，这是由于 `mRNA 剪接加工`的方式不同所致。结果使同一个基因（确切地说是同一段`DNA序列`）产生两条或以上的 mRNA 链。这是真核生物基因的表达中，由于一个基因的内含子成为另一个基因的外显子，产生基因的差异表达，构成剖裂基因结构上的一个重要特点。\n\n每个剖裂基因中第一个外显子的上游和最末一个外显子的下游，都有一段不被转录的非编码区，称为`侧翼序列`。包括`启动子`、`增强子`以及`终止子`等对 DNA 转录起`调控作用`的DNA序列。\n\n剖裂基因结构中`外显子-内含子`的接头区是高度保守的一致序列，称为`外显子-内含子接头`。这是剖裂基因结构上的又一个重要特点。每一个内含子的两端具有广泛的同源性和互补性，5'端起始的两个碱基是 GT，3'端最后的两个碱基是 AG，通常把这种接头形式叫作`GT-AG 法则`（GT-AG rule）。这两个序列是高度保守的，在各种真核生物基因的内含子中均相同。\n\n## 人类基因组构成\n\n随着`人类基因组计划研究`的深入和结构基因组学的基本完成，已知人类基因约有`20000～22000个基因`。这些与蛋白质合成有关的基因序列只占整个基因组序列的1.1%左右；4%为基因调控序列和RNA基因序列；20%为内含子、基因非翻译区序列以及假基因；75%为基因外（extragenic）序列，其中55%为重复DNA序列。近年来发现人类基因组存在`8000多种非编码RNA基因`，表明了人类基因组实际上具有很高的复杂性。人类基因组按DNA序列分类既有单拷贝序列，也有重复频率不等的多拷贝序列。\n\n# 基因表达与调控\n\n## 基因表达\n\n`基因表达（gene expression）`一般是所储存的遗传信息转变为由特定的氨基酸种类和序列构成的多肽链，再由多肽链构成蛋白质或酶分子，从而决定生物各种性状（表型）的过程。\n\n![image-20250116192807058](/images/assets//image-20250116192807058.png)\n\n基因表达包括两个步骤：\n\n### 以DNA为模板转录合成mRNA\n\n转录 `转录（transcription）`是在RNA聚合酶催化下，以DNA的3'→5'单链（模板链）为模板，按照碱基互补配对原则（但RNA以U和DNA的A配对，其余配对形式与DNA复制时一致），以三磷酸核苷酸（NTP）为原料合成RNA的过程。\n\n转录的最终产物是`mRNA、tRNA和rRNA等`。合成不同的RNA所需的RNA聚合酶不同，RNA聚合酶I合成rRNA；RNA聚合酶II合成mRNA的前体，RNA聚合酶III合成snRNA及tRNA等小分子RNA。\n\n### 将遗传信息翻译成多肽链中相应的氨基酸种类和序列\n\n `翻译（translation）`是以mRNA为模板指导蛋白质合成的过程。蛋白质合成在细胞质内的核糖体上进行。`mRNA、tRNA和核糖体`在翻译中起着重要的作用，mRNA携带遗传信息，作为合成蛋白质的模板；tRNA转运活化的氨基酸和识别mRNA分子上的遗传密码；核糖体是蛋白质合成的场所，把各种特定的氨基酸分子连接成多肽链。蛋白质合成通常分为`3个阶段：起始、延长和终止`。每个阶段都涉及许多不同而重要的生化过程。\n\n要成为有功能的成熟的翻译产物，需要对合成初级翻译产物进行加工。mRNA只能决定多肽链中的氨基酸顺序，而蛋白质分子的空间结构是由翻译后修饰所决定的。\n\n## 基因调控\n\n- `奢侈基因`：一种组织细胞中通常只有一种或几种蛋白质发挥优势作用，如上皮细胞为角蛋白、结缔组织为胶原蛋白和弹性蛋白、红细胞为血红蛋白、胰岛细胞为胰岛素等，这些特异表达的基因称为`奢侈基因（luxury gene）`。\n- `持家基因`：几乎在一切体细胞中均能被表达的基因称为`持家基因（housekeeping gene）`，如与DNA复制、RNA转录和蛋白质合成酶有关的基因及控制糖酵解和三羧酸循环的基因。\n\n这表明，细胞表现的分化是由于编码这些蛋白质的基因被选择性地表达，而其他多数基因则处于失活状态或效率相对低的表达状态。\n\n### 转录水平调控\n\n基因表达的转录水平调控可通过蛋白因子与旁侧或内含子序列中的调控序列相结合来进行。\n\n#### 顺式作用元件\n\n在真核基因的`转录调控区`含有的特异的DNA序列被称为`顺式作用元件`（cis-acting element），包括`启动子`、`增强子`和`沉默子`等。顺式作用元件是决定基因表达的内在因素，影响与其自身同处于一个DNA分子上的基因。\n\n- `启动子`：启动基因转录的一段特异DNA序列，一般距转录起始点200bp以内，包括核心启动子和近侧启动子区域。TATA框位于核心启动子区，其序列是TATAAAA，是基本转录因子TFIID的识别和结合位点。GC框和CAAT框位于近侧启动子区，其序列分别为GGGCGG和GCCAAT（CCAAT），用于调节核心启动子的基础转录。\n- `增强子`：位于真核基因转录调控区的一段DNA序列，能增强核心启动子元件起始的基础转录。增强子可位于远离转录起始位点的区域，决定基因的时空特异性表达。\n- `沉默子`：位于调控区抑制或阻遏基因转录的DNA序列，可降低或抑制转录。沉默子可以位于临近启动子的区域，启动子上游或者内含子内部。\n\n#### 反式作用因子\n\n在真核生物中`与顺式作用元件特异性结合`，并参与调节RNA转录的蛋白统称为`转录因子`（transcription factor，TF）或转录调节蛋白。大部分转录因子以反式作用方式结合到靶基因启动子的特定DNA序列上增强或抑制靶基因的转录，又被称为反式作用蛋白（trans-acting protein）。\n\n转录因子能够与基因上游的`非编码区`内特定的DNA模块结合，通过调控核糖核酸酶（RNA聚合酶）与DNA模板的结合，起到激活或者抑制基因表达的作用。在DNA上能够与转录因子相结合的DNA序列即为转录因子结合位点（TFBS），大部分位于基因的启动子区域。\n\n同一转录因子结合位点有很高的`序列相似性`，通常为6～20bp的一段短序列。单个转录因子可以与许多不同的调节区结合，从而调节多个基因的转录；而同一个靶基因也可以受到多个转录因子或转录因子形成的复合物的调节。\n\n#### 组蛋白修饰和染色质重构\n\n`核小体`的致密结构能够阻止DNA与蛋白质之间的相互作用，而`组蛋白修饰`和`染色质重构`有助于局部的染色质可逆地由浓缩状态转变为易接近的构象。\n\n- 组蛋白乙酰基转移酶可以使组蛋白乙酰化，使组蛋白与DNA的结合力降低。\n- `染色质重构`则是指染色质重构复合体通过ATP水解暂时改变核小体的结构，从而使各种蛋白质易于与DNA接近。\n\n### 转录后水平调控\n\n前面提到，真核细胞`mRNA转录后形成成熟的mRNA`需要经过剪接、加帽、加尾等过程，影响其中任何一个环节都将调控基因的表达，如选择性剪接、RNA编辑等。\n\n- 选择性剪接：`选择性剪接（alternative splicing）`又称可变剪接，是指在RNA剪接过程中，同一基因的转录产物经过不同的剪接方式，产生不同的mRNA，进而表达出多个不同的相关蛋白产物，行使不同的生理功能。可变剪接的产物称为亚型。大于90%的人类基因将经历可变剪接。\n\n- RNA编辑：`RNA编辑（RNA editing）`是导致形成的mRNA分子在编码区的核苷酸序列不同于它的DNA模板相应序列的过程。RNA编辑与真核生物mRNA前体的修饰（如截帽、加尾和剪接等）不同，后者不改变DNA的编码序列。\n\n\nRNA编辑的生物学意义主要表现在：\n\n- 经过编辑的mRNA具有翻译活性；\n- 使该mRNA能被通读；\n- 在一些转录物5'末端可创造生成起始密码子AUG，以调节翻译活性；\n- RNA编辑可能与生物进化有关；\n- RNA编辑不偏离中心法则，因为提供编辑的信息源仍然来源于DNA贮藏的遗传信息。\n\n### 翻译水平的调控\n\n许多基因在蛋白合成的水平上也受到调节，由于免去了改变mRNA转录水平所需的时间，翻译水平的调控对外界刺激的反应更为迅速。\n\n- 翻译起始的调控：在翻译起始阶段，许多蛋白质参与了翻译的起始，如`帽结合蛋白`对核糖体与mRNA的结合起着关键的连接作用。而mRNA的序列也参与了翻译的起始调控，如起始密码AUG的旁侧序列、5'的非翻译区等。\n\n- `microRNA的调控作用`：`microRNA（miRNA）`是一类长度约18～25个核苷酸的小单链RNA（ssRNA），由DNA转录产生，不翻译成蛋白质，通过碱基互补配对的方式与靶基因的3'UTR区部分或完全互补，剪切靶基因的转录产物或者抑制转录产物的翻译，从而起到转录后调控靶基因的表达的作用。\n\n`microRNA`的调控作用主要包括：\n\n- `miRNA`对靶mRNA翻译起始的抑制；\n- `miRNA`对靶mRNA翻译起始后抑制；\n- `miRNA`诱导mRNA转录衰减；\n- `miRNA`的正调控与去抑制。\n\n### 翻译后水平的调控\n\n有些蛋白质合成完成后需经过适当的加工修饰才有活性，因而`翻译后修饰`是蛋白质结构和功能调节的一种重要方式，大大增加了蛋白质的多样性和复杂性。\n\n- `常见的蛋白质翻译后修饰`：体内最常见的蛋白质翻译后修饰是`磷酸化修饰`，即在蛋白激酶的作用下，将ATP或GTP上的磷酸基团转移到底物上。除此以外，`糖基化、泛素化、类泛素化（SUMOylation）、乙酰化和甲基化`等也是常见的蛋白质翻译后修饰的方式。通过翻译后修饰维持蛋白质的活性，发挥其生理功能，参与蛋白质的降解和蛋白间的相互作用，影响蛋白在细胞内的分布等。\n- `翻译后修饰的协同作用`：细胞中翻译后修饰种类繁多，往往是多种修饰协同发挥作用，形成调控网络。无论是生理还是病理过程，都需要各种修饰的蛋白质共同作用。\n\n### 表观调控\n\n一个基因的结构除了编码特定功能产物的DNA序列外，还包括对这个特定产物表达所需的`邻接DNA序列`。在对某些遗传病的家系研究中发现，虽然基因的编码部分结构完整，也未发生改变，但若它的邻接DNA序列发生了改变，如常见的邻接序列某些区域单个碱基的替换可使此功能产物不能表达，也可能引发疾病。\n\n另外，在基因的核苷酸序列不发生突变的情况下，基因的修饰如`DNA甲基化`、`组蛋白的乙酰化`等也可能导致基因的活性发生改变，使基因决定的表型出现变化，且可传递少数世代。这是`表观遗传学（epigenetics）`所涉及的主要内容。\n\n# 遗传病概述\n\n## 遗传病的特点\n\n### 遗传病的传播方式\n\n如果某些疾病是由于环境因素致病，在群体中应该按`水平方式`出现，如果是遗传性的，一般则以`垂直方式`出现，不延伸至无亲缘关系的个体，这在显性遗传方式的病例中尤其突出。\n### 遗传病的数量分布\n患者在`亲祖代和子孙中是以一定数量比例出现的`，即患者与正常成员间有一定的数量关系，通过特定的数量关系，可以了解疾病的遗传特点和发病规律，并预期再发风险等。\n### 遗传病的先天性\n遗传病往往有`先天性`特点，但并非所有的遗传病都是先天的。反过来，先天性疾病也有两种可能性，即有些先天性疾病是遗传性的，如白化病，有些则是获得性的，如妇女妊娠时因风疹病毒感染，致胎儿患有先天性心脏病。 `虽然患儿出生时有心脏病，但按传统概念来说它是不遗传的`。\n\n### 遗传病的家族性\n\n遗传病往往有`家族性`等特点。 所谓`家族性是疾病的发生所具有的家族聚集性`。 但并非所有的遗传病都表现为家族性。反过来，家族性疾病可能是遗传的，但不是所有的家族性疾病都是遗传的。\n\n如有一种夜盲症（即当光线比较弱时，视力极度低下的一种疾病）是由于饮食中长期缺乏维生素A引起的，如果同一家庭饮食中长期缺乏维生素A，则这个家庭中的若干成员就有可能出现夜盲症。 这一类家族性疾病是由共同环境条件的影响，而不是出自遗传原因，如果在饮食中补充足够的维生素A后，全家患者的病情都可以得到改善。所以说，由于维生素A缺乏所引起的夜盲症，尽管表现有家族性，但它不是遗传病。\n\n### 遗传病的传染性\n一般的观点认为，`遗传病是没有传染性的`，故在传播方式上，它是垂直传递，而不是水平传递的。\n\n但在目前已知的疾病中，`人类朊粒蛋白病`则是一种既遗传又具传染性的疾病。`朊粒蛋白`是一种功能尚不完全明确的蛋白质。目前认为PrP基因突变会导致PrP的错误折叠或通过使其他蛋白的错误折叠进而引起脑组织的海绵状病变，最终导致脑功能紊乱，称为`蛋白折叠病`；而错误折叠的PrP可以通过某些传播方式使正常人细胞中的正常蛋白质也发生错误折叠并致病。\n\n总之，必须正确地、辩证地认识人类遗传病，这将有助于在医学实践中采取相应的诊断、 治疗和预防措施。\n\n## 人类遗传病的分类\n\n### 单基因病\n单基因病是由`单基因突变`所致。这种突变可发生于两条染色体中的一条，由此所引起的疾病呈常染色体（或性染色体）显性遗传；这种突变也可同时存在于两条染色体上，由此所引起的疾病呈常染色体（或性染色体）隐性遗传。\n\n单基因病相对较少见，在各个种族或民族中的发生频率不同，发生率较高时也仅为1/500，但由于其遗传性，因而危害极大。\n\n### 多基因病\n多基因病是有一定家族史，但没有单基因性状遗传中所见到的系谱特征的一类疾病，如先天性畸形及若干人类常见病（高血压、动脉粥样硬化、糖尿病、哮喘、自身免疫性疾病、老年痴呆、癫痫、精神分裂症、类风湿关节炎、智能发育障碍等）。\n\n环境因素在这类疾病的发生中起不同程度的作用。`多基因病是最常见的遗传病`。\n\n### 染色体病 \n染色体病是`染色体结构或数目异常`引起的一类疾病（综合征）。\n\n从本质上说，这类疾病涉及一个或多个基因结构或数量的变化，故其对个体的危害往往大于单基因病和多基因病，其中最常见的染色体病为Down综合征。染色体病在新生儿中的发病率约为0.5%。\n\n### 体细胞遗传病\n单基因病、多基因病和染色体病的遗传异常发生在人体所有细胞包括`生殖细胞（精子和卵子）`的DNA中，并能传递给下一代，而`体细胞遗传病的累积突变只在特定的体细胞中发生`，体细胞基因突变是此类疾病发生的基础。这类疾病包括恶性肿瘤、白血病、自身免疫缺陷病以及衰老等。\n\n在经典的遗传病的概念中，并不包括这一类疾病。\n\n### 线粒体遗传病\n`线粒体`是细胞内的一个重要细胞器，是除细胞核之外唯一含有DNA的细胞器，具有自己的蛋白质翻译系统和遗传密码。`线粒体遗传病`就是由线粒体DNA缺陷引起的疾病，包括`Leber视神经萎缩`等。\n\n## 在线《人类孟德尔遗传》 OMIM\n\nOMIM，由Johns Hopkins大学医学院Victor A. McKusick教授主编的权威`医学遗传学`百科全书和数据库。\n\n该数据库至1998年已出到第12版，网址为[http://www.omim.org](http://www.omim.org)。\n\n## 疾病的发生与遗传因素和环境因素的关系\n\n- 完全由遗传因素决定发病：与环境因素无关，如先天性成骨不全症等；\n- 基本上由遗传决定，但需要环境中一定诱因的作用：如苯丙氨酸尿症、蚕豆病等；\n- 遗传因素和环境因素对发病都有作用：不同疾病中遗传率不同：唇裂、腭裂等遗传率在70%以上；先天性心脏病等遗传率不足40%；脊柱裂、高血压等遗传率为50%~60%；\n- 发病完全取决于环境因素，与遗传基本上无关：如烧伤、烫伤等外伤。","categories":["医学遗传学"]},{"title":"Linux命令详解---netstat","url":"/2024/10/09/7un4eax0/","content":"\n`netstat` 是一个用于网络诊断和管理的命令行工具，主要用来显示网络连接、路由表、接口统计、网络协议以及网络端口的使用情况。在 Linux、Unix 和 Windows 系统中都可以使用。\n\n以下是对 `netstat` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\nnetstat [选项]\n```\n\n- **选项**：用于指定要显示的信息类型，例如活动连接、监听端口、网络接口统计等。\n\n---\n\n# **常用选项**\n\n| 选项 | 功能                                                         |\n| ---- | ------------------------------------------------------------ |\n| `-a` | 显示所有连接和监听端口。                                     |\n| `-t` | 显示 TCP 协议的连接。                                        |\n| `-u` | 显示 UDP 协议的连接。                                        |\n| `-l` | 仅显示监听状态的连接（Listening）。                          |\n| `-p` | 显示连接对应的进程信息（需要超级用户权限）。                 |\n| `-n` | 以数字形式显示地址和端口（不进行 DNS 或服务名解析，提高查询速度）。 |\n| `-r` | 显示路由表。                                                 |\n| `-e` | 显示详细的网络信息（如数据包统计）。                         |\n| `-c` | 持续显示网络状态，每隔一段时间更新一次。                     |\n| `-s` | 按协议显示统计信息。                                         |\n| `-i` | 显示网络接口的状态。                                         |\n\n---\n\n# **常用选项组合**\n\n1. **`netstat -an`**  \n   - 显示所有连接和监听端口，使用数字形式表示地址和端口。\n\n2. **`netstat -tuln`**  \n   - 显示所有监听的 TCP 和 UDP 端口，使用数字形式。\n\n3. **`netstat -p`**  \n   - 显示连接对应的进程信息（需要 `sudo` 权限）。\n\n4. **`netstat -r`**  \n   - 显示路由表。\n\n5. **`netstat -i`**  \n   - 显示网络接口的状态。\n\n---\n\n# **详解选项和示例**\n\n## **显示所有连接和监听端口（`-a`）**\n\n- 命令：\n  ```bash\n  netstat -a\n  ```\n- 输出：\n  - 显示所有活动的网络连接以及监听的端口（TCP 和 UDP）。\n\n---\n\n## **仅显示监听端口（`-l`）**\n\n- 命令：\n  ```bash\n  netstat -l\n  ```\n- 用途：\n  - 查看当前系统正在监听的端口，通常用于检查服务器服务是否正常运行。\n\n---\n\n## **显示 TCP 连接（`-t`）**\n\n- 命令：\n  ```bash\n  netstat -t\n  ```\n- 用途：\n  - 查看当前系统的所有 TCP 连接。\n\n---\n\n## **显示 UDP 连接（`-u`）**\n\n- 命令：\n  ```bash\n  netstat -u\n  ```\n- 用途：\n  - 查看当前系统的所有 UDP 连接。\n\n---\n\n## **以数字形式显示地址和端口（`-n`）**\n\n- 命令：\n  ```bash\n  netstat -an\n  ```\n- 用途：\n  - 不进行 DNS 和服务名解析，直接显示 IP 地址和端口号，提高查询速度。\n\n---\n\n## **显示连接对应的进程信息（`-p`）**\n\n- 命令：\n  ```bash\n  sudo netstat -ap\n  ```\n- 用途：\n  - 查看每个连接或监听端口对应的进程名称和 PID（需要超级用户权限）。\n- 输出示例：\n  ```\n  tcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      1234/mysqld\n  ```\n\n---\n\n## **显示路由表（`-r`）**\n\n- 命令：\n  ```bash\n  netstat -r\n  ```\n- 用途：\n  - 显示系统的路由表，类似于 `route -n` 命令。\n- 输出示例：\n  ```\n  Kernel IP routing table\n  Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface\n  0.0.0.0         192.168.1.1     0.0.0.0         UG        0 0          0 eth0\n  ```\n\n---\n\n## **显示网络接口状态（`-i`）**\n\n- 命令：\n  ```bash\n  netstat -i\n  ```\n- 用途：\n  - 查看网络接口的传输状态，例如接收和发送的字节数、错误数等。\n- 输出示例：\n  ```\n  Kernel Interface table\n  Iface      MTU    RX-OK  RX-ERR  TX-OK  TX-ERR\n  eth0       1500   12345  0       23456  0\n  ```\n\n---\n\n## 按协议统计网络信息（`-s`）\n\n- 命令：\n  ```bash\n  netstat -s\n  ```\n- 用途：\n  - 按协议（TCP、UDP、ICMP 等）显示网络统计信息。\n- 输出示例：\n  ```\n  Tcp:\n      12345 active connections openings\n      23456 passive connection openings\n      0 failed connection attempts\n  Udp:\n      5678 packets received\n      0 packet receive errors\n  ```\n\n---\n\n##  **持续更新网络状态（`-c`）**\n\n- 命令：\n  ```bash\n  netstat -c\n  ```\n- 用途：\n  - 每隔一秒更新一次网络连接状态，适合实时监控网络活动。\n\n---\n\n##  **显示监听的 TCP 和 UDP 端口（`-tuln`）**\n\n- 命令：\n  ```bash\n  netstat -tuln\n  ```\n- 用途：\n  - 查看当前监听的所有 TCP 和 UDP 端口，显示数字形式的 IP 和端口号。\n- 输出示例：\n  ```\n  Proto Recv-Q Send-Q Local Address           Foreign Address         State\n  tcp        0      0 127.0.0.1:22            0.0.0.0:*               LISTEN\n  udp        0      0 0.0.0.0:68              0.0.0.0:*\n  ```\n\n---\n\n# **结合其他命令**\n\n## **查看某端口的使用情况**\n\n- 查看系统中 80 端口是否被监听：\n  ```bash\n  netstat -an | grep \":80\"\n  ```\n\n---\n\n##  **查看某进程的网络连接**\n\n- 查找 PID 为 1234 的进程的网络连接：\n  ```bash\n  netstat -anp | grep \"1234\"\n  ```\n\n---\n\n##  **按状态过滤连接**\n\n- 查看所有 `ESTABLISHED` 状态的连接：\n  ```bash\n  netstat -an | grep ESTABLISHED\n  ```\n\n- 查看所有处于 `LISTEN` 状态的端口：\n  ```bash\n  netstat -an | grep LISTEN\n  ```\n\n---\n\n##  **统计连接数**\n\n- 统计所有 `ESTABLISHED` 连接的数量：\n  ```bash\n  netstat -an | grep ESTABLISHED | wc -l\n  ```\n\n---\n\n# **注意事项**\n\n1. **权限问题**：\n   \n   - 使用 `-p` 选项查看进程信息时，需要具备超级用户权限（`sudo`）。\n   \n2. **替代工具**：\n   - 在现代 Linux 系统中，`netstat` 已逐渐被 `ss` 命令取代：\n     - `ss` 的功能和输出格式类似于 `netstat`，但性能更高。\n     - 示例：\n       ```bash\n       ss -tuln\n       ```\n\n3. **性能问题**：\n   - 如果系统中有大量网络连接，`netstat` 的执行速度可能较慢，`ss` 通常是更好的选择。\n\n---\n\n# **总结**\n\n- **`netstat` 是一个强大的网络诊断工具**，可以快速查看系统的网络连接、监听端口、路由表和网络接口状态。\n- **常用组合**：\n  - 查看监听的端口：`netstat -tuln`\n  - 查看连接的进程：`sudo netstat -ap`\n  - 查看路由表：`netstat -r`\n- **现代系统建议使用 `ss` 替代 `netstat`**，但在许多场景下，`netstat` 仍然是非常有用的工具。\n","categories":["Linux"]},{"title":"Linux命令详解---top","url":"/2024/10/09/2yn952dc/","content":"\n`top` 是 Linux 和类 Unix 系统中用于动态显示系统运行信息的命令行工具，它可以实时监控系统的**进程活动**和**系统资源使用情况**，如 CPU 使用率、内存使用情况、任务状态等。`top` 是系统管理员和开发人员用来排查性能问题的一个重要工具。\n\n---\n\n# **基本用法**\n\n运行 `top` 命令：\n\n```bash\ntop\n```\n\n- 默认情况下，`top` 会持续刷新系统状态（通常每 3 秒刷新一次），显示系统的资源使用情况和当前运行的进程。\n\n---\n\n# **界面解析**\n\n`top` 命令启动后，默认显示如下内容（可能因系统不同稍有差异）：\n\n## **系统整体信息（顶部摘要部分）**\n顶部摘要部分显示系统的全局信息，包含以下字段：\n\n### **第一行：任务时间和系统负载**\n```\ntop - 10:05:32 up 2 days,  3:45,  3 users,  load average: 0.10, 0.20, 0.15\n```\n- **10:05:32**：当前系统时间。\n- **up 2 days, 3:45**：系统已运行时间，格式为“天、小时:分钟”。\n- **3 users**：当前登录的用户数量。\n- **load average**：系统负载平均值，分别为过去 **1 分钟、5 分钟、15 分钟** 的平均负载值。接近或高于 CPU 核心数可能表示系统过载。\n\n### **第二行：任务信息**\n```\nTasks: 120 total, 1 running, 119 sleeping, 0 stopped, 0 zombie\n```\n- **120 total**：系统中总共的任务（进程）数。\n- **1 running**：正在运行的任务数。\n- **119 sleeping**：处于“休眠”状态的任务数。\n- **0 stopped**：停止的任务数。\n- **0 zombie**：僵尸进程数。\n\n### **第三行：CPU 使用情况**\n```\n%Cpu(s):  1.5 us,  0.5 sy,  0.0 ni, 98.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n```\n- **us**（user）：用户空间占用的 CPU 百分比。\n- **sy**（system）：内核空间占用的 CPU 百分比。\n- **ni**（nice）：被调整优先级的进程占用的 CPU 百分比。\n- **id**（idle）：空闲 CPU 百分比。\n- **wa**（IO wait）：等待 I/O 操作完成占用的 CPU 百分比。\n- **hi**（hardware interrupts）：硬件中断占用的 CPU 百分比。\n- **si**（software interrupts）：软件中断占用的 CPU 百分比。\n- **st**（steal）：虚拟机环境中被其他虚拟机占用的 CPU 百分比。\n\n### **第四行：内存使用情况**\n```\nMiB Mem :  8000.0 total,  3000.0 free,  2500.0 used,  2500.0 buff/cache\n```\n- **total**：总物理内存大小。\n- **free**：未被使用的内存大小。\n- **used**：已使用的内存大小（不包括缓冲和缓存）。\n- **buff/cache**：用于缓冲和缓存的内存大小。\n\n### **第五行：交换分区使用情况**\n```\nMiB Swap:  2000.0 total,  1500.0 free,   500.0 used.  5000.0 avail Mem\n```\n- **total**：总交换分区大小。\n- **free**：未使用的交换分区大小。\n- **used**：已使用的交换分区大小。\n- **avail Mem**：可用内存（包括 free 和部分 buff/cache）。\n\n---\n\n## **进程信息（下方动态表格部分）**\n下方表格动态显示系统的进程信息，每个进程占一行。默认显示的列包含以下字段：\n\n| 列名        | 含义                                                         |\n| ----------- | ------------------------------------------------------------ |\n| **PID**     | 进程 ID。                                                    |\n| **USER**    | 进程所属用户。                                               |\n| **PR**      | 进程优先级（priority）。                                     |\n| **NI**      | 进程的 nice 值（优先级调整值）。                             |\n| **VIRT**    | 进程占用的虚拟内存总量（包括交换分区）。                     |\n| **RES**     | 进程占用的物理内存大小。                                     |\n| **SHR**     | 共享内存大小。                                               |\n| **S**       | 进程状态：`R`（运行）、`S`（休眠）、`Z`（僵尸）、`T`（停止）。 |\n| **%CPU**    | 进程占用的 CPU 百分比。                                      |\n| **%MEM**    | 进程占用的内存百分比。                                       |\n| **TIME+**   | 进程累计运行时间（格式：分钟:秒.百分秒）。                   |\n| **COMMAND** | 启动进程的命令名称或路径。                                   |\n\n---\n\n# **常用操作与快捷键**\n\n在运行 `top` 命令时，可以通过键盘输入快捷键动态调整显示内容或执行操作：\n\n| 快捷键     | 功能                                              |\n| ---------- | ------------------------------------------------- |\n| `h`        | 显示帮助菜单。                                    |\n| `q`        | 退出 `top` 命令。                                 |\n| `Space`    | 马上刷新一次显示（无需等待刷新间隔）。            |\n| `P`        | 按 CPU 使用率排序（默认）。                       |\n| `M`        | 按内存使用率排序。                                |\n| `T`        | 按运行时间排序。                                  |\n| `k`        | 杀死进程（需要输入 PID）。                        |\n| `r`        | 调整进程优先级（需要输入 PID 和新的 `nice` 值）。 |\n| `u`        | 显示指定用户的进程。                              |\n| `s`        | 设置刷新时间间隔（以秒为单位）。                  |\n| `f`        | 设置或取消显示的列（自定义显示字段）。            |\n| `o` 或 `O` | 按指定字段排序（输入字段名称）。                  |\n| `l`        | 开关显示第一行（系统时间和负载）。                |\n| `t`        | 开关显示 CPU 使用信息。                           |\n| `m`        | 开关显示内存信息。                                |\n| `z`        | 切换显示颜色模式。                                |\n\n---\n\n# **常用选项**\n\n除了交互模式操作外，`top` 命令也支持选项，可以直接在命令行中指定：\n\n| 选项          | 功能                                                   |\n| ------------- | ------------------------------------------------------ |\n| `-b`          | 以**批处理模式**运行，适合脚本抓取数据（非交互模式）。 |\n| `-n [次数]`   | 指定刷新次数后退出（需结合 `-b` 使用）。               |\n| `-u [用户名]` | 仅显示指定用户的进程。                                 |\n| `-p [PID]`    | 仅监控指定的进程 ID。                                  |\n| `-d [秒]`     | 设置刷新间隔时间（默认 3 秒）。                        |\n| `-H`          | 显示线程信息，而非进程信息。                           |\n| `-o [字段名]` | 指定排序字段（如 `%CPU` 或 `%MEM`）。                  |\n| `-c`          | 显示完整的命令行（包括命令参数）。                     |\n\n---\n\n# **常用示例**\n\n## **普通运行**\n```bash\ntop\n```\n\n- 默认以交互模式运行，实时显示系统资源使用情况。\n\n---\n\n## **监控某个用户的进程**\n```bash\ntop -u username\n```\n\n- 仅显示指定用户的进程。\n\n---\n\n## **批处理模式（抓取一次数据后退出）**\n```bash\ntop -b -n 1 > top_output.txt\n```\n\n- 以批处理模式运行，抓取一次系统状态并保存到 `top_output.txt` 文件中。\n\n---\n\n## **每 5 秒刷新一次**\n```bash\ntop -d 5\n```\n\n- 设置刷新时间间隔为 5 秒。\n\n---\n\n## **仅监控某个进程（按 PID）**\n```bash\ntop -p 12345\n```\n\n- 仅显示 PID 为 `12345` 的进程。\n\n---\n\n## **按内存使用率排序**\n在 `top` 运行后按 `M`，或者直接使用选项：\n```bash\ntop -o %MEM\n```\n\n---\n\n## **显示线程信息**\n```bash\ntop -H\n```\n\n- 显示每个线程的信息，而不是进程。\n\n---\n\n# **注意事项**\n\n1. **权限问题**：\n   - 普通用户运行时，无法监控其他用户的某些进程（如系统守护进程）。\n   - 使用 `sudo` 提升权限可以查看所有用户的进程。\n\n2. **刷新间隔**：\n   - 刷新间隔过短可能导致系统负载增加，建议设置适当的刷新时间（如 3 秒或更长）。\n\n3. **僵尸进程**：\n   - 如果看到 `zombie` 进程（僵尸进程），需要检查程序的父进程是否处理了子进程的退出状态。\n\n---\n\n# **总结**\n\n- **`top` 是实时监控系统性能和进程活动的核心工具**，它可以帮助快速定位性能瓶颈（如高 CPU、内存占用）。\n- **常用快捷键**：\n  - `P`：按 CPU 使用率排序。\n  - `M`：按内存使用率排序。\n  - `k`：杀死进程。\n  - `q`：退出。\n- 如果需要非交互式使用 `top`，可以结合 `-b` 和其他选项，方便在脚本中使用或保存结果到文件中。\n","categories":["Linux"]},{"title":"Linux命令详解---touch","url":"/2024/10/09/z9gvqadp/","content":"\n`touch` 是 Linux/Unix 系统中用于创建空文件或更新文件时间戳的命令。它是一个简单而常用的工具，特别适合文件操作时快速创建新文件或修改现有文件的时间信息。\n\n---\n\n# **基本语法**\n\n```bash\ntouch [选项] 文件名\n```\n\n- **选项**：控制行为（如修改时间戳、创建文件等）。\n- **文件名**：指定需要操作的目标文件，可以是一个或多个。\n\n---\n\n# **常用功能**\n\n## **创建空文件**\n\n如果文件不存在，`touch` 会创建一个新的空文件。\n\n```bash\ntouch 文件名\n```\n\n- **示例**：\n\n```bash\ntouch example.txt\n```\n\n- 作用：创建一个名为 `example.txt` 的空文件。\n\n---\n\n## **批量创建多个文件**\n\n可以同时创建多个文件。\n\n```bash\ntouch 文件1 文件2 文件3\n```\n\n- **示例**：\n\n```bash\ntouch file1.txt file2.txt file3.txt\n```\n\n- 作用：创建 `file1.txt`、`file2.txt` 和 `file3.txt`。\n\n---\n\n## **更新文件的时间戳**\n\n如果文件已存在，`touch` 会更新该文件的 **访问时间（atime）** 和 **修改时间（mtime）**。\n\n```bash\ntouch 文件名\n```\n\n- **示例**：\n\n```bash\ntouch existing_file.txt\n```\n\n- 作用：更新 `existing_file.txt` 的时间戳为当前时间。\n\n---\n\n## **指定时间戳**\n\n使用 `-t` 选项可以设置自定义的时间戳。\n\n```bash\ntouch -t [[CC]YY]MMDDhhmm[.ss] 文件名\n```\n\n- 格式说明：\n  - `CC`：世纪（可选）。\n  - `YY`：年。\n  - `MM`：月（01-12）。\n  - `DD`：日（01-31）。\n  - `hh`：小时（00-23）。\n  - `mm`：分钟（00-59）。\n  - `.ss`：秒（可选，00-59）。\n\n- **示例**：\n\n```bash\ntouch -t 202312312359.59 example.txt\n```\n\n- 作用：将 `example.txt` 的时间戳设置为 2023 年 12 月 31 日 23:59:59。\n\n---\n\n## **使用参考文件的时间戳**\n\n可以使用 `-r` 或 `--reference` 选项以其他文件的时间戳为参考。\n\n```bash\ntouch -r 参考文件 文件名\n```\n\n- **示例**：\n\n```bash\ntouch -r old_file.txt new_file.txt\n```\n\n- 作用：将 `new_file.txt` 的时间戳设置为与 `old_file.txt` 相同。\n\n---\n\n## **不创建文件，仅修改时间戳**\n\n使用 `-c` 或 `--no-create` 选项可以避免创建新文件，仅更新已有文件的时间戳。\n\n```bash\ntouch -c 文件名\n```\n\n- **示例**：\n\n```bash\ntouch -c existing_file.txt\n```\n\n- 作用：更新 `existing_file.txt` 的时间戳，如果文件不存在，则不创建。\n\n---\n\n## **修改访问时间或修改时间**\n\n### **1) 仅修改访问时间（atime）**\n\n使用 `-a` 选项可以只更新访问时间。\n\n```bash\ntouch -a 文件名\n```\n\n- **示例**：\n\n```bash\ntouch -a example.txt\n```\n\n- 作用：仅更新 `example.txt` 的访问时间，保持修改时间（mtime）不变。\n\n---\n\n### **2) 仅修改修改时间（mtime）**\n\n使用 `-m` 选项可以只更新修改时间。\n\n```bash\ntouch -m 文件名\n```\n\n- **示例**：\n\n```bash\ntouch -m example.txt\n```\n\n- 作用：仅更新 `example.txt` 的修改时间，保持访问时间（atime）不变。\n\n---\n\n## **检查文件时间信息**\n\n虽然 `touch` 不直接显示文件时间信息，但可以使用 `ls -l` 查看文件的修改时间，或使用 `stat` 查看详细的时间信息。\n\n### **1) 查看修改时间**\n\n```bash\nls -l 文件名\n```\n\n- **示例**：\n\n```bash\nls -l example.txt\n```\n\n- 输出：显示文件的修改时间。\n\n---\n\n### **2) 查看详细时间信息**\n\n```bash\nstat 文件名\n```\n\n- **示例**：\n\n```bash\nstat example.txt\n```\n\n- 输出：显示文件的访问时间（atime）、修改时间（mtime）和状态更改时间（ctime）。\n\n---\n\n# **常用选项总结**\n\n| **选项**              | **作用**                                            |\n| --------------------- | --------------------------------------------------- |\n| `-a`                  | 仅更新访问时间（atime）。                           |\n| `-m`                  | 仅更新修改时间（mtime）。                           |\n| `-c` 或 `--no-create` | 不创建新文件，仅修改已有文件的时间戳。              |\n| `-r` 或 `--reference` | 使用参考文件的时间戳。                              |\n| `-t`                  | 指定自定义时间戳（格式：`[[CC]YY]MMDDhhmm[.ss]`）。 |\n\n---\n\n# **示例场景**\n\n## **创建多个文件**\n\n```bash\ntouch file1.txt file2.txt file3.txt\n```\n\n- 作用：同时创建 `file1.txt`、`file2.txt` 和 `file3.txt`。\n\n---\n\n## **更新文件时间戳**\n\n```bash\ntouch existing_file.txt\n```\n\n- 作用：更新 `existing_file.txt` 的时间戳为当前时间。\n\n---\n\n## **修改文件为特定时间戳**\n\n```bash\ntouch -t 202312312359.59 file.txt\n```\n\n- 作用：将 `file.txt` 的时间戳设置为 2023 年 12 月 31 日 23:59:59。\n\n---\n\n## **模拟文件访问**\n\n如果需要模拟文件被访问的行为，可以只更新文件的访问时间。\n\n```bash\ntouch -a file.txt\n```\n\n---\n\n## **复制时间戳**\n\n将一个文件的时间戳复制到另一个文件。\n\n```bash\ntouch -r source_file.txt target_file.txt\n```\n\n---\n\n## **避免创建新文件**\n\n如果不希望 `touch` 创建新文件，可以使用 `-c` 选项。\n\n```bash\ntouch -c file_does_not_exist.txt\n```\n\n- 作用：如果 `file_does_not_exist.txt` 不存在，则什么都不做。\n\n---\n\n# **注意事项**\n\n1. **没有权限**：如果对目标文件或目录没有写权限，则 `touch` 命令会失败。\n2. **文件已存在**：`touch` 不会覆盖文件内容，仅更新时间戳。\n3. **批量操作**：可以在命令中一次性操作多个文件，例如批量创建文件或批量更新文件时间。\n\n---\n\n# **总结**\n\n| **操作**           | **命令**                     |\n| ------------------ | ---------------------------- |\n| 创建空文件         | `touch 文件名`               |\n| 创建多个文件       | `touch 文件1 文件2 文件3`    |\n| 更新文件时间戳     | `touch 文件名`               |\n| 仅更新访问时间     | `touch -a 文件名`            |\n| 仅更新修改时间     | `touch -m 文件名`            |\n| 设置特定时间戳     | `touch -t 时间戳 文件名`     |\n| 使用参考文件时间戳 | `touch -r 参考文件 目标文件` |\n| 不创建新文件       | `touch -c 文件名`            |\n\n`touch` 是一个快速、灵活的文件操作工具，尤其在脚本和系统自动化任务中非常有用！\n","categories":["Linux"]},{"title":"Linux命令详解---yum","url":"/2024/10/09/jneaca9h/","content":"\n`yum` 是基于 RPM 包管理的 Linux 系统（如 CentOS、RHEL）的包管理工具，用于方便地安装、更新、卸载和管理软件包。`yum` 会自动解决软件包的依赖关系，并从指定的仓库中下载和安装所需的包。\n\n在 CentOS 8 和 RHEL 8 中，`yum` 被替换为 `dnf`（但 `yum` 仍作为兼容命令存在）。以下内容基于传统的 `yum` 命令。\n\n---\n\n# **基本语法**\n\n```bash\nyum [选项] [子命令] [参数]\n```\n\n- **选项**：可以用来控制 `yum` 的行为（如 `-y` 表示自动确认）。\n- **子命令**：指定要执行的操作（如 `install`、`update`、`remove` 等）。\n- **参数**：指定操作的目标（如某个软件包名称）。\n\n---\n\n# **常用子命令及用法**\n\n## **安装软件包**\n\n### **安装一个软件包**\n\n```bash\nyum install <软件包名>\n```\n\n- 示例：\n\n```bash\nyum install vim\n```\n\n### **安装多个软件包**\n```bash\nyum install <软件包名1> <软件包名2>\n```\n\n- 示例：\n\n```bash\nyum install wget curl\n```\n\n### **自动确认安装（无需交互）**\n```bash\nyum install -y <软件包名>\n```\n\n- 示例：\n\n```bash\nyum install -y httpd\n```\n\n---\n\n## **卸载软件包**\n\n### **卸载一个软件包**\n\n```bash\nyum remove <软件包名>\n```\n\n- 示例：\n\n```bash\nyum remove vim\n```\n\n### **自动确认卸载（无需交互）**\n\n```bash\nyum remove -y <软件包名>\n```\n\n- 示例：\n\n```bash\nyum remove -y httpd\n```\n\n---\n\n## **更新软件**\n\n### **更新单个软件包**\n\n```bash\nyum update <软件包名>\n```\n\n- 示例：\n\n```bash\nyum update vim\n```\n\n### **更新所有软件包**\n\n```bash\nyum update\n```\n\n- 示例：\n\n```bash\nyum update\n```\n\n- 作用：更新系统中的所有软件包及其依赖，同时升级内核（如果有更新）。\n\n### **仅更新特定软件包组**\n\n```bash\nyum groupupdate \"<组名>\"\n```\n\n- 示例：\n\n```bash\nyum groupupdate \"Development Tools\"\n```\n\n---\n\n## **搜索软件包**\n\n### **搜索软件包名称**\n\n```bash\nyum search <关键词>\n```\n\n- 示例：\n\n```bash\nyum search vim\n```\n\n- 输出：列出名称或描述中包含 `vim` 的相关软件包。\n\n### **列出软件包详细信息**\n\n```bash\nyum info <软件包名>\n```\n\n- 示例：\n\n```bash\nyum info vim\n```\n\n- 输出：显示软件包的版本、大小、描述、依赖等详细信息。\n\n---\n\n## **列出软件包**\n\n### **列出已安装的软件包**\n\n```bash\nyum list installed\n```\n\n- 示例：\n\n```bash\nyum list installed\n```\n\n### **列出可用的软件包**\n\n```bash\nyum list available\n```\n\n- 示例：\n\n```bash\nyum list available\n```\n\n### **列出特定软件包**\n\n```bash\nyum list <软件包名>\n```\n\n- 示例：\n\n```bash\nyum list vim\n```\n\n---\n\n## **清理缓存**\n\n### **清理所有缓存**\n\n```bash\nyum clean all\n```\n\n- 作用：清除本地缓存（包括软件包文件和元数据）。\n\n### **清理软件包缓存**\n\n```bash\nyum clean packages\n```\n\n- 作用：删除已下载但未安装的软件包缓存。\n\n### **清理元数据缓存**\n\n```bash\nyum clean metadata\n```\n\n- 作用：删除缓存的仓库元数据（如包列表、更新信息）。\n\n---\n\n## **仓库管理**\n\n### **列出所有仓库**\n\n```bash\nyum repolist\n```\n\n- 示例：\n\n```bash\nyum repolist\n```\n\n- 输出：显示已启用的仓库名称、ID 和包数量。\n\n### **列出所有仓库（包括禁用的）**\n\n```bash\nyum repolist all\n```\n\n- 示例：\n\n```bash\nyum repolist all\n```\n\n### **启用特定仓库**\n\n```bash\nyum --enablerepo=<仓库ID> install <软件包名>\n```\n\n- 示例：\n\n```bash\nyum --enablerepo=epel install htop\n```\n\n### **禁用特定仓库**\n\n```bash\nyum --disablerepo=<仓库ID> install <软件包名>\n```\n\n- 示例：\n\n```bash\nyum --disablerepo=epel install vim\n```\n\n---\n\n## **软件包组管理**\n\n### **列出所有可用的软件包组**\n\n```bash\nyum grouplist\n```\n\n- 示例：\n\n```bash\nyum grouplist\n```\n\n- 输出：显示所有可用的软件包组名称。\n\n### **安装软件包组**\n\n```bash\nyum groupinstall \"<组名>\"\n```\n\n- 示例：\n\n```bash\nyum groupinstall \"Development Tools\"\n```\n\n- 作用：安装开发工具组（包含 GCC、Make 等常用开发工具）。\n\n### **卸载软件包组**\n\n```bash\nyum groupremove \"<组名>\"\n```\n\n- 示例：\n\n```bash\nyum groupremove \"Development Tools\"\n```\n\n---\n\n## **查看历史操作**\n\n### **查看操作历史**\n\n```bash\nyum history\n```\n\n- 示例：\n\n```bash\nyum history\n```\n\n### **查看特定操作的详情**\n\n```bash\nyum history info <操作ID>\n```\n\n- 示例：\n\n```bash\nyum history info 5\n```\n\n### **撤销某次操作**\n\n```bash\nyum history undo <操作ID>\n```\n\n- 示例：\n\n```bash\nyum history undo 5\n```\n\n### **重做某次操作**\n\n```bash\nyum history redo <操作ID>\n```\n\n- 示例：\n\n```bash\nyum history redo 5\n```\n\n---\n\n# **常用选项**\n\n| **选项**        | **作用**                                             |\n| --------------- | ---------------------------------------------------- |\n| `-y`            | 自动确认所有提示（适用于安装、卸载等操作）。         |\n| `--enablerepo`  | 启用指定仓库，仅在当前命令中生效。                   |\n| `--disablerepo` | 禁用指定仓库，仅在当前命令中生效。                   |\n| `-q`            | 安静模式，不输出多余信息。                           |\n| `-v`            | 显示详细信息。                                       |\n| `--nogpgcheck`  | 跳过 GPG 签名检查（仅在仓库未配置 GPG 签名时使用）。 |\n\n---\n\n# **示例场景**\n\n## **安装指定版本的软件包**\n\n```bash\nyum install <软件包名>-<版本号>\n```\n\n- 示例：\n\n```bash\nyum install nginx-1.18.0\n```\n\n---\n\n## **启用 EPEL 仓库并安装软件**\n\n```bash\nyum --enablerepo=epel install htop\n```\n\n---\n\n## **仅下载软件包，不安装**\n\n```bash\nyum install --downloadonly --downloaddir=<目录> <软件包名>\n```\n\n- 示例：\n\n```bash\nyum install --downloadonly --downloaddir=/tmp wget\n```\n\n---\n\n## **查看软件包的依赖关系**\n\n```bash\nyum deplist <软件包名>\n```\n\n- 示例：\n\n```bash\nyum deplist vim\n```\n\n---\n\n## **显示仓库中某个包的详细信息**\n\n```bash\nyum info <软件包名>\n```\n\n- 示例：\n\n```bash\nyum info httpd\n```\n\n---\n\n# **总结**\n\n| **功能分类**   | **常用命令**                                  |\n| -------------- | --------------------------------------------- |\n| **安装软件**   | `yum install <软件包>`                        |\n| **卸载软件**   | `yum remove <软件包>`                         |\n| **更新软件**   | `yum update` / `yum update <软件包>`          |\n| **搜索软件**   | `yum search <关键词>`                         |\n| **列出软件包** | `yum list installed` / `yum list available`   |\n| **清理缓存**   | `yum clean all` / `yum clean metadata`        |\n| **仓库管理**   | `yum repolist` / `yum --enablerepo=<仓库>`    |\n| **软件组管理** | `yum grouplist` / `yum groupinstall \"<组名>\"` |\n| **操作历史**   | `yum history` / `yum history undo <ID>`       |\n\n`yum` 是一个功能强大且灵活的包管理工具，通过熟练使用 `yum`，可以轻松管理 Linux 系统中的软件包和依赖关系。\n","categories":["Linux"]},{"title":"Linux命令详解---vim","url":"/2024/10/09/442h4dlb/","content":"\n`vim` 是 Linux/Unix 系统中功能强大的文本编辑器，支持多种模式（如普通模式、插入模式、命令模式），并提供丰富的命令操作，用于编辑、查找、替换、保存等任务。以下是 `vim` 常用命令及其用法的详解。\n\n---\n\n# **启动 `vim`**\n\n## **打开文件**\n\n```bash\nvim 文件名\n```\n\n- **示例**：\n\n```bash\nvim example.txt\n```\n\n- 作用：打开 `example.txt` 文件。如果文件不存在，则创建一个新文件。\n\n---\n\n## **打开多个文件**\n\n```bash\nvim 文件1 文件2\n```\n\n- **示例**：\n\n```bash\nvim file1.txt file2.txt\n```\n\n- 作用：同时打开 `file1.txt` 和 `file2.txt`，可以在多个文件之间切换。\n\n---\n\n## **打开文件并跳转到指定行**\n\n```bash\nvim +行号 文件名\n```\n\n- **示例**：\n\n```bash\nvim +10 example.txt\n```\n\n- 作用：打开 `example.txt` 并直接跳转到第 10 行。\n\n---\n\n# **模式切换**\n\n## **三种主要模式**\n\n| **模式**     | **进入方式**       | **作用**                                                     |\n| ------------ | ------------------ | ------------------------------------------------------------ |\n| **普通模式** | 默认进入           | 用于浏览文件、删除文本、复制粘贴等（按 `Esc` 可回到普通模式）。 |\n| **插入模式** | 按 `i`、`a` 或 `o` | 用于编辑文本内容。                                           |\n| **命令模式** | 按 `:`             | 用于执行命令（如保存、退出、查找、替换等）。                 |\n\n---\n\n# **普通模式命令**\n\n普通模式用于文件的浏览、编辑、操作等。\n\n## **移动光标**\n\n| **命令** | **作用**                                |\n| -------- | --------------------------------------- |\n| `h`      | 左移光标。                              |\n| `l`      | 右移光标。                              |\n| `j`      | 下移光标。                              |\n| `k`      | 上移光标。                              |\n| `w`      | 移动到下一个单词的开头。                |\n| `e`      | 移动到当前单词的结尾。                  |\n| `b`      | 移动到上一个单词的开头。                |\n| `0`      | 移动到行首。                            |\n| `^`      | 移动到当前行第一个非空字符处。          |\n| `$`      | 移动到行尾。                            |\n| `gg`     | 移动到文件开头。                        |\n| `G`      | 移动到文件末尾。                        |\n| `数字G`  | 跳转到指定行（如 `10G` 跳到第 10 行）。 |\n\n---\n\n## **删除文本**\n\n| **命令** | **作用**                                            |\n| -------- | --------------------------------------------------- |\n| `x`      | 删除当前光标所在字符。                              |\n| `dd`     | 删除当前行。                                        |\n| `ndd`    | 删除从当前行开始的 **n** 行（如 `3dd` 删除 3 行）。 |\n| `d$`     | 删除从光标处到行尾的内容。                          |\n| `d0`     | 删除从光标处到行首的内容。                          |\n\n---\n\n## **复制、剪切和粘贴**\n\n| **命令** | **作用**                                            |\n| -------- | --------------------------------------------------- |\n| `yy`     | 复制当前行。                                        |\n| `nyy`    | 复制从当前行开始的 **n** 行（如 `3yy` 复制 3 行）。 |\n| `p`      | 在光标后粘贴内容。                                  |\n| `P`      | 在光标前粘贴内容。                                  |\n\n---\n\n## **撤销与重做**\n\n| **命令**   | **作用**         |\n| ---------- | ---------------- |\n| `u`        | 撤销上一次操作。 |\n| `Ctrl + r` | 重做撤销的操作。 |\n\n---\n\n## **查找**\n\n| **命令**  | **作用**            |\n| --------- | ------------------- |\n| `/关键词` | 向下查找 `关键词`。 |\n| `?关键词` | 向上查找 `关键词`。 |\n| `n`       | 查找下一个匹配项。  |\n| `N`       | 查找上一个匹配项。  |\n\n---\n\n## **替换**\n\n| **命令**               | **作用**                                   |\n| ---------------------- | ------------------------------------------ |\n| `:s/旧文本/新文本`     | 替换当前行第一个匹配的文本。               |\n| `:s/旧文本/新文本/g`   | 替换当前行所有匹配的文本。                 |\n| `:%s/旧文本/新文本/g`  | 替换整个文件中所有匹配的文本。             |\n| `:%s/旧文本/新文本/gc` | 替换整个文件中所有匹配的文本，替换前确认。 |\n\n---\n\n## **行操作**\n\n| **命令** | **作用**                             |\n| -------- | ------------------------------------ |\n| `dd`     | 删除当前行（剪切）。                 |\n| `yy`     | 复制当前行。                         |\n| `p`      | 粘贴到当前行下方。                   |\n| `o`      | 在当前行下方插入一行并进入插入模式。 |\n| `O`      | 在当前行上方插入一行并进入插入模式。 |\n\n---\n\n# **插入模式命令**\n\n插入模式用于编辑和输入文本内容。\n\n| **命令** | **作用**                             |\n| -------- | ------------------------------------ |\n| `i`      | 在光标前插入文本。                   |\n| `I`      | 在行首插入文本。                     |\n| `a`      | 在光标后插入文本。                   |\n| `A`      | 在行尾插入文本。                     |\n| `o`      | 在当前行下方新建一行并进入插入模式。 |\n| `O`      | 在当前行上方新建一行并进入插入模式。 |\n| `Esc`    | 退出插入模式，返回普通模式。         |\n\n---\n\n# **命令模式命令**\n\n命令模式用于保存文件、退出编辑器、打开新文件等操作。进入命令模式的方法是按 `:`。\n\n## **文件保存与退出**\n\n| **命令**      | **作用**                   |\n| ------------- | -------------------------- |\n| `:w`          | 保存当前文件。             |\n| `:w 文件名`   | 另存为指定文件名。         |\n| `:q`          | 退出编辑器。               |\n| `:q!`         | 强制退出（不保存修改）。   |\n| `:wq` 或 `:x` | 保存并退出。               |\n| `ZZ`          | 保存并退出（普通模式下）。 |\n\n---\n\n## **打开新文件**\n\n| **命令**        | **作用**                         |\n| --------------- | -------------------------------- |\n| `:e 文件名`     | 打开指定文件。                   |\n| `:e! 文件名`    | 放弃当前修改，强制打开指定文件。 |\n| `:n`            | 切换到下一个文件（多文件模式）。 |\n| `:prev` 或 `:N` | 切换到上一个文件（多文件模式）。 |\n\n---\n\n## **显示文件信息**\n\n| **命令**        | **作用**                             |\n| --------------- | ------------------------------------ |\n| `:f`            | 显示当前文件名、行号、总行数等信息。 |\n| `:set number`   | 显示行号。                           |\n| `:set nonumber` | 隐藏行号。                           |\n\n---\n\n## **跳转到指定行**\n\n| **命令** | **作用**                                  |\n| -------- | ----------------------------------------- |\n| `:数字`  | 跳转到指定行（如 `:10` 跳转到第 10 行）。 |\n| `gg`     | 跳转到文件开头。                          |\n| `G`      | 跳转到文件末尾。                          |\n\n---\n\n# **搜索与替换**\n\n## **搜索**\n\n| **命令**  | **作用**            |\n| --------- | ------------------- |\n| `/关键词` | 向下查找 `关键词`。 |\n| `?关键词` | 向上查找 `关键词`。 |\n| `n`       | 查找下一个匹配项。  |\n| `N`       | 查找上一个匹配项。  |\n\n---\n\n## **替换**\n\n| **命令**               | **作用**                                       |\n| ---------------------- | ---------------------------------------------- |\n| `:s/旧文本/新文本`     | 替换当前行第一个匹配的文本。                   |\n| `:s/旧文本/新文本/g`   | 替换当前行所有匹配的文本。                     |\n| `:%s/旧文本/新文本/g`  | 替换整个文件中所有匹配的文本。                 |\n| `:%s/旧文本/新文本/gc` | 替换整个文件中所有匹配的文本，并在替换前确认。 |\n\n---\n\n# **总结常用命令**\n\n| **操作**     | **命令**           |\n| ------------ | ------------------ |\n| 保存文件     | `:w`               |\n| 退出编辑器   | `:q`               |\n| 强制退出     | `:q!`              |\n| 保存并退出   | `:wq` 或 `:x`      |\n| 删除当前行   | `dd`               |\n| 复制当前行   | `yy`               |\n| 粘贴         | `p`                |\n| 查找文本     | `/关键词`          |\n| 替换文本     | `:%s/旧/新/gc`     |\n| 显示行号     | `:set number`      |\n| 跳转到指定行 | `:数字` 或 `数字G` |\n\n通过熟练掌握 `vim` 的基本命令和模式切换，可以高效地编辑和管理文本文件！\n","categories":["Linux"]},{"title":"Linux命令详解---rsync","url":"/2024/10/09/zr2olwm8/","content":"\n`rsync` 是 Linux 和类 Unix 系统中一个强大的命令行工具，用于快速、高效地同步文件和目录。它支持本地同步、远程同步，并且可以增量传输文件（仅传输更改的部分），从而提高效率。`rsync` 常用于文件备份、远程复制以及数据迁移。\n\n---\n\n# **基本语法**\n\n```bash\nrsync [选项] 源路径 目标路径\n```\n\n- **源路径**：需要同步的文件或目录。\n- **目标路径**：同步的目标位置，可以是本地路径或远程路径。\n- **远程路径格式**：`user@host:path`。\n\n---\n\n# **常用选项**\n\n| 选项         | 功能                                                         |\n| ------------ | ------------------------------------------------------------ |\n| `-a`         | 归档模式，递归传输，并保留文件权限、时间戳、符号链接等（常用）。 |\n| `-v`         | 显示详细信息（verbose）。                                    |\n| `-z`         | 在传输过程中压缩数据（适用于网络传输）。                     |\n| `-r`         | 递归传输目录（包含子目录和文件）。                           |\n| `-u`         | 仅更新文件（如果目标文件更新日期较新，则跳过）。             |\n| `-t`         | 保留文件的时间戳。                                           |\n| `-p`         | 保留文件权限。                                               |\n| `--progress` | 显示同步的详细进度信息。                                     |\n| `--delete`   | 删除目标路径中源路径中不存在的文件（保持两端完全同步）。     |\n| `--exclude`  | 排除指定文件或目录（如 `--exclude '*.log'` 排除所有 `.log` 文件）。 |\n| `--include`  | 包含指定文件或目录（与 `--exclude` 结合使用）。              |\n| `--dry-run`  | 模拟执行命令，不真正传输文件（用于测试）。                   |\n| `-e`         | 指定远程连接使用的加密协议（如 `ssh`）。                     |\n\n---\n\n# **常用操作和示例**\n\n## **本地文件同步**\n\n将目录 `/source/path` 同步到 `/destination/path`：\n\n```bash\nrsync -av /source/path /destination/path\n```\n\n- **选项解释**：\n  - `-a`：归档模式，保留文件属性。\n  - `-v`：显示详细信息。\n- **注意**：\n  - 如果源路径以斜杠 `/` 结尾（如 `/source/path/`），只同步目录内的内容。\n  - 如果没有斜杠（如 `/source/path`），则整个目录包括其内容都会同步。\n\n### 示例：\n```bash\n# 同步目录内容（不包含目录本身）\nrsync -av /home/user/docs/ /backup/docs/\n\n# 同步整个目录（包含目录本身）\nrsync -av /home/user/docs /backup/\n```\n\n---\n\n## **远程文件同步**\n\n### **从本地同步到远程**\n\n```bash\nrsync -av /local/path/ user@remote_host:/remote/path/\n```\n\n- 将本地的 `/local/path/` 同步到远程主机的 `/remote/path/`。\n\n### **从远程同步到本地**\n\n```bash\nrsync -av user@remote_host:/remote/path/ /local/path/\n```\n\n- 将远程主机的 `/remote/path/` 同步到本地的 `/local/path/`。\n\n---\n\n## **压缩传输**\n\n- 使用 `-z` 选项可以在传输过程中压缩数据以提高传输效率：\n  ```bash\n  rsync -avz /local/path/ user@remote_host:/remote/path/\n  ```\n\n---\n\n## **显示同步进度**\n\n- 使用 `--progress` 查看每个文件的传输进度：\n  ```bash\n  rsync -av --progress /source/path/ /destination/path/\n  ```\n\n---\n\n## **删除目标中多余的文件**\n\n- 使用 `--delete` 选项，可以删除目标路径中不存在于源路径的文件：\n  ```bash\n  rsync -av --delete /source/path/ /destination/path/\n  ```\n\n### **注意**：\n- 使用 `--delete` 前建议加上 `--dry-run` 进行模拟测试，避免意外删除：\n  ```bash\n  rsync -av --delete --dry-run /source/path/ /destination/path/\n  ```\n\n---\n\n## **排除文件或目录**\n\n- 使用 `--exclude` 排除特定文件或目录：\n  ```bash\n  rsync -av --exclude '*.log' /source/path/ /destination/path/\n  ```\n\n### **排除多个文件/目录**：\n```bash\nrsync -av --exclude 'tmp/' --exclude '*.log' /source/path/ /destination/path/\n```\n\n### **排除和包含结合**：\n```bash\nrsync -av --exclude '*.tmp' --include '*.txt' /source/path/ /destination/path/\n```\n\n---\n\n## **仅更新文件**\n\n- 使用 `-u` 选项，只同步更新的文件（目标文件较新时不覆盖）：\n  ```bash\n  rsync -avu /source/path/ /destination/path/\n  ```\n\n---\n\n## **测试同步（模拟执行）**\n\n- 使用 `--dry-run` 模拟执行命令，不真正传输文件：\n  ```bash\n  rsync -av --dry-run /source/path/ /destination/path/\n  ```\n\n---\n\n## **使用 SSH 远程同步**\n\n- 默认情况下，`rsync` 使用 `rsh` 作为远程传输协议。可以通过 `-e` 指定使用 `ssh`：\n  ```bash\n  rsync -av -e ssh /source/path/ user@remote_host:/remote/path/\n  ```\n\n- 指定 SSH 端口：\n  ```bash\n  rsync -av -e \"ssh -p 2222\" /source/path/ user@remote_host:/remote/path/\n  ```\n\n---\n\n## **限制传输带宽**\n\n- 使用 `--bwlimit` 限制传输速度（单位为 KB/s）：\n  ```bash\n  rsync -av --bwlimit=1000 /source/path/ /destination/path/\n  ```\n\n---\n\n## **同步符号链接和特殊文件**\n\n- 默认情况下，`rsync` 会同步符号链接而不是目标文件。如果需要同步符号链接，可以使用：\n  ```bash\n  rsync -av --links /source/path/ /destination/path/\n  ```\n\n---\n\n## **增量备份**\n\n- 使用 `--backup` 和 `--backup-dir` 创建增量备份：\n  ```bash\n  rsync -av --backup --backup-dir=/backup/incremental /source/path/ /backup/full/\n  ```\n\n---\n\n# **常见用法总结**\n\n| 用法               | 命令示例                                                     |\n| ------------------ | ------------------------------------------------------------ |\n| 本地目录同步       | `rsync -av /source/path/ /destination/path/`                 |\n| 远程同步到本地     | `rsync -av user@remote_host:/remote/path/ /local/path/`      |\n| 本地同步到远程     | `rsync -av /local/path/ user@remote_host:/remote/path/`      |\n| 显示进度           | `rsync -av --progress /source/path/ /destination/path/`      |\n| 删除目标中多余文件 | `rsync -av --delete /source/path/ /destination/path/`        |\n| 排除文件/目录      | `rsync -av --exclude 'tmp/' /source/path/ /destination/path/` |\n| 使用 SSH 同步      | `rsync -av -e ssh /source/path/ user@remote_host:/remote/path/` |\n| 模拟运行（测试）   | `rsync -av --dry-run /source/path/ /destination/path/`       |\n| 增量备份           | `rsync -av --backup --backup-dir=/backup/incremental /source/path/ /backup/full/` |\n\n---\n\n## **`rsync` 的优点**\n\n1. **增量传输**：仅传输更改的部分，节省带宽。\n2. **支持多种协议**：支持本地和远程同步，远程同步可以通过 SSH 进行安全传输。\n3. **高效**：支持压缩传输和快速文件对比。\n4. **灵活的选项**：可以排除特定文件、删除多余文件等。\n\n---\n\n# **注意事项**\n\n1. **斜杠区别**：\n   - 源路径 **带斜杠**：仅同步目录内容。\n   - 源路径 **不带斜杠**：同步整个目录及其内容。\n\n2. **小心使用 `--delete`**：\n   - `--delete` 会删除目标路径中多余的文件，建议先使用 `--dry-run` 测试。\n\n3. **权限问题**：\n   - 如果需要保留文件的权限、所有者等属性，可能需要使用 `sudo`。\n\n---\n\n# **总结**\n\n`rsync` 是一个功能强大且高效的工具，适用于本地和远程的文件同步和备份。通过灵活的选项组合，`rsync` 能满足多种文件传输需求。熟练掌握 `rsync` 的用法，可以大大提高数据同步和备份的效率。\n","categories":["Linux"]},{"title":"Linux命令详解---pwd","url":"/2024/10/09/imn8uma5/","content":"\n`pwd` 是 `Linux` 和`类 Unix 操作系统`中的一个基本命令，用于显示当前工作目录的绝对路径。它是 \"`print working directory`\" 的缩写，常用于确认当前所在的目录位置。\n\n以下是对 `pwd` 命令的详细介绍，包括其基本用法、选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\npwd [选项]\n```\n\n- 如果不带任何选项，`pwd` 默认输出当前工作目录的绝对路径。\n\n---\n\n#  **常用选项**\n\n| 选项 | 功能                                                |\n| ---- | --------------------------------------------------- |\n| `-L` | 显示逻辑路径（基于 `PWD` 环境变量，考虑符号链接）。 |\n| `-P` | 显示实际路径（解析符号链接，显示真实的物理路径）。  |\n\n##  **逻辑路径 vs 物理路径**\n\n- **逻辑路径**：基于当前目录路径的逻辑表示，依赖于 `PWD` 环境变量。\n- **物理路径**：真实路径，不包括符号链接。\n\n---\n\n#  **环境变量与 `pwd`**\n\n- **`PWD` 环境变量**：存储当前工作目录的逻辑路径。\n  ```bash\n  echo $PWD\n  ```\n- **`OLDPWD` 环境变量**：存储上一次的工作目录路径（与 `cd -` 相关）。\n\n---\n\n#  **示例**\n\n##  **显示当前工作目录**\n\n```bash\npwd\n```\n\n输出示例：\n\n```bash\n/home/user/documents\n```\n\n---\n\n## **显示真实路径（解析符号链接）**\n\n假设当前目录 `/home/user/documents` 是符号链接，指向 `/mnt/data/documents`。\n\n```bash\npwd -P\n```\n\n输出示例：\n\n```bash\n/mnt/data/documents\n```\n\n---\n\n## **显示逻辑路径**\n\n即使当前目录是符号链接，`pwd -L` 会显示符号链接路径。\n\n```bash\npwd -L\n```\n\n输出示例：\n\n```bash\n/home/user/documents\n```\n\n---\n\n## **结合其他命令**\n\n### 获取当前目录后创建一个文件\n\n```bash\ntouch $(pwd)/newfile.txt\n```\n\n### 获取当前目录后跳转到另一个目录：\n\n```bash\ncd $(pwd)/../other_folder\n```\n\n---\n\n# **典型场景**\n\n1. **确认当前所在的目录**\n   - 在复杂的文件系统中，使用 `pwd` 确保当前正确的工作目录。\n\n2. **检查符号链接的真实路径**\n   - 使用 `pwd -P` 查看物理路径，特别是在符号链接可能干扰的情况下。\n\n3. **脚本编写**\n   - 在脚本中动态获取当前目录路径，便于文件操作。\n\n---\n\n# **总结**\n\n- `pwd` 是一个简单而实用的命令，主要用于输出当前工作目录的路径。\n- 结合选项 `-L` 和 `-P`，可以灵活显示逻辑路径或物理路径。\n- 在文件操作、脚本编写或符号链接解析时，`pwd` 是一个非常有用的工具。\n","categories":["Linux"]},{"title":"Linux命令详解---scp","url":"/2024/10/09/m3ti3j32/","content":"\n`scp` （**Secure Copy Protocol**）是 Linux/Unix 系统中的命令行工具，用于在本地与远程主机之间，或两台远程主机之间安全地复制文件或目录。`scp` 使用 **SSH（Secure Shell）** 协议进行数据传输，确保数据在传输过程中加密。\n\n---\n\n# **基本语法**\n\n```bash\nscp [选项] 源路径 目标路径\n```\n\n- **源路径**：指定需要复制的文件或目录，可以是本地路径或远程路径。\n- **目标路径**：指定文件复制的目标，可以是本地路径或远程路径。\n- **选项**：控制 `scp` 的行为（如显示进度、递归复制等）。\n\n---\n\n# **常见用法**\n\n## **从本地传输到远程主机**\n\n```bash\nscp 本地文件 用户名@远程IP:远程路径\n```\n\n- **示例**：\n\n```bash\nscp file.txt user@192.168.1.100:/home/user/\n```\n\n- 作用：将本地的 `file.txt` 文件复制到远程主机 `192.168.1.100` 的 `/home/user/` 目录。\n\n---\n\n## **从远程主机传输到本地**\n\n```bash\nscp 用户名@远程IP:远程文件 本地路径\n```\n\n- **示例**：\n\n```bash\nscp user@192.168.1.100:/home/user/file.txt /local/directory/\n```\n\n- 作用：将远程主机 `/home/user/file.txt` 文件复制到本地的 `/local/directory/` 目录。\n\n---\n\n## **从一台远程主机传输到另一台远程主机**\n\n```bash\nscp 用户1@远程IP1:远程文件 用户2@远程IP2:目标路径\n```\n\n- **示例**：\n\n```bash\nscp user1@192.168.1.100:/home/user1/file.txt user2@192.168.1.101:/home/user2/\n```\n\n- 作用：将远程主机 `192.168.1.100` 的 `/home/user1/file.txt` 复制到另一台远程主机 `192.168.1.101` 的 `/home/user2/` 目录。\n\n---\n\n## **递归复制目录**\n\n- 使用 `-r` 选项递归复制整个目录。\n\n```bash\nscp -r 本地目录 用户名@远程IP:远程路径\n```\n\n- **示例**：\n\n```bash\nscp -r /local/directory user@192.168.1.100:/home/user/\n```\n\n- 作用：将本地的 `/local/directory` 整个目录复制到远程主机的 `/home/user/`。\n\n---\n\n## **指定端口号**\n\n- 使用 `-P` 选项指定远程主机的 SSH 端口号（注意：`P` 为大写）。\n\n```bash\nscp -P 端口号 源路径 目标路径\n```\n\n- **示例**：\n\n```bash\nscp -P 2222 file.txt user@192.168.1.100:/home/user/\n```\n\n- 作用：通过端口号 `2222` 将本地的 `file.txt` 复制到远程主机。\n\n---\n\n## **限制传输带宽**\n\n- 使用 `-l` 选项限制传输速率（单位为 Kbps）。\n\n```bash\nscp -l 带宽限制 源路径 目标路径\n```\n\n- **示例**：\n\n```bash\nscp -l 1000 file.txt user@192.168.1.100:/home/user/\n```\n\n- 作用：将本地的 `file.txt` 复制到远程主机，并限制传输速率为 1000 Kbps。\n\n---\n\n## **显示传输进度**\n\n- 使用 `-v` 或 `-C` 选项显示传输过程中的详细信息。\n\n```bash\nscp -v 源路径 目标路径\n```\n\n- **示例**：\n\n```bash\nscp -v file.txt user@192.168.1.100:/home/user/\n```\n\n- 作用：显示传输过程中使用的 SSH 配置、文件大小、进度等信息。\n\n---\n\n# **常用选项**\n\n| **选项** | **作用**                                        |\n| -------- | ----------------------------------------------- |\n| `-r`     | 递归复制目录。                                  |\n| `-P`     | 指定远程主机的 SSH 端口号（注意：`P` 为大写）。 |\n| `-l`     | 限制传输带宽（单位为 Kbps）。                   |\n| `-v`     | 显示传输的详细信息（调试模式）。                |\n| `-C`     | 启用压缩，适用于慢速网络。                      |\n| `-q`     | 静默模式，不显示任何信息。                      |\n| `-o`     | 指定 SSH 配置选项（如密钥文件）。               |\n\n---\n\n# **示例说明**\n\n## **基本文件传输**\n```bash\nscp file.txt user@192.168.1.100:/home/user/\n```\n- 将本地 `file.txt` 复制到远程主机 `/home/user/` 目录。\n\n---\n\n## **复制到远程主机并重命名**\n```bash\nscp file.txt user@192.168.1.100:/home/user/newfile.txt\n```\n- 将本地 `file.txt` 复制到远程主机 `/home/user/` 并重命名为 `newfile.txt`。\n\n---\n\n## **使用指定端口传输**\n```bash\nscp -P 2222 file.txt user@192.168.1.100:/home/user/\n```\n- 使用端口号 `2222` 传输文件。\n\n---\n\n## **复制整个目录**\n```bash\nscp -r /local/directory user@192.168.1.100:/home/user/\n```\n- 递归复制本地目录 `/local/directory` 到远程主机目录 `/home/user/`。\n\n---\n\n## **从远程主机下载文件**\n```bash\nscp user@192.168.1.100:/home/user/file.txt /local/directory/\n```\n- 从远程主机 `/home/user/` 下载 `file.txt` 到本地的 `/local/directory/`。\n\n---\n\n## **从远程主机下载目录**\n```bash\nscp -r user@192.168.1.100:/home/user/directory /local/directory/\n```\n- 从远程主机递归下载目录 `/home/user/directory` 到本地的 `/local/directory/`。\n\n---\n\n## **使用压缩加速传输**\n```bash\nscp -C file.txt user@192.168.1.100:/home/user/\n```\n- 使用压缩传输文件，提高慢速网络的传输效率。\n\n---\n\n# **注意事项**\n\n1. **权限问题**：\n   - 确保有足够的权限访问源文件和目标路径。\n   - 如果远程主机需要密码，`scp` 会提示输入密码。\n\n2. **端口号**：\n   - 如果远程主机的 SSH 使用非默认端口（22），必须用 `-P` 指定端口号。\n\n3. **SSH 配置**：\n   - 如果需要使用密钥文件进行身份验证，可以通过 `-o` 指定。\n   - 示例：\n     ```bash\n     scp -i /path/to/private_key file.txt user@192.168.1.100:/home/user/\n     ```\n\n4. **网络性能**：\n   - 对于大文件传输，可以结合 `-C` 选项（压缩）和 `-l` 选项（限制带宽）优化传输。\n\n5. **文件路径**：\n   - 确保路径正确，远程路径需要以 `用户名@IP地址:路径` 格式指定。\n\n---\n\n# **总结**\n\n| **操作**             | **命令**                                                     |\n| -------------------- | ------------------------------------------------------------ |\n| 从本地复制到远程主机 | `scp file.txt user@192.168.1.100:/home/user/`                |\n| 从远程主机复制到本地 | `scp user@192.168.1.100:/home/user/file.txt /local/directory/` |\n| 递归复制目录         | `scp -r /local/directory user@192.168.1.100:/home/user/`     |\n| 指定端口             | `scp -P 2222 file.txt user@192.168.1.100:/home/user/`        |\n| 限制带宽             | `scp -l 1000 file.txt user@192.168.1.100:/home/user/`        |\n| 开启压缩             | `scp -C file.txt user@192.168.1.100:/home/user/`             |\n| 显示详细信息         | `scp -v file.txt user@192.168.1.100:/home/user/`             |\n| 使用密钥文件认证     | `scp -i /path/to/key file.txt user@192.168.1.100:/home/user/` |\n\n`scp` 是一种简单高效的文件传输方式，但较大型传输任务推荐使用 **`rsync`**。\n","categories":["Linux"]},{"title":"Linux命令详解---ssh","url":"/2024/10/09/blqybpqn/","content":"\n`ssh`（Secure Shell）是一个用于远程登录和管理服务器的网络协议和工具。它通过加密的方式提供安全的通信，可以远程登录、执行命令、传输文件等，是系统管理员和开发人员日常工作中非常重要的工具。\n\n---\n\n# **`ssh` 命令的基本语法**\n\n```bash\nssh [选项] [用户@]主机 [命令]\n```\n\n- **用户**：远程主机上的用户名（可选，默认使用本地用户名）。\n- **主机**：目标服务器的 IP 地址或主机名。\n- **命令**：可选，如果指定，会在远程主机上执行该命令并退出。\n\n---\n\n# **基本用法**\n\n## **连接远程服务器**\n\n```bash\nssh user@host\n```\n\n- **示例**：\n  ```bash\n  ssh root@192.168.1.10\n  ```\n\n  - 连接 IP 为 `192.168.1.10` 的主机，使用用户名 `root`。\n  - 如果未指定用户，则使用当前登录用户。例如：\n    ```bash\n    ssh 192.168.1.10\n    ```\n\n---\n\n## **指定端口**\n\n```bash\nssh -p [端口号] user@host\n```\n\n- 默认情况下，`ssh` 使用端口 `22`。如果远程服务器使用了非默认端口，可以通过 `-p` 指定端口号。\n\n- **示例**：\n  ```bash\n  ssh -p 2222 root@192.168.1.10\n  ```\n\n  - 使用端口 `2222` 连接远程服务器。\n\n---\n\n## **执行远程命令**\n\n```bash\nssh user@host [命令]\n```\n\n- 直接在远程主机上执行命令，执行完成后退出。\n\n- **示例**：\n  ```bash\n  ssh root@192.168.1.10 \"ls -l /var/www\"\n  ```\n\n  - 在远程服务器上列出 `/var/www` 目录的内容。\n\n---\n\n## **使用密钥认证**\n\n`ssh` 支持通过密钥认证方式登录，无需输入密码，安全性更高。\n\n### **生成 SSH 密钥**\n\n```bash\nssh-keygen -t rsa\n```\n\n- 按提示保存密钥对。生成的密钥文件默认存储在 `~/.ssh/id_rsa`（私钥）和 `~/.ssh/id_rsa.pub`（公钥）。\n\n### **将公钥复制到远程主机**\n\n```bash\nssh-copy-id user@host\n```\n\n- **示例**：\n  ```bash\n  ssh-copy-id root@192.168.1.10\n  ```\n\n- 这会将公钥添加到远程主机的 `~/.ssh/authorized_keys` 中，之后可以通过密钥登录。\n\n### **使用密钥登录**\n\n```bash\nssh -i /path/to/private_key user@host\n```\n\n- **示例**：\n  ```bash\n  ssh -i ~/.ssh/id_rsa root@192.168.1.10\n  ```\n\n---\n\n##  **端口转发**\n\n### **本地端口转发**\n\n将远程服务器的某个端口转发到本地。\n\n```bash\nssh -L [本地端口]:[目标地址]:[远程端口] user@host\n```\n\n- **示例**：\n  ```bash\n  ssh -L 8080:127.0.0.1:3306 root@192.168.1.10\n  ```\n\n  - 将本地的 `8080` 端口映射到远程 `192.168.1.10` 的 `3306` 端口（通常是 MySQL 服务）。\n\n### **远程端口转发**\n\n将本地的某个端口转发到远程服务器。\n\n```bash\nssh -R [远程端口]:[目标地址]:[本地端口] user@host\n```\n\n- **示例**：\n  ```bash\n  ssh -R 8080:127.0.0.1:80 root@192.168.1.10\n  ```\n\n  - 将远程服务器上的 `8080` 端口映射到本地的 `80` 端口。\n\n---\n\n## **代理转发**\n\n允许通过跳板机访问目标服务器。\n\n```bash\nssh -J user@jump_server user@target_server\n```\n\n- **示例**：\n  ```bash\n  ssh -J user@jumpserver.com root@192.168.1.10\n  ```\n\n  - 通过 `jumpserver.com` 跳板服务器连接目标服务器 `192.168.1.10`。\n\n---\n\n## **保持连接（防止超时断开）**\n\n通过配置 `ServerAliveInterval` 和 `ServerAliveCountMax` 参数，防止 SSH 会话因长时间无操作而断开。\n\n```bash\nssh -o ServerAliveInterval=60 user@host\n```\n\n- **`ServerAliveInterval=60`**：每 60 秒发送一个心跳包。\n\n---\n\n## **使用配置文件简化连接**\n\n通过修改 `~/.ssh/config` 文件，可以为常用的主机设置别名和默认选项，简化连接命令。\n\n### **编辑配置文件**\n\n```bash\nnano ~/.ssh/config\n```\n\n添加以下内容：\n\n```plaintext\nHost myserver\n    HostName 192.168.1.10\n    User root\n    Port 2222\n    IdentityFile ~/.ssh/id_rsa\n```\n\n- **`Host`**：别名。\n- **`HostName`**：目标主机 IP 或域名。\n- **`User`**：默认用户名。\n- **`Port`**：默认端口。\n- **`IdentityFile`**：指定私钥文件。\n\n### **使用别名连接**\n\n```bash\nssh myserver\n```\n\n---\n\n## **复制文件（`scp` 和 `rsync`）**\n\n### **使用 `scp`**\n通过 SSH 传输文件。\n\n```bash\nscp /local/path/file user@host:/remote/path/\n```\n\n- 从本地复制到远程：\n  ```bash\n  scp file.txt root@192.168.1.10:/var/www/\n  ```\n- 从远程复制到本地：\n  ```bash\n  scp root@192.168.1.10:/var/www/file.txt /local/path/\n  ```\n\n### **使用 `rsync`**\n同步文件或目录，支持断点续传。\n\n```bash\nrsync -avz /local/path/ user@host:/remote/path/\n```\n\n- **示例**：\n  ```bash\n  rsync -avz file.txt root@192.168.1.10:/var/www/\n  ```\n\n---\n\n# **常用选项**\n\n| **选项**        | **功能**                                                     |\n| --------------- | ------------------------------------------------------------ |\n| `-p [端口号]`   | 指定远程主机的端口号（默认是 22）。                          |\n| `-i [私钥路径]` | 使用指定的私钥文件进行认证。                                 |\n| `-L [本地转发]` | 配置本地端口转发。                                           |\n| `-R [远程转发]` | 配置远程端口转发。                                           |\n| `-J [跳板机]`   | 配置跳板机代理转发。                                         |\n| `-o [选项]`     | 设置 SSH 配置参数（如 `ServerAliveInterval` 等）。           |\n| `-X` 或 `-Y`    | 启用 X11 图形转发，允许运行远程图形界面程序（需要 X11 环境）。 |\n| `-C`            | 启用压缩，提高低带宽网络的传输速度。                         |\n| `-f`            | 在后台运行 SSH 会话（常用于端口转发）。                      |\n| `-q`            | 安静模式，不显示任何输出信息。                               |\n\n---\n\n# **常见问题与解决**\n\n## **连接超时或拒绝连接**\n\n- **原因**：\n  - 目标主机 SSH 服务未启动。\n  - 防火墙阻止了 SSH 端口。\n  - 使用了错误的端口号。\n\n- **解决方法**：\n  - 确认目标主机 SSH 服务是否运行：\n    ```bash\n    sudo systemctl status ssh\n    ```\n  - 检查防火墙规则：\n    ```bash\n    sudo ufw allow 22\n    ```\n\n---\n\n## **公钥认证失败**\n\n- **原因**：\n  - 公钥未正确添加到远程主机。\n  - 权限问题（`~/.ssh` 目录或文件权限不正确）。\n\n- **解决方法**：\n  - 检查公钥是否已复制：\n    ```bash\n    cat ~/.ssh/authorized_keys\n    ```\n  - 修复权限：\n    ```bash\n    chmod 700 ~/.ssh\n    chmod 600 ~/.ssh/authorized_keys\n    ```\n\n---\n\n## **断开后无法重新连接**\n\n- **原因**：\n  - SSH 会话未正确关闭，导致僵尸会话。\n  \n- **解决方法**：\n  - 在本地清理已知主机的缓存：\n    ```bash\n    ssh-keygen -R [host]\n    ```\n\n---\n\n# **总结**\n\n- **基本连接**：`ssh user@host`\n- **执行远程命令**：`ssh user@host \"command\"`\n- **密钥登录**：`ssh-keygen` -> `ssh-copy-id`\n- **简化配置**：使用 `~/.ssh/config`\n- **文件传输**：`scp` 或 `rsync`\n\n`ssh` 是一个强大且灵活的工具，熟练掌握它可以极大提升远程管理和协作的效率。\n","categories":["Linux"]},{"title":"Linux命令详解---tar","url":"/2024/10/09/c8yrzjxg/","content":"\n`tar` 是 Linux/Unix 系统中用于创建、解压缩归档文件的工具。它常用于备份文件、打包文件夹以及解压归档文件。`tar` 支持多种压缩格式（如 `.gz`、`.bz2` 和 `.xz`），并且可以直接操作这些压缩文件。\n\n---\n\n# **基本语法**\n\n```bash\ntar [选项] [参数] [文件/目录]\n```\n\n- **选项**：指定操作类型（如打包、解压缩等）和附加功能（如显示详细信息）。\n- **参数**：指定目标文件或目录。\n- **文件/目录**：操作的目标文件或目录。\n\n---\n\n# **常用选项**\n\n| **选项**    | **含义**                                                     |\n| ----------- | ------------------------------------------------------------ |\n| `-c`        | 创建归档文件（create）。                                     |\n| `-x`        | 解压归档文件（extract）。                                    |\n| `-f`        | 指定归档文件的名称（file）。                                 |\n| `-v`        | 显示操作过程的详细信息（verbose）。                          |\n| `-z`        | 使用 gzip 压缩或解压（与 `.tar.gz` 或 `.tgz` 文件类型配合使用）。 |\n| `-j`        | 使用 bzip2 压缩或解压（与 `.tar.bz2` 文件类型配合使用）。    |\n| `-J`        | 使用 xz 压缩或解压（与 `.tar.xz` 文件类型配合使用）。        |\n| `-t`        | 列出归档文件的内容（list）。                                 |\n| `-r`        | 向现有的归档文件中追加内容（append）。                       |\n| `-u`        | 仅追加比归档文件中已有版本更新的文件（update）。             |\n| `--exclude` | 排除指定的文件或目录。                                       |\n| `-C`        | 指定解压后文件存放的目录（change directory）。               |\n\n---\n\n# **常用操作**\n\n## **创建归档文件**\n\n### **1) 打包目录或文件（不压缩）**\n\n```bash\ntar -cvf archive.tar 文件1 文件2 目录/\n```\n\n- **示例**：\n\n```bash\ntar -cvf backup.tar /home/user\n```\n\n- 作用：将 `/home/user` 目录打包为 `backup.tar` 文件。\n- **选项**：\n  - `-c`：创建归档文件。\n  - `-v`：显示打包过程。\n  - `-f`：指定归档文件名称。\n\n---\n\n### **2) 打包并使用 gzip 压缩**\n\n```bash\ntar -zcvf archive.tar.gz 文件1 文件2 目录/\n```\n\n- **示例**：\n\n```bash\ntar -zcvf backup.tar.gz /home/user\n```\n\n- 作用：将 `/home/user` 目录打包为 `backup.tar.gz` 文件（gzip 压缩）。\n\n---\n\n### **3) 打包并使用 bzip2 压缩**\n\n```bash\ntar -jcvf archive.tar.bz2 文件1 文件2 目录/\n```\n\n- **示例**：\n\n```bash\ntar -jcvf backup.tar.bz2 /home/user\n```\n\n- 作用：将 `/home/user` 目录打包为 `backup.tar.bz2` 文件（bzip2 压缩）。\n\n---\n\n### **4) 打包并使用 xz 压缩**\n\n```bash\ntar -Jcvf archive.tar.xz 文件1 文件2 目录/\n```\n\n- **示例**：\n\n```bash\ntar -Jcvf backup.tar.xz /home/user\n```\n\n- 作用：将 `/home/user` 目录打包为 `backup.tar.xz` 文件（xz 压缩）。\n\n---\n\n## **解压归档文件**\n\n### **1) 解压 `.tar` 文件（无压缩）**\n\n```bash\ntar -xvf archive.tar\n```\n\n- **示例**：\n\n```bash\ntar -xvf backup.tar\n```\n\n- 作用：解压 `backup.tar` 文件到当前目录。\n\n---\n\n### **2) 解压 `.tar.gz` 文件（gzip 压缩）**\n\n```bash\ntar -zxvf archive.tar.gz\n```\n\n- **示例**：\n\n```bash\ntar -zxvf backup.tar.gz\n```\n\n- 作用：解压 `backup.tar.gz` 文件到当前目录。\n\n---\n\n### **3) 解压 `.tar.bz2` 文件（bzip2 压缩）**\n\n```bash\ntar -jxvf archive.tar.bz2\n```\n\n- **示例**：\n\n```bash\ntar -jxvf backup.tar.bz2\n```\n\n- 作用：解压 `backup.tar.bz2` 文件到当前目录。\n\n---\n\n### **4) 解压 `.tar.xz` 文件（xz 压缩）**\n\n```bash\ntar -Jxvf archive.tar.xz\n```\n\n- **示例**：\n\n```bash\ntar -Jxvf backup.tar.xz\n```\n\n- 作用：解压 `backup.tar.xz` 文件到当前目录。\n\n---\n\n### **5) 解压到指定目录**\n\n```bash\ntar -xvf archive.tar -C /目标/目录\n```\n\n- **示例**：\n\n```bash\ntar -zxvf backup.tar.gz -C /home/user/extracted\n```\n\n- 作用：解压 `backup.tar.gz` 文件到 `/home/user/extracted` 目录。\n\n---\n\n## **列出归档文件内容**\n\n```bash\ntar -tvf archive.tar\n```\n\n- **示例**：\n\n```bash\ntar -tvf backup.tar\n```\n\n- 作用：列出 `backup.tar` 文件中的内容。\n\n---\n\n## **向现有归档文件中追加文件**\n\n```bash\ntar -rvf archive.tar 新文件\n```\n\n- **示例**：\n\n```bash\ntar -rvf backup.tar newfile.txt\n```\n\n- 作用：将 `newfile.txt` 追加到 `backup.tar` 文件中。\n\n---\n\n## **排除文件或目录**\n\n```bash\ntar --exclude=文件或目录 -zcvf archive.tar.gz 目录/\n```\n\n- **示例**：\n\n```bash\ntar --exclude=/home/user/temp -zcvf backup.tar.gz /home/user\n```\n\n- 作用：打包 `/home/user` 目录时，排除其中的 `temp` 子目录。\n\n---\n\n## **检查归档文件完整性**\n\n```bash\ntar -tvf archive.tar\n```\n\n- 作用：列出归档文件内容，检查文件是否被正确打包。\n\n---\n\n## **解压部分文件**\n\n```bash\ntar -xvf archive.tar 文件1 文件2\n```\n\n- **示例**：\n\n```bash\ntar -xvf backup.tar file1.txt file2.txt\n```\n\n- 作用：从 `backup.tar` 中仅解压 `file1.txt` 和 `file2.txt`。\n\n---\n\n## **压缩目录为 `.tar.gz` 的快捷方式**\n\n```bash\ntar -czvf archive.tar.gz 目录/\n```\n\n- **示例**：\n\n```bash\ntar -czvf mybackup.tar.gz /var/log\n```\n\n- 作用：将 `/var/log` 目录压缩为 `mybackup.tar.gz`。\n\n---\n\n# **常用示例总结**\n\n| **操作**                       | **命令**                                        |\n| ------------------------------ | ----------------------------------------------- |\n| 打包目录为 `.tar` 文件         | `tar -cvf archive.tar 目录/`                    |\n| 打包并 gzip 压缩为 `.tar.gz`   | `tar -zcvf archive.tar.gz 目录/`                |\n| 打包并 bzip2 压缩为 `.tar.bz2` | `tar -jcvf archive.tar.bz2 目录/`               |\n| 打包并 xz 压缩为 `.tar.xz`     | `tar -Jcvf archive.tar.xz 目录/`                |\n| 解压 `.tar` 文件               | `tar -xvf archive.tar`                          |\n| 解压 `.tar.gz` 文件            | `tar -zxvf archive.tar.gz`                      |\n| 解压 `.tar.bz2` 文件           | `tar -jxvf archive.tar.bz2`                     |\n| 解压 `.tar.xz` 文件            | `tar -Jxvf archive.tar.xz`                      |\n| 解压到指定目录                 | `tar -xvf archive.tar.gz -C /目标/目录`         |\n| 列出归档文件内容               | `tar -tvf archive.tar`                          |\n| 向归档文件追加文件             | `tar -rvf archive.tar 新文件`                   |\n| 排除某些文件或目录             | `tar --exclude=文件 -zcvf archive.tar.gz 目录/` |\n\n---\n\n# **常见问题**\n\n## **如何快速压缩和解压缩目录？**\n\n- **压缩目录**：\n\n```bash\ntar -zcvf archive.tar.gz 目录/\n```\n\n- **解压目录**：\n\n```bash\ntar -zxvf archive.tar.gz\n```\n\n## **如何排除某些文件或目录？**\n\n- 使用 `--exclude` 选项：\n\n```bash\ntar --exclude=/path/to/exclude -zcvf archive.tar.gz 目录/\n```\n\n## **如何解压到指定目录？**\n\n- 使用 `-C` 选项：\n\n```bash\ntar -zxvf archive.tar.gz -C /目标/目录\n```\n\n---\n\n通过熟练使用 `tar` 命令，可以高效地进行文件和目录的打包和压缩操作，是 Linux 系统中备份和传输文件的重要工具！\n","categories":["Linux"]},{"title":"Linux命令详解---ps","url":"/2024/10/09/wf2j1m3e/","content":"\n`ps`（process status）是 Linux 和类 Unix 系统中用于显示系统中运行进程信息的命令。它可以查看当前用户的进程、所有用户的进程、特定进程，以及进程的状态、CPU/内存使用情况等。`ps` 是排查系统问题和管理进程的重要工具。\n\n---\n\n# **基本语法**\n\n```bash\nps [选项]\n```\n\n---\n\n# **常用选项**\n\n`ps` 的选项分为 **UNIX 风格**、**BSD 风格** 和 **GNU 风格**，可以混合使用。\n\n| **选项**         | **描述**                                                     |\n| ---------------- | ------------------------------------------------------------ |\n| **-A** 或 **-e** | 显示系统中所有的进程。                                       |\n| **-a**           | 显示终端上所有用户的进程（不包括会话领导进程）。             |\n| **-u [用户]**    | 显示指定用户的进程信息。                                     |\n| **-x**           | 显示没有控制终端的进程（后台进程）。                         |\n| **-f**           | 显示完整格式的进程信息（包含父进程、启动时间等）。           |\n| **-o [字段名]**  | 自定义显示的列（指定输出字段）。                             |\n| **-p [PID]**     | 显示指定 PID 的进程信息。                                    |\n| **-T**           | 显示与当前终端相关的所有进程。                               |\n| **--forest**     | 以树状结构显示进程的父子关系。                               |\n| **aux**          | BSD 风格组合：显示所有用户的所有进程，并附带详细信息（常用）。 |\n| **-C [进程名]**  | 显示指定名称的进程（如 `-C nginx`）。                        |\n\n---\n\n# **输出字段说明**\n\n默认情况下，`ps` 输出以下字段（可以通过 `-f` 或 `-o` 扩展显示更多字段）：\n\n| **字段**  | **描述**                                         |\n| --------- | ------------------------------------------------ |\n| **PID**   | 进程 ID。                                        |\n| **TTY**   | 进程所属的终端（如果进程没有终端，则显示 `?`）。 |\n| **TIME**  | 进程消耗的总 CPU 时间（格式：分钟:秒）。         |\n| **CMD**   | 启动进程的命令名称或路径。                       |\n| **USER**  | 启动进程的用户。                                 |\n| **%CPU**  | 进程占用的 CPU 使用率。                          |\n| **%MEM**  | 进程占用的内存使用率。                           |\n| **PPID**  | 父进程 ID。                                      |\n| **STAT**  | 进程状态（如 R、S、T 等，详见下文）。            |\n| **START** | 进程启动时间。                                   |\n\n---\n\n# **进程状态（STAT 字段）**\n\n`ps` 输出的 **STAT** 列表示进程的状态，常见的状态含义如下：\n\n| **状态** | **描述**                                                     |\n| -------- | ------------------------------------------------------------ |\n| **R**    | 运行（Running）：进程正在运行或在运行队列中等待。            |\n| **S**    | 休眠（Sleeping）：进程处于休眠状态，等待某个事件完成。       |\n| **D**    | 不可中断休眠（Uninterruptible Sleep）：通常是 I/O 进程，不能被信号唤醒。 |\n| **T**    | 停止（Stopped）：进程被停止或暂停。                          |\n| **Z**    | 僵尸（Zombie）：进程已终止，但其父进程尚未回收。             |\n\n---\n\n# **常用命令和示例**\n\n## **查看当前终端的进程**\n\n```bash\nps\n```\n\n- 默认显示当前终端（TTY）中运行的进程。\n- 输出示例：\n  ```plaintext\n    PID TTY          TIME CMD\n   1234 pts/0    00:00:00 bash\n   5678 pts/0    00:00:01 ps\n  ```\n\n---\n\n## **查看系统中所有进程**\n\n```bash\nps -e\n```\n或：\n```bash\nps -A\n```\n\n- 显示系统中所有运行的进程。\n\n---\n\n## **显示详细进程信息**\n\n```bash\nps -f\n```\n\n- **`-f`** 显示进程的完整格式，包括父进程 ID（PPID）和进程启动时间（START）。\n\n---\n\n## **显示所有用户的所有进程**\n\n```bash\nps aux\n```\n\n- 这是一个常见的组合，显示所有用户的所有进程，并附带详细信息。\n- 输出示例：\n  ```plaintext\n  USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n  root         1  0.0  0.1  16900  1344 ?        Ss   Dec08   0:01 /sbin/init\n  user      1234  0.2  1.0  12345  5678 pts/0    R+   12:34   0:00 python3 script.py\n  ```\n\n---\n\n## **查看特定用户的进程**\n\n```bash\nps -u username\n```\n\n- 仅显示指定用户的进程。\n\n### 示例：查看 `root` 用户的进程\n```bash\nps -u root\n```\n\n---\n\n##  **按进程名称过滤**\n\n```bash\nps -C process_name\n```\n\n- 显示指定名称的进程（注意：只匹配完全相同的名称）。\n\n### 示例：查看 `nginx` 进程\n```bash\nps -C nginx\n```\n\n---\n\n## **查看指定 PID 的进程**\n\n```bash\nps -p PID\n```\n\n- 显示特定 PID 的进程信息。\n\n### 示例：查看 PID 为 `1234` 的进程\n```bash\nps -p 1234\n```\n\n---\n\n## **显示进程树**\n\n```bash\nps -ejH\n```\n或：\n```bash\nps --forest\n```\n\n- 以树状结构显示进程的父子关系，方便分析进程之间的依赖。\n\n---\n\n## **自定义显示字段**\n\n```bash\nps -eo pid,user,%cpu,%mem,cmd\n```\n\n- 使用 `-o` 选项自定义显示的列。\n- **示例**：显示 PID、用户、CPU 使用率、内存使用率和命令：\n  ```plaintext\n    PID USER       %CPU %MEM CMD\n   1234 root       0.2  1.0 python3 script.py\n   5678 user       0.1  0.5 /usr/bin/bash\n  ```\n\n---\n\n## **结合管道过滤进程**\n\n`ps` 的输出可以通过管道过滤以获取目标进程。\n\n### 示例：通过 `grep` 查找某个进程\n```bash\nps aux | grep nginx\n```\n\n---\n\n## **显示与当前终端相关的进程**\n\n```bash\nps -T\n```\n\n- 显示当前终端上的所有进程（包括子进程）。\n\n---\n\n## **显示所有线程**\n\n```bash\nps -eLf\n```\n\n- **`-L`**：显示线程信息。\n\n---\n\n# **常见用法总结**\n\n| **用法**               | **命令示例**                    |\n| ---------------------- | ------------------------------- |\n| 查看当前终端进程       | `ps`                            |\n| 查看系统中所有进程     | `ps -e` 或 `ps -A`              |\n| 显示所有用户的所有进程 | `ps aux`                        |\n| 查看特定用户的进程     | `ps -u username`                |\n| 查看特定进程的详细信息 | `ps -p PID`                     |\n| 查看特定名称的进程     | `ps -C process_name`            |\n| 显示进程树             | `ps --forest`                   |\n| 查看线程信息           | `ps -eLf`                       |\n| 自定义显示字段         | `ps -eo pid,user,%cpu,%mem,cmd` |\n\n---\n\n# **注意事项**\n\n1. **实时监控进程**：\n   - `ps` 显示的是**执行命令时的快照**，并不会实时刷新。要实时监控进程，可以使用 `top` 或 `htop`。\n\n2. **权限问题**：\n   - 普通用户默认只能查看自己启动的进程。如果需要查看所有用户的进程，可以使用 `sudo` 提升权限：\n     ```bash\n     sudo ps aux\n     ```\n\n3. **僵尸进程**：\n   - 如果看到 `STAT` 列中有 `Z`（僵尸进程），说明进程已终止，但其父进程未回收资源。需要检查父进程是否正常运行。\n\n---\n\n# **总结**\n\n- **`ps` 是一个强大的进程管理工具**，适合查看当前系统的进程快照。\n- 它可以通过选项和过滤灵活显示进程信息，比如按用户、进程名称、PID 等筛选。\n- 熟练掌握 `ps`，可以帮助快速定位系统性能问题、调试进程运行状态、排查僵尸进程等问题。\n","categories":["Linux"]},{"title":"Linux命令详解---mv","url":"/2024/10/09/tisxux0z/","content":"\n`mv` 是 Linux 和类 Unix 操作系统中的一个基本命令，用于移动文件或目录，也可以用来重命名文件或目录。它是 \"move\" 的缩写，但功能不仅仅是 \"移动\"，还可以实现 \"重命名\"。\n\n以下是对 `mv` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\nmv [选项] 源文件/目录 目标文件/目录\n```\n\n- **源文件/目录**：要移动或重命名的文件或目录。\n- **目标文件/目录**：移动到的目标路径，或者新的文件/目录名称。\n- **选项**：用于控制移动行为，例如交互式确认、覆盖提示等。\n\n---\n\n# **功能说明**\n\n1. **移动文件或目录**：将文件或目录从一个位置移动到另一个位置。\n2. **重命名文件或目录**：直接将文件或目录重命名。\n\n---\n\n# **常用选项**\n\n| 选项       | 功能                                                     |\n| ---------- | -------------------------------------------------------- |\n| `-i`       | 如果目标文件已存在，提示用户确认是否覆盖。               |\n| `-f`       | 强制移动，不提示用户确认（默认行为）。                   |\n| `-n`       | 不覆盖目标文件（如果目标文件已存在，则不进行移动操作）。 |\n| `-v`       | 显示移动操作的详细信息（verbose）。                      |\n| `--backup` | 在覆盖目标文件前创建备份文件。                           |\n| `-u`       | 仅在源文件比目标文件新或目标文件不存在时移动。           |\n\n---\n\n# **详解选项**\n\n##  **提示覆盖（`-i`）**\n\n- 如果目标文件已经存在，`mv` 默认直接覆盖目标文件。使用 `-i` 选项，在覆盖前会提示用户确认。\n- 示例：\n  ```bash\n  mv -i file1.txt /path/to/destination/\n  ```\n  - 如果目标路径中已经存在 `file1.txt`，会提示：\n    ```bash\n    overwrite '/path/to/destination/file1.txt'? (y/n)\n    ```\n\n---\n\n## **强制移动（`-f`）**\n\n- `-f` 是默认行为，但可以显式指定。强制覆盖目标文件，不提示用户确认。\n- 示例：\n  ```bash\n  mv -f file1.txt /path/to/destination/\n  ```\n\n---\n\n##  **禁止覆盖（`-n`）**\n\n- 使用 `-n`，如果目标文件已存在，则不会覆盖目标文件。\n- 示例：\n  ```bash\n  mv -n file1.txt /path/to/destination/\n  ```\n\n---\n\n##  **显示详细信息（`-v`）**\n\n- 使用 `-v` 选项会显示每个文件的移动或重命名过程。\n- 示例：\n  ```bash\n  mv -v file1.txt /path/to/destination/\n  ```\n  输出示例：\n  ```bash\n  renamed 'file1.txt' -> '/path/to/destination/file1.txt'\n  ```\n\n---\n\n##  **仅移动更新的文件（`-u`）**\n\n- 使用 `-u`，仅在源文件比目标文件新，或者目标文件不存在时移动。\n- 示例：\n  ```bash\n  mv -u file1.txt /path/to/destination/\n  ```\n\n---\n\n##  **创建备份文件（`--backup`）**\n\n- 使用 `--backup`，在覆盖文件前创建备份文件。\n- 示例：\n  ```bash\n  mv --backup file1.txt /path/to/destination/\n  ```\n\n---\n\n# **示例**\n\n##  **移动单个文件**\n\n```bash\nmv file1.txt /path/to/destination/\n```\n- 将 `file1.txt` 移动到 `/path/to/destination/`。\n\n---\n\n## 移动多个文件到目标目录**\n\n```bash\nmv file1.txt file2.txt file3.txt /path/to/destination/\n```\n- 将 `file1.txt`、`file2.txt` 和 `file3.txt` 移动到 `/path/to/destination/`。\n\n---\n\n##  **重命名文件**\n\n```bash\nmv old_name.txt new_name.txt\n```\n- 将文件 `old_name.txt` 重命名为 `new_name.txt`。\n\n---\n\n## **移动目录**\n\n```bash\nmv source_dir /path/to/destination/\n```\n- 将目录 `source_dir` 移动到 `/path/to/destination/`。\n\n---\n\n##  **重命名目录**\n\n```bash\nmv old_dir new_dir\n```\n- 将目录 `old_dir` 重命名为 `new_dir`。\n\n---\n\n##  **覆盖目标文件前提示确认**\n\n```bash\nmv -i file1.txt /path/to/destination/\n```\n- 如果目标路径中存在同名文件，会提示用户确认是否覆盖。\n\n---\n\n## **显示详细信息的移动操作**\n\n```bash\nmv -v file1.txt /path/to/destination/\n```\n输出示例：\n```bash\nrenamed 'file1.txt' -> '/path/to/destination/file1.txt'\n```\n\n---\n\n##  **禁止覆盖目标文件**\n\n```bash\nmv -n file1.txt /path/to/destination/\n```\n- 如果目标路径中存在同名文件，`mv` 不会覆盖文件。\n\n---\n\n##  **仅移动更新的文件**\n\n```bash\nmv -u file1.txt /path/to/destination/\n```\n- 如果目标路径中已经存在 `file1.txt`，但比源文件旧，才会移动。\n\n---\n\n# **常见错误及解决方法**\n\n1. **权限不足**\n\n```bash\nmv: cannot move 'file1.txt' to '/path/to/destination/': Permission denied\n```\n- 解决方法：使用 `sudo` 提权：\n  ```bash\n  sudo mv file1.txt /path/to/destination/\n  ```\n\n---\n\n2. **文件或目录不存在**\n\n```bash\nmv: cannot stat 'file1.txt': No such file or directory\n```\n- 解决方法：检查文件路径是否正确。\n\n---\n\n3. **目标目录不存在**\n\n```bash\nmv: cannot move 'file1.txt' to '/path/to/destination/': No such file or directory\n```\n- 解决方法：先创建目标目录：\n  ```bash\n  mkdir -p /path/to/destination/\n  mv file1.txt /path/to/destination/\n  ```\n\n---\n\n# **结合其他命令**\n\n##  **移动特定类型的文件**\n\n- 将所有 `.txt` 文件移动到目标目录：\n  ```bash\n  mv *.txt /path/to/destination/\n  ```\n\n## 配合 `find` 按条件移动文件**\n\n- 移动当前目录中所有 `.log` 文件到目标目录：\n  ```bash\n  find . -name \"*.log\" -exec mv {} /path/to/destination/ \\;\n  ```\n\n---\n\n# **总结**\n\n- **`mv` 是一个功能强大的命令**，既可以用于移动文件或目录，也可以用于重命名。\n- **通过选项（如 `-i`、`-n`、`-v` 等）**，可以灵活控制是否提示覆盖、显示详细信息等。\n- 使用 `mv` 时要特别小心，尤其在移动或重命名重要文件时，建议使用 `-i` 选项以避免误操作。\n","categories":["Linux"]},{"title":"Linux命令详解---ls","url":"/2024/10/09/11z9gf7b/","content":"\n`ls` 是 Linux 和类 Unix 操作系统中的一个常用命令，用于列出目录内容（类似于 `Windows` 的文件资源管理器的功能）。它可以显示指定目录下的文件和子目录，并附带多种选项来控制输出格式和显示信息的详细程度。\n\n以下是对 `ls` 命令的详细介绍，包括其基本用法、常用选项和示例。\n\n---\n\n## **基本用法**\n\n```bash\nls [选项] [路径]\n```\n\n- **路径**：指定要列出内容的目录。如果省略路径，`ls` 会列出当前目录的内容。\n- **选项**：用于控制输出的格式和显示的详细信息。\n\n## **常用选项**\n\n### **基本选项**\n| 选项 | 功能                                                         |\n| ---- | ------------------------------------------------------------ |\n| `-a` | 显示所有文件，包括隐藏文件（以 `.` 开头的文件）。            |\n| `-A` | 显示所有文件，但不包括 `.`（当前目录）和 `..`（父目录）。    |\n| `-l` | 使用长格式显示文件的详细信息（权限、所有者、大小、时间等）。 |\n| `-R` | 递归显示子目录中的内容。                                     |\n| `-d` | 显示目录本身，而不是目录中的内容。                           |\n| `-h` | 在长格式输出中，以人类可读的方式显示文件大小（如 KB、MB）。  |\n| `-t` | 按时间排序（最近修改的文件排在前面）。                       |\n| `-S` | 按文件大小排序（最大的文件排在前面）。                       |\n| `-r` | 反向排序（与默认排序顺序相反）。                             |\n\n---\n\n### **长格式选项组合**\n| 选项组合 | 功能                                                         |\n| -------- | ------------------------------------------------------------ |\n| `-lh`    | 以人类可读的长格式显示文件信息（文件大小单位为 KB、MB 等）。 |\n| `-ltr`   | 按时间排序，并以长格式显示，最旧的文件排在前面。             |\n| `-R`     | 递归显示目录及其子目录的内容。                               |\n\n---\n\n## **输出详细信息（`ls -l` 的含义）**\n使用 `ls -l` 命令时，会显示类似以下的输出：\n\n```bash\ndrwxr-xr-x  2 user group  4096 Dec 9 10:00 my_folder\n-rw-r--r--  1 user group  1234 Dec 8 15:30 example.txt\n```\n\n每列的含义如下：\n\n| 列序 | 含义                                                         |\n| ---- | ------------------------------------------------------------ |\n| 1    | 文件类型和权限（`d` 表示目录，`-` 表示普通文件，`l` 表示符号链接）。 |\n| 2    | 硬链接数（指向文件的引用数）。                               |\n| 3    | 文件所有者（user）。                                         |\n| 4    | 文件所属组（group）。                                        |\n| 5    | 文件大小（以字节为单位，或结合 `-h` 以人类可读方式显示）。   |\n| 6    | 最后修改时间（日期和时间）。                                 |\n| 7    | 文件或目录名称。                                             |\n\n---\n\n## **文件类型标记**\n\n当使用 `ls -F` 命令时，文件和目录名称后会附加一个标记以表示文件类型：\n\n| 标记 | 含义             |\n| ---- | ---------------- |\n| `/`  | 目录             |\n| `*`  | 可执行文件       |\n| `@`  | 符号链接         |\n| `=`  | 套接字文件       |\n| `|`  | 命名管道（FIFO） |\n\n---\n\n## **排序选项**\n\n- 默认情况下，`ls` 按文件名的字母顺序排序。\n- 使用以下选项可以更改排序方式：\n  - `-t`：按修改时间排序。\n  - `-S`：按文件大小排序。\n  - `-X`：按文件扩展名排序。\n  - `-r`：反转排序顺序。\n\n---\n\n## **递归显示子目录**\n\n使用 `ls -R`，可以递归显示目录及其所有子目录的内容。例如：\n\n```bash\nls -R\n```\n\n输出示例：\n\n```bash\n.:\nfile1.txt  dir1\n\n./dir1:\nfile2.txt  file3.txt\n```\n\n---\n\n## **颜色区分**\n\n- `ls` 默认会根据文件类型使用不同颜色输出（如果支持）。\n- 颜色的意义：\n  - **蓝色**：目录。\n  - **绿色**：可执行文件。\n  - **红色**：压缩文件。\n  - **紫色**：符号链接。\n  - **黄色**：设备文件。\n\n使用 `--color=auto` 强制启用颜色显示。\n\n---\n\n## **隐藏文件**\n\n- 以 `.` 开头的文件是隐藏文件，不会在默认情况下显示。\n- 使用 `ls -a` 或 `ls -A` 可以查看隐藏文件。\n\n---\n\n## **示例**\n\n### **列出当前目录内容**\n\n```bash\nls\n```\n\n### **显示隐藏文件**\n\n```bash\nls -a\n```\n\n###  **以长格式显示文件信息**\n\n```bash\nls -l\n```\n\n###  **以人类可读格式显示文件大小**\n\n```bash\nls -lh\n```\n\n###  **按时间排序并显示详细信息**\n\n```bash\nls -lt\n```\n\n###  **递归显示目录内容**\n\n```bash\nls -R\n```\n\n###  **查看目录本身信息**\n\n```bash\nls -ld /\n```\n\n---\n\n## **总结**\n\n`ls` 是一个功能强大且灵活的命令，适用于列出和查看目录内容。通过结合不同的选项，可以方便地获取文件或目录的详细信息。熟练使用 `ls` 可以显著提高在 Linux 系统中的工作效率。","categories":["Linux"]},{"title":"Linux命令详解---rm","url":"/2024/10/09/3xakt2ek/","content":"\n`rm` 是 Linux 和类 Unix 操作系统中的一个基本命令，用于删除文件或目录。它是 \"remove\" 的缩写。`rm` 命令可以删除单个文件、多个文件或整个目录，但使用时需要非常小心，因为删除操作通常是不可逆的。\n\n以下是对 `rm` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\nrm [选项] 文件/目录\n```\n\n- **文件/目录**：指定要删除的文件或目录路径。\n- **选项**：用于控制删除行为，例如递归删除、强制删除、交互确认等。\n\n---\n\n# **常用选项**\n\n| 选项         | 功能                                                         |\n| ------------ | ------------------------------------------------------------ |\n| `-i`         | 删除前逐一询问确认。                                         |\n| `-f`         | 强制删除，不提示，即使文件不存在也不会报错（忽略权限和不存在的文件）。 |\n| `-r` 或 `-R` | 递归删除目录及其内容（包括子目录）。                         |\n| `-v`         | 显示删除的详细信息（verbose）。                              |\n\n---\n\n# **详解选项**\n\n## **交互式删除（`-i`）**\n\n- 使用 `-i`，在删除每个文件或目录之前会提示确认。\n- 示例：\n  ```bash\n  rm -i file1.txt\n  ```\n  输出：\n  ```bash\n  rm: remove regular file 'file1.txt'? y\n  ```\n\n---\n\n## 递归删除目录（`-r` 或 `-R`）**\n\n- `rm` 默认不能直接删除目录，如果要删除目录及其内容，必须使用 `-r` 或 `-R`。\n- 示例：\n  ```bash\n  rm -r my_folder\n  ```\n  - 删除 `my_folder` 目录及其所有子文件和子目录。\n\n---\n\n##  **强制删除（`-f`）**\n\n- 使用 `-f` 可以忽略不存在的文件或权限限制，直接强制删除。\n- 示例：\n  ```bash\n  rm -f file2.txt\n  ```\n  - 即使文件不存在，也不会报错。\n\n---\n\n## **显示详细信息（`-v`）**\n\n- 使用 `-v`，删除时会显示正在删除的文件/目录。\n- 示例：\n  ```bash\n  rm -v file3.txt\n  ```\n  输出：\n  ```bash\n  removed 'file3.txt'\n  ```\n\n---\n\n# **警告**\n\n- 使用 `rm` 命令时需要格外小心，特别是结合 `-r` 和 `-f` 选项，因为删除操作通常是不可逆的。\n- 例如，以下命令会强制删除整个目录，以及其中的所有内容：\n  ```bash\n  rm -rf /path/to/directory\n  ```\n  **危险提示**：不建议在没有确认路径的情况下使用 `rm -rf`，尤其是对系统重要目录，如 `/`。\n\n---\n\n# **示例**\n\n## **删除单个文件**\n\n```bash\nrm file1.txt\n```\n- 删除当前目录下的 `file1.txt` 文件。\n\n---\n\n##  **删除多个文件**\n\n```bash\nrm file1.txt file2.txt file3.txt\n```\n- 一次性删除多个文件。\n\n---\n\n##  **删除目录及其内容**\n\n```bash\nrm -r my_folder\n```\n- 删除 `my_folder` 目录及其所有子文件和子目录。\n\n---\n\n##  **强制删除目录及其内容**\n\n```bash\nrm -rf my_folder\n```\n- 强制删除 `my_folder` 及其内容，不提示确认。\n\n---\n\n##  **交互式删除**\n\n```bash\nrm -i file1.txt\n```\n- 删除前会询问确认。\n\n---\n\n## **删除多个文件并显示详细信息**\n\n```bash\nrm -v file1.txt file2.txt\n```\n输出示例：\n```bash\nremoved 'file1.txt'\nremoved 'file2.txt'\n```\n\n---\n\n##  **删除当前目录下所有文件**\n\n```bash\nrm *\n```\n- 删除当前目录下的所有文件（不包括子目录）。\n\n---\n\n##  **删除当前目录下的所有文件和目录**\n\n```bash\nrm -rf *\n```\n- 删除当前目录下的所有文件和目录，包括子目录及其内容。\n\n---\n\n# **常见错误及解决方法**\n\n1. **文件不存在**\n\n```bash\nrm: cannot remove 'file.txt': No such file or directory\n```\n- 解决方法：确保文件路径正确，或者使用 `rm -f` 忽略不存在的文件。\n\n---\n\n2. **权限不足**\n\n```bash\nrm: cannot remove 'file.txt': Permission denied\n```\n- 解决方法：使用 `sudo` 提权删除：\n  ```bash\n  sudo rm file.txt\n  ```\n\n---\n\n3. **误删重要文件**\n\n- 如果误删了文件，通常无法直接恢复。\n- 解决方法：\n  - 定期备份数据。\n  - 使用文件恢复工具尝试恢复（如 `extundelete` 或 `testdisk`）。\n\n---\n\n# **结合其他命令**\n\n## **删除特定类型的文件**\n\n- 删除当前目录下所有 `.txt` 文件：\n  ```bash\n  rm *.txt\n  ```\n\n##  **配合 `find` 命令按条件删除**\n\n- 删除当前目录及子目录中所有 `.log` 文件：\n  ```bash\n  find . -name \"*.log\" -type f -exec rm -v {} \\;\n  ```\n\n- 删除 7 天前的文件：\n  ```bash\n  find /path/to/dir -type f -mtime +7 -exec rm -v {} \\;\n  ```\n\n---\n\n# **总结**\n\n- **`rm` 是一个强大但危险的命令**，可用于删除文件和目录，尤其在使用递归和强制选项（如 `-r` 和 `-f`）时需要特别小心。\n- **推荐使用 `-i` 确保删除前进行确认**，避免误删重要文件。\n- 如果涉及批量删除文件或目录，建议先检查路径和内容，以免造成不可恢复的损失。\n","categories":["Linux"]},{"title":"Linux命令详解---which","url":"/2024/10/09/vdxxz4ti/","content":"\n`which` 是一个用来查找可执行文件路径的命令，用于显示命令或程序所在的绝对路径。它会根据当前用户的环境变量 `PATH` 中定义的搜索路径，依次查找指定的命令，并返回第一个匹配的路径。\n\n---\n\n# **基本语法**\n\n```bash\nwhich [选项] 命令\n```\n\n- **命令**：需要查找的可执行文件名称。\n- **选项**：可选参数，用于修改 `which` 的行为。\n\n---\n\n# **用法示例**\n\n## **查找命令的路径**\n\n```bash\nwhich ls\n```\n\n- **输出**：\n  ```\n  /bin/ls\n  ```\n\n- 说明：返回 `ls` 命令的绝对路径 `/bin/ls`。\n\n---\n\n## **检查某个程序是否安装**\n\n```bash\nwhich python\n```\n\n- 如果程序已安装，输出类似以下路径：\n  ```\n  /usr/bin/python\n  ```\n- 如果程序未安装，没有任何输出或返回空。\n\n---\n\n## **查看用户使用的命令位置**\n\n```bash\nwhich ssh\n```\n\n- **输出**：\n  ```\n  /usr/bin/ssh\n  ```\n\n- 说明：在 PATH 路径中找到 `ssh` 可执行程序的位置。\n\n---\n\n## **查找多个命令路径**\n\n```bash\nwhich ls pwd cat\n```\n\n- **输出**：\n  ```\n  /bin/ls\n  /bin/pwd\n  /bin/cat\n  ```\n\n- 说明：同时查找多个命令的路径。\n\n---\n\n## **检查自定义脚本或别名**\n\n### 如果 `PATH` 中存在同名脚本或工具，`which` 会返回第一个匹配项：\n\n```bash\nwhich myscript\n```\n\n- 如果 `myscript` 是可执行脚本，返回其绝对路径。\n\n---\n\n# **常用选项**\n\n| **选项** | **作用**                                   |\n| -------- | ------------------------------------------ |\n| `-a`     | 显示所有匹配的路径，而不仅仅是第一个路径。 |\n\n---\n\n## **显示所有匹配的路径**\n\n```bash\nwhich -a python\n```\n\n- **输出**：\n  ```\n  /usr/bin/python\n  /bin/python\n  ```\n\n- 说明：`-a` 会列出所有路径，而不仅仅是第一个匹配的路径。\n\n---\n\n# **配合环境变量**\n\n`which` 会根据用户的 `PATH` 环境变量依次查找命令的路径。\n\n## **查看 `PATH` 变量**\n\n```bash\necho $PATH\n```\n\n- **输出**：\n  ```\n  /usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\n  ```\n\n- 说明：`which` 会按照 `PATH` 的顺序查找命令。\n\n---\n\n## **临时修改 `PATH` 并用 `which` 检查**\n\n```bash\nexport PATH=/custom/path:$PATH\nwhich my_command\n```\n\n- 说明：将 `/custom/path` 添加到 `PATH` 的开头，优先在该路径中查找命令。\n\n---\n\n# **区别于其他相关命令**\n\n## **`type` 命令**\n\n`type` 命令不仅可以显示命令的路径，还可以检查命令是否是 Shell 内置命令或别名。\n\n```bash\ntype cd\n```\n\n- **输出**：\n  ```\n  cd is a shell builtin\n  ```\n\n```bash\ntype ls\n```\n\n- **输出**：\n  ```\n  ls is /bin/ls\n  ```\n\n---\n\n## **`command -v`**\n\n`command -v` 和 `which` 类似，但功能更广泛，可以检查所有命令类型（内置命令、别名、函数等）。\n\n```bash\ncommand -v ls\n```\n\n- **输出**：\n  ```\n  /bin/ls\n  ```\n\n---\n\n## **`whereis` 命令**\n\n`whereis` 查找命令的位置、源码路径和手册页路径。\n\n```bash\nwhereis ls\n```\n\n- **输出**：\n  ```\n  ls: /bin/ls /usr/share/man/man1/ls.1.gz\n  ```\n\n- 说明：`whereis` 提供更多信息，但搜索范围比 `which` 更广。\n\n---\n\n# **注意事项**\n\n1. **`which` 只查找可执行文件：**\n   - 如果文件不可执行，或不在 `PATH` 环境变量中，`which` 将无法找到它。\n\n2. **别名和内置命令：**\n   - `which` 不会解析 Shell 的别名或内置命令。如果需要检查别名，可以使用 `type` 命令。\n\n   ```bash\n   alias ls='ls --color=auto'\n   which ls\n   # 输出：/bin/ls\n   ```\n\n3. **所有路径优先级：**\n   - `which` 返回 `PATH` 中第一个匹配的路径。可以使用 `which -a` 查看所有可能的路径。\n\n---\n\n# **示例总结**\n\n| **操作**           | **命令**                    | **说明**                                           |\n| ------------------ | --------------------------- | -------------------------------------------------- |\n| 查找单个命令路径   | `which ls`                  | 返回 `/bin/ls`，显示 `ls` 的第一个匹配路径。       |\n| 查找多个命令路径   | `which ls pwd cat`          | 同时查找多个命令路径。                             |\n| 显示所有匹配路径   | `which -a python`           | 返回所有匹配的 `python` 可执行文件路径。           |\n| 检查命令是否存在   | `which git`                 | 如果返回路径则存在，否则为空。                     |\n| 检查特定路径优先级 | `export PATH=/custom:$PATH` | 临时修改 `PATH`，优先查找 `/custom` 目录中的命令。 |\n\n---\n\n`which` 是一个简单又实用的命令，可以快速帮助你定位程序的位置，并与其他命令（如 `type`、`whereis`）配合使用，进一步了解命令的来源或行为。\n","categories":["Linux"]},{"title":"Linux命令详解---mkdir","url":"/2024/10/09/gz9fhm21/","content":"\n`mkdir` 是 Linux 和类 Unix 操作系统中的一个基本命令，用于创建目录。它是 \"make directory\" 的缩写，可以按照指定的路径创建一个或多个目录，同时支持设置目录的权限。\n\n以下是对 `mkdir` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\nmkdir [选项] 目录名称\n```\n\n- **目录名称**：指定要创建的目录路径，可以是相对路径或绝对路径。\n- **选项**：用于扩展功能，比如递归创建、设置权限等。\n\n---\n\n# **常用选项**\n\n| 选项      | 功能                                             |\n| --------- | ------------------------------------------------ |\n| `-p`      | 递归创建多级目录。如果父目录不存在，会一并创建。 |\n| `-m MODE` | 设置新目录的权限（权限用八进制表示）。           |\n| `-v`      | 显示创建目录的详细信息。                         |\n\n---\n\n# **详解选项**\n\n## **递归创建目录（`-p`）**\n\n- 如果要创建的目录路径中包含不存在的父目录，`-p` 选项会自动创建所有必要的父目录。\n- 示例：\n  ```bash\n  mkdir -p /path/to/parent/child\n  ```\n  - 如果 `/path/to/parent` 不存在，`mkdir -p` 会自动创建 `parent` 和 `child` 目录。\n\n---\n\n## **设置目录权限（`-m`）**\n\n- 使用 `-m` 选项可以直接指定新建目录的权限。\n- 权限使用八进制数指定（例如 `755`, `700`）。\n- 示例：\n  ```bash\n  mkdir -m 755 my_folder\n  ```\n  - 创建 `my_folder` 并设置权限为 `755`（拥有者可读写执行，组和其他用户可读执行）。\n\n---\n\n## **显示详细信息（`-v`）**\n\n- 使用 `-v` 选项可以显示每个创建的目录对应的操作信息。\n- 示例：\n  ```bash\n  mkdir -v new_folder\n  ```\n  输出：\n  ```bash\n  mkdir: created directory 'new_folder'\n  ```\n\n---\n\n# **示例**\n\n## **创建单个目录**\n\n```bash\nmkdir my_folder\n```\n- 在当前目录下创建名为 `my_folder` 的目录。\n\n---\n\n## **递归创建多级目录**\n\n```bash\nmkdir -p /home/user/projects/python/scripts\n```\n- 如果路径 `/home/user/projects/python` 不存在，`-p` 选项会自动创建所有必要的父目录。\n\n---\n\n## **创建目录并设置权限**\n\n```bash\nmkdir -m 700 secure_folder\n```\n- 创建名为 `secure_folder` 的目录，并将权限设置为 `700`（仅拥有者可读写执行）。\n\n---\n\n## **创建多个目录**\n\n```bash\nmkdir folder1 folder2 folder3\n```\n- 一次创建 `folder1`、`folder2` 和 `folder3` 三个目录。\n\n---\n\n## **显示详细信息**\n\n```bash\nmkdir -v project_folder\n```\n输出：\n```bash\nmkdir: created directory 'project_folder'\n```\n\n---\n\n#  **权限的说明**\n\n- 默认情况下，`mkdir` 创建的目录权限由 **`umask`** 控制（用户文件创建模式掩码）。\n  - 例如，如果 `umask` 是 `0022`，默认目录权限为 `777 - 022 = 755`。\n  - 查看当前的 `umask`：\n    ```bash\n    umask\n    ```\n\n- 通过 `-m` 选项可以覆盖默认的权限设置。\n\n---\n\n#  **错误处理**\n\n1. **目录已存在**\n   - 如果尝试创建的目录已存在，`mkdir` 会报错：\n     ```bash\n     mkdir: cannot create directory 'my_folder': File exists\n     ```\n\n2. **无权限创建目录**\n   \n   - 如果没有权限在指定路径下创建目录，`mkdir` 会报错：\n     ```bash\n     mkdir: cannot create directory '/restricted_folder': Permission denied\n     ```\n   \n3. **解决方法**\n   \n   - 使用 `-p` 选项避免 \"已存在\" 的错误。\n   - 确保在有权限的路径下执行，或者使用 `sudo` 提权：\n     ```bash\n     sudo mkdir /restricted_folder\n     ```\n\n---\n\n#  **结合其他命令**\n\n1. **递归创建并切换到新目录**\n   ```bash\n   mkdir -p /path/to/new_folder && cd /path/to/new_folder\n   ```\n\n2. **创建目录后立即设置权限**\n   ```bash\n   mkdir new_folder && chmod 700 new_folder\n   ```\n\n3. **配合 `find` 查看创建的目录**\n   ```bash\n   mkdir -p /tmp/test_folder && find /tmp -name test_folder\n   ```\n\n---\n\n#   **总结**\n\n- `mkdir` 是一个功能简单但非常实用的命令，用于快速创建目录。\n- 通过选项 `-p` 和 `-m` 可以递归创建目录并灵活设置权限。\n- 配合其他命令（如 `cd`、`chmod`），可以提高操作效率，是日常文件管理中不可或缺的工具。\n","categories":["Linux"]},{"title":"Linux命令详解---nohup","url":"/2024/10/09/70nqk05e/","content":"\n`nohup` 是 Linux 和类 Unix 系统中的一个命令，用于在**后台运行程序**，即使用户退出终端或断开会话，程序依然可以继续运行。`nohup` 全称是 \"no hang up\"，意思是不挂起程序。\n\n---\n\n# **基本语法**\n\n```bash\nnohup 命令 [参数] &\n```\n\n- **`nohup`**：表示忽略挂起信号（SIGHUP），防止程序因用户退出终端而终止。\n- **`命令`**：需要运行的程序或脚本。\n- **`&`**：将程序放到后台运行。\n\n---\n\n# **`nohup` 的作用**\n\n- 用于让程序在后台运行，即使用户退出终端，程序依然可以继续执行。\n- 默认情况下，`nohup` 会将程序的输出（标准输出和标准错误）重定向到文件 `nohup.out`，除非用户手动指定输出位置。\n\n---\n\n# **常用示例**\n\n## **后台运行一个程序**\n\n```bash\nnohup python3 script.py &\n```\n\n- 含义：\n  - `nohup` 确保 `script.py` 即使用户退出终端也能继续运行。\n  - `&` 将程序放到后台运行。\n  - 输出和错误信息会被默认保存到当前目录下的 `nohup.out` 文件中。\n\n---\n\n## **指定输出日志文件**\n\n```bash\nnohup python3 script.py > output.log 2>&1 &\n```\n\n- 含义：\n  - `> output.log`：将标准输出重定向到 `output.log` 文件。\n  - `2>&1`：将标准错误重定向到标准输出（`output.log`）。\n  - `&`：将程序放到后台运行。\n\n---\n\n##  **运行一个脚本**\n\n```bash\nnohup ./myscript.sh > myscript.log 2>&1 &\n```\n\n- 将 `myscript.sh` 放到后台运行，输出内容保存到 `myscript.log`。\n\n---\n\n## **使用 `nohup` 配合其他命令**\n\n### **运行一个长期任务**\n\n```bash\nnohup tar -czf backup.tar.gz /data > backup.log 2>&1 &\n```\n\n- 将 `/data` 目录打包为 `backup.tar.gz`，并在后台运行，输出保存到 `backup.log` 文件中。\n\n### **运行一个服务**\n\n```bash\nnohup java -jar myapp.jar > myapp.log 2>&1 &\n```\n\n- 启动一个 Java 应用程序，将输出保存到 `myapp.log`，即使终端关闭仍继续运行。\n\n---\n\n##  **查看后台运行的任务**\n\n可以通过 `jobs` 或 `ps` 命令查看后台运行的任务。\n\n- **查看当前会话的后台任务**：\n  ```bash\n  jobs\n  ```\n  输出示例：\n  ```\n  [1]+  Running                 nohup python3 script.py &\n  ```\n\n- **查看所有进程**：\n  ```bash\n  ps aux | grep script.py\n  ```\n\n---\n\n## **终止后台任务**\n\n- 使用 `ps` 查找到进程的 PID，然后使用 `kill` 终止：\n  ```bash\n  ps aux | grep script.py\n  kill -9 <PID>\n  ```\n\n---\n\n# **注意事项**\n\n1. **默认输出文件是 `nohup.out`**：\n   - 如果没有手动指定输出文件，`nohup` 会将输出和错误信息保存到当前目录下的 `nohup.out` 文件。\n   - 如果当前目录无写权限，`nohup` 会将输出重定向到用户的主目录下的 `nohup.out`。\n\n2. **配合 `&` 使用**：\n   - `nohup` 通常需要配合 `&` 使用，才能将任务放到后台运行。\n   - 如果没有加 `&`，运行的程序不会自动进入后台，但仍然不会因终端关闭而终止。\n\n3. **与 `cron` 或 `at` 结合**：\n   - 如果需要定时运行任务，可以将 `nohup` 和定时任务工具（如 `cron`）结合使用。\n\n---\n\n# **总结**\n\n- **基本用法**：\n  - `nohup 命令 &`：后台运行命令。\n  - `nohup 命令 > output.log 2>&1 &`：后台运行命令，并指定日志文件。\n- **适用场景**：\n  - 长时间运行的任务（如备份、压缩、大型数据处理）。\n  - 启动服务或守护进程（如 Java 应用、HTTP 服务）。\n- 熟练掌握 `nohup`，可以让任务在后台稳定运行，避免因为退出终端导致任务中断。\n","categories":["Linux"]},{"title":"Linux命令详解---cp","url":"/2024/10/08/qhbiamjq/","content":"\n`cp` 是 Linux 和类 Unix 操作系统中的一个基本命令，用于复制文件或目录。它是 \"copy\" 的缩写，支持将文件复制到指定位置，或者递归复制整个目录。\n\n以下是对 `cp` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\ncp [选项] 源文件/目录 目标文件/目录\n```\n\n- **源文件/目录**：要复制的文件或目录。\n- **目标文件/目录**：复制后的文件或目录路径。\n- **选项**：用于定制复制行为，例如递归复制、保留属性、显示详细信息等。\n\n---\n\n# **常用选项**\n\n| 选项         | 功能                                                         |\n| ------------ | ------------------------------------------------------------ |\n| `-r` 或 `-R` | 递归复制目录及其内容（必须用于复制目录）。                   |\n| `-i`         | 如果目标路径存在，提示用户确认是否覆盖文件。                 |\n| `-f`         | 强制复制，覆盖目标文件而不提示（默认行为）。                 |\n| `-u`         | 仅在源文件比目标文件新或目标文件不存在时复制。               |\n| `-v`         | 显示复制过程的详细信息（verbose）。                          |\n| `-p`         | 保留文件的属性（如权限、时间戳、所有者等）。                 |\n| `-a`         | 归档模式，相当于 `-dR --preserve=all`，保留文件的所有属性并递归复制。 |\n| `--backup`   | 在覆盖文件之前创建备份文件。                                 |\n| `--preserve` | 指定保留文件属性（如 `mode`、`ownership`、`timestamps`）。   |\n| `--parents`  | 保留源文件的目录结构。                                       |\n\n---\n\n# **详解选项**\n\n##  **递归复制目录（`-r` 或 `-R`）**\n\n- 默认情况下，`cp` 不能直接复制目录。使用 `-r` 或 `-R` 选项，可以递归复制目录及其内容。\n- 示例：\n  ```bash\n  cp -r source_dir target_dir\n  ```\n  - 复制整个目录 `source_dir` 到 `target_dir`。\n\n---\n\n## **提示覆盖（`-i`）**\n\n- 如果目标文件已存在，`cp` 默认直接覆盖文件。使用 `-i` 选项，复制前会提示用户确认。\n- 示例：\n  ```bash\n  cp -i file1.txt /path/to/destination/\n  ```\n  - 如果目标路径中已存在 `file1.txt`，会提示：\n    ```bash\n    overwrite '/path/to/destination/file1.txt'? (y/n)\n    ```\n\n---\n\n##  **强制复制（`-f`）**\n\n- 强制覆盖目标文件，不会提示用户确认（默认行为）。\n- 示例：\n  ```bash\n  cp -f file1.txt /path/to/destination/\n  ```\n\n---\n\n##  **仅复制更新的文件（`-u`）**\n\n- 如果目标文件不存在，或者源文件比目标文件新，则复制文件；否则跳过。\n- 示例：\n  ```bash\n  cp -u file1.txt /path/to/destination/\n  ```\n\n---\n\n## **显示详细信息（`-v`）**\n\n- 显示每个文件的复制过程。\n- 示例：\n  ```bash\n  cp -v file1.txt /path/to/destination/\n  ```\n  输出示例：\n  ```bash\n  'file1.txt' -> '/path/to/destination/file1.txt'\n  ```\n\n---\n\n##  **保留文件属性（`-p`）**\n\n- 复制时保留文件的权限、时间戳和所有者信息。\n- 示例：\n  ```bash\n  cp -p file1.txt /path/to/destination/\n  ```\n\n---\n\n## **归档模式（`-a`）**\n\n- `-a` 等价于 `-dR --preserve=all`，递归复制目录，并保留文件的所有属性。\n- 示例：\n  ```bash\n  cp -a source_dir target_dir\n  ```\n  - 复制 `source_dir` 到 `target_dir`，保留所有文件属性。\n\n---\n\n##  **保留目录结构（`--parents`）**\n\n- 复制文件时保留源文件的目录层次结构。\n- 示例：\n  ```bash\n  cp --parents source_dir/file1.txt /path/to/destination/\n  ```\n  - 如果 `file1.txt` 位于 `source_dir/sub_dir/` 中，目标路径会创建 `/path/to/destination/source_dir/sub_dir/file1.txt`。\n\n---\n\n# **示例**\n\n##  **复制单个文件**\n\n```bash\ncp file1.txt /path/to/destination/\n```\n- 将 `file1.txt` 复制到目标目录 `/path/to/destination/`。\n\n---\n\n##  **复制多个文件到目标目录**\n\n```bash\ncp file1.txt file2.txt /path/to/destination/\n```\n- 将 `file1.txt` 和 `file2.txt` 复制到 `/path/to/destination/`。\n\n---\n\n##  **递归复制目录**\n\n```bash\ncp -r source_dir /path/to/destination/\n```\n- 将整个目录 `source_dir` 及其内容复制到 `/path/to/destination/`。\n\n---\n\n##  **覆盖目标文件前提示确认**\n\n```bash\ncp -i file1.txt /path/to/destination/\n```\n- 如果目标路径中存在同名文件，会提示用户确认是否覆盖。\n\n---\n\n##  **仅复制更新的文件**\n\n```bash\ncp -u file1.txt /path/to/destination/\n```\n- 如果 `file1.txt` 比目标路径中的同名文件新，则复制；否则不复制。\n\n---\n\n## 显示复制过程的详细信息**\n\n```bash\ncp -v file1.txt /path/to/destination/\n```\n输出示例：\n```bash\n'file1.txt' -> '/path/to/destination/file1.txt'\n```\n\n---\n\n##  **复制并保留文件属性**\n\n```bash\ncp -p file1.txt /path/to/destination/\n```\n- 保留文件的权限、时间戳和所有者信息。\n\n---\n\n##  **复制目录并保留所有属性**\n\n```bash\ncp -a source_dir /path/to/destination/\n```\n- 将 `source_dir` 及其内容复制到 `/path/to/destination/`，并保留所有文件属性。\n\n---\n\n##  **保留目录结构复制文件**\n\n```bash\ncp --parents source_dir/file1.txt /path/to/destination/\n```\n- 在目标路径中保留 `source_dir` 的目录结构。\n\n---\n\n# **常见错误及解决方法**\n\n1. **权限不足**\n\n```bash\ncp: cannot create regular file '/path/to/destination/file1.txt': Permission denied\n```\n- 解决方法：使用 `sudo` 提权：\n  ```bash\n  sudo cp file1.txt /path/to/destination/\n  ```\n\n2. **文件不存在**\n\n```bash\ncp: cannot stat 'file1.txt': No such file or directory\n```\n- 解决方法：检查文件路径是否正确。\n\n3. **目标目录不存在**\n\n```bash\ncp: cannot create directory '/path/to/destination/': No such file or directory\n```\n- 解决方法：先创建目标目录：\n  ```bash\n  mkdir -p /path/to/destination/\n  cp file1.txt /path/to/destination/\n  ```\n\n---\n\n# **结合其他命令**\n\n##  **配合 `find` 按条件复制文件**\n\n- 复制所有 `.txt` 文件到目标目录：\n  ```bash\n  find /source_dir -name \"*.txt\" -exec cp {} /path/to/destination/ \\;\n  ```\n\n## **配合通配符复制文件**\n\n- 复制当前目录下所有 `.log` 文件：\n  ```bash\n  cp *.log /path/to/destination/\n  ```\n\n---\n\n# **总结**\n\n- **`cp` 是 Linux 中常用的文件和目录复制命令**，支持单个文件的复制、多文件的批量复制，以及目录递归复制。\n- **通过选项（如 `-r`、`-i`、`-p`、`-a` 等）**，可以灵活实现递归复制、保留属性、交互确认等功能。\n- **谨慎使用覆盖选项（`-f` 和 `-i`）**，避免误操作导致重要文件丢失。\n","categories":["Linux"]},{"title":"Linux命令详解---时间和日期","url":"/2024/10/08/zxz9iq7w/","content":"\n在 Linux/Unix 系统中，与时间和日期相关的命令主要用于查看、设置和操作系统时间，以及格式化输出和处理日期数据。以下是常用的时间和日期管理命令及其详细用法。\n\n---\n\n# **查看当前时间和日期**\n\n## **`date`**\n\n用于显示和设置系统的当前时间和日期。\n\n### **语法**\n\n```bash\ndate [选项] [+格式]\n```\n\n### **常用示例**\n\n1. **查看当前时间和日期**\n\n```bash\ndate\n```\n\n- **输出示例**：\n  ```\n  Mon Dec  9 12:34:56 UTC 2024\n  ```\n\n---\n\n2. **自定义日期和时间格式**\n\n通过 `+` 指定格式化输出：\n\n```bash\ndate \"+%Y-%m-%d %H:%M:%S\"\n```\n\n- **输出**：\n  ```\n  2024-12-09 12:34:56\n  ```\n\n- **常用格式化符**：\n\n  | **符号** | **含义**         | **示例输出** |\n  | -------- | ---------------- | ------------ |\n  | `%Y`     | 年（四位数）     | `2024`       |\n  | `%m`     | 月（两位数）     | `12`         |\n  | `%d`     | 日（两位数）     | `09`         |\n  | `%H`     | 小时（24小时制） | `12`         |\n  | `%I`     | 小时（12小时制） | `12`         |\n  | `%M`     | 分钟             | `34`         |\n  | `%S`     | 秒               | `56`         |\n  | `%A`     | 星期几（全称）   | `Monday`     |\n  | `%a`     | 星期几（缩写）   | `Mon`        |\n  | `%B`     | 月份（全称）     | `December`   |\n  | `%b`     | 月份（缩写）     | `Dec`        |\n  | `%p`     | 显示 AM 或 PM    | `PM`         |\n  | `%Z`     | 时区             | `UTC`        |\n\n---\n\n3. **显示时间戳（秒级）**\n\n```bash\ndate +%s\n```\n\n- **输出**：\n  ```\n  1733741696\n  ```\n\n- 说明：输出从 1970 年 1 月 1 日的 **Epoch 时间**（Unix 时间戳）。\n\n---\n\n## **`cal`**\n\n用于显示日历。\n\n### **语法**\n\n```bash\ncal [选项] [月] [年]\n```\n\n### **常用示例**\n\n1. **显示当前月的日历**\n\n```bash\ncal\n```\n\n- **输出**：\n  ```\n     December 2024\n  Su Mo Tu We Th Fr Sa\n   1  2  3  4  5  6  7\n   8  9 10 11 12 13 14\n  15 16 17 18 19 20 21\n  22 23 24 25 26 27 28\n  29 30 31\n  ```\n\n---\n\n2. **显示特定年份的日历**\n\n```bash\ncal 2024\n```\n\n---\n\n3. **显示特定月份的日历**\n\n```bash\ncal 12 2024\n```\n\n---\n\n## **`timedatectl`**\n\n用于查看和管理系统时间设置。\n\n### **语法**\n\n```bash\ntimedatectl [选项]\n```\n\n### **常用示例**\n\n1. **查看当前时间和时区**\n\n```bash\ntimedatectl\n```\n\n- **输出**：\n  ```\n               Local time: Mon 2024-12-09 12:34:56 UTC\n           Universal time: Mon 2024-12-09 12:34:56 UTC\n                 RTC time: Mon 2024-12-09 12:34:56\n                Time zone: UTC (UTC, +0000)\n  System clock synchronized: yes\n              NTP service: active\n  ```\n\n---\n\n2. **设置时区**\n\n```bash\nsudo timedatectl set-timezone America/New_York\n```\n\n- **说明**：将系统时区设置为 `America/New_York`。\n\n---\n\n3. **同步时间**\n\n```bash\nsudo timedatectl set-ntp true\n```\n\n- **说明**：启用基于 NTP（网络时间协议）的时间同步。\n\n---\n\n# **时间和日期操作**\n\n## **计算日期**\n\n### **`date` 命令加减时间**\n\n1. **计算未来或过去的日期**\n\n```bash\ndate -d \"+7 days\"\n```\n\n- **输出**：\n  ```\n  Mon Dec 16 12:34:56 UTC 2024\n  ```\n\n2. **计算过去的时间**\n\n```bash\ndate -d \"yesterday\"\n```\n\n- **输出**：\n  ```\n  Sun Dec  8 12:34:56 UTC 2024\n  ```\n\n3. **指定特定日期加减时间**\n\n```bash\ndate -d \"2024-12-09 +2 months\"\n```\n\n- **输出**：\n  ```\n  Sat Feb  9 12:34:56 UTC 2025\n  ```\n\n---\n\n## **格式化时间戳**\n\n1. **将时间戳转换为日期**\n\n```bash\ndate -d @1733741696\n```\n\n- **输出**：\n  ```\n  Mon Dec  9 12:34:56 UTC 2024\n  ```\n\n2. **将日期转换为时间戳**\n\n```bash\ndate -d \"2024-12-09 12:34:56\" +%s\n```\n\n- **输出**：\n  ```\n  1733741696\n  ```\n\n---\n\n# **时间同步**\n\n## **使用 `ntpdate`**\n\n### 安装 NTP 客户端（如果未安装）\n\n```bash\nsudo apt install ntpdate    # Debian/Ubuntu 系列\nsudo yum install ntpdate    # CentOS/RHEL 系列\n```\n\n### 手动同步时间\n\n```bash\nsudo ntpdate pool.ntp.org\n```\n\n- **说明**：从 `pool.ntp.org` NTP 服务器同步时间。\n\n---\n\n## **使用 `chronyc`**\n\n### 查看时间同步状态\n\n```bash\nchronyc tracking\n```\n\n---\n\n# **定时任务**\n\n## **使用 `crontab`**\n\n`crontab` 是 Linux 定时任务的管理工具，可以用来定期执行脚本或命令。\n\n1. **编辑定时任务**\n\n```bash\ncrontab -e\n```\n\n2. **示例任务**：每天凌晨 2 点执行备份脚本\n\n```bash\n0 2 * * * /path/to/backup.sh\n```\n\n---\n\n## **使用 `at`**\n\n用于执行一次性定时任务。\n\n1. **安装 `at` 命令**\n\n```bash\nsudo apt install at\n```\n\n2. **设置任务**\n\n```bash\necho \"backup.sh\" | at now + 1 hour\n```\n\n- **说明**：1 小时后运行 `backup.sh`。\n\n---\n\n# **时间和日期命令总结**\n\n| **命令**      | **作用**                 | **示例**                             |\n| ------------- | ------------------------ | ------------------------------------ |\n| `date`        | 显示或设置当前时间和日期 | `date \"+%Y-%m-%d %H:%M:%S\"`          |\n| `cal`         | 显示日历                 | `cal 2024`                           |\n| `timedatectl` | 管理系统时间和时区       | `timedatectl set-timezone UTC`       |\n| `ntpdate`     | 手动同步时间             | `sudo ntpdate pool.ntp.org`          |\n| `chronyc`     | 查看时间同步状态         | `chronyc tracking`                   |\n| `crontab`     | 创建周期性定时任务       | `crontab -e`                         |\n| `at`          | 创建一次性定时任务       | `echo \"backup.sh\" | at now + 2 days` |\n\n通过这些命令，您可以轻松管理 Linux 系统的时间和日期，以及处理与时间相关的任务！\n","categories":["Linux"]},{"title":"Linux命令详解---重定向和管道","url":"/2024/10/08/ie3o1mib/","content":"\n在 Linux 和 Unix 系统中，**重定向**和**管道**是两个非常重要的功能，用于控制命令的输入、输出和处理数据流。通过重定向和管道，可以将命令的输出保存到文件、作为另一个命令的输入，或进行更复杂的数据处理。\n\n---\n\n# **重定向命令**\n\n重定向用于将命令的标准输入（`stdin`）、标准输出（`stdout`）或标准错误输出（`stderr`）重定向到文件或其他设备。\n\n## **重定向符号**\n\n| **符号**    | **描述**                                                     |\n| ----------- | ------------------------------------------------------------ |\n| `>`         | 将标准输出（`stdout`）重定向到文件，**覆盖**文件内容。       |\n| `>>`        | 将标准输出（`stdout`）重定向到文件，**追加**到文件末尾。     |\n| `<`         | 将文件的内容作为标准输入（`stdin`）。                        |\n| `2>`        | 将标准错误输出（`stderr`）重定向到文件，**覆盖**文件内容。   |\n| `2>>`       | 将标准错误输出（`stderr`）重定向到文件，**追加**到文件末尾。 |\n| `&>`        | 将标准输出和标准错误（`stdout` 和 `stderr`）**同时重定向**到文件，覆盖内容。 |\n| `&>>`       | 将标准输出和标准错误（`stdout` 和 `stderr`）**同时重定向**到文件，追加内容。 |\n| `/dev/null` | 丢弃输出或错误（相当于垃圾桶）。                             |\n\n---\n\n## **重定向用法**\n\n### **将命令输出重定向到文件**\n\n```bash\necho \"Hello, World!\" > output.txt\n```\n\n- `>`：将输出写入文件 `output.txt`（覆盖文件内容）。\n- 如果 `output.txt` 不存在，会自动创建。\n\n### **将输出追加到文件**\n\n```bash\necho \"Another line\" >> output.txt\n```\n\n- `>>`：将输出追加到 `output.txt` 的末尾。\n\n### **将文件内容作为命令的输入**\n\n```bash\ncat < input.txt\n```\n\n- `<`：将文件 `input.txt` 的内容作为 `cat` 命令的输入。\n\n### **将错误输出重定向到文件**\n\n```bash\nls non_existent_file 2> error.log\n```\n\n- `2>`：将错误输出保存到 `error.log` 文件中。\n\n### **同时重定向标准输出和错误**\n\n```bash\nls /etc > output.log 2>&1\n```\n\n- `2>&1`：将错误输出（`stderr`）重定向到标准输出（`stdout`），然后统一保存到 `output.log` 中。\n\n### **丢弃输出**\n\n```bash\nls /etc > /dev/null\n```\n\n- `/dev/null`：将输出丢弃，不显示也不保存。\n\n### **丢弃错误输出**\n\n```bash\nls non_existent_file 2> /dev/null\n```\n\n- `2>`：仅将错误输出丢弃。\n\n### **丢弃所有输出**\n\n```bash\nls /etc > /dev/null 2>&1\n```\n\n- 同时丢弃标准输出和错误输出。\n\n---\n\n# **管道命令**\n\n管道（`|`）用于将一个命令的输出作为另一个命令的输入。它是连接多个命令的重要工具。\n\n## **管道的基本语法**\n\n```bash\ncommand1 | command2\n```\n\n- `command1` 的输出通过管道传递给 `command2` 作为输入。\n\n## **管道示例**\n\n### **将命令输出传递给另一个命令**\n\n```bash\nls -l | grep \".txt\"\n```\n\n- `ls -l`：列出目录的详细内容。\n- `grep \".txt\"`：过滤出包含 `.txt` 的行。\n\n### **统计命令输出的行数**\n\n```bash\nls | wc -l\n```\n\n- `ls`：列出当前目录的文件。\n- `wc -l`：统计文件列表的行数。\n\n### **显示进程并过滤关键字**\n\n```bash\nps aux | grep \"nginx\"\n```\n\n- `ps aux`：显示所有运行中的进程。\n- `grep \"nginx\"`：过滤出包含 `nginx` 的进程。\n\n### **排序和去重**\n\n```bash\ncat file.txt | sort | uniq\n```\n\n- `cat file.txt`：显示文件内容。\n- `sort`：对文件内容排序。\n- `uniq`：去重，显示唯一的行。\n\n### **查找大文件并排序**\n\n```bash\ndu -h | sort -h\n```\n\n- `du -h`：显示目录和文件的大小。\n- `sort -h`：按人类可读格式（如 KB、MB 等）排序。\n\n---\n\n# **重定向与管道结合**\n\n重定向和管道可以结合使用，用于更复杂的数据处理。\n\n## **示例 1：将输出保存到文件**\n\n```bash\nls -l | grep \".txt\" > txt_files.log\n```\n\n- `ls -l`：列出目录内容。\n- `grep \".txt\"`：过滤出包含 `.txt` 的文件。\n- `>`：将结果保存到 `txt_files.log` 文件中。\n\n## **示例 2：同时处理输出和错误**\n\n```bash\nfind /etc -name \"*.conf\" > output.log 2>&1\n```\n\n- `find /etc -name \"*.conf\"`：查找 `/etc` 下的 `.conf` 文件。\n- `>`：将输出保存到 `output.log`。\n- `2>&1`：将错误输出一起保存。\n\n## **示例 3：统计错误行数**\n\n```bash\nls /nonexistent 2>&1 | wc -l\n```\n\n- `ls /nonexistent`：尝试列出不存在的目录。\n- `2>&1`：将错误输出通过管道传递。\n- `wc -l`：统计错误消息的行数。\n\n---\n\n# **常见组合示例**\n\n## **示例 1：查找日志中的错误并保存**\n\n```bash\ngrep \"ERROR\" /var/log/syslog | tee error_log.txt\n```\n\n- `grep \"ERROR\"`：查找日志中的错误行。\n- `tee`：将输出写入文件，同时打印到屏幕。\n\n---\n\n## **示例 2：监控文件变化**\n\n```bash\ntail -f /var/log/syslog | grep \"ERROR\"\n```\n\n- `tail -f`：实时查看文件变化。\n- `grep \"ERROR\"`：实时过滤包含 `ERROR` 的行。\n\n---\n\n## **示例 3：过滤并统计文件中出现最多的单词**\n\n```bash\ncat file.txt | tr -s ' ' '\\n' | sort | uniq -c | sort -nr | head -10\n```\n\n- `tr -s ' ' '\\n'`：将空格转换为换行符，将每个单词分行。\n- `sort`：对单词排序。\n- `uniq -c`：统计每个单词出现的次数。\n- `sort -nr`：按数字降序排序。\n- `head -10`：取出现次数最多的前 10 个单词。\n\n---\n\n# **总结**\n\n## **重定向符号**\n\n| **符号**    | **作用**                         |\n| ----------- | -------------------------------- |\n| `>`         | 标准输出重定向到文件（覆盖）。   |\n| `>>`        | 标准输出重定向到文件（追加）。   |\n| `<`         | 从文件读取输入。                 |\n| `2>`        | 错误输出重定向到文件（覆盖）。   |\n| `2>>`       | 错误输出重定向到文件（追加）。   |\n| `&>`        | 标准输出和错误同时重定向到文件。 |\n| `/dev/null` | 丢弃输出或错误。                 |\n\n## **管道符号**\n\n| **符号** | **作用**                           |\n| -------- | ---------------------------------- |\n| `|`      | 将命令的输出作为另一个命令的输入。 |\n\n## **常用命令组合**\n\n- **筛选**：`ps aux | grep \"nginx\"`\n- **统计**：`ls | wc -l`\n- **排序**：`cat file.txt | sort | uniq -c | sort -nr`\n\n通过灵活使用重定向和管道，可以大大提高 Linux 日常操作的效率和灵活性！\n","categories":["Linux"]},{"title":"Linux命令详解---find","url":"/2024/10/08/rh586uhh/","content":"\n`find` 是 Linux 和类 Unix 操作系统中的一个强大命令，用于在目录中查找文件或目录，并可以对找到的文件执行特定的操作。它支持根据文件名、类型、大小、时间等条件进行搜索，非常灵活和强大。\n\n以下是对 `find` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\nfind [路径] [条件] [操作]\n```\n\n- **路径**：指定要搜索的目录路径，默认为当前目录（`.`）。\n- **条件**：指定查找文件的条件（例如文件名、大小、时间等）。\n- **操作**：对查找到的文件执行的操作（例如删除、移动或打印路径）。\n\n---\n\n# **常用选项和条件**\n\n| 条件/选项   | 功能                                                         |\n| ----------- | ------------------------------------------------------------ |\n| `-name`     | 按文件名查找，支持通配符（如 `*.txt`）。                     |\n| `-type`     | 按文件类型查找（`f` 表示文件，`d` 表示目录）。               |\n| `-size`     | 按文件大小查找（如 `+100k` 表示大于 100 KB，`-10M` 表示小于 10 MB）。 |\n| `-mtime`    | 查找按修改时间的文件（如 `-mtime +7` 表示 7 天前修改的文件）。 |\n| `-atime`    | 查找按访问时间的文件。                                       |\n| `-ctime`    | 查找按更改属性时间的文件（例如权限变化）。                   |\n| `-user`     | 按文件的拥有者查找。                                         |\n| `-group`    | 按文件的所属组查找。                                         |\n| `-perm`     | 按文件权限查找（如 `-perm 755`）。                           |\n| `-exec`     | 对查找到的文件执行操作。                                     |\n| `-delete`   | 删除查找到的文件。                                           |\n| `-iname`    | 按文件名查找，但忽略大小写。                                 |\n| `-empty`    | 查找空文件或空目录。                                         |\n| `-maxdepth` | 限制搜索的目录深度。                                         |\n| `-mindepth` | 设置搜索的最小深度。                                         |\n\n---\n\n# **详解条件和操作**\n\n##  **按文件名查找（`-name` 和 `-iname`）**\n\n- 使用 `-name` 按精确文件名查找（区分大小写）。\n- 使用 `-iname` 按文件名查找（不区分大小写）。\n- 支持通配符 `*` 和 `?`：\n  - `*` 匹配任意多个字符。\n  - `?` 匹配任意单个字符。\n\n示例：\n```bash\nfind . -name \"*.txt\"\nfind /var/log -iname \"*.log\"\n```\n\n---\n\n##  **按文件类型查找（`-type`）**\n\n- `f`：普通文件。\n- `d`：目录。\n- `l`：符号链接文件。\n- `c`：字符设备文件。\n- `b`：块设备文件。\n\n示例：\n```bash\nfind . -type f    # 查找所有文件\nfind . -type d    # 查找所有目录\n```\n\n---\n\n##  **按文件大小查找（`-size`）**\n\n- `+` 表示大于，`-` 表示小于，直接数字表示等于。\n- 单位：\n  - `b`：字节。\n  - `k`：千字节。\n  - `M`：兆字节。\n  - `G`：千兆字节。\n\n示例：\n```bash\nfind . -size +1M    # 查找大于 1 MB 的文件\nfind . -size -10k   # 查找小于 10 KB 的文件\n```\n\n---\n\n## **按时间查找（`-mtime`、`-atime`、`-ctime`）**\n\n- `-mtime`：按文件的修改时间查找。\n- `-atime`：按文件的访问时间查找。\n- `-ctime`：按文件的属性更改时间查找。\n\n时间格式：\n- `+n` 表示 n 天前。\n- `-n` 表示 n 天以内。\n- `n` 表示正好 n 天前。\n\n示例：\n```bash\nfind . -mtime +7    # 查找 7 天前修改的文件\nfind . -atime -2    # 查找最近 2 天访问过的文件\nfind . -ctime 1     # 查找正好 1 天前更改属性的文件\n```\n\n---\n\n##  **按文件权限查找（`-perm`）**\n\n- 精确匹配权限：\n  ```bash\n  find . -perm 644\n  ```\n- 文件至少包含指定权限：\n  ```bash\n  find . -perm -755\n  ```\n\n---\n\n## 限制搜索范围（`-maxdepth` 和 `-mindepth`）**\n\n- `-maxdepth`：限制搜索的最大目录深度。\n- `-mindepth`：限制搜索的最小目录深度。\n\n示例：\n```bash\nfind . -maxdepth 2 -name \"*.txt\"   # 仅搜索当前目录及下一级目录\nfind . -mindepth 3 -type f         # 搜索第三层及更深的文件\n```\n\n---\n\n##  **执行操作（`-exec` 和 `-delete`）**\n\n#### **`-exec`**\n- 对查找到的文件执行命令。\n- `{}` 用于占位，表示找到的文件。\n- `\\;` 表示命令结束。\n\n示例：\n```bash\nfind . -name \"*.log\" -exec rm {} \\;    # 删除所有 .log 文件\nfind . -type f -exec chmod 644 {} \\;  # 将所有文件权限设置为 644\n```\n\n#### **`-delete`**\n- 删除满足条件的文件或目录（危险操作）。\n- 示例：\n  ```bash\n  find . -name \"*.tmp\" -delete\n  ```\n\n---\n\n##  **查找空文件或目录（`-empty`）**\n\n示例：\n```bash\nfind . -empty    # 查找空文件或空目录\n```\n\n---\n\n##  **按用户或组查找（`-user` 和 `-group`）**\n\n- `-user`：按文件的所有者查找。\n- `-group`：按文件所属的组查找。\n\n示例：\n```bash\nfind . -user root    # 查找所有者是 root 的文件\nfind . -group staff  # 查找所属组是 staff 的文件\n```\n\n---\n\n# **示例**\n\n##  **查找当前目录下的所有 `.txt` 文件**\n\n```bash\nfind . -name \"*.txt\"\n```\n\n---\n\n##  **查找 `/var/log` 下大于 10 MB 的文件**\n\n```bash\nfind /var/log -size +10M\n```\n\n---\n\n## **查找最近 3 天修改过的文件**\n\n```bash\nfind . -mtime -3\n```\n\n---\n\n##  **查找并删除所有 `.tmp` 文件**\n\n```bash\nfind . -name \"*.tmp\" -delete\n```\n\n---\n\n##  **查找并复制所有 `.jpg` 文件到 `/backup`**\n\n```bash\nfind . -name \"*.jpg\" -exec cp {} /backup/ \\;\n```\n\n---\n\n##  **查找空文件或空目录**\n\n```bash\nfind . -empty\n```\n\n---\n\n##  **查找目录的最大深度为 2 的所有 `.sh` 文件**\n\n```bash\nfind . -maxdepth 2 -name \"*.sh\"\n```\n\n---\n\n## **查找所有权限为 644 的文件**\n\n```bash\nfind . -perm 644\n```\n\n---\n\n## **查找用户为 `root` 的所有文件**\n\n```bash\nfind / -user root\n```\n\n---\n\n##  **按目录结构保留并压缩查找到的文件**\n\n- 查找 `.log` 文件并打包成 `logs.tar.gz`：\n  ```bash\n  find . -name \"*.log\" | tar -czvf logs.tar.gz -T -\n  ```\n\n---\n\n# **总结**\n\n- **`find` 是 Linux 中功能最强大的文件搜索工具之一，支持多种条件组合和自定义操作。**\n- **结合其他命令（如 `rm`、`chmod`、`cp` 等），可以完成复杂的批量操作。**\n- 使用 `-delete` 和 `-exec` 时需格外小心，确保路径和条件正确，以避免误操作导致数据丢失。\n","categories":["Linux"]},{"title":"Linux命令详解---apt","url":"/2024/10/08/lx5mg678/","content":"\n`apt` 是基于 Debian 和 Ubuntu 系列的 Linux 发行版中常用的包管理工具。它是 `apt-get` 和 `apt-cache` 的简化版，提供了更直观的命令和输出，用于安装、卸载、更新和管理软件包。\n\n---\n\n# **基本语法**\n\n```bash\napt [子命令] [选项] [参数]\n```\n\n- **子命令**：指定要执行的操作（如 `install`、`update`、`remove` 等）。\n- **选项**：可以用来控制 `apt` 的行为（如 `-y` 表示自动确认）。\n- **参数**：指定操作的目标（如某个软件包名称）。\n\n---\n\n# **常用子命令及用法**\n\n## **更新软件包索引**\n\n```bash\napt update\n```\n\n- 作用：从配置的源服务器上获取最新的软件包列表，更新本地索引。\n- **示例**：\n\n```bash\napt update\n```\n\n---\n\n## **升级系统中的软件包**\n\n### **全量升级**\n\n```bash\napt upgrade\n```\n\n- 作用：将所有已安装的软件包升级到新版本（但不会自动移除或安装新包）。\n- **示例**：\n\n```bash\napt upgrade\n```\n\n### **智能升级**\n\n```bash\napt full-upgrade\n```\n\n- 作用：与 `upgrade` 类似，但会自动处理依赖关系，安装新包或移除旧包以完成升级。\n- **示例**：\n\n```bash\napt full-upgrade\n```\n\n---\n\n## **安装软件包**\n\n### **安装单个软件包**\n\n```bash\napt install <软件包名>\n```\n\n- **示例**：\n\n```bash\napt install vim\n```\n\n### **安装多个软件包**\n\n```bash\napt install <软件包1> <软件包2>\n```\n\n- **示例**：\n\n```bash\napt install git curl\n```\n\n### **自动确认安装（无需交互）**\n\n```bash\napt install -y <软件包名>\n```\n\n- **示例**：\n\n```bash\napt install -y nginx\n```\n\n---\n\n## **卸载软件包**\n\n### **卸载软件包**\n\n```bash\napt remove <软件包名>\n```\n\n- 作用：卸载软件包，但保留配置文件。\n- **示例**：\n\n```bash\napt remove vim\n```\n\n### **卸载并移除配置文件**\n\n```bash\napt purge <软件包名>\n```\n\n- **示例**：\n\n```bash\napt purge vim\n```\n\n### **自动确认卸载**\n\n```bash\napt remove -y <软件包名>\n```\n\n- **示例**：\n\n```bash\napt remove -y vim\n```\n\n---\n\n## **搜索软件包**\n\n### **搜索软件包名称**\n\n```bash\napt search <关键词>\n```\n\n- **示例**：\n\n```bash\napt search vim\n```\n\n- 作用：查找名称或描述中包含 `vim` 的软件包。\n\n### **显示软件包的详细信息**\n\n```bash\napt show <软件包名>\n```\n\n- **示例**：\n\n```bash\napt show vim\n```\n\n- 输出：显示软件包的详细信息，包括版本号、依赖、大小、描述等。\n\n---\n\n## **清理缓存**\n\n### **清除已下载但未使用的包文件**\n\n```bash\napt autoclean\n```\n\n- 作用：清理旧版本的包文件，仅保留当前版本。\n\n### **清理所有已下载的包文件**\n\n```bash\napt clean\n```\n\n- 作用：删除 `/var/cache/apt/archives` 下的所有缓存包文件。\n\n### **清除未使用的依赖包**\n\n```bash\napt autoremove\n```\n\n- 作用：删除不再使用的依赖包和孤立的软件包。\n- **示例**：\n\n```bash\napt autoremove\n```\n\n---\n\n## **列出软件包**\n\n### **列出已安装的软件包**\n\n```bash\napt list --installed\n```\n\n- **示例**：\n\n```bash\napt list --installed\n```\n\n### **列出可升级的软件包**\n\n```bash\napt list --upgradable\n```\n\n- **示例**：\n\n```bash\napt list --upgradable\n```\n\n---\n\n## **查看依赖关系**\n\n### **查看软件包的依赖**\n\n```bash\napt depends <软件包名>\n```\n\n- **示例**：\n\n```bash\napt depends vim\n```\n\n### **查看软件包被哪些包依赖**\n\n```bash\napt rdepends <软件包名>\n```\n\n- **示例**：\n\n```bash\napt rdepends vim\n```\n\n---\n\n## **检查和修复系统**\n\n### **检查并修复依赖问题**\n\n```bash\napt install -f\n```\n\n- 作用：修复由于软件包依赖问题导致的错误。\n\n---\n\n# **常用选项**\n\n| **选项**                  | **作用**                                                 |\n| ------------------------- | -------------------------------------------------------- |\n| `-y`                      | 自动确认所有提示（适用于安装、卸载等操作）。             |\n| `-q`                      | 安静模式，不输出多余信息。                               |\n| `--no-install-recommends` | 禁止安装推荐的软件包，仅安装必要的依赖项。               |\n| `--fix-broken`            | 修复依赖关系问题。                                       |\n| `--simulate`              | 模拟执行命令，不实际安装或卸载软件包，用于测试命令结果。 |\n\n---\n\n# **示例场景**\n\n## **安装指定版本的软件包**\n\n```bash\napt install <软件包名>=<版本号>\n```\n\n- **示例**：\n\n```bash\napt install nginx=1.18.0-1ubuntu1\n```\n\n---\n\n## **仅下载软件包，不安装**\n\n```bash\napt install --download-only <软件包名>\n```\n\n- **示例**：\n\n```bash\napt install --download-only nginx\n```\n\n---\n\n## **列出仓库中某个包的详细信息**\n\n```bash\napt show <软件包名>\n```\n\n- **示例**：\n\n```bash\napt show nginx\n```\n\n---\n\n## **升级所有可升级的软件包**\n\n```bash\napt upgrade\n```\n\n---\n\n## **查看软件包的依赖关系**\n\n```bash\napt depends <软件包名>\n```\n\n- **示例**：\n\n```bash\napt depends curl\n```\n\n---\n\n# **清理系统**\n\n## **清除未使用的包和缓存**\n\n```bash\napt autoremove && apt clean\n```\n\n- **作用**：清除系统中不需要的孤立包和缓存，释放磁盘空间。\n\n---\n\n# **与传统工具的对比**\n\n`apt` 是对 `apt-get` 和 `apt-cache` 的简化和统一。以下是主要命令对比：\n\n| **功能**         | **`apt` 命令**     | **`apt-get` / `apt-cache` 命令**       |\n| ---------------- | ------------------ | -------------------------------------- |\n| 更新软件包索引   | `apt update`       | `apt-get update`                       |\n| 升级所有软件包   | `apt upgrade`      | `apt-get upgrade`                      |\n| 全量升级系统     | `apt full-upgrade` | `apt-get dist-upgrade`                 |\n| 安装软件包       | `apt install`      | `apt-get install`                      |\n| 卸载软件包       | `apt remove`       | `apt-get remove`                       |\n| 搜索软件包       | `apt search`       | `apt-cache search`                     |\n| 显示软件包信息   | `apt show`         | `apt-cache show`                       |\n| 清理无用包和缓存 | `apt autoremove`   | `apt-get autoremove` / `apt-get clean` |\n\n---\n\n# **总结**\n\n| **功能分类** | **常用命令**                                 |\n| ------------ | -------------------------------------------- |\n| **更新索引** | `apt update`                                 |\n| **升级软件** | `apt upgrade` / `apt full-upgrade`           |\n| **安装软件** | `apt install <软件包>`                       |\n| **卸载软件** | `apt remove <软件包>` / `apt purge <软件包>` |\n| **搜索软件** | `apt search <关键词>`                        |\n| **查看信息** | `apt show <软件包>`                          |\n| **清理缓存** | `apt clean` / `apt autoremove`               |\n| **修复依赖** | `apt install -f`                             |\n\n通过熟练使用 `apt`，可以轻松管理基于 Debian 的 Linux 系统中的软件包，完成安装、更新、清理等任务。\n","categories":["Linux"]},{"title":"Linux命令详解---ifconfig","url":"/2024/10/08/gfmqsu2l/","content":"\n`ifconfig`（**Interface Configuration**）是一个用于查看和配置网络接口的命令。在 Linux 系统中，`ifconfig` 主要用于显示网络接口的状态信息（例如 IP 地址、子网掩码、广播地址等）以及配置网络接口。\n\n尽管在较新的 Linux 发行版中，`ifconfig` 已逐渐被 `ip` 命令所取代，但它仍然是许多网络工程师和管理员熟悉和使用的命令。\n\n---\n\n# **基本语法**\n\n```bash\nifconfig [网络接口] [选项] [参数]\n```\n\n- **网络接口**：网络设备的名称，例如 `eth0`、`wlan0`、`lo` 等。\n- **选项和参数**：用于配置或查看网络接口的功能。\n\n---\n\n# **查看网络接口信息**\n\n## **查看所有网络接口**\n\n```bash\nifconfig\n```\n\n- **输出示例**：\n\n  ```\n  eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n          inet 192.168.1.10  netmask 255.255.255.0  broadcast 192.168.1.255\n          inet6 fe80::1e5a:3ff:fe42:8c25  prefixlen 64  scopeid 0x20<link>\n          ether 00:1e:5a:42:8c:25  txqueuelen 1000  (Ethernet)\n          RX packets 12345  bytes 9876543 (9.8 MB)\n          RX errors 0  dropped 0  overruns 0  frame 0\n          TX packets 54321  bytes 1234567 (1.2 MB)\n          TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n  lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n          inet 127.0.0.1  netmask 255.0.0.0\n          inet6 ::1  prefixlen 128  scopeid 0x10<host>\n          loop  txqueuelen 1000  (Local Loopback)\n          RX packets 100  bytes 2000 (2.0 KB)\n          TX packets 100  bytes 2000 (2.0 KB)\n  ```\n\n- **字段说明**：\n  - **网络接口名称**（如 `eth0`、`lo`）：表示网络设备名称。\n  - **flags**：接口的状态标志，如 `UP`（接口激活）、`RUNNING`（接口正在运行）。\n  - **inet**：IPv4 地址。\n  - **inet6**：IPv6 地址。\n  - **netmask**：子网掩码。\n  - **broadcast**：广播地址。\n  - **ether**：MAC 地址（物理地址）。\n  - **RX/TX packets**：接收（RX）和发送（TX）数据包的统计信息。\n  - **errors/dropped**：接收和发送过程中发生的错误统计。\n\n---\n\n## **查看指定网络接口**\n\n```bash\nifconfig eth0\n```\n\n- **输出示例**：\n  ```\n  eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n          inet 192.168.1.10  netmask 255.255.255.0  broadcast 192.168.1.255\n          ether 00:1e:5a:42:8c:25  txqueuelen 1000  (Ethernet)\n          RX packets 12345  bytes 9876543 (9.8 MB)\n          TX packets 54321  bytes 1234567 (1.2 MB)\n  ```\n\n- 说明：只显示指定接口（如 `eth0`）的信息。\n\n---\n\n# **配置网络接口**\n\n## **设置 IP 地址**\n\n```bash\nsudo ifconfig eth0 192.168.1.100 netmask 255.255.255.0\n```\n\n- **说明**：\n  - 将接口 `eth0` 的 IP 地址设置为 `192.168.1.100`，子网掩码为 `255.255.255.0`。\n\n---\n\n## **启用网络接口**\n\n```bash\nsudo ifconfig eth0 up\n```\n\n- **说明**：激活网络接口 `eth0`。\n\n---\n\n## **禁用网络接口**\n\n```bash\nsudo ifconfig eth0 down\n```\n\n- **说明**：关闭网络接口 `eth0`。\n\n---\n\n## **设置广播地址**\n\n```bash\nsudo ifconfig eth0 broadcast 192.168.1.255\n```\n\n- **说明**：将 `eth0` 的广播地址设置为 `192.168.1.255`。\n\n---\n\n## **设置 MTU（最大传输单元）**\n\n```bash\nsudo ifconfig eth0 mtu 1400\n```\n\n- **说明**：设置网络接口 `eth0` 的 MTU 值为 `1400`。\n\n---\n\n## **配置别名接口**\n\n通过别名创建虚拟接口（常用于多 IP 绑定）。\n\n```bash\nsudo ifconfig eth0:1 192.168.2.1 netmask 255.255.255.0\n```\n\n- **说明**：为 `eth0` 创建一个别名接口 `eth0:1`，并分配 IP 地址 `192.168.2.1`。\n\n---\n\n# **检测和诊断网络**\n\n## **查看接口流量统计**\n\n接口的接收（RX）和发送（TX）字节数、数据包数量：\n\n```bash\nifconfig eth0\n```\n\n- **字段说明**：\n  - **RX packets**：接收的数据包数量。\n  - **TX packets**：发送的数据包数量。\n  - **bytes**：接收或发送的字节总量。\n  - **errors**：接收或发送过程中遇到的错误。\n  - **dropped**：丢弃的包。\n  - **overruns**：硬件缓存溢出统计。\n\n---\n\n## **清除网络接口的统计信息**\n\n```bash\nsudo ifconfig eth0 -statistics\n```\n\n- **说明**：清除接口的流量统计数据（部分系统可能不支持）。\n\n---\n\n# **替代命令**\n\n在较新的 Linux 系统中，`ifconfig` 已被 `ip` 命令所取代。以下是 `ip` 命令的等效操作：\n\n| **操作**         | **`ifconfig` 命令**           | **`ip` 命令**                                |\n| ---------------- | ----------------------------- | -------------------------------------------- |\n| 查看所有接口信息 | `ifconfig`                    | `ip addr` 或 `ip a`                          |\n| 查看指定接口信息 | `ifconfig eth0`               | `ip addr show dev eth0`                      |\n| 设置 IP 地址     | `ifconfig eth0 192.168.1.100` | `sudo ip addr add 192.168.1.100/24 dev eth0` |\n| 启用网络接口     | `ifconfig eth0 up`            | `sudo ip link set eth0 up`                   |\n| 禁用网络接口     | `ifconfig eth0 down`          | `sudo ip link set eth0 down`                 |\n| 设置 MTU         | `ifconfig eth0 mtu 1400`      | `sudo ip link set dev eth0 mtu 1400`         |\n| 查看接口流量统计 | `ifconfig eth0`               | `ip -s link show dev eth0`                   |\n\n---\n\n# **注意事项**\n\n1. **权限问题**：\n   - 需要超级用户权限（`sudo`）才能配置网络接口。\n   \n2. **替代工具**：\n   - `ifconfig` 已在较新的 Linux 发行版中被标记为过时，建议使用 `ip` 命令。\n   \n3. **安装 `ifconfig`**：\n   - 如果系统中没有安装 `ifconfig`，可以通过以下命令安装：\n     ```bash\n     sudo apt install net-tools    # 在基于 Debian 的系统中\n     sudo yum install net-tools    # 在基于 RHEL 的系统中\n     ```\n\n---\n\n# **总结**\n\n| **功能**         | **命令**                                     |\n| ---------------- | -------------------------------------------- |\n| 查看所有接口信息 | `ifconfig`                                   |\n| 查看指定接口信息 | `ifconfig eth0`                              |\n| 启用接口         | `sudo ifconfig eth0 up`                      |\n| 禁用接口         | `sudo ifconfig eth0 down`                    |\n| 设置 IP 地址     | `sudo ifconfig eth0 192.168.1.100`           |\n| 设置子网掩码     | `sudo ifconfig eth0 netmask 255.255.255.0`   |\n| 设置广播地址     | `sudo ifconfig eth0 broadcast 192.168.1.255` |\n| 设置 MTU         | `sudo ifconfig eth0 mtu 1400`                |\n\n尽管 `ifconfig` 仍然有效，但建议在现代系统中逐渐过渡到 `ip` 命令，以便获得更多功能和更好的支持。\n","categories":["Linux"]},{"title":"Linux命令详解---用户权限相关","url":"/2024/10/08/o85pl50g/","content":"\n在 Linux/Unix 系统中，用户权限管理是非常重要的内容。以下是一些与用户权限相关的常用命令及其功能说明。这些命令主要用于管理用户、组、文件权限和特权操作。\n\n---\n\n# **用户和组管理相关命令**\n\n## **添加用户**\n\n### `useradd`  \n用于添加新用户。\n\n```bash\nsudo useradd 用户名\n```\n\n- **常用选项**：\n  | **选项**       | **说明**                                 |\n  | -------------- | ---------------------------------------- |\n  | `-m`           | 自动为用户创建主目录。                   |\n  | `-s /bin/bash` | 指定用户的默认 Shell，例如 `/bin/bash`。 |\n  | `-G 组名`      | 将用户添加到指定组。                     |\n  | `-u 用户ID`    | 指定用户 ID（UID）。                     |\n\n- **示例**：\n  ```bash\n  sudo useradd -m -s /bin/bash -G sudo alice\n  ```\n\n  - 创建用户 `alice`，并为其分配主目录、默认 Shell 为 `/bin/bash`，同时将其加入 `sudo` 组。\n\n---\n\n## **删除用户**\n\n### `userdel`  \n用于删除用户账户。\n\n```bash\nsudo userdel 用户名\n```\n\n- **常用选项**：\n  | **选项** | **说明**                           |\n  | -------- | ---------------------------------- |\n  | `-r`     | 删除用户的同时删除其主目录和文件。 |\n\n- **示例**：\n  ```bash\n  sudo userdel -r alice\n  ```\n\n  - 删除用户 `alice` 及其主目录。\n\n---\n\n## **修改用户**\n\n### `usermod`  \n用于修改已存在的用户账户。\n\n```bash\nsudo usermod [选项] 用户名\n```\n\n- **常用选项**：\n  | **选项**       | **说明**                                 |\n  | -------------- | ---------------------------------------- |\n  | `-l 新用户名`  | 修改用户名。                             |\n  | `-G 组名`      | 将用户添加到新组（覆盖现有组）。         |\n  | `-aG 组名`     | 将用户追加到一个附加组（不覆盖原有组）。 |\n  | `-s /bin/bash` | 修改用户的默认 Shell。                   |\n  | `-d 目录路径`  | 修改用户主目录。                         |\n\n- **示例**：\n  ```bash\n  sudo usermod -aG docker alice\n  ```\n\n  - 将用户 `alice` 添加到 `docker` 组。\n\n---\n\n## **查看用户信息**\n\n### `id`  \n显示用户的 UID、GID 和用户所属组。\n\n```bash\nid 用户名\n```\n\n- **示例**：\n  ```bash\n  id alice\n  ```\n\n  - **输出**：\n    ```\n    uid=1001(alice) gid=1001(alice) groups=1001(alice),27(sudo)\n    ```\n\n---\n\n### `who`  \n查看当前在线用户。\n\n```bash\nwho\n```\n\n- **输出示例**：\n  ```\n  alice    pts/0        2024-12-09 10:00 (192.168.1.100)\n  ```\n\n---\n\n### `last`  \n显示最近登录的用户列表。\n\n```bash\nlast\n```\n\n- **输出示例**：\n  ```\n  alice    pts/0        192.168.1.100    Mon Dec  9 10:00   still logged in\n  ```\n\n---\n\n## **管理用户组**\n\n### `groupadd`  \n创建新组。\n\n```bash\nsudo groupadd 组名\n```\n\n- **示例**：\n  ```bash\n  sudo groupadd developers\n  ```\n\n---\n\n### `groupdel`  \n删除组。\n\n```bash\nsudo groupdel 组名\n```\n\n- **示例**：\n  ```bash\n  sudo groupdel developers\n  ```\n\n---\n\n### `gpasswd`  \n用于添加或移除用户到组。\n\n```bash\nsudo gpasswd -a 用户名 组名\nsudo gpasswd -d 用户名 组名\n```\n\n- **示例**：\n  ```bash\n  sudo gpasswd -a alice developers\n  sudo gpasswd -d alice developers\n  ```\n\n---\n\n# **文件权限管理相关命令**\n\n## **查看文件权限**\n\n### `ls -l`  \n查看文件的详细信息，包括权限。\n\n```bash\nls -l 文件名\n```\n\n- **输出示例**：\n  ```\n  -rw-r--r-- 1 alice alice 1234 Dec 9 12:34 file.txt\n  ```\n\n  - 权限字段 `-rw-r--r--`：\n    - 第一位：文件类型（`-` 表示普通文件，`d` 表示目录）。\n    - 后 9 位：分为 3 组，每组 3 位，分别表示 **所有者**、**组**、**其他用户** 的权限。\n      - `r`：可读，`w`：可写，`x`：可执行。\n\n---\n\n## **修改文件权限**\n\n### `chmod`  \n修改文件或目录的权限。\n\n```bash\nchmod [权限模式] 文件名\n```\n\n- **权限模式**：\n  - **数字模式**（常用）：\n    - `4`：可读（`r`）。\n    - `2`：可写（`w`）。\n    - `1`：可执行（`x`）。\n    - 通过加和表示权限，例如 `7 = r + w + x`。\n  - **符号模式**：\n    - `u`：用户（所有者），`g`：组，`o`：其他用户。\n    - `+`：添加权限，`-`：移除权限，`=`：设置精确权限。\n\n- **示例**：\n  ```bash\n  chmod 755 file.txt\n  ```\n  - 设置权限为：\n    ```\n    -rwxr-xr-x\n    ```\n\n  ```bash\n  chmod u+w,g-r,o-x file.txt\n  ```\n  - 给用户添加写权限，移除组的读权限，移除其他用户的执行权限。\n\n---\n\n## **修改文件所有者**\n\n### `chown`  \n修改文件或目录的所有者和所属组。\n\n```bash\nsudo chown [所有者][:组] 文件名\n```\n\n- **示例**：\n  ```bash\n  sudo chown alice file.txt\n  sudo chown alice:developers file.txt\n  ```\n\n---\n\n## **修改文件组**\n\n### `chgrp`  \n修改文件的所属组。\n\n```bash\nsudo chgrp 组名 文件名\n```\n\n- **示例**：\n  ```bash\n  sudo chgrp developers file.txt\n  ```\n\n---\n\n# **特权操作相关命令**\n\n## **提权操作**\n\n### `sudo`  \n以超级用户（root）权限执行命令。\n\n```bash\nsudo 命令\n```\n\n- **示例**：\n  ```bash\n  sudo apt update\n  ```\n\n---\n\n## **切换用户**\n\n### `su`  \n切换到其他用户。\n\n```bash\nsu [用户名]\n```\n\n- **示例**：\n  ```bash\n  su alice\n  ```\n\n  - 如果用户名为空，则切换到 `root` 用户。\n\n---\n\n## **临时获取 root 权限**\n\n### `sudo -i` 或 `sudo su`  \n切换到 root 用户环境。\n\n```bash\nsudo -i\n```\n\n- 提示输入当前用户密码后，进入 root 环境。\n\n---\n\n# **权限相关的系统文件**\n\n## **用户信息文件**\n\n### `/etc/passwd`  \n存储所有用户的信息。\n\n```bash\ncat /etc/passwd\n```\n\n- **输出示例**：\n  ```\n  alice:x:1001:1001:Alice:/home/alice:/bin/bash\n  ```\n\n---\n\n## **用户密码文件**\n\n### `/etc/shadow`  \n存储用户密码的加密信息（仅 root 可访问）。\n\n```bash\nsudo cat /etc/shadow\n```\n\n---\n\n## **组信息文件**\n\n### `/etc/group`  \n存储所有组的信息。\n\n```bash\ncat /etc/group\n```\n\n- **输出示例**：\n  ```\n  developers:x:1002:alice\n  ```\n\n---\n\n# **权限管理常见任务总结**\n\n| **任务**         | **命令**                              |\n| ---------------- | ------------------------------------- |\n| 添加用户         | `sudo useradd -m -s /bin/bash 用户名` |\n| 删除用户         | `sudo userdel -r 用户名`              |\n| 添加用户到组     | `sudo usermod -aG 组名 用户名`        |\n| 修改文件权限     | `chmod 755 文件名`                    |\n| 修改文件所有者   | `sudo chown 用户名 文件名`            |\n| 查看用户所属组   | `id 用户名`                           |\n| 切换到其他用户   | `su 用户名`                           |\n| 提升到 root 权限 | `sudo -i` 或 `sudo su`                |\n\n通过这些命令，可以灵活管理 Linux 系统中的用户、组和权限！\n","categories":["Linux"]},{"title":"Linux命令详解---ln","url":"/2024/10/08/crbm8mfk/","content":"\n`ln` 是 Linux 和 Unix 系统中用于**创建链接文件**的命令。链接文件分为两种类型：\n\n1. **硬链接（Hard Link）**：指向文件数据本身，链接与原文件共享相同的 inode。\n2. **符号链接（Symbolic Link）**：类似于 Windows 中的快捷方式，指向原文件的路径，而不是文件数据。\n\n---\n\n# **`ln` 命令的基本语法**\n\n```bash\nln [选项] 源文件 目标文件\n```\n\n## 参数说明：\n\n- **源文件**：需要创建链接的原文件或目录。\n- **目标文件**：链接文件的名称或路径。\n- **选项**：\n  - `-s`：创建符号链接（软链接）。\n  - `-f`：强制删除已有的目标链接文件。\n  - `-v`：显示详细信息。\n  - `-n`：在符号链接上创建新的符号链接（而不是覆盖符号链接指向的文件）。\n  - `-i`：在覆盖目标文件时提示用户确认。\n  - `-T`：将目标始终作为文件（强制不将目标视为目录）。\n\n---\n\n# **硬链接（Hard Link）**\n\n硬链接是指向同一个文件数据块的多个文件名。这些文件共享相同的 **inode**，因此它们是完全等价的。\n\n## **硬链接的特点：**\n- 硬链接与原文件共享相同的文件数据和 inode。\n- 删除硬链接或原文件不会影响文件数据，只有当所有的硬链接都删除后，数据才会被释放。\n- 硬链接只能在同一个文件系统中创建，不能跨分区。\n\n## **创建硬链接**\n\n```bash\nln 源文件 硬链接文件\n```\n\n- **示例：**\n\n```bash\nln file1 hardlink1\n```\n\n- 查看硬链接和 inode 信息：\n\n```bash\nls -li\n```\n\n**示例输出：**\n```plaintext\n123456 -rw-r--r-- 2 user group  1234 Dec 9 10:10 file1\n123456 -rw-r--r-- 2 user group  1234 Dec 9 10:10 hardlink1\n```\n\n- **说明：**\n  - `123456` 是 inode 号，`file1` 和 `hardlink1` 的 inode 相同。\n  - 硬链接文件数量为 `2`，表示文件有两个硬链接。\n\n---\n\n# **符号链接（Symbolic Link）**\n\n符号链接（软链接）是一个指向目标文件路径的快捷方式，它与原文件有独立的 inode。\n\n## **符号链接的特点：**\n- 符号链接是一个独立的文件，内容仅是指向目标文件的路径。\n- 如果原文件被删除，符号链接会变为“断开的链接”（Broken Link），无法访问。\n- 符号链接可以跨文件系统或分区创建。\n\n## **创建符号链接**\n\n```bash\nln -s 源文件 符号链接文件\n```\n\n- **示例：**\n\n```bash\nln -s file1 symlink1\n```\n\n- 查看符号链接信息：\n\n```bash\nls -l\n```\n\n**示例输出：**\n```plaintext\nlrwxrwxrwx 1 user group    5 Dec 9 10:10 symlink1 -> file1\n```\n\n- **说明：**\n  - `l` 表示这是一个符号链接。\n  - `symlink1 -> file1` 表示 `symlink1` 指向 `file1`。\n\n---\n\n# **删除链接**\n\n- 删除硬链接或符号链接时，直接使用 `rm` 命令：\n  ```bash\n  rm 链接文件\n  ```\n\n- 删除链接不会删除原文件（除非原文件本身也被删除）。\n\n---\n\n# **目录链接**\n\n## **为目录创建符号链接**\n\n```bash\nln -s 源目录 符号链接目录\n```\n\n- **示例：**\n\n```bash\nln -s /var/log mylog\n```\n\n- 查看符号链接目录：\n  ```bash\n  ls -l\n  ```\n\n**示例输出：**\n```plaintext\nlrwxrwxrwx 1 user group    8 Dec 9 10:10 mylog -> /var/log\n```\n\n- 说明：`mylog` 是指向 `/var/log` 的符号链接。\n\n## **硬链接不能直接用于目录**\n硬链接默认不能用于目录，因为这会破坏文件系统的结构（防止循环引用）。如果确实需要对目录创建硬链接，可以使用 `cp` 命令或高级工具（如 `rsync`）。\n\n---\n\n# **强制覆盖目标链接**\n\n如果目标链接文件已存在，可以使用 `-f` 选项强制覆盖：\n\n```bash\nln -sf 源文件 符号链接文件\n```\n\n- **示例：**\n\n```bash\nln -sf file2 symlink1\n```\n\n- 说明：将 `symlink1` 强制指向新的文件 `file2`。\n\n---\n\n# **常见用法示例**\n\n## **创建硬链接**\n\n```bash\nln file1 hardlink1\n```\n\n- 创建一个硬链接 `hardlink1`，与 `file1` 共享同一个文件数据。\n\n---\n\n## **创建符号链接**\n\n```bash\nln -s file1 symlink1\n```\n\n- 创建一个符号链接 `symlink1`，指向 `file1`。\n\n---\n\n## **为目录创建符号链接**\n\n```bash\nln -s /usr/local/bin mybin\n```\n\n- 将 `/usr/local/bin` 目录链接到当前目录下的 `mybin`。\n\n---\n\n## **强制覆盖符号链接**\n\n```bash\nln -sf file2 symlink1\n```\n\n- 强制将 `symlink1` 指向 `file2`（即使 `symlink1` 已存在）。\n\n---\n\n## **跨分区创建链接**\n\n- **硬链接**不能跨分区：\n  ```bash\n  ln /mnt/file1 /tmp/hardlink1\n  ```\n\n  **错误：**\n  ```plaintext\n  ln: failed to create hard link '/tmp/hardlink1': Invalid cross-device link\n  ```\n\n- **符号链接**可以跨分区：\n  ```bash\n  ln -s /mnt/file1 /tmp/symlink1\n  ```\n\n---\n\n# **硬链接与符号链接的区别**\n\n| **特性**           | **硬链接**                           | **符号链接**                       |\n| ------------------ | ------------------------------------ | ---------------------------------- |\n| **链接方式**       | 指向文件数据块，直接共享 inode       | 指向文件路径                       |\n| **文件系统**       | 必须在同一个文件系统内               | 可以跨文件系统或分区               |\n| **删除源文件**     | 不影响硬链接文件，文件数据仍然存在   | 符号链接会变为断开的链接，无法访问 |\n| **支持目录**       | 默认不支持目录硬链接（防止循环引用） | 支持目录符号链接                   |\n| **inode 是否相同** | 相同                                 | 不同                               |\n\n---\n\n# **查看链接信息**\n\n- 使用 `ls -li` 查看文件 inode 信息：\n\n```bash\nls -li\n```\n\n- 示例输出：\n  ```plaintext\n  123456 -rw-r--r-- 2 user group 1234 Dec 9 10:10 file1\n  123456 -rw-r--r-- 2 user group 1234 Dec 9 10:10 hardlink1\n  789012 lrwxrwxrwx 1 user group   5 Dec 9 10:10 symlink1 -> file1\n  ```\n\n  - `file1` 和 `hardlink1` 的 inode 相同，表示它们是硬链接。\n  - `symlink1` 的 inode 不同，且 `-> file1` 表示它是一个符号链接。\n\n---\n\n# **总结**\n\n- **硬链接**（`ln`）：`ln 源文件 硬链接文件`\n- **符号链接**（`ln -s`）：`ln -s 源文件 符号链接文件`\n- **常用选项**：\n  - `-s`：创建符号链接。\n  - `-f`：强制覆盖目标链接。\n  - `-v`：显示详细信息。\n- **硬链接特点**：\n  - 同一个文件的多个名字，共享 inode。\n  - 不能跨分区创建。\n- **符号链接特点**：\n  - 独立文件，指向原文件路径。\n  - 可以跨分区，也可以指向目录。\n\n熟练使用 `ln` 命令，可以高效地管理文件链接和目录结构。\n","categories":["Linux"]},{"title":"Linux命令详解---bash脚本语法","url":"/2024/10/08/fqhsjsca/","content":"\nBash 脚本是一种用于自动化任务、管理系统和运行命令的强大工具。以下是 Bash 脚本的基本语法、结构和常用功能的详细介绍。\n\n---\n\n# **Bash 脚本的基本结构**\n\n## **脚本文件的格式**\n\n- **文件开头指定解释器**：使用 `#!/bin/bash` 告诉系统脚本应该由 Bash 解释器执行。\n\n```bash\n#!/bin/bash\n# 这是一个简单的 Bash 脚本\necho \"Hello, World!\"\n```\n\n- **保存文件**：将文件保存为 `.sh` 后缀，例如 `script.sh`。\n- **赋予执行权限**：\n\n```bash\nchmod +x script.sh\n```\n\n- **运行脚本**：\n\n```bash\n./script.sh\n```\n\n---\n\n## **注释**\n\n- 单行注释：用 `#` 开头。\n\n```bash\n# 这是一个注释\necho \"这是一条命令\"\n```\n\n- 多行注释：一般用 `<<COMMENT` 和 `COMMENT`。\n\n```bash\n: <<'COMMENT'\n这是多行注释\n可以写多行内容\nCOMMENT\n```\n\n---\n\n## **变量**\n\n### **定义变量**\n\n- 定义变量时，中间**不能有空格**。\n\n```bash\nname=\"Alice\"\nage=25\n```\n\n### **使用变量**\n\n- 使用变量时需要加 `$`。\n\n```bash\necho \"Name: $name\"\necho \"Age: $age\"\n```\n\n### **读取用户输入**\n\n```bash\nread -p \"Enter your name: \" user_name\necho \"Hello, $user_name!\"\n```\n\n### **环境变量**\n\n- 访问系统环境变量，例如：\n\n```bash\necho \"Home directory: $HOME\"\necho \"Shell: $SHELL\"\n```\n\n---\n\n## **条件判断**\n\n### **if-else 语法**\n\n```bash\nif [ 条件 ]; then\n    # 条件为真时执行\n    echo \"条件为真\"\nelse\n    # 条件为假时执行\n    echo \"条件为假\"\nfi\n```\n\n- **示例**：\n\n```bash\n#!/bin/bash\nread -p \"输入一个数: \" num\nif [ $num -gt 10 ]; then\n    echo \"数值大于 10\"\nelse\n    echo \"数值小于或等于 10\"\nfi\n```\n\n---\n\n## **循环**\n\n### **for 循环**\n\n```bash\nfor i in 1 2 3 4 5; do\n    echo \"数字: $i\"\ndone\n```\n\n- **遍历文件**：\n\n```bash\nfor file in *.sh; do\n    echo \"文件: $file\"\ndone\n```\n\n---\n\n### **while 循环**\n\n```bash\ncount=1\nwhile [ $count -le 5 ]; do\n    echo \"计数: $count\"\n    count=$((count + 1))\ndone\n```\n\n---\n\n### **until 循环**\n\n```bash\ncount=1\nuntil [ $count -gt 5 ]; do\n    echo \"计数: $count\"\n    count=$((count + 1))\ndone\n```\n\n---\n\n## **函数**\n\n### **定义和调用函数**\n\n```bash\nfunction greet() {\n    echo \"Hello, $1!\"\n}\n\ngreet \"Alice\"  # 调用函数并传递参数\n```\n\n- **带返回值的函数**：\n\n```bash\nfunction add() {\n    result=$(( $1 + $2 ))\n    echo $result\n}\n\nsum=$(add 5 10)\necho \"结果是: $sum\"\n```\n\n---\n\n## **文件操作**\n\n### **检查文件或目录**\n\n```bash\nfile=\"test.txt\"\nif [ -f \"$file\" ]; then\n    echo \"$file 是一个文件\"\nelif [ -d \"$file\" ]; then\n    echo \"$file 是一个目录\"\nelse\n    echo \"$file 不存在\"\nfi\n```\n\n- 常用的文件测试符：\n  | **测试符** | **描述**       |\n  | ---------- | -------------- |\n  | `-f`       | 是否为普通文件 |\n  | `-d`       | 是否为目录     |\n  | `-e`       | 是否存在       |\n  | `-r`       | 是否可读       |\n  | `-w`       | 是否可写       |\n  | `-x`       | 是否可执行     |\n\n---\n\n### **读取文件内容**\n\n```bash\nfile=\"test.txt\"\nwhile read line; do\n    echo $line\ndone < \"$file\"\n```\n\n---\n\n### **重定向输出**\n\n- **输出到文件**：\n\n```bash\necho \"Hello, World!\" > output.txt\n```\n\n- **追加到文件**：\n\n```bash\necho \"追加内容\" >> output.txt\n```\n\n---\n\n## **运算**\n\n### **整数运算**\n\n- 使用 `$((表达式))` 进行整数运算：\n\n```bash\na=10\nb=5\nsum=$((a + b))\necho \"Sum: $sum\"\n```\n\n### **浮点运算**\n\n- 使用 `bc` 进行小数运算：\n\n```bash\nresult=$(echo \"scale=2; 10 / 3\" | bc)\necho \"结果: $result\"\n```\n\n---\n\n## **数组**\n\n### **定义数组**\n\n```bash\narr=(\"apple\" \"banana\" \"cherry\")\n```\n\n### **访问数组元素**\n\n```bash\necho ${arr[0]}  # 输出第一个元素\n```\n\n### **获取数组长度**\n\n```bash\necho ${#arr[@]}\n```\n\n### **遍历数组**\n\n```bash\nfor item in \"${arr[@]}\"; do\n    echo $item\ndone\n```\n\n---\n\n## **高级功能**\n\n### **参数传递**\n\n- 脚本可以通过命令行参数接收输入。\n\n```bash\n#!/bin/bash\necho \"第一个参数: $1\"\necho \"第二个参数: $2\"\necho \"所有参数: $@\"\necho \"参数个数: $#\"\n```\n\n- **运行脚本**：\n\n```bash\n./script.sh arg1 arg2\n```\n\n---\n\n### **条件表达式**\n\n- **数值比较**：\n\n  | **运算符** | **描述** |\n  | ---------- | -------- |\n  | `-eq`      | 等于     |\n  | `-ne`      | 不等于   |\n  | `-gt`      | 大于     |\n  | `-lt`      | 小于     |\n  | `-ge`      | 大于等于 |\n  | `-le`      | 小于等于 |\n\n- **字符串比较**：\n\n  | **运算符** | **描述**       |\n  | ---------- | -------------- |\n  | `=`        | 等于           |\n  | `!=`       | 不等于         |\n  | `-z`       | 字符串是否为空 |\n  | `-n`       | 字符串是否非空 |\n\n---\n\n### **捕获命令执行结果**\n\n- 使用反引号 `` 或 `$()` 捕获命令输出：\n\n```bash\ncurrent_date=$(date)\necho \"当前时间: $current_date\"\n```\n\n---\n\n## **示例脚本**\n\n### **备份脚本**\n\n```bash\n#!/bin/bash\nbackup_dir=\"/backup\"\nsrc_dir=\"/home/user\"\ntimestamp=$(date \"+%Y%m%d_%H%M%S\")\n\nmkdir -p $backup_dir\ntar -czf $backup_dir/backup_$timestamp.tar.gz $src_dir\n\necho \"备份完成: $backup_dir/backup_$timestamp.tar.gz\"\n```\n\n### **检测服务运行状态**\n\n```bash\n#!/bin/bash\nservice=\"nginx\"\n\nif systemctl is-active --quiet $service; then\n    echo \"$service 正在运行\"\nelse\n    echo \"$service 未运行，尝试启动...\"\n    sudo systemctl start $service\nfi\n```\n\n---\n\n通过掌握这些 Bash 脚本语法和功能，您可以轻松编写脚本来自动化日常任务或实现复杂的系统管理功能！\n","categories":["Linux"]},{"title":"Linux命令详解---grep","url":"/2024/10/08/fdkyicqe/","content":"\n`grep` 是 Linux 和类 Unix 操作系统中一个强大的文本搜索工具，用于在文件或标准输入中查找与指定模式匹配的行。它支持正则表达式，可以快速定位文件中的特定内容。\n\n以下是对 `grep` 命令的详细介绍，包括基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\ngrep [选项] \"搜索模式\" [文件...]\n```\n\n- **搜索模式**：指定要查找的文本模式（可以是字符串或正则表达式）。\n- **文件**：要搜索的文件，可以是一个或多个文件。如果不指定文件，则从标准输入（`stdin`）读取数据。\n- **选项**：控制搜索行为，例如忽略大小写、递归搜索、显示行号等。\n\n---\n\n# **常用选项**\n\n| 选项            | 功能                                                         |\n| --------------- | ------------------------------------------------------------ |\n| `-i`            | 忽略大小写匹配。                                             |\n| `-v`            | 反向匹配，显示不符合模式的行。                               |\n| `-r` 或 `-R`    | 递归搜索目录中的所有文件。                                   |\n| `-n`            | 显示匹配行的行号。                                           |\n| `-c`            | 仅显示匹配的行数。                                           |\n| `-l`            | 仅显示包含匹配内容的文件名。                                 |\n| `-L`            | 仅显示不包含匹配内容的文件名。                               |\n| `-o`            | 仅显示匹配的内容（而非整行）。                               |\n| `-w`            | 匹配整个单词。                                               |\n| `-x`            | 匹配整行。                                                   |\n| `-A [行数]`     | 显示匹配行及其后面指定的行数。                               |\n| `-B [行数]`     | 显示匹配行及其前面指定的行数。                               |\n| `-C [行数]`     | 显示匹配行及其前后指定的行数（等价于 `-A` 和 `-B` 的组合）。 |\n| `--color`       | 高亮显示匹配的内容（通常默认启用）。                         |\n| `--include`     | 只搜索匹配的文件类型（如 `--include=\"*.txt\"`）。             |\n| `--exclude`     | 排除特定文件类型（如 `--exclude=\"*.log\"`）。                 |\n| `--exclude-dir` | 排除特定目录（如 `--exclude-dir=\"backup\"`）。                |\n\n---\n\n# **详解选项和示例**\n\n## 基本匹配**\n\n- 在文件中搜索包含 \"pattern\" 的行：\n  ```bash\n  grep \"pattern\" file.txt\n  ```\n\n- 示例：\n  如果 `file.txt` 内容为：\n  ```\n  hello world\n  grep is powerful\n  pattern matching\n  ```\n  输出：\n  ```\n  pattern matching\n  ```\n\n---\n\n## **忽略大小写（`-i`）**\n\n- 忽略大小写匹配：\n  ```bash\n  grep -i \"pattern\" file.txt\n  ```\n\n---\n\n## **反向匹配（`-v`）**\n\n- 显示不包含 \"pattern\" 的行：\n  ```bash\n  grep -v \"pattern\" file.txt\n  ```\n\n---\n\n## **递归搜索（`-r` 或 `-R`）**\n\n- 在当前目录及其子目录中递归搜索 \"pattern\"：\n  ```bash\n  grep -r \"pattern\" .\n  ```\n\n---\n\n## **显示行号（`-n`）**\n\n- 显示匹配行及其行号：\n  ```bash\n  grep -n \"pattern\" file.txt\n  ```\n\n- 输出示例：\n  ```\n  3:pattern matching\n  ```\n\n---\n\n## **仅显示匹配文件名（`-l`）**\n\n- 查找包含 \"pattern\" 的文件，仅显示文件名：\n  ```bash\n  grep -l \"pattern\" *.txt\n  ```\n\n---\n\n## **统计匹配行数（`-c`）**\n\n- 显示文件中匹配的行数：\n  ```bash\n  grep -c \"pattern\" file.txt\n  ```\n\n---\n\n## **仅显示匹配内容（`-o`）**\n\n- 仅显示匹配的部分，而不是整行：\n  ```bash\n  grep -o \"pattern\" file.txt\n  ```\n\n---\n\n## **匹配整个单词（`-w`）**\n\n- 仅匹配独立的 \"pattern\" 单词（避免匹配部分单词）：\n  ```bash\n  grep -w \"pattern\" file.txt\n  ```\n\n---\n\n## **匹配整行（`-x`）**\n\n- 仅匹配整行与 \"pattern\" 完全一致的行：\n  ```bash\n  grep -x \"pattern\" file.txt\n  ```\n\n---\n\n## **显示上下文行（`-A`、`-B`、`-C`）**\n\n- 显示匹配行及其后 2 行（`-A`）：\n  ```bash\n  grep -A 2 \"pattern\" file.txt\n  ```\n\n- 显示匹配行及其前 2 行（`-B`）：\n  ```bash\n  grep -B 2 \"pattern\" file.txt\n  ```\n\n- 显示匹配行及其前后 2 行（`-C`）：\n  ```bash\n  grep -C 2 \"pattern\" file.txt\n  ```\n\n---\n\n## **排除特定文件或目录**\n\n- 排除特定文件类型：\n  ```bash\n  grep -r --exclude=\"*.log\" \"pattern\" .\n  ```\n\n- 排除特定目录：\n  ```bash\n  grep -r --exclude-dir=\"backup\" \"pattern\" .\n  ```\n\n---\n\n## **结合正则表达式**\n\n### 匹配以 \"start\" 开头的行：\n```bash\ngrep \"^start\" file.txt\n```\n\n### 匹配以 \"end\" 结尾的行：\n```bash\ngrep \"end$\" file.txt\n```\n\n### 匹配包含数字的行：\n```bash\ngrep \"[0-9]\" file.txt\n```\n\n### 匹配包含 \"error\" 或 \"fail\" 的行：\n```bash\ngrep -E \"error|fail\" file.txt\n```\n\n---\n\n# **grep 的扩展版本**\n\n## **`egrep` 和 `fgrep`**\n- `egrep` 等价于 `grep -E`，支持扩展正则表达式。\n- `fgrep` 等价于 `grep -F`，不支持正则表达式，仅匹配固定字符串。\n\n---\n\n# **综合示例**\n\n## **在所有 `.log` 文件中查找 \"error\" 并显示行号**\n\n```bash\ngrep -n \"error\" *.log\n```\n\n---\n\n## **递归查找包含 \"TODO\" 的文件，排除 `backup` 目录**\n\n```bash\ngrep -r --exclude-dir=\"backup\" \"TODO\" .\n```\n\n---\n\n## **查找包含 \"https://\" 的行，并仅显示匹配内容**\n\n```bash\ngrep -o \"https://[a-zA-Z0-9./?=_-]*\" file.txt\n```\n\n---\n\n## **在文件中查找错误日志（不区分大小写）并显示上下文 3 行**\n\n```bash\ngrep -i -C 3 \"error\" system.log\n```\n\n---\n\n## **查找某用户的所有进程**\n\n结合 `ps` 使用：\n```bash\nps aux | grep \"username\"\n```\n\n---\n\n## **统计文件中出现某单词的次数**\n\n```bash\ngrep -o \"word\" file.txt | wc -l\n```\n\n---\n\n## **查找大写开头的单词**\n\n```bash\ngrep -o \"\\b[A-Z][a-z]*\\b\" file.txt\n```\n\n---\n\n# **总结**\n\n- **`grep` 是 Linux 中最常用的文本处理工具之一，适用于从文件或输出中快速搜索指定内容。**\n- **通过选项（如 `-i`、`-v`、`-r`）和正则表达式，可以实现灵活高效的内容过滤。**\n- 使用时要注意正则表达式的语法，以及结合 `grep` 的扩展功能（如 `--exclude` 和 `--include`）以优化搜索效率。\n","categories":["Linux"]},{"title":"Linux命令详解---系统信息相关","url":"/2024/10/08/xiou2s43/","content":"\n在 Linux 和类 Unix 系统中，有许多命令可以用来查看和监控操作系统的基本信息、硬件配置和运行状态。这些命令通常用于系统管理、故障排查和性能优化。\n\n---\n\n# **系统信息相关命令分类**\n\n## **操作系统和内核信息**\n\n这些命令用于查看操作系统的版本、内核版本和主机名等信息。\n\n| **命令**              | **功能**                                                  |\n| --------------------- | --------------------------------------------------------- |\n| `uname`               | 显示系统名称和内核信息。                                  |\n| `hostname`            | 显示或设置主机名。                                        |\n| `cat /etc/os-release` | 查看操作系统名称和版本（适用于大多数现代 Linux 发行版）。 |\n| `lsb_release`         | 显示发行版信息（需要安装 `lsb-core`）。                   |\n| `uptime`              | 查看系统连续运行时间、当前用户数、平均负载。              |\n| `dmesg`               | 查看系统启动日志（内核环缓冲区日志）。                    |\n\n### **示例用法**\n\n- **查看内核版本：**\n  ```bash\n  uname -r\n  ```\n\n- **查看操作系统名称和版本：**\n  ```bash\n  cat /etc/os-release\n  ```\n\n  **示例输出：**\n  ```plaintext\n  NAME=\"Ubuntu\"\n  VERSION=\"20.04.6 LTS (Focal Fossa)\"\n  ID=ubuntu\n  ```\n\n- **查看主机名：**\n  ```bash\n  hostname\n  ```\n\n---\n\n## **CPU 信息**\n\n| **命令**            | **功能**                                          |\n| ------------------- | ------------------------------------------------- |\n| `lscpu`             | 显示 CPU 体系结构信息（内核数、线程数、频率等）。 |\n| `cat /proc/cpuinfo` | 查看详细的 CPU 信息。                             |\n| `nproc`             | 显示当前系统的可用 CPU 核心数量。                 |\n| `mpstat`            | 显示 CPU 使用情况（需要安装 `sysstat`）。         |\n\n### **示例用法**\n\n- **查看 CPU 的详细信息：**\n  ```bash\n  cat /proc/cpuinfo\n  ```\n\n- **查看 CPU 核心数量：**\n  ```bash\n  lscpu\n  ```\n\n  **示例输出：**\n  ```plaintext\n  Architecture:        x86_64\n  CPU(s):              8\n  Model name:          Intel(R) Core(TM) i7-9750H\n  ```\n\n---\n\n## **内存信息**\n\n| **命令**            | **功能**                                    |\n| ------------------- | ------------------------------------------- |\n| `free`              | 查看系统内存和交换分区的使用情况。          |\n| `vmstat`            | 显示虚拟内存统计信息（需要安装 `procps`）。 |\n| `cat /proc/meminfo` | 查看详细的内存信息。                        |\n\n### **示例用法**\n\n- **查看内存使用情况：**\n  ```bash\n  free -h\n  ```\n\n  **示例输出：**\n  ```plaintext\n                total        used        free      shared  buff/cache   available\n  Mem:           16G         8G         4G         512M         4G         7G\n  Swap:           2G         1G         1G\n  ```\n\n- **查看详细内存信息：**\n  ```bash\n  cat /proc/meminfo\n  ```\n\n---\n\n## **磁盘和文件系统信息**\n\n| **命令**               | **功能**                                      |\n| ---------------------- | --------------------------------------------- |\n| `df`                   | 查看文件系统的磁盘使用情况。                  |\n| `du`                   | 查看指定目录或文件占用的磁盘空间。            |\n| `lsblk`                | 查看磁盘分区和挂载点信息。                    |\n| `blkid`                | 查看分区的 UUID 和文件系统类型。              |\n| `mount`                | 查看当前挂载的文件系统。                      |\n| `cat /proc/partitions` | 查看所有磁盘分区信息。                        |\n| `iostat`               | 显示磁盘 I/O 使用情况（需要安装 `sysstat`）。 |\n\n### **示例用法**\n\n- **查看磁盘使用情况：**\n  ```bash\n  df -h\n  ```\n\n  **示例输出：**\n  ```plaintext\n  Filesystem      Size  Used Avail Use% Mounted on\n  /dev/sda1        50G   20G   30G  40% /\n  /dev/sdb1       500G  300G  200G  60% /mnt/data\n  ```\n\n- **查看分区信息：**\n  ```bash\n  lsblk\n  ```\n\n  **示例输出：**\n  ```plaintext\n  NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n  sda      8:0    0   50G  0 disk\n  └─sda1   8:1    0   50G  0 part /\n  sdb      8:16   0  500G  0 disk\n  └─sdb1   8:17   0  500G  0 part /mnt/data\n  ```\n\n---\n\n## **网络信息**\n\n| **命令**            | **功能**                                                  |\n| ------------------- | --------------------------------------------------------- |\n| `ip`                | 查看和配置网络接口信息（推荐替代 `ifconfig`）。           |\n| `ifconfig`          | 查看网络接口信息（较旧的工具，现已被 `ip` 替代）。        |\n| `ping`              | 测试与目标主机的网络连通性。                              |\n| `netstat`           | 显示网络连接、路由表和端口信息（较旧，推荐替代为 `ss`）。 |\n| `ss`                | 显示网络连接状态（推荐替代 `netstat`）。                  |\n| `traceroute`        | 跟踪数据包到目标主机的路径。                              |\n| `nslookup` 或 `dig` | 查询域名的 DNS 信息。                                     |\n\n### **示例用法**\n\n- **查看网络接口信息：**\n  ```bash\n  ip addr\n  ```\n\n- **测试与目标主机的连通性：**\n  ```bash\n  ping 8.8.8.8\n  ```\n\n- **查看网络连接状态：**\n  ```bash\n  ss -tuln\n  ```\n\n  **示例输出：**\n  ```plaintext\n  State     Recv-Q    Send-Q      Local Address:Port      Peer Address:Port\n  LISTEN    0         128        127.0.0.1:3306          *:*\n  LISTEN    0         128        *:22                    *:*\n  ```\n\n---\n\n## **运行时统计信息**\n\n| **命令** | **功能**                                             |\n| -------- | ---------------------------------------------------- |\n| `top`    | 实时显示系统当前的运行状态（包括 CPU、内存、任务）。 |\n| `htop`   | 类似于 `top`，但提供更友好的界面（需要安装）。       |\n| `vmstat` | 显示系统性能（CPU、内存、IO 等）的统计信息。         |\n| `iostat` | 显示 CPU 和磁盘 I/O 使用情况（需要安装 `sysstat`）。 |\n| `sar`    | 系统性能监控工具（需要安装 `sysstat`）。             |\n\n### **示例用法**\n\n- **实时查看系统状态：**\n  ```bash\n  top\n  ```\n\n- **详细分析系统性能：**\n  ```bash\n  vmstat 2 5\n  ```\n\n  **示例输出：**\n  ```plaintext\n  procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----\n   r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa\n   1  0      0  80000  40000 200000    0    0     1     2   50  200   1   0  98   1\n  ```\n\n---\n\n## **硬件信息**\n\n| **命令**    | **功能**                                      |\n| ----------- | --------------------------------------------- |\n| `lspci`     | 列出所有 PCI 设备信息（如显卡、网卡）。       |\n| `lsusb`     | 列出所有 USB 设备信息。                       |\n| `dmidecode` | 查看硬件的详细信息（如 BIOS、内存、CPU 等）。 |\n| `hwinfo`    | 显示硬件信息（可能需要安装）。                |\n| `inxi`      | 简单易读的硬件信息工具（需要安装）。          |\n\n### **示例用法**\n\n- **列出 PCI 设备：**\n  ```bash\n  lspci\n  ```\n\n  **示例输出：**\n  ```plaintext\n  00:00.0 Host bridge: Intel Corporation Device 3e10 (rev 07)\n  00:02.0 VGA compatible controller: Intel Corporation UHD Graphics 630 (rev 02)\n  ```\n\n- **列出 USB 设备：**\n  ```bash\n  lsusb\n  ```\n\n- **查看 CPU、内存、BIOS 信息：**\n  ```bash\n  sudo dmidecode\n  ```\n\n---\n\n## **日志信息**\n\n| **命令**                | **功能**                             |\n| ----------------------- | ------------------------------------ |\n| `journalctl`            | 查看系统日志（适用于 systemd）。     |\n| `dmesg`                 | 查看内核日志，用于诊断硬件问题。     |\n| `cat /var/log/syslog`   | 查看系统日志（传统日志文件）。       |\n| `cat /var/log/messages` | 查看系统消息日志（某些发行版使用）。 |\n\n### **示例用法**\n\n- **查看最新的系统日志：**\n  ```bash\n  journalctl -xe\n  ```\n\n- **查看特定服务的日志：**\n  ```bash\n  journalctl -u sshd\n  ```\n\n---\n\n## **总结**\n\n| **功能分类** | **常用命令**                                              |\n| ------------ | --------------------------------------------------------- |\n| 操作系统信息 | `uname`, `hostname`, `cat /etc/os-release`, `lsb_release` |\n| CPU 信息     | `lscpu`, `cat /proc/cpuinfo`, `nproc`                     |\n| 内存信息     | `free`, `cat /proc/meminfo`, `vmstat`                     |\n| 磁盘信息     | `df`, `du`, `lsblk`, `blkid`                              |\n| 网络信息     | `ip`, `ifconfig`, `ss`, `ping`, `traceroute`              |\n| 运行时统计   | `top`, `htop`, `vmstat`, `iostat`                         |\n| 硬件信息     | `lspci`, `lsusb`, `dmidecode`, `hwinfo`                   |\n| 日志信息     | `journalctl`, `dmesg`, `/var/log/syslog`                  |\n\n熟练使用这些命令可以帮助有效地管理和监控 Linux 系统的运行状态。\n","categories":["Linux"]},{"title":"Linux命令详解---命令帮助信息","url":"/2024/10/08/w7hzn2bs/","content":"\n在 Linux/Unix 系统中，获取命令的帮助信息是常见的需求。以下是几种常用的方法，用于查看命令的帮助文档、参数说明和相关使用信息。\n\n---\n\n# **使用 `--help`**\n\n几乎所有命令都支持 `--help` 选项，用于简要地显示命令的使用方法和参数说明。\n\n```bash\n命令 --help\n```\n\n- **示例**：\n\n```bash\nls --help\n```\n\n- 输出：显示 `ls` 命令的所有选项及其功能。\n\n- **适用场景**：快速查看命令的基本用法和选项。\n\n---\n\n# **使用 `man`（手册页）**\n`man` 命令用于查看命令的详细手册页，包括用法、参数、描述等。\n\n```bash\nman 命令\n```\n\n- **示例**：\n\n```bash\nman ls\n```\n\n- 输出：显示 `ls` 命令的完整手册页。\n\n## **`man` 的快捷键操作**\n| **快捷键** | **作用**                 |\n| ---------- | ------------------------ |\n| `Space`    | 向下翻页。               |\n| `b`        | 向上翻页。               |\n| `q`        | 退出手册页。             |\n| `/关键词`  | 搜索关键字。             |\n| `n`        | 跳到下一个匹配的关键字。 |\n| `Shift+n`  | 跳到上一个匹配的关键字。 |\n\n- **适用场景**：需要更详细的命令信息时。\n\n---\n\n# **使用 `info`**\n`info` 命令提供类似于 `man` 的文档，但通常包含更详细的说明和结构化的内容。\n\n```bash\ninfo 命令\n```\n\n- **示例**：\n\n```bash\ninfo ls\n```\n\n- 输出：显示 `ls` 命令的详细信息，通常比 `man` 更详细。\n\n## **`info` 的快捷键操作**\n| **快捷键** | **作用**       |\n| ---------- | -------------- |\n| `Space`    | 向下翻页。     |\n| `b`        | 向上翻页。     |\n| `q`        | 退出文档。     |\n| `n`        | 跳到下一节点。 |\n| `p`        | 跳到上一节点。 |\n\n- **适用场景**：需要更深入的命令文档时。\n\n---\n\n# **使用 `help`（Shell 内置命令）**\n对于 Shell 内置命令（如 `cd`、`echo`），可以使用 `help` 显示它们的帮助信息。\n\n```bash\nhelp 命令\n```\n\n- **示例**：\n\n```bash\nhelp cd\n```\n\n- 输出：显示 `cd` 命令的内置帮助信息。\n\n- **适用场景**：查看 Shell 内置命令的帮助信息。\n\n---\n\n# **查看命令位置与手册页**\n## **使用 `which`**\n`which` 命令用于查看命令的实际路径，以区分外部命令和内置命令。\n\n```bash\nwhich 命令\n```\n\n- **示例**：\n\n```bash\nwhich ls\n```\n\n- 输出：显示 `ls` 的实际路径，如 `/bin/ls`。\n\n---\n\n## **使用 `type`**\n`type` 命令用于查看命令是外部命令还是内置命令。\n\n```bash\ntype 命令\n```\n\n- **示例**：\n\n```bash\ntype cd\n```\n\n- 输出：`cd` 是一个 Shell 内置命令。\n\n---\n\n# **使用 `apropos`**\n`apropos` 命令根据关键字搜索相关的命令和手册页。\n\n```bash\napropos 关键词\n```\n\n- **示例**：\n\n```bash\napropos file\n```\n\n- 输出：显示与 `file` 相关的命令和手册页简介。\n\n- **适用场景**：不确定命令名称时，查找相关命令。\n\n---\n\n# **使用 `whatis`**\n`whatis` 命令简要描述某个命令的功能。\n\n```bash\nwhatis 命令\n```\n\n- **示例**：\n\n```bash\nwhatis ls\n```\n\n- 输出：`ls (1)             - list directory contents`\n\n- **适用场景**：快速了解命令的功能。\n\n---\n\n# **使用 `-h`**\n许多命令支持 `-h` 参数，用于显示帮助信息（类似于 `--help`）。\n\n```bash\n命令 -h\n```\n\n- **示例**：\n\n```bash\ntar -h\n```\n\n- 输出：显示 `tar` 命令的帮助信息。\n\n- **适用场景**：快速查看命令的基本用法。\n\n---\n\n# **通过 `command --help` 与 `man` 的区别**\n- **`command --help` 或 `command -h`**：\n  - 提供简短的帮助信息。\n  - 适合快速了解命令的基本选项和用法。\n- **`man command`**：\n  - 提供更详细的文档，包含用法、选项、示例和注意事项。\n  - 适合深入了解命令。\n\n---\n\n# **示例总结**\n\n| **方法**  | **命令示例**   | **作用**                                 |\n| --------- | -------------- | ---------------------------------------- |\n| `--help`  | `ls --help`    | 查看命令的简要帮助信息。                 |\n| `-h`      | `tar -h`       | 查看命令的简要帮助信息（部分命令支持）。 |\n| `man`     | `man ls`       | 查看命令的详细手册页。                   |\n| `info`    | `info ls`      | 查看命令的详细信息（更结构化）。         |\n| `help`    | `help cd`      | 查看 Shell 内置命令的帮助信息。          |\n| `apropos` | `apropos file` | 根据关键字查找相关命令。                 |\n| `whatis`  | `whatis ls`    | 快速了解命令的功能。                     |\n| `which`   | `which ls`     | 查看命令所在路径（判断是否为外部命令）。 |\n| `type`    | `type cd`      | 查看命令是内置命令还是外部命令。         |\n\n---\n\n# **推荐组合使用**\n1. 不确定命令功能时：\n   ```bash\n   whatis 命令\n   ```\n2. 想快速查看选项：\n   ```bash\n   命令 --help\n   ```\n3. 想详细了解用法：\n   ```bash\n   man 命令\n   ```\n4. 想查找相关命令：\n   ```bash\n   apropos 关键词\n   ```\n\n通过这些方法，可以快速找到命令的帮助信息并高效使用！\n","categories":["Linux"]},{"title":"Linux命令详解---crontab","url":"/2024/10/08/3pjws2yl/","content":"\n`crontab` 是 `Linux` 和类 `Unix` 系统中用来管理定时任务的命令。通过 `crontab`，可以定期执行脚本或命令，比如每天备份、自动清理日志等。`crontab` 是基于 **cron** 服务的用户接口，每个用户都可以单独定义自己的定时任务。\n\n---\n\n# **基本语法**\n\n```bash\ncrontab [选项]\n```\n\n- **常用选项**：\n\n| 选项      | 功能                                            |\n| --------- | ----------------------------------------------- |\n| `-e`      | 编辑当前用户的 `crontab` 文件。                 |\n| `-l`      | 列出当前用户的 `crontab` 内容。                 |\n| `-r`      | 删除当前用户的 `crontab` 文件（清空定时任务）。 |\n| `-u 用户` | 指定用户管理其 `crontab`（需要管理员权限）。    |\n\n---\n\n# **`crontab` 文件格式**\n\n`crontab` 文件的每一行定义一个任务，其格式如下：\n\n```plaintext\n分钟 小时 日 月 星期 [命令或脚本]\n```\n\n- **时间字段**的解释：\n\n| 字段     | 范围   | 描述                                                  |\n| -------- | ------ | ----------------------------------------------------- |\n| **分钟** | `0-59` | 指定在每小时的哪一分钟执行任务。                      |\n| **小时** | `0-23` | 指定在每天的哪个小时执行任务。                        |\n| **日**   | `1-31` | 指定在每月的哪一天执行任务。                          |\n| **月**   | `1-12` | 指定在哪个月执行任务。                                |\n| **星期** | `0-7`  | 指定在每周的哪一天执行任务，`0` 和 `7` 都表示星期日。 |\n\n- **特殊符号**：\n\n| 符号 | 含义                                                   |\n| ---- | ------------------------------------------------------ |\n| `*`  | 任意值（例如，每分钟、每天等）。                       |\n| `,`  | 指定多个值（例如，`1,15` 表示第 1 分钟和第 15 分钟）。 |\n| `-`  | 指定范围（例如，`1-5` 表示从第 1 分钟到第 5 分钟）。   |\n| `/`  | 指定步长（例如，`*/5` 表示每 5 分钟执行一次）。        |\n\n---\n\n## **示例任务时间表**\n\n| 表达式         | 含义                             |\n| -------------- | -------------------------------- |\n| `0 5 * * *`    | 每天早上 5 点执行任务。          |\n| `30 8 * * 1-5` | 每周一到周五早上 8:30 执行任务。 |\n| `*/10 * * * *` | 每 10 分钟执行一次任务。         |\n| `0 0 1 * *`    | 每月 1 日凌晨 0 点执行任务。     |\n| `0 0 * * 0`    | 每周日凌晨 0 点执行任务。        |\n| `0 */2 * * *`  | 每两小时执行一次任务。           |\n| `0 8,18 * * *` | 每天 8 点和 18 点执行任务。      |\n\n---\n\n# **`crontab` 管理任务的步骤**\n\n##  **查看当前用户的任务**\n\n- 命令：\n  ```bash\n  crontab -l\n  ```\n- 说明：\n  - 列出当前用户的所有定时任务。\n  - 如果没有任务，则会显示类似以下内容：\n    ```\n    no crontab for <user>\n    ```\n\n---\n\n## **编辑定时任务**\n\n- 命令：\n  ```bash\n  crontab -e\n  ```\n- 说明：\n  - 打开当前用户的 `crontab` 文件（默认使用系统的文本编辑器，如 `vim` 或 `nano`）。\n  - 在文件中添加新的任务，每行一个任务。\n\n### **示例**：\n\n在 `crontab -e` 中添加以下内容：\n\n```plaintext\n0 6 * * * /home/user/backup.sh\n```\n\n- 任务说明：\n  - 每天早上 6 点运行 `/home/user/backup.sh` 脚本。\n\n---\n\n## **删除所有定时任务**\n\n- 命令：\n  ```bash\n  crontab -r\n  ```\n- 说明：\n  - 删除当前用户的所有定时任务。\n  - **注意：此操作不可恢复，请小心使用！**\n\n---\n\n## **为其他用户管理任务**\n\n- 命令（需要管理员权限）：\n  ```bash\n  sudo crontab -u username -e\n  ```\n- 说明：\n  - 编辑指定用户的 `crontab` 文件。\n  - 通常用于管理员为其他用户配置任务。\n\n---\n\n# **特殊时间宏**\n\n`crontab` 支持一些特殊的时间宏，可以简化时间表达式：\n\n| 宏                       | 等价表达式  | 含义                             |\n| ------------------------ | ----------- | -------------------------------- |\n| `@reboot`                | -           | 系统启动时执行任务。             |\n| `@yearly` 或 `@annually` | `0 0 1 1 *` | 每年执行一次（1 月 1 日 0 点）。 |\n| `@monthly`               | `0 0 1 * *` | 每月执行一次（1 日 0 点）。      |\n| `@weekly`                | `0 0 * * 0` | 每周执行一次（周日 0 点）。      |\n| `@daily` 或 `@midnight`  | `0 0 * * *` | 每天执行一次（0 点）。           |\n| `@hourly`                | `0 * * * *` | 每小时执行一次。                 |\n\n### **示例**：\n- 在系统启动时运行任务：\n  ```plaintext\n  @reboot /home/user/startup.sh\n  ```\n\n---\n\n# **查看和调试任务**\n\n## **查看任务执行日志**\n\n- 系统会记录 `cron` 任务的执行日志，日志文件通常位于：\n  - **Debian/Ubuntu**：\n    ```bash\n    /var/log/syslog\n    ```\n    查看日志：\n    ```bash\n    grep CRON /var/log/syslog\n    ```\n\n  - **CentOS/RHEL**：\n    ```bash\n    /var/log/cron\n    ```\n\n---\n\n## **调试任务**\n\n如果任务没有按预期执行，可以尝试以下方法：\n\n1. **确保脚本有可执行权限**：\n   ```bash\n   chmod +x /path/to/script.sh\n   ```\n\n2. **使用绝对路径**：\n   - 在 `crontab` 中，环境变量可能与登录时不同，因此需要使用命令或文件的绝对路径。\n\n3. **捕获输出**：\n   - 将标准输出和错误输出重定向到日志文件：\n     ```plaintext\n     0 6 * * * /home/user/backup.sh >> /home/user/backup.log 2>&1\n     ```\n\n4. **测试环境变量**：\n   - 在脚本顶部添加：\n     ```bash\n     env > /tmp/env.log\n     ```\n   - 查看是否缺少必要的环境变量。\n\n---\n\n# **综合示例**\n\n## 示例 1：每周一凌晨 2 点备份日志文件\n```plaintext\n0 2 * * 1 tar -czf /var/backups/logs_$(date +\\%Y\\%m\\%d).tar.gz /var/log\n```\n\n---\n\n## 示例 2：每 10 分钟检查服务是否运行\n```plaintext\n*/10 * * * * systemctl is-active nginx || systemctl start nginx\n```\n- 如果 Nginx 服务未运行，则启动它。\n\n---\n\n## 示例 3：系统启动时挂载网络驱动器\n```plaintext\n@reboot mount -t nfs 192.168.1.100:/shared /mnt/network\n```\n\n---\n\n## 示例 4：每天下午 5 点发送提醒邮件\n```plaintext\n0 17 * * * echo \"Backup completed\" | mail -s \"Daily Backup Status\" user@example.com\n```\n\n---\n\n# **注意事项**\n\n1. **环境变量**：\n   - `cron` 的运行环境与用户登录的环境不同，可能缺少一些变量。\n   - 可以在任务开头指定所需变量，例如：\n     ```plaintext\n     PATH=/usr/local/bin:/usr/bin:/bin\n     ```\n\n2. **权限问题**：\n   - 普通用户只能编辑自己的 `crontab`。\n   - `/etc/cron.allow` 和 `/etc/cron.deny` 文件可以控制用户是否允许使用 `cron`。\n\n3. **任务频率太高**：\n   - 如果任务频率太高（如每秒运行一次），可能会对系统造成压力。\n\n---\n\n# **总结**\n\n- **`crontab` 是 Linux 系统中管理定时任务的核心工具，具有灵活强大的时间调度功能。**\n- **常用命令**：\n  - 查看任务：`crontab -l`\n  - 编辑任务：`crontab -e`\n  - 删除任务：`crontab -r`\n- **编写任务时要特别注意时间字段格式、环境变量和日志捕获等问题，以确保任务正常执行。**\n","categories":["Linux"]},{"title":"Linux命令详解---echo","url":"/2024/10/08/fnb83o9t/","content":"\n`echo` 是一个非常常用的命令，用于在终端打印文本或变量的值。它简单而强大，适用于脚本编写、调试和输出信息等场景。\n\n---\n\n# **基本语法**\n\n```bash\necho [选项] [字符串]\n```\n\n- **字符串**：要输出的内容，可以是普通文本、变量值或转义字符。\n- **选项**：控制 `echo` 的行为（如是否解析转义字符等）。\n\n---\n\n# **常用选项**\n\n| **选项** | **作用**                                           |\n| -------- | -------------------------------------------------- |\n| `-n`     | 输出内容后不换行。                                 |\n| `-e`     | 启用转义字符处理（默认不解析转义字符）。           |\n| `-E`     | 禁用转义字符处理（默认行为，通常不需要显式指定）。 |\n\n---\n\n# **示例用法**\n\n## **输出文本**\n\n```bash\necho \"Hello, World!\"\n```\n\n- **输出**：\n  ```\n  Hello, World!\n  ```\n\n- 作用：在终端打印字符串。\n\n---\n\n## **输出变量**\n\n```bash\nname=\"Alice\"\necho \"Hello, $name!\"\n```\n\n- **输出**：\n  ```\n  Hello, Alice!\n  ```\n\n- 说明：`$name` 被解析为变量的值。\n\n---\n\n## **不换行输出**\n\n```bash\necho -n \"Processing...\"\necho \" Done.\"\n```\n\n- **输出**：\n  ```\n  Processing... Done.\n  ```\n\n- 说明：`-n` 禁止 `echo` 命令在输出后自动换行。\n\n---\n\n## **转义字符**\n\n### 启用转义字符处理（`-e`）\n\n```bash\necho -e \"Line1\\nLine2\"\n```\n\n- **输出**：\n  ```\n  Line1\n  Line2\n  ```\n\n- 说明：`\\n` 表示换行符，`-e` 启用了转义字符的解析。\n\n---\n\n### 常用转义字符\n\n| **转义字符** | **作用**                 |\n| ------------ | ------------------------ |\n| `\\n`         | 换行符                   |\n| `\\t`         | 水平制表符（Tab 键）     |\n| `\\\\`         | 反斜杠                   |\n| `\\\"`         | 双引号                   |\n| `\\'`         | 单引号                   |\n| `\\b`         | 退格符（删除前一个字符） |\n| `\\a`         | 警告声音（响铃）         |\n\n### 示例：\n\n```bash\necho -e \"Name:\\tAlice\\nAge:\\t25\"\n```\n\n- **输出**：\n  ```\n  Name:   Alice\n  Age:    25\n  ```\n\n---\n\n## **禁用转义字符**\n\n```bash\necho -E \"Hello\\nWorld\"\n```\n\n- **输出**：\n  ```\n  Hello\\nWorld\n  ```\n\n- 说明：`-E` 禁用转义字符解析，默认行为是直接输出文本。\n\n---\n\n## **输出文件内容**\n\n### 使用重定向符输出到文件：\n\n```bash\necho \"Hello, File!\" > file.txt\n```\n\n- 说明：将 `Hello, File!` 写入到 `file.txt` 文件中（覆盖原内容）。\n\n### 追加到文件：\n\n```bash\necho \"Another Line\" >> file.txt\n```\n\n- 说明：将 `Another Line` 追加到 `file.txt` 的末尾。\n\n---\n\n## **多行输出**\n\n### 方法 1：使用 `-e` 和换行符\n\n```bash\necho -e \"Line1\\nLine2\\nLine3\"\n```\n\n- **输出**：\n  ```\n  Line1\n  Line2\n  Line3\n  ```\n\n### 方法 2：直接使用多次 `echo`\n\n```bash\necho \"Line1\"\necho \"Line2\"\necho \"Line3\"\n```\n\n### 方法 3：使用 Here Document\n\n```bash\ncat <<EOF\nLine1\nLine2\nLine3\nEOF\n```\n\n---\n\n## **输出命令结果**\n\n```bash\necho \"Today is $(date)\"\n```\n\n- **输出**：\n  ```\n  Today is Mon Dec 9 12:34:56 UTC 2024\n  ```\n\n- 说明：`$(date)` 将运行 `date` 命令，并将结果嵌入到 `echo` 中。\n\n---\n\n## **格式化显示**\n\n### 使用 Tab 对齐：\n\n```bash\necho -e \"Name\\tAge\\tCity\\nAlice\\t25\\tNew York\\nBob\\t30\\tLondon\"\n```\n\n- **输出**：\n  ```\n  Name    Age     City\n  Alice   25      New York\n  Bob     30      London\n  ```\n\n---\n\n## **输出空行**\n\n```bash\necho\n```\n\n- 作用：打印一个空行。\n\n或者：\n\n```bash\necho -e \"\\n\"\n```\n\n---\n\n# **常见应用场景**\n\n## **打印错误信息**\n使用标准错误输出：\n\n```bash\necho \"Error: Something went wrong!\" >&2\n```\n\n---\n\n## **配合脚本输出日志**\n\n```bash\n#!/bin/bash\necho \"Starting the script...\"\necho \"Processing...\"\nsleep 1\necho \"Done.\"\n```\n\n运行输出：\n\n```\nStarting the script...\nProcessing...\nDone.\n```\n\n---\n\n## **打印路径或环境变量**\n\n```bash\necho \"Current Path: $PATH\"\n```\n\n- **输出**：\n  ```\n  Current Path: /usr/local/bin:/usr/bin:/bin\n  ```\n\n---\n\n## **生成简单警告提示**\n\n```bash\necho -e \"\\aWarning: Low disk space!\"\n```\n\n- 说明：`-e` 启用转义字符，`\\a` 会发出警告声音。\n\n---\n\n# **总结**\n\n| **功能**           | **命令示例**                              |\n| ------------------ | ----------------------------------------- |\n| 输出文本           | `echo \"Hello, World!\"`                    |\n| 输出变量值         | `echo \"User: $USER\"`                      |\n| 不换行输出         | `echo -n \"Processing...\"`                 |\n| 启用转义字符       | `echo -e \"Line1\\nLine2\"`                  |\n| 禁用转义字符       | `echo -E \"Hello\\nWorld\"`                  |\n| 输出到文件（覆盖） | `echo \"Text\" > file.txt`                  |\n| 输出到文件（追加） | `echo \"More Text\" >> file.txt`            |\n| 打印命令结果       | `echo \"Today is $(date)\"`                 |\n| 格式化输出         | `echo -e \"Name\\tAge\\nAlice\\t25\\nBob\\t30\"` |\n\n`echo` 是 Bash 脚本中不可或缺的工具，简单易用，能够满足多种文本输出需求！\n","categories":["Linux"]},{"title":"Linux命令详解---curl","url":"/2024/10/08/6s15w53k/","content":"\n`curl` 是 Linux 和类 Unix 系统中一个非常强大的命令行工具，用于发起 HTTP、HTTPS、FTP 等多种协议的请求。它的全名是 **Client URL**，主要用于从命令行与服务器交互，支持下载文件、上传数据、测试 API、发送 POST/GET 请求等功能。\n\n以下是 `curl` 命令的详细介绍，包括基本用法、常用选项和丰富的示例。\n\n---\n\n# **基本语法**\n\n```bash\ncurl [选项] [URL]\n```\n\n- **URL**：目标地址，支持多种协议，如 HTTP、HTTPS、FTP 等。\n- **选项**：用于控制请求的行为，例如头信息、数据传递、文件保存等。\n\n---\n\n# **常用选项**\n\n| 选项                | 功能                                                         |\n| ------------------- | ------------------------------------------------------------ |\n| `-X` 或 `--request` | 指定 HTTP 方法（如 GET、POST、PUT、DELETE 等）。             |\n| `-d` 或 `--data`    | 发送数据（通常用于 POST 请求）。                             |\n| `-H` 或 `--header`  | 添加自定义请求头。                                           |\n| `-o`                | 将输出保存到指定文件中。                                     |\n| `-O`                | 使用 URL 的文件名保存文件。                                  |\n| `-L`                | 跟随重定向。                                                 |\n| `-I` 或 `--head`    | 仅显示响应头信息。                                           |\n| `-k`                | 跳过 SSL 证书验证（适用于 HTTPS）。                          |\n| `-u`                | 指定用户名和密码（如 `username:password`）。                 |\n| `-s`                | 静默模式（不显示进度条或错误信息）。                         |\n| `-v`                | 显示详细的请求和响应信息。                                   |\n| `-w`                | 自定义输出格式。                                             |\n| `--limit-rate`      | 限制传输速度（如 `--limit-rate 100K` 表示每秒最大 100 KB）。 |\n| `--cookie`          | 发送指定的 Cookie（如 `--cookie \"name=value\"`）。            |\n| `--cookie-jar`      | 保存服务器返回的 Cookie 到文件。                             |\n| `-F` 或 `--form`    | 模拟表单提交（用于上传文件或多部分表单数据）。               |\n| `--compressed`      | 请求压缩数据，并自动解压响应（如 gzip）。                    |\n\n---\n\n# **常用功能和示例**\n\n## **发送 GET 请求**\n\n- 命令：\n  ```bash\n  curl https://example.com\n  ```\n- 用途：\n  - 发送一个 GET 请求并输出响应的内容。\n\n---\n\n## **保存响应到文件**\n\n- 使用 `-o` 指定保存的文件名：\n  ```bash\n  curl -o output.html https://example.com\n  ```\n  - 保存为 `output.html`。\n\n- 使用 `-O` 直接使用 URL 的文件名：\n  ```bash\n  curl -O https://example.com/file.zip\n  ```\n  - 保存为 `file.zip`。\n\n---\n\n## **发送 POST 请求**\n\n- 发送带数据的 POST 请求：\n  ```bash\n  curl -X POST -d \"key1=value1&key2=value2\" https://example.com/api\n  ```\n  - 使用 `-d` 传递 POST 数据。\n\n- 使用 JSON 数据：\n  ```bash\n  curl -X POST -H \"Content-Type: application/json\" -d '{\"key1\":\"value1\",\"key2\":\"value2\"}' https://example.com/api\n  ```\n\n---\n\n## **添加自定义请求头**\n\n- 使用 `-H` 添加请求头：\n  ```bash\n  curl -H \"Authorization: Bearer <token>\" https://example.com/api\n  ```\n\n---\n\n## **跟随重定向**\n\n- 默认情况下，`curl` 不会跟随重定向。使用 `-L` 可以实现：\n  ```bash\n  curl -L https://example.com\n  ```\n\n---\n\n## **仅显示响应头**\n\n- 使用 `-I` 或 `--head`：\n  ```bash\n  curl -I https://example.com\n  ```\n  输出示例：\n  ```\n  HTTP/1.1 200 OK\n  Date: Mon, 09 Dec 2024 10:00:00 GMT\n  Content-Type: text/html\n  Content-Length: 1234\n  ```\n\n---\n\n## **忽略 SSL 证书验证**\n\n- 如果目标网站使用了无效的 SSL 证书，可以使用 `-k` 跳过验证：\n  ```bash\n  curl -k https://example.com\n  ```\n\n---\n\n## **发送带认证信息的请求**\n\n- 使用 `-u` 传递用户名和密码：\n  ```bash\n  curl -u username:password https://example.com\n  ```\n\n---\n\n## **模拟浏览器访问**\n\n- 添加常见的浏览器 User-Agent：\n  ```bash\n  curl -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)\" https://example.com\n  ```\n\n---\n\n## **下载文件并限制速度**\n\n- 限制下载速度为 100 KB/s：\n  ```bash\n  curl --limit-rate 100K -O https://example.com/file.zip\n  ```\n\n---\n\n## **发送 Cookie**\n\n- 发送指定的 Cookie：\n  ```bash\n  curl --cookie \"name=value\" https://example.com\n  ```\n\n- 保存服务器返回的 Cookie：\n  ```bash\n  curl --cookie-jar cookies.txt https://example.com\n  ```\n\n---\n\n## **上传文件**\n\n- 使用表单上传文件：\n  ```bash\n  curl -F \"file=@/path/to/file\" https://example.com/upload\n  ```\n\n---\n\n## **压缩请求和解压响应**\n\n- 请求启用压缩并自动解压：\n  ```bash\n  curl --compressed https://example.com\n  ```\n\n---\n\n## **显示详细的请求和响应信息**\n\n- 使用 `-v` 查看请求和响应的完整细节：\n  ```bash\n  curl -v https://example.com\n  ```\n  输出示例：\n  ```\n  > GET / HTTP/1.1\n  > Host: example.com\n  > User-Agent: curl/7.68.0\n  > Accept: */*\n  ...\n  < HTTP/1.1 200 OK\n  < Content-Type: text/html\n  < Content-Length: 1234\n  ```\n\n---\n\n##  **测试 API**\n\n- 使用 `curl` 测试 REST API：\n  ```bash\n  curl -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"1234\"}' https://example.com/api/login\n  ```\n\n---\n\n## **自定义输出格式**\n\n- 使用 `-w` 自定义输出格式：\n  ```bash\n  curl -w \"HTTP Code: %{http_code}\\n\" -o /dev/null -s https://example.com\n  ```\n  输出示例：\n  ```\n  HTTP Code: 200\n  ```\n\n---\n\n## **并发请求（结合 `xargs`）**\n\n- 对多个 URL 并发请求：\n  ```bash\n  echo \"https://example.com/1 https://example.com/2\" | xargs -n 1 -P 2 curl -O\n  ```\n  - `-n 1`：每次处理一个 URL。\n  - `-P 2`：同时发起 2 个请求。\n\n---\n\n# **查看 `curl` 版本和支持的协议**\n\n- 查看 `curl` 版本和支持的协议：\n  ```bash\n  curl --version\n  ```\n  输出示例：\n  ```\n  curl 7.68.0 (x86_64-pc-linux-gnu) libcurl/7.68.0\n  Release-Date: 2020-01-08\n  Protocols: dict file ftp ftps http https imap imaps pop3 pop3s smtp smtps telnet tftp\n  ```\n\n---\n\n# **结合 `curl` 的高级使用**\n\n##  **下载多个文件**\n\n- 使用多个 URL 下载：\n  ```bash\n  curl -O https://example.com/file1 -O https://example.com/file2\n  ```\n\n---\n\n##  **模拟多段下载（断点续传）**\n\n- 从指定偏移量继续下载文件：\n  ```bash\n  curl -C - -O https://example.com/largefile.zip\n  ```\n\n---\n\n## **执行复杂的 API 请求**\n\n- 发送 PUT 请求：\n  ```bash\n  curl -X PUT -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' https://example.com/api/resource\n  ```\n\n- 发送 DELETE 请求：\n  ```bash\n  curl -X DELETE https://example.com/api/resource/123\n  ```\n\n---\n\n# **注意事项**\n\n1. **HTTPS 请求中的证书问题**：\n   - 如果遇到 SSL 证书问题，可以暂时使用 `-k` 跳过验证，但在生产环境中建议解决证书问题以确保安全。\n\n2. **静默模式**：\n   - 使用 `-s` 可以隐藏进度条和错误信息，但建议结合 `-o` 或 `-w` 进行更好的控制。\n\n---\n\n# **总结**\n\n- **`curl` 是一个功能强大的命令行工具**，适用于数据传输、API 测试、文件下载等多种场景。\n- **常用选项组合**：\n  - 简单 GET 请求：`curl https://example.com`\n  - POST 请求：`curl -X POST -d \"key=value\" https://example.com/api`\n  - 文件下载：`curl -O https://example.com/file.zip`\n  - 跟随重定向：`curl -L https://example.com`\n- 掌握 `curl` 的使用，可以非常高效地完成各种网络交互任务，尤其是在开发和调试 API 时，`curl` 是必不可少的工具。\n","categories":["Linux"]},{"title":"Linux命令详解---挂载","url":"/2024/10/08/a30sgeki/","content":"\n在 Linux 和类 Unix 系统中，**挂载（mount）** 是将一个设备、分区或远程文件系统与系统的某个目录（挂载点）关联的过程。通过挂载，用户可以访问设备上的文件和目录。\n\n---\n\n# **挂载命令：`mount`**\n\n`mount` 命令用于挂载文件系统或查看已挂载的文件系统。\n\n---\n\n## **基本语法**\n\n```bash\nmount [选项] [设备] [挂载点]\n```\n\n- **设备**：要挂载的设备或分区（如 `/dev/sda1`、`/dev/sdb2`，或远程文件系统路径）。\n- **挂载点**：系统中的一个目录（如 `/mnt/mydisk`），需要提前创建。\n- **选项**：控制挂载行为的参数，例如只读挂载、文件系统类型等。\n\n---\n\n# **挂载常见操作**\n\n## **查看已挂载的文件系统**\n\n```bash\nmount\n```\n\n- 显示当前系统中所有已挂载的文件系统及其详细信息。\n\n### 示例输出：\n```plaintext\n/dev/sda1 on / type ext4 (rw,relatime)\ndevtmpfs on /dev type devtmpfs (rw,nosuid,size=4000000k,nr_inodes=1000000,mode=755)\n```\n\n- **`/dev/sda1`**：设备名。\n- **`on /`**：挂载点。\n- **`type ext4`**：文件系统类型。\n- **`(rw,relatime)`**：挂载选项，`rw` 表示可读写。\n\n---\n\n## **挂载文件系统**\n\n要挂载设备或分区，必须先知道设备名。可以通过以下命令查看设备分区信息：\n\n```bash\nlsblk\n```\n\n- **`lsblk` 输出示例：**\n  ```plaintext\n  NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n  sda      8:0    0  500G  0 disk\n  ├─sda1   8:1    0  100G  0 part /\n  └─sda2   8:2    0  400G  0 part\n  sdb      8:16   0   1T   0 disk\n  └─sdb1   8:17   0   1T   0 part\n  ```\n\n### 挂载设备或分区到目录\n```bash\nsudo mount /dev/sdb1 /mnt\n```\n\n- **`/dev/sdb1`**：设备路径。\n- **`/mnt`**：挂载点目录，必须提前存在。\n\n### 验证挂载\n```bash\nmount | grep /mnt\n```\n\n---\n\n## **指定文件系统类型**\n\n如果文件系统类型不是自动识别或需要指定，可以用 `-t` 选项：\n\n```bash\nsudo mount -t ext4 /dev/sdb1 /mnt\n```\n\n- **`ext4`**：文件系统类型（常见的有 `ext4`、`xfs`、`vfat`、`ntfs` 等）。\n\n---\n\n## **只读挂载**\n\n使用 `-o ro` 选项挂载文件系统为只读：\n\n```bash\nsudo mount -o ro /dev/sdb1 /mnt\n```\n\n- **`-o ro`**：只读模式，挂载后无法写入数据。\n\n---\n\n## **挂载 ISO 文件**\n\n挂载 ISO 文件（光盘镜像）到目录：\n\n```bash\nsudo mount -o loop /path/to/file.iso /mnt\n```\n\n- **`-o loop`**：将文件作为一个虚拟设备挂载。\n\n---\n\n## **卸载文件系统**\n\n使用 `umount` 命令卸载挂载的文件系统。\n\n```bash\nsudo umount /mnt\n```\n\n- **卸载时的注意事项**：\n  - 目标挂载点不能被占用（如终端正在该目录下），否则会报错。\n  - 可以使用 `lsof` 检查挂载点的占用情况：\n    ```bash\n    lsof | grep /mnt\n    ```\n\n---\n\n## **永久挂载设备**\n\n临时挂载的设备在系统重启后会失效。如果需要永久挂载，可以编辑 `/etc/fstab` 文件。\n\n### **编辑 `/etc/fstab` 文件**\n\n1. 查看设备的 UUID：\n   ```bash\n   blkid\n   ```\n\n   示例输出：\n   ```plaintext\n   /dev/sda1: UUID=\"123e4567-e89b-12d3-a456-426655440000\" TYPE=\"ext4\"\n   /dev/sdb1: UUID=\"abcdef12-3456-7890-abcd-ef1234567890\" TYPE=\"ext4\"\n   ```\n\n2. 编辑 `/etc/fstab` 文件：\n   ```bash\n   sudo nano /etc/fstab\n   ```\n\n3. 添加挂载项：\n   ```plaintext\n   UUID=abcdef12-3456-7890-abcd-ef1234567890 /mnt ext4 defaults 0 0\n   ```\n\n   - **UUID**：设备的唯一标识符（推荐使用 UUID，而不是设备名，避免设备名变化）。\n   - **挂载点**：例如 `/mnt`。\n   - **文件系统类型**：例如 `ext4`。\n   - **选项**：`defaults` 表示使用默认挂载选项，其他常见选项包括 `ro`（只读）、`noexec`（禁止执行文件）等。\n\n4. 保存文件并退出。\n\n5. 测试挂载：\n   ```bash\n   sudo mount -a\n   ```\n\n---\n\n## **挂载网络文件系统（NFS 或 CIFS）**\n\n### 挂载 NFS（Network File System）\n```bash\nsudo mount -t nfs 192.168.1.100:/shared /mnt\n```\n\n- **`192.168.1.100:/shared`**：NFS 服务器地址和共享目录。\n- **`/mnt`**：本地挂载点。\n\n### 挂载 CIFS（Windows SMB 文件共享）\n```bash\nsudo mount -t cifs //192.168.1.100/shared /mnt -o username=user,password=pass\n```\n\n- **`//192.168.1.100/shared`**：共享地址。\n- **用户名和密码**：通过 `-o` 选项指定。\n\n---\n\n# **挂载选项（`-o`）**\n\n`mount` 命令支持多种挂载选项，通过 `-o` 指定：\n\n| **选项**       | **描述**                                                     |\n| -------------- | ------------------------------------------------------------ |\n| `ro`           | 以只读模式挂载。                                             |\n| `rw`           | 以读写模式挂载（默认）。                                     |\n| `loop`         | 将文件作为虚拟设备挂载（例如 ISO 文件）。                    |\n| `noexec`       | 禁止在挂载点上执行文件。                                     |\n| `nosuid`       | 不允许设置 SUID/SGID 权限。                                  |\n| `nodev`        | 禁止设备文件（如 `/dev/null`）在挂载点下生效。               |\n| `sync`         | 同步写入数据到磁盘。                                         |\n| `async`        | 异步写入数据到磁盘（默认）。                                 |\n| `uid=1000`     | 设置挂载文件的所有者（通常用于 FAT、NTFS 等非 Unix 文件系统）。 |\n| `gid=1000`     | 设置挂载文件的所属组。                                       |\n| `username=...` | 指定共享文件系统的用户名（例如 CIFS）。                      |\n| `password=...` | 指定共享文件系统的密码（例如 CIFS）。                        |\n\n---\n\n# **常见问题与解决**\n\n1. **挂载时报错：`mount: /mnt: unknown filesystem type`**\n   - 原因：系统未安装对应的文件系统驱动（如 NTFS、exFAT）。\n   - 解决：安装所需驱动。\n     ```bash\n     sudo apt install ntfs-3g        # 挂载 NTFS 文件系统\n     sudo apt install exfat-utils   # 挂载 exFAT 文件系统\n     ```\n\n2. **卸载时报错：`target is busy`**\n   - 原因：挂载点被使用。\n   - 解决：\n     ```bash\n     lsof | grep /mnt     # 查看占用挂载点的进程\n     kill -9 <PID>        # 终止占用进程\n     sudo umount /mnt     # 再次卸载\n     ```\n\n---\n\n# **总结**\n\n- **挂载设备**：`sudo mount /dev/sdX /mnt`\n- **卸载设备**：`sudo umount /mnt`\n- **查看已挂载设备**：`mount` 或 `lsblk`\n- **永久挂载**：编辑 `/etc/fstab`\n- **网络挂载**：支持 NFS 和 CIFS 文件系统。\n\n熟练掌握挂载命令，可以高效管理本地磁盘、外部存储设备和远程文件系统。\n","categories":["Linux"]},{"title":"Linux命令详解---cd","url":"/2024/10/08/234g7vhp/","content":"\n`cd` 是 Linux 和类 Unix 操作系统中的一个基本命令，用于更改当前工作目录。它是 \"change directory\" 的缩写，主要用于在文件系统中的不同目录之间导航。\n\n以下是对 `cd` 命令的详细介绍，包括其基本用法、常用选项和示例。\n\n---\n\n# **基本语法**\n\n```bash\ncd [目录路径]\n```\n\n- **目录路径**：指定要切换到的目标目录。\n- 可以是绝对路径（从根目录开始）或相对路径（基于当前目录）。\n\n如果不带路径直接输入 `cd`，默认会切换到用户的主目录（`~`）。\n\n---\n\n# **常用用法**\n\n## **切换到指定目录**\n\n```bash\ncd /path/to/directory\n```\n## **返回到上一级目录**\n\n```bash\ncd ..\n```\n\n## **切换到当前用户的主目录**\n\n```bash\ncd\n```\n\n或者：\n```bash\ncd ~\n```\n\n## **返回到之前的工作目录**\n\n```bash\ncd -\n```\n\n- 假设当前目录是 `/home/user/documents`，切换到 `/var/log` 后，再运行 `cd -`，会返回到 `/home/user/documents`。\n\n## **使用相对路径切换目录**\n\n- 当前目录为 `/home/user`，执行：\n  ```bash\n  cd documents\n  ```\n- 切换到 `/home/user/documents`。\n\n##  **切换到根目录**\n\n```bash\ncd /\n```\n\n---\n\n# **特殊符号的含义**\n\n| 符号 | 含义                                    |\n| ---- | --------------------------------------- |\n| `.`  | 当前目录。                              |\n| `..` | 上一级目录。                            |\n| `~`  | 当前用户的主目录（例如 `/home/user`）。 |\n| `-`  | 上一次的工作目录。                      |\n| `/`  | 文件系统的根目录。                      |\n\n---\n\n# **环境变量与 `cd` 的关系**\n\n- **`HOME` 环境变量**：\n\n   `cd` 不带参数时，会切换到 `HOME` 变量定义的目录。查看 `HOME` 变量：\n\n   ```bash\n   echo $HOME\n   ```\n\n- **`OLDPWD` 环境变量**：\n\n   - 存储上一次的工作目录路径。\n   - 使用 `cd -` 切换到 `OLDPWD` 指定的目录。\n\n---\n\n# **注意事项**\n\n如果目录名称包含空格，可以使用引号或反斜杠转义空格：\n```bash\ncd \"My Documents\"\n```\n或：\n```bash\ncd My\\ Documents\n```\n\n# **结合其他命令**\n\n`cd` 常与其他命令组合使用，例如：\n\n## **切换目录后列出文件**\n\n```bash\ncd /var/log && ls\n```\n\n## **返回并执行命令**\n\n```bash\ncd /path/to/directory && touch newfile.txt\n```\n\n---\n\n# **总结**\n\n`cd` 是一个简单但非常重要的命令，用于在 Linux 文件系统中导航。通过结合绝对路径、相对路径和特殊符号（如 `..`、`~`、`-`），可以快速切换到目标目录，大大提高工作效率。\n","categories":["Linux"]},{"title":"Linux基础命令汇总","url":"/2024/10/07/upprf7st/","content":"\n# 引言\n\nLinux 是一个功能强大的操作系统，广泛应用于服务器、开发和日常计算中。掌握 Linux 的基本命令，不仅能提高工作效率，还能帮助用户更好地管理系统和解决问题。\n\n本文将详细介绍一些常用的 Linux 命令，涵盖文件和目录操作、系统信息、网络管理、权限管理等多个方面，帮助更深入地了解和使用 Linux。\n\n请注意，由于不同 Linux 子系统的操作命令有所差异，本文所有命令在下述系统中测试通过：\n\n```bash\n$ cat /etc/os-release\nNAME=\"CentOS Linux\"\nVERSION=\"7 (Core)\"\nID=\"centos\"\nID_LIKE=\"rhel fedora\"\nVERSION_ID=\"7\"\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\nANSI_COLOR=\"0;31\"\n```\n<hr>\n# 文件和目录操作命令\n\n## ls\n\n列出目录内容。\n\n```bash\nls                      # 列出当前目录的文件和子目录\nls -l                   # 以长格式（详细信息）列出文件\nls -a                   # 列出所有文件，包括隐藏文件（以 \".\" 开头）\nls -h                   # 配合 -l 选项，以人类可读的格式显示文件大小\nls -R                   # 递归列出子目录内容\nls /path/to/directory   # 列出指定目录的内容\n```\n\n## cd\n\n切换目录。\n\n```bash\ncd /path/to/directory    # 切换到指定目录\ncd ..                    # 返回上一级目录\ncd ~                     # 切换到当前用户的主目录\ncd -                     # 切换到上次所在的目录\n```\n\n## pwd\n\n显示用户当前的工作目录。\n\n```bash\npwd\t\t\t# 显示用户当前的工作目录\n```\n\n## mkdir\n\n创建新目录。\n\n```bash\nmkdir new_directory         # 创建名为 `new_directory` 的目录\nmkdir -p dir1/dir2/dir3     # 递归创建多级目录（父目录不存在时一起创建）\n```\n\n## rmdir\n\n删除空目录。\n\n```bash\nrmdir empty_directory       # 删除名为 `empty_directory` 的空目录\n```\n\n## rm\n\n删除文件或目录。\n\n```bash\nrm file.txt                 # 删除文件\nrm -r directory_name        # 递归删除目录及其内容\nrm -f file.txt              # 强制删除文件，不提示确认\nrm -rf directory_name       # 强制递归删除目录及其内容\n```\n\n## cp\n\n复制文件或目录。\n\n```bash\ncp source.txt destination.txt          # 复制文件\ncp -r source_directory/ destination/   # 递归复制目录\ncp -p source.txt destination.txt       # 保留文件的原始权限、时间戳等属性\ncp -i source.txt destination.txt       # 提示确认后再覆盖目标文件\n```\n\n## mv\n\n移动或重命名文件或目录。\n\n```bash\nmv old_name.txt new_name.txt           # 重命名文件\nmv file.txt /path/to/directory/        # 移动文件到指定目录\nmv -i old_name.txt new_name.txt        # 提示确认后再覆盖目标文件\n```\n\n## touch\n\n创建空文件或更新文件的时间戳。\n\n```bash\ntouch newfile.txt                     # 创建一个空文件\ntouch -c file.txt                     # 仅更新文件时间戳，文件不存在时不创建\ntouch -t 202401011200 file.txt        # 设置文件时间为指定时间（格式：[[CC]YY]MMDDhhmm[.ss]）\n```\n\n# 文件查看和编辑命令\n\n## cat\n\n**Concatenate**，主要用于显示文件内容、将文件内容合并输出到标准输出或其他文件中。\n\n```bash\ncat file.txt                          # 显示文件内容\ncat file1.txt file2.txt > merged.txt  # 合并文件\ncat -n file.txt                       # 显示行号\n```\n\n## less\n\n分页查看文件内容。\n\n```bash\nless file.txt                         # 分页查看文件内容，支持上下移动\n```\n\n快捷键：\n\n- `q`：退出\n- `F`：实时刷新内容（适用于查看日志文件）\n- `/pattern`：搜索匹配的字符串\n\n## head\n\n查看文件的前几行。\n\n```bash\nhead -n 10 file.txt                   # 查看文件的前 10 行\nhead file.txt                         # 默认显示前 10 行\n```\n\n## tail\n\n查看文件的后几行。\n\n```bash\ntail -n 10 file.txt                   # 查看文件的后 10 行\ntail -f file.txt                      # 持续输出文件新增的内容（常用于查看日志）\n```\n\n## nano / vim\n\n文本编辑器。\n\n```bash\nnano file.txt                         # 使用 nano 编辑文件\nvim file.txt                          # 使用 vim 编辑文件\n```\n\n---\n\n# 文件搜索和查找命令\n\n## find\n\n在指定目录中查找文件。\n\n```bash\nfind /path/to/directory -name \"filename.txt\"   # 按名称查找文件\nfind . -type d -name \"mydir\"                  # 查找名为 \"mydir\" 的目录\nfind / -size +1M                              # 查找大于 1MB 的文件\nfind / -perm 755                              # 查找权限为 755 的文件\nfind / -mtime -7                              # 查找过去 7 天内修改的文件\nfind / -user username                         # 查找属于指定用户的文件\n```\n\n## locate\n\n快速查找文件。\n\n```bash\nlocate filename.txt       # 查找文件\nupdatedb                  # 更新数据库（需要 root 权限）\n```\n\n## grep\n\n在文件中搜索特定字符串。\n\n```bash\ngrep \"search_term\" file.txt                   # 在文件中查找字符串\ngrep -r \"search_term\" /path/to/directory      # 递归搜索目录中的文件\ngrep -i \"term\" file.txt                       # 忽略大小写\ngrep -v \"term\" file.txt                       # 排除包含 \"term\" 的行\ngrep -n \"term\" file.txt                       # 显示匹配行的行号\n```\n\n---\n\n# 网络命令\n\n## ping\n\n测试网络连接。\n\n```bash\nping www.example.com           # 连续发送网络数据包\nping -c 5 www.example.com      # 仅发送 5 个数据包\n```\n\n## netstat\n\n显示网络连接状态。\n\n```bash\nnetstat -a             # 显示所有连接\nnetstat -tuln          # 显示监听的端口\n```\n\n## curl\n\n从网络上获取数据。\n\n```bash\ncurl http://www.example.com                 # 下载网页内容并显示\ncurl -O http://example.com/file.zip         # 下载文件\ncurl -I http://example.com                  # 显示响应头信息\n```\n\n---\n\n# 任务调度\n\n## crontab\n\n定时任务管理。\n\n```bash\ncrontab -e      # 编辑当前用户的定时任务\ncrontab -l      # 查看当前用户的定时任务\ncrontab -r      # 删除当前用户的定时任务\n```\n\nCron 格式：\n\n```plaintext\n*  *  *  *  * command\n-  -  -  -  -\n|  |  |  |  |\n|  |  |  |  +---- 星期几 (0 - 7) (0 和 7 都表示周日)\n|  |  |  +------- 月份 (1 - 12)\n|  |  +---------- 日期 (1 - 31)\n|  +------------- 小时 (0 - 23)\n+---------------- 分钟 (0 - 59)\n```\n\n示例：\n\n```bash\n0 5 * * * /path/to/script.sh       # 每天早上5点执行脚本\n```\n\n# 结论\n\n掌握这些 Linux 命令，可以帮助你更高效地管理文件、监控系统、进行网络操作和任务调度。通过不断实践，你可以逐步深入了解 Linux 的强大功能并灵活运用到实际工作中。","categories":["Linux"]},{"title":"深度学习---基础概念","url":"/2024/10/01/11cnxpb1/","content":"\n深度学习（`Deep Learning`）是机器学习（`Machine Learning`）的一个分领域，它通过模拟人脑神经网络的结构和功能来处理复杂的数据问题。深度学习在诸多领域（如计算机视觉、自然语言处理、语音识别等）取得了显著的成果。以下从基本概念、核心技术、常见模型到实际应用对深度学习进行全面解析。\n\n# **深度学习的基本概念**\n\n## 什么是深度学习？\n\n深度学习是一种基于**人工神经网络**（`Artificial Neural Networks`, `ANN`）的算法，它之所以被称为“深度”，是因为模型通常由多层神经网络组成。这些层级结构使得深度学习模型能够逐步提取数据中的特征，从低级特征（如边缘、纹理）到高级特征（如形状、语义）。\n\n## 深度学习与机器学习的关系\n\n| **对比点**     | **机器学习**                  | **深度学习**                    |\n| -------------- | ----------------------------- | ------------------------------- |\n| **特征提取**   | 特征需要人工设计              | 自动学习特征                    |\n| **模型复杂度** | 模型较浅（如逻辑回归、`SVM`） | 模型较深（多层神经网络）        |\n| **数据需求**   | 对小数据集表现较好            | 需要大量数据                    |\n| **计算需求**   | 计算需求相对较低              | 需要高性能计算资源（`GPU/TPU`） |\n\n---\n\n# **深度学习的核心技术**\n\n## 人工神经网络（`ANN`）\n\n神经网络是深度学习的基础。一个**人工神经网络**通常包括以下几个核心部分：\n\n- **输入层**：接收数据输入（向量化后的数据）。\n- **隐藏层**：通过权重和激活函数提取数据特征。\n- **输出层**：输出最终的预测结果。\n\n数学表示：\n- 给定输入数据 **$x$** 和权重 **$w$**，隐藏层输出为：  **$h = f(wx + b)$**  ，其中，**$f$** 是非线性激活函数（如 `ReLU`、`Sigmoid`）。\n\n---\n\n## 深度神经网络（`DNN`）\n\n深度神经网络是由多层隐藏层组成的神经网络。每一层提取的数据特征都更复杂，适合处理图像、文本等复杂问题。\n\n**优点**：\n\n- 强大的表示能力。\n- 可处理非线性问题。\n\n**挑战**：\n\n- 训练难度大（梯度消失或爆炸问题）。\n- 对计算资源和数据量依赖高。\n\n---\n\n## 激活函数\n\n激活函数是深度学习模型的核心组件，用来引入非线性能力。常见激活函数包括：\n\n| **函数**       | **公式**                           | **优点**                                 | **缺点**         |\n| -------------- | ---------------------------------- | ---------------------------------------- | ---------------- |\n| **Sigmoid**    | $σ(x) = \\dfrac{1}{1 + e^{-x}}$     | 平滑，适合概率输出                       | 梯度消失问题     |\n| **ReLU**       | $f(x) = max(0,~ x)$                | 计算简单，收敛快                         | 神经元可能“死亡” |\n| **Tanh**       | $tanh(x)$                          | 归一化输出（`-1到1`），比`Sigmoid`更平滑 | 梯度可能消失     |\n| **Leaky ReLU** | $f(x) = x (x > 0), ~~~ax (x <= 0)$ | 解决ReLU死亡问题                         | 引入了额外参数   |\n\n---\n\n## 损失函数\n\n损失函数衡量模型预测值和真实值之间的差距，常见的损失函数有：\n\n- **均方误差（MSE）**：用于回归问题。\n- **交叉熵损失（Cross Entropy Loss）**：用于分类问题。\n- **Hinge Loss**：用于`SVM`。\n\n例如交叉熵损失：\n$$\n\\mathcal{L}(\\theta) = -\\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\log(p_i) + (1-y_i) \\log(1-p_i)\\right]\n$$\n\n\n## 优化算法\n\n优化算法用于调整模型权重以最小化损失函数。常见优化算法包括：\n\n| **算法**                | **特点**                                      |\n| ----------------------- | --------------------------------------------- |\n| **梯度下降**            | 基础算法，逐步调整权重以最小化损失            |\n| **随机梯度下降（SGD）** | 每次更新只使用一个样本，速度更快              |\n| **Adam**                | 自适应学习率算法，结合了`Momentum`和`RMSProp` |\n| **RMSProp**             | 针对稀疏数据优化，调整学习率                  |\n\n---\n\n## 正则化技术\n\n为了防止模型过拟合，常用的正则化技术包括：\n\n- **L1/L2正则化**：对权重加约束。\n- **Dropout**：随机丢弃神经元，减少过拟合风险。\n- **Batch Normalization**：加速训练，提高泛化能力。\n\n---\n\n# **深度学习的常见模型**\n\n## 卷积神经网络（`CNN`）\n\n**用途**：图像处理（如图像分类、目标检测）。\n\n**特点**：\n\n- **卷积层**：提取空间特征。\n- **池化层**：降维，降低计算复杂度。\n- **全连接层**：整合特征，输出结果。\n\n---\n\n## 循环神经网络（`RNN`）\n\n**用途**：时间序列数据（如语音识别、文本生成）。\n\n**特点**：\n\n- 能捕捉时间依赖性。\n- 存在梯度消失问题。\n\n**改进模型**：\n\n- **LSTM（长短期记忆网络）**：解决RNN梯度消失问题。\n- **GRU（门控循环单元）**：LSTM的简化版。\n\n---\n\n## Transformer\n\n**用途**：自然语言处理（如翻译、文本生成）。\n\n**特点**：\n\n- 基于注意力机制。\n- 替代了`RNN/LSTM`，性能更强。\n\n代表模型：`BERT`、`GPT`、`T5`。\n\n---\n\n## 生成对抗网络（`GAN`）\n\n**用途**：生成数据（如图像生成、数据增强）。\n\n**特点**：\n\n- 包含生成器（`Generator`）和判别器（`Discriminator`）。\n- 训练过程是一个对抗博弈。\n\n---\n\n# **深度学习的实际应用**\n\n## 计算机视觉\n\n- 图像分类（`ResNet`、`EfficientNet`等）。\n- 目标检测（`YOLO`、`Faster R-CNN`）。\n- 图像分割（`U-Net`、`Mask R-CNN`）。\n\n---\n\n## 自然语言处理\n\n- 文本分类、情感分析（`BERT`、`RoBERTa`）。\n- 机器翻译（`Transformer`、`GPT`）。\n- 对话生成（`ChatGPT`）。\n\n---\n\n## 语音处理\n\n- 语音识别（`DeepSpeech`）。\n- 语音合成（`Tacotron`、`WaveNet`）。\n\n---\n\n## 自动驾驶\n\n- 目标检测（车道线检测、障碍物识别）。\n- 决策控制（深度强化学习）。\n\n---\n\n这里仅展示了深度学习的一些基本概念，深度学习作为人工智能的重要分支，已经深刻改变了多个行业。\n\n随着硬件的进步和算法的优化，其未来潜力不可估量。如果大家需要进一步了解相关技术，可以参考本类的其他文章。","categories":["深度学习"]},{"title":"文心一言，能超过ChatGPT吗？","url":"/2024/09/24/iwuv6gww/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 文心一言，能超过ChatGPT吗？ https://mp.weixin.qq.com/s/GJoLgooqwQdnWNWgXszOeg /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"Adam优化器","url":"/2024/09/12/ysibbt0p/","content":"\n在深度学习和机器学习的模型训练过程中，优化算法起着关键作用。\n\n**Adam**（Adaptive Moment Estimation）优化器是目前最受欢迎和广泛使用的优化算法之一。它结合了`动量优化器`和 `RMSProp` 的优势，能够在训练过程中`自适应地调整学习率`，实现`高效`和`稳健`的梯度更新。\n\n下面，我们将详细介绍 Adam 优化器的原理、数学公式，以及 Python 代码实现。\n\n---\n\n# 背景与动机\n\n在深度学习中，我们需要通过优化算法最小化损失函数，以找到模型参数的最佳值。传统的优化算法，如随机梯度下降（SGD）和动量优化器，在一些情况下可能会遇到以下问题：\n\n- **学习率选择困难**：固定的全局学习率可能导致收敛速度慢或陷入局部最小值。\n- **梯度稀疏或噪声干扰**：在高维参数空间中，梯度可能稀疏且受噪声影响，影响优化效果。\n- **不适应非平稳目标**：模型训练过程中，数据分布可能发生变化，需要优化算法能够适应非平稳目标。\n\n为了解决上述问题，`Adam 优化器`应运而生。它结合了`动量优化器`对梯度一阶矩的累积和 `RMSProp` 对梯度二阶矩的累积，实现了对学习率的`自适应调整`。\n\n---\n\n# 数学公式\n\n`Adam 优化器`的更新规则如下：\n\n1. **一阶矩估计（动量项）**\n\n   $$\n   m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_{\\theta_t} J(\\theta_t)\n   $$\n\n2. **二阶矩估计（RMSProp 部分）**\n\n   $$\n   v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) [\\nabla_{\\theta_t} J(\\theta_t)]^2\n   $$\n\n3. **偏差校正**\n\n   为了纠正 $m_t$ 和 $v_t$ 在初始阶段偏向于零的现象，进行偏差校正：\n\n   - 一阶矩偏差校正：\n\n     $$\n     \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n     $$\n\n   - 二阶矩偏差校正：\n\n     $$\n     \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n     $$\n\n4. **参数更新**\n\n   $$\n   \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n   $$\n\n其中：\n\n- $\\theta_t$：第 $t$ 次迭代的参数向量。\n- $\\nabla_{\\theta_t} J(\\theta_t)$：损失函数 $J$ 关于参数 $\\theta_t$ 的梯度。\n- $m_t$：梯度的一阶矩估计（动量）。\n- $v_t$：梯度的二阶矩估计（平方梯度的指数加权平均）。\n- $\\beta_1$、$\\beta_2$：一阶和二阶矩估计的指数衰减率超参数，通常取值为 $\\beta_1 = 0.9$，$\\beta_2 = 0.999$。\n- $\\eta$：初始学习率（通常取值为 0.001）。\n- $\\epsilon$：微小常数（如 $10^{-8}$）防止除以零。\n- $t$：当前迭代次数。\n\n---\n\n# 原理解析\n\n`Adam 优化器`的核心思想是对`梯度的一阶矩（均值）和二阶矩（方差）进行指数加权移动平均`，以此来动态调整学习率。\n\n1. **一阶矩估计 $m_t$**\n   - 类似于动量优化器的动量项，累积了过去梯度的均值，平滑了梯度更新方向。\n   - 指数加权平均通过 $\\beta_1$ 控制，$\\beta_1$ 越接近 1，对历史梯度的记忆越长。\n   \n2. **二阶矩估计 $v_t$**\n\n   - 类似于 RMSProp 中对梯度平方的指数加权平均，反映了梯度的方差。\n   - 通过对梯度平方的累积，可以适应梯度的变化范围，调整学习率。\n\n3. **偏差校正**\n\n   - 在初始阶段，$m_0$ 和 $v_0$ 被初始化为零，可能导致估计值偏小。\n   - 通过除以 $1 - \\beta_1^t$ 和 $1 - \\beta_2^t$ 对估计值进行校正，获得无偏估计。\n\n4. **参数更新**\n\n   - 参数更新步长中，$\\hat{m}_t$ 是对梯度的校正一阶矩估计，$\\sqrt{\\hat{v}_t} + \\epsilon$ 是对梯度方差的校正估计。\n   - 这样，学习率根据梯度的历史信息自适应调整，实现了参数的有效更新。\n\n---\n\n# 超参数的选择与含义\n\n- **学习率 $\\eta$**\n\n  - 默认值为 0.001。\n  - `Adam` 对学习率相对不敏感，但在某些情况下需要调节。\n\n- **一阶矩衰减率 $\\beta_1$**\n\n  - 通常设置为 0.9。\n  - 控制一阶矩估计的移动平均，$\\beta_1$ 越大，对历史梯度的记忆越长。\n\n- **二阶矩衰减率 $\\beta_2$**\n\n  - 通常设置为 0.999。\n  - 控制二阶矩估计的移动平均，$\\beta_2$ 越大，对历史梯度平方的记忆越长。\n\n- **$\\epsilon$**\n\n  - 防止除以零的数值稳定性常数，通常取值为 $10^{-8}$。\n  - 对结果影响不大，无需调整。\n\n**注意：** 在实际应用中，默认超参数已经在很多任务上表现良好，通常无需调整。\n\n---\n\n# Python 代码实现\n\n以下是 `Adam 优化器`的简单 Python 实现：\n\n```python\nimport numpy as np\n\n# 参数初始化\ntheta = np.zeros((n_parameters,))\nm = np.zeros_like(theta)  # 一阶矩估计\nv = np.zeros_like(theta)  # 二阶矩估计\n\n# 超参数设置\neta = 0.001       # 学习率\nbeta_1 = 0.9      # 一阶矩衰减率\nbeta_2 = 0.999    # 二阶矩衰减率\nepsilon = 1e-8    # 防止除以零的常数\nnum_iterations = 1000\n\nfor t in range(1, num_iterations + 1):\n    grad = compute_gradient(theta)  # 计算梯度\n\n    # 更新一阶矩估计\n    m = beta_1 * m + (1 - beta_1) * grad\n\n    # 更新二阶矩估计\n    v = beta_2 * v + (1 - beta_2) * (grad ** 2)\n\n    # 计算偏差校正\n    m_hat = m / (1 - beta_1 ** t)\n    v_hat = v / (1 - beta_2 ** t)\n\n    # 更新参数\n    theta = theta - (eta / (np.sqrt(v_hat) + epsilon)) * m_hat\n```\n\n在上述代码中：\n\n- `compute_gradient(theta)` 用于计算当前参数 `theta` 下的梯度。\n- 使用了偏差校正的 $\\hat{m}_t$ 和 $\\hat{v}_t$，提高了优化器在初始阶段的性能。\n- 参数更新中，学习率被梯度的二阶矩估计 $\\sqrt{\\hat{v}_t}$ 自适应调整。\n\n---\n\n# 与其他优化器的比较\n\n| **优化算法**   | **特点**                                                     | **适用场景**                       |\n| -------------- | ------------------------------------------------------------ | ---------------------------------- |\n| **SGD**        | 简单易实现，可能收敛慢且容易陷入局部最小值                   | 小型数据集和凸优化问题             |\n| **动量优化器** | 引入动量项，加速收敛，减少振荡                               | 有鞍点或深谷的优化问题             |\n| **Adagrad**    | 自适应学习率，适合处理稀疏数据，学习率会持续衰减             | 稀疏特征、高维特征                 |\n| **Adadelta**   | 解决 Adagrad 学习率衰减问题，无需设置全局学习率              | 需要自适应学习率且不愿调参的情况   |\n| **RMSProp**    | 对梯度平方的指数加权平均，稳定学习率，适应非平稳目标         | 训练过程中有噪声或非平稳数据       |\n| **Adam**       | 结合动量和 RMSProp 的优势，自适应学习率，兼顾一阶和二阶矩估计，偏差校正提高稳定性 | 大多数深度学习任务，默认首选优化器 |\n\n**Adam 优化器的优势：**\n\n- **自适应学习率**：根据梯度的一阶和二阶矩动态调整学习率，无需手动调节。\n- **快速收敛**：能够在复杂的优化空间中快速逼近最优值。\n- **鲁棒性强**：对超参数不敏感，具有良好的数值稳定性。\n\n---\n\n# 实践中的注意事项\n\n1. **参数初始化**\n\n   - 建议对参数进行合适的初始化，如 `Xavier` 或 `He` 初始化，增强训练效果。\n\n2. **梯度裁剪**\n\n   - 对于存在梯度爆炸的情况，可以考虑进行`梯度裁剪`（`Gradient Clipping`），防止梯度过大影响训练。\n\n3. **学习率调整**\n\n   - 虽然 `Adam` 对学习率不敏感，但在某些特定任务中，`适当调整学习率`仍然有助于提升性能。\n\n4. **正则化**\n\n   - 可以结合权重衰减（`L2 正则化`）或` Dropout` 等方法，`防止过拟合`。\n\n5. **偶尔出现的不稳定性**\n\n   - 在个别情况下，`Adam` 可能在收敛后期表现出震荡或不稳定。可以考虑`降低学习率`或切换到 SGD 进行微调。\n\n---\n\n# Adam 的变种\n\n## Adamax\n\n- **原理**：`Adamax` 是 Adam 的变体，基于无穷范数（`infinity norm`），在某些情况下表现更好。\n- **更新规则**：\n\n  $$\n  v_t = \\max (\\beta_2 v_{t-1}, |\\nabla_{\\theta_t} J(\\theta_t)|)\n  $$\n\n- **参数更新**：\n\n  $$\n  \\theta_{t+1} = \\theta_t - \\frac{\\eta}{v_t} m_t\n  $$\n\n## NAdam\n\n- **原理**：结合了 `Nesterov加速梯度`和 `Adam优化器`的思想，进一步加速收敛。\n- **特点**：对`一阶矩`估计进行了 `Nesterov动量`的调整。\n\n---\n\n# 结论\n\n`Adam优化器`作为一种强大而有效的优化算法，`已经成为深度学习训练的默认选择`。它通过对梯度的一阶和二阶矩进行自适应估计，动态调整学习率，实现了快速而稳健的收敛。\n\n在实际应用中，Adam 优化器具有以下优点：\n\n- **易用性**：对超参数不敏感，默认设置即可获得良好效果。\n- **泛用性**：适用于大多数神经网络结构和任务。\n- **高效性**：能够处理大规模和高维数据，具有较高的计算效率。\n\n**然而，也需要注意以下事项：**\n\n- **过拟合风险**：由于具有快速收敛能力，可能在训练数据上过拟合，需要配合正则化方法。\n- **理论研究**：关于 Adam 的收敛性和泛化能力的理论研究仍在进行中，某些情况下可能需要结合其他优化策略。\n","categories":["小小知识"]},{"title":"动量优化器","url":"/2024/09/06/ti2a4z75/","content":"\n在深度学习和机器学习的优化过程中，梯度下降算法是最基本也是最常用的优化算法之一。然而，标准的梯度下降算法在某些情况下收敛速度较慢，或者在接近最优点时产生振荡。为了加速收敛和减少振荡，引入了动量（`Momentum`）优化器。\n\n下面，我们将详细介绍动量优化器的原理、数学公式，以及Python代码实现。\n\n---\n\n# 背景与动机\n\n在标准的梯度下降（`Gradient Descent`，GD）算法中，参数的更新规则是：\n\n$$\n\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta J(\\theta_t)\n$$\n\n其中：\n- $\\theta_t$ 表示第 $t$ 次迭代的参数向量。\n- $\\eta$ 是学习率（`learning rate`）。\n- $\\nabla_\\theta J(\\theta_t)$ 是目标函数 $J$ 关于参数 $\\theta_t$ 的梯度。\n\n在高维空间中，目标函数的形状可能是狭长的椭圆，导致梯度在不同维度上的尺度差异较大。在这种情况下，标准的梯度下降算法可能会在接近最优点时产生振荡，导致收敛缓慢。\n\n为了克服这一问题，动量优化器在梯度下降的基础上引入了“`动量`”概念，利用过去梯度的累积信息，平滑更新方向，加速收敛。\n\n---\n\n# 动量优化器的数学公式\n\n动量优化器的核心思想是引入一个`动量项`，对过去梯度的累积进行加权，从而平滑参数更新的方向。\n\n**动量优化器的更新规则：**\n\n1. **动量项的更新：**\n\n$$\nv_{t} = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta_t)\n$$\n\n2. **参数的更新：**\n\n$$\n\\theta_{t+1} = \\theta_t - v_{t}\n$$\n\n其中：\n- $v_t$ 是第 $t$ 次迭代的动量项（也称为速度，`velocity`）。\n- $\\gamma$ 是动量系数（`momentum coefficient`），取值范围为 $0 \\leq \\gamma < 1$，通常取接近1的值（如0.9）。\n- 其他符号同前所述。\n\n---\n\n# 原理解析\n\n- **累积历史梯度**：动量项 $v_t$ 是对历史梯度的指数加权移动平均，它在一定程度上记忆了过去梯度的方向和大小。\n- **加速相同方向的更新**：如果连续多个迭代的梯度方向相同，动量项会逐渐增加，从而加速参数在该方向上的更新。\n- **减小振荡**：在梯度方向变化较大的维度上，动量项由于正负抵消，更新幅度被减小，从而抑制了振荡现象。\n\n**形象比喻：** 可以将参数更新过程想象成一个带有惯性的物体在损失函数的曲面上滑动。动量项赋予了物体惯性，使其能够越过局部最小值，朝着全局最小值方向前进。\n\n---\n\n# 动量优化器的Python代码实现\n\n以下是一个简化的`动量优化器`的Python实现示例：\n\n```python\nimport numpy as np\n\n# 假设我们有一个需要优化的参数 theta\ntheta = np.zeros((n_parameters,))  # 参数向量，维度根据具体问题确定\nv = np.zeros_like(theta)           # 动量项初始化为零\n\n# 超参数设置\neta = 0.01     # 学习率\ngamma = 0.9    # 动量系数\nnum_iterations = 1000  # 迭代次数\n\nfor t in range(num_iterations):\n    grad = compute_gradient(theta)  # 计算当前梯度，需要根据具体问题定义\n\n    # 更新动量项\n    v = gamma * v + eta * grad\n\n    # 更新参数\n    theta = theta - v\n```\n\n在上述代码中：\n- `compute_gradient(theta)` 是一个函数，用于计算当前参数 `theta` 下的梯度，需要根据具体的损失函数和模型定义。\n- 动量项 `v` 的更新包含了对过去动量的记忆，通过参数 `gamma` 控制。\n\n---\n\n# 与标准梯度下降的比较\n\n|              | **标准梯度下降**                                           | **动量优化器**                                               |\n| ------------ | ---------------------------------------------------------- | ------------------------------------------------------------ |\n| **更新规则** | $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta J(\\theta_t)$ | $\\begin{cases} v_{t} = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta_t) \\\\ \\theta_{t+1} = \\theta_t - v_{t} \\end{cases}$ |\n| **特点**     | 只考虑当前梯度，可能在陡峭方向产生振荡                     | 累积历史梯度，加速收敛，减少振荡                             |\n| **收敛速度** | 较慢，可能需要较小的学习率避免振荡                         | 较快，允许使用较大的学习率                                   |\n\n---\n\n# 超参数的选择\n\n- **学习率 $\\eta$**：动量优化器通常允许使用比标准梯度下降更大的学习率，但仍需根据具体问题进行调节。\n- **动量系数 $\\gamma$**：一般取值在 [0.5, 0.9] 之间，典型值为 0.9。较大的 $\\gamma$ 值赋予了动量项更强的惯性，对过去梯度的记忆更长。\n\n---\n\n# 动量优化器的变种\n\n## Nesterov 加速梯度（Nesterov Accelerated Gradient，NAG）\n\n`NAG` 对动量优化器进行了改进，通过对未来位置的梯度进行`前瞻性估计`，进一步加速了收敛。\n\n**NAG 的更新规则：**\n\n1. **计算前瞻位置：**\n\n$$\n\\theta_{\\text{lookahead}} = \\theta_t - \\gamma v_{t-1}\n$$\n\n2. **计算前瞻梯度：**\n\n$$\ng_t = \\nabla_\\theta J(\\theta_{\\text{lookahead}})\n$$\n\n3. **更新动量项：**\n\n$$\nv_t = \\gamma v_{t-1} + \\eta g_t\n$$\n\n4. **更新参数：**\n\n$$\n\\theta_{t+1} = \\theta_t - v_t\n$$\n\n**Python 实现示例：**\n\n```python\n# 更新参数时的前瞻位置\ntheta_lookahead = theta - gamma * v\n\n# 计算前瞻位置的梯度\ngrad = compute_gradient(theta_lookahead)\n\n# 更新动量项\nv = gamma * v + eta * grad\n\n# 更新参数\ntheta = theta - v\n```\n\n---\n\n## RMSProp 和 Adam 优化器\n\n动量优化器只能解决`梯度方向`的问题，而无法调整不同参数维度上梯度的尺度。为了解决这个问题，引入了`自适应学习率`的算法，如 `RMSProp` 和 `Adam`。这些算法在动量优化器的基础上，结合了梯度的二阶矩信息，实现了对学习率的自适应调整。可参考：\n\n{% postLinkCard u9c9ki5q  \"auto\" %}\n\n{% postLinkCard ysibbt0p  \"auto\" %}\n\n---\n\n# 总结\n\n动量优化器通过引入对`历史梯度`的累积，赋予了参数更新一定的“惯性”，从而在优化过程中能够：\n\n- **加速收敛速度**：在一致的梯度方向上，动量项的累积使得参数更新步伐加大，加速了收敛。\n- **减少振荡**：在梯度方向变化频繁的维度上，动量项的相消作用平滑了参数更新，减少了振荡现象。\n\n在深度学习的实际应用中，动量优化器是一种常用且有效的优化算法。通过合理地选择超参数 $\\eta$ 和 $\\gamma$，可以显著提升模型训练的效率和效果。\n","categories":["小小知识"]},{"title":"自适应学习率优化器","url":"/2024/09/04/u9c9ki5q/","content":"\n在深度学习和机器学习的模型训练过程中，优化算法起着至关重要的作用。除了标准的梯度下降和动量优化器之外，还有许多`自适应学习率`的优化算法，如 `Adagrad`、`Adadelta` 和 `RMSProp`。它们通过自适应地调整学习率，以提升收敛速度和稳定性。\n\n以下将详细介绍这三个优化算法，包括公式、原理，以及 Python 代码实现。\n\n---\n\n# Adagrad 算法\n\n## 背景与动机\n\n在标准的梯度下降过程中，学习率 $\\eta$ 是一个全局的超参数，对所有参数 $\\theta$ 都保持不变。在某些情况下，不同参数的特性可能差异很大，使用相同的学习率可能导致收敛效果不佳。\n\n**Adagrad**（Adaptive Gradient Algorithm）算法通过为每个参数引入不同的`自适应学习率`，根据历史梯度信息`动态调整`参数的更新步长，特别适合处理`稀疏数据`和`高维特征`。\n\n## 数学公式\n\n**Adagrad 的参数更新规则：**\n\n对于每个参数 $\\theta_i$，有：\n\n1. **累积历史梯度的平方和：**\n\n$$\nG_{t,i} = G_{t-1,i} + [\\nabla_{\\theta_i} J(\\theta_t)]^2\n$$\n\n2. **更新参数：**\n\n$$\n\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,i} + \\epsilon}} \\nabla_{\\theta_i} J(\\theta_t)\n$$\n\n其中：\n\n- $G_{t,i}$ 是关于参数 $\\theta_i$ 的梯度平方和累积，到第 $t$ 次迭代时的值。\n- $\\nabla_{\\theta_i} J(\\theta_t)$ 是损失函数关于参数 $\\theta_i$ 的梯度。\n- $\\eta$ 是全局学习率（初始学习率）。\n- $\\epsilon$ 是一个微小的常数（如 $10^{-8}$），用于防止除以零。\n\n## 原理解析\n\n- **自适应学习率**：`Adagrad` 通过累积每个参数的梯度平方和 $G_{t,i}$ 来缩放学习率。对于那些经常出现大梯度的参数，梯度平方和会增大，从而使得学习率变小；对于那些梯度较小或较少更新的参数，学习率相对较大。这种自适应性有助于更有效地更新`不同尺度`的参数。\n- **适合处理稀疏数据**：在自然语言处理等`稀疏特征`的任务中，`Adagrad` 能够有效地调整学习率，提高训练效率。\n\n## Python 代码实现\n\n```python\nimport numpy as np\n\n# 假设我们有一个需要优化的参数 theta\ntheta = np.zeros((n_parameters,))  # 参数向量\nG = np.zeros_like(theta)           # 累积梯度平方和\n\n# 超参数设置\neta = 0.01       # 初始学习率\nepsilon = 1e-8   # 防止除以零的微小常数\nnum_iterations = 1000  # 迭代次数\n\nfor t in range(1, num_iterations + 1):\n    grad = compute_gradient(theta)  # 计算当前梯度，需要根据具体问题定义\n\n    # 累积梯度平方和\n    G += grad ** 2\n\n    # 更新参数\n    adjusted_learning_rate = eta / (np.sqrt(G) + epsilon)\n    theta = theta - adjusted_learning_rate * grad\n```\n\n在上述代码中：\n\n- `compute_gradient(theta)` 是一个函数，用于计算当前参数 `theta` 下的梯度。\n- `G` 是累积的梯度平方和，用于调整学习率。\n- 学习率会根据每个参数的梯度历史进行缩放，实现自适应。\n\n---\n\n# Adadelta 算法\n\n## 背景与动机\n\n`Adagrad` 在训练过程中，学习率会不断地缩小，可能导致后期学习率过小，无法继续优化。**Adadelta** 是对 `Adagrad` 的改进版，通过限制累积梯度的窗口大小，解决了 `Adagrad学习率不断衰减`的问题。此外，`Adadelta` 还消除了对初始学习率 $\\eta$ 的依赖。\n\n## 数学公式\n\n**Adadelta 的参数更新规则：**\n\n1. **梯度的指数加权平均（EWA）：**\n\n$$\nE[g^2]_t = \\rho E[g^2]_{t-1} + (1 - \\rho) [\\nabla_{\\theta_t} J(\\theta_t)]^2\n$$\n\n2. **计算参数更新量的期望平方：**\n\n$$\nE[\\Delta \\theta^2]_t = \\rho E[\\Delta \\theta^2]_{t-1} + (1 - \\rho) [\\Delta \\theta_t]^2\n$$\n\n3. **计算更新量：**\n\n$$\n\\Delta \\theta_t = - \\frac{\\sqrt{E[\\Delta \\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\nabla_{\\theta_t} J(\\theta_t)\n$$\n\n4. **更新参数：**\n\n$$\n\\theta_{t+1} = \\theta_t + \\Delta \\theta_t\n$$\n\n其中：\n\n- $E[g^2]_t$ 是梯度平方的指数加权平均。\n- $E[\\Delta \\theta^2]_t$ 是参数更新量平方的指数加权平均。\n- $\\rho$ 是衰减系数，通常取值为 0.9。\n- $\\epsilon$ 是防止除以零的微小常数。\n\n## 原理解析\n\n- **消除全局学习率依赖**：Adadelta 通过计算参数更新量的期望值，消除了对全局学习率 $\\eta$ 的依赖，实现了真正的自适应学习率。\n- **动态调整步长**：通过梯度和参数更新量的历史信息，自适应地调整更新步长，避免学习率过大或过小的问题。\n\n## Python 代码实现\n\n```python\nimport numpy as np\n\n# 参数初始化\ntheta = np.zeros((n_parameters,))\nE_grad = np.zeros_like(theta)        # 梯度平方的指数加权平均\nE_delta = np.zeros_like(theta)       # 参数更新量平方的指数加权平均\n\n# 超参数设置\nrho = 0.95\nepsilon = 1e-6\nnum_iterations = 1000\n\nfor t in range(1, num_iterations + 1):\n    grad = compute_gradient(theta)  # 计算梯度\n\n    # 更新梯度平方的指数加权平均\n    E_grad = rho * E_grad + (1 - rho) * grad ** 2\n\n    # 计算参数更新量\n    delta_theta = - (np.sqrt(E_delta + epsilon) / np.sqrt(E_grad + epsilon)) * grad\n\n    # 更新参数\n    theta = theta + delta_theta\n\n    # 更新参数更新量平方的指数加权平均\n    E_delta = rho * E_delta + (1 - rho) * delta_theta ** 2\n```\n\n---\n\n# RMSProp 算法\n\n## 背景与动机\n\n**RMSProp**（Root Mean Square Propagation）是 `Geoffrey Hinton` 提出的，用于解决 `Adagrad 学习率不断衰减`的问题，与 `Adadelta` 类似。`RMSProp` 通过对累积梯度平方和进行指数加权平均，限制了累积历史数据的窗口大小，从而保持学习率的稳定。\n\n##  数学公式\n\n**RMSProp 的参数更新规则：**\n\n1. **梯度平方的指数加权平均：**\n\n$$\nE[g^2]_t = \\rho E[g^2]_{t-1} + (1 - \\rho) [\\nabla_{\\theta_t} J(\\theta_t)]^2\n$$\n\n2. **更新参数：**\n\n$$\n\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\nabla_{\\theta_t} J(\\theta_t)\n$$\n\n其中：\n\n- $E[g^2]_t$ 是梯度平方的指数加权平均。\n- $\\eta$ 是全局学习率。\n- $\\rho$ 是衰减系数，通常取值为 0.9。\n- $\\epsilon$ 是防止除以零的微小常数。\n\n## 原理解析\n\n- **稳定学习率**：`RMSProp` 对梯度平方进行指数加权平均，避免了 `Adagrad` 中累积梯度平方和无限增大的问题，保持了学习率的稳定性。\n- **适用于非平稳目标**：通过限制累积历史梯度的窗口大小，`RMSProp` 能够在`非平稳目标`中保持稳定的学习率。\n\n## Python 代码实现\n\n```python\nimport numpy as np\n\n# 参数初始化\ntheta = np.zeros((n_parameters,))\nE_grad = np.zeros_like(theta)  # 梯度平方的指数加权平均\n\n# 超参数设置\neta = 0.001      # 学习率\nrho = 0.9\nepsilon = 1e-8\nnum_iterations = 1000\n\nfor t in range(1, num_iterations + 1):\n    grad = compute_gradient(theta)  # 计算梯度\n\n    # 更新梯度平方的指数加权平均\n    E_grad = rho * E_grad + (1 - rho) * grad ** 2\n\n    # 更新参数\n    theta = theta - (eta / (np.sqrt(E_grad) + epsilon)) * grad\n```\n\n---\n\n# 优化算法的比较\n\n| **算法**     | **更新规则**                                                 | **特点**                                                 |\n| ------------ | ------------------------------------------------------------ | -------------------------------------------------------- |\n| **Adagrad**  | $\\theta_{t+1} = \\theta_t - \\dfrac{\\eta}{\\sqrt{G_t + \\epsilon}} \\nabla_\\theta J(\\theta_t)$ | 自适应学习率，对稀疏数据效果好，但学习率不断衰减         |\n| **Adadelta** | $\\theta_{t+1} = \\theta_t + \\Delta \\theta_t$，其中 $\\Delta \\theta_t$ 的计算见上文 | 无需学习率参数，适应性强，解决了 Adagrad 的衰减问题      |\n| **RMSProp**  | $\\theta_{t+1} = \\theta_t - \\dfrac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\nabla_\\theta J(\\theta_t)$ | 对梯度平方进行指数加权平均，稳定学习率，适用于非平稳目标 |\n\n---\n\n# 参数的选择与注意事项\n\n- **学习率 $\\eta$**：\n\n  - 对于 Adagrad，$\\eta$ 通常设置较小，如 0.01。\n  - 对于 RMSProp，$\\eta$ 通常设置为 0.001。\n  - Adadelta 不需要指定全局学习率，这也是其优势之一。\n\n- **衰减系数 $\\rho$**：\n\n  - 通常取值为 0.9 到 0.95。\n  - $\\rho$ 越大，表示对过去梯度的记忆越长。\n\n- **$\\epsilon$ 的选择**：\n\n  - 一般设置为 $e^{-6}$ 或 $e^{-8}$，用于防止除以零。\n\n---\n\n# 总结\n\n- **Adagrad**：通过`累积梯度平方和`来适应每个参数的学习率，适合处理`稀疏数据`。然而，由于累积量不断增大，学习率会持续衰减，可能导致后期训练停滞。\n- **Adadelta**：对 `Adagrad` 的改进，通过使用`梯度`和`参数更新量`的`指数加权平均`，限制了累积窗口大小，避免了学习率过度衰减的问题，并且消除了对初始学习率的依赖。\n- **RMSProp**：与 `Adadelta` 类似，使用`梯度平方的指数加权平均`来调整学习率，保持了学习率的稳定性，适用于处理非平稳目标。\n\n如果结合`动量优化器`和 `RMSProp` 的优势，就可以得到目前深度学习训练的高效而强大的默认选择优化器：`Adam优化器`，具体可参考：\n\n{% postLinkCard ysibbt0p  \"auto\" %}\n","categories":["小小知识"]},{"title":"梯度下降优化器","url":"/2024/09/03/m6jm8qpi/","content":"\n梯度下降（`Gradient Descent`）是一种最常用的优化算法，广泛应用于机器学习和深度学习模型的训练中。它的主要目的是在参数空间中找到使损失函数最小化的参数集合。下面将详细介绍梯度下降的原理、公式以及Python中的代码实现。\n\n# 梯度下降的原理\n\n梯度下降是一种基于一阶导数的信息，沿着`负梯度方向`搜索最小值的迭代优化算法。直观上，可以将其想象成一个人在山坡上（损失函数表面）下山，每一步都按照当前位置的坡度（负梯度）选择下坡的方向，以达到最低点（全局最小值）。\n\n梯度下降的核心思想是：**在参数空间中，从初始点开始，沿着损失函数梯度的反方向迭代地更新参数，使得每一步都朝着使损失函数值减小的方向前进，直到达到损失函数的最小值或收敛于某个值**。\n\n# 梯度下降的数学公式\n\n假设我们有一个需要最小化的目标函数（损失函数）$J(\\theta)$，其中 $\\theta$ 是参数向量。\n\n梯度下降算法的更新规则为：\n\n$$\n\\theta^{(t+1)} = \\theta^{(t)} - \\alpha \\nabla J(\\theta^{(t)})\n$$\n其中：\n\n- $\\theta^{(t)}$ 表示第 $t$ 次迭代时的参数。\n- $\\alpha$ 是学习率（步长），决定了每次更新的幅度。\n- $\\nabla J(\\theta^{(t)})$ 是损失函数关于参数的梯度向量，在 $\\theta^{(t)}$ 处计算。\n\n梯度 $\\nabla J(\\theta)$ 表示函数在参数 $\\theta$ 处的导数向量，指向函数增长最快的方向。由于我们希望找到使损失函数最小化的参数，因此需要沿着负梯度方向更新参数。\n\n# 梯度下降的类型\n\n梯度下降根据使用的`数据量`不同，可以分为以下三种类型：\n\n1. **批量梯度下降（Batch Gradient Descent）**：\n\n   - 在每一次参数更新时，使用所有训练数据计算梯度。\n   - 更新规则：\n\n     $$\n     \\theta = \\theta - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\nabla J^{(i)}\\theta\n     $$\n     其中 $m$ 为训练样本总数。\n     \n   - 优点：方向更新稳定。\n   - 缺点：每次更新计算开销大，尤其是大数据集。\n   \n2. **随机梯度下降（Stochastic Gradient Descent, SGD）**：\n\n   - 在每一次参数更新时，仅使用一个样本计算梯度。\n   - 更新规则：\n\n     $$\n     \\theta = \\theta - \\alpha \\cdot \\nabla J^{(i)}\\theta\n     $$\n\n     \n\n   - 优点：计算速度快，能跳出局部最小值。\n   - 缺点：容易引起损失函数的波动，收敛路径不稳定。\n\n3. **小批量梯度下降（Mini-batch Gradient Descent）**：\n\n   - 在每一次参数更新时，使用一个小批量（batch）的样本计算梯度。\n   - 更新规则：\n\n     $$\n     \\theta = \\theta - \\alpha \\cdot \\frac{1}{b} \\sum_{i=1}^{b} \\nabla J^{(i)}\\theta\n     $$\n      其中 $b$ 是batch的大小。\n     \n- 综合了批量和随机梯度下降的优点，常用的`batch大小`为32、64、128等。\n\n# 梯度下降的收敛性与学习率\n\n学习率 $\\alpha$ 是梯度下降中的一个关键超参数，决定了每次参数更新的步长。\n\n- **学习率过大**：可能导致越过最优点，甚至导致发散。\n- **学习率过小**：收敛速度慢，可能陷入局部最小值或鞍点。\n\n因此，常常需要通过实验或使用自适应的学习率调整方法（如`Adagrad`、`RMSProp`、`Adam`等）来选择合适的学习率。\n\n# 梯度下降的Python代码实现\n\n以下以简单的线性回归为例，使用Python实现梯度下降算法。\n\n## 问题描述\n\n假设我们有一组一维数据点，想要拟合一条直线 $y = wx + b$，需要通过最小化均方误差（MSE）损失函数来求解参数 $w$ 和 $b$。\n\n损失函数：\n\n$$\nJ(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (y^{(i)} - (w x^{(i)} + b))^2\n$$\n\n## 实现步骤\n\n- 初始化参数 $w$ 和 $b$。\n- 定义损失函数 $J(w, b)$。\n- 计算损失函数对 $w$ 和 $b$ 的梯度。\n- 迭代更新参数，直到满足停止条件（如达到`最大迭代次数`或`损失函数收敛`）。\n\n## 代码实现\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 生成模拟数据\nnp.random.seed(42)\nm = 100  # 样本数量\nX = 2 * np.random.rand(m, 1)\ntrue_w = 3.5\ntrue_b = 1.2\ny = true_w * X + true_b + np.random.randn(m, 1)  # 添加一些噪声\n\n# 可视化数据\nplt.scatter(X, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()\n\n# 梯度下降算法实现\ndef gradient_descent(X, y, lr=0.1, n_iterations=1000):\n    m = len(y)\n    # 初始化参数\n    w = np.random.randn(1)\n    b = 0\n\n    loss_history = []\n\n    for iteration in range(n_iterations):\n        # 计算模型预测\n        y_pred = w * X + b\n        # 计算损失\n        loss = (1 / (2 * m)) * np.sum((y_pred - y) ** 2)\n        loss_history.append(loss)\n        # 计算梯度\n        dw = (1 / m) * np.sum((y_pred - y) * X)\n        db = (1 / m) * np.sum(y_pred - y)\n        # 更新参数\n        w = w - lr * dw\n        b = b - lr * db\n\n        if iteration % 100 == 0:\n            print(f\"Iteration {iteration}: Loss = {loss}, w = {w[0]}, b = {b}\")\n\n    return w, b, loss_history\n\n# 设置超参数\nlearning_rate = 0.1\nn_iters = 1000\n\n# 运行梯度下降\nw_opt, b_opt, loss_hist = gradient_descent(X, y, lr=learning_rate, n_iterations=n_iters)\n\nprint(f\"Optimized parameters: w = {w_opt[0]}, b = {b_opt}\")\n\n# 绘制损失函数变化\nplt.plot(loss_hist)\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss over iterations')\nplt.show()\n\n# 绘制拟合结果\nplt.scatter(X, y, label='Data')\nplt.plot(X, w_opt * X + b_opt, color='red', label='Fitted line')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n```\n\n## 代码解释\n\n输出：\n\n```bash\nIteration 0: Loss = 12.288322478218705, w = 0.5482405149791566, b = 0.4477958365103154\nIteration 100: Loss = 0.406609440292755, w = 3.141471680138024, b = 1.560792222398323\nIteration 200: Loss = 0.40340042917083907, w = 3.246885681182567, b = 1.4414032188965682\nIteration 300: Loss = 0.4032958078369932, w = 3.265919363304535, b = 1.419846193018257\nIteration 400: Loss = 0.40329239693466856, w = 3.2693561084441964, b = 1.4159538298150631\nIteration 500: Loss = 0.4032922857312052, w = 3.2699766513890296, b = 1.4152510199102504\nIteration 600: Loss = 0.40329228210570994, w = 3.2700886973891645, b = 1.4151241196862692\nIteration 700: Loss = 0.4032922819875102, w = 3.2701089285532627, b = 1.4151012064251764\nIteration 800: Loss = 0.4032922819836566, w = 3.270112581517226, b = 1.4150970691784694\nIteration 900: Loss = 0.40329228198353106, w = 3.2701132411009084, b = 1.415096322152097\nOptimized parameters: w = 3.270113359743099, b = 1.4150961877812085\n```\n\n- **数据生成部分**：模拟生成一组线性关系的数据，并添加了噪声。\n\n- **`gradient_descent` 函数**：实现梯度下降算法，包含参数初始化、损失计算、梯度计算和参数更新。\n\n- **参数更新规则**：\n\n  $$\n  \\begin{cases}\n  w = w - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} (w x^{(i)} + b - y^{(i)}) x^{(i)} \\\\\n  b = b - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} (w x^{(i)} + b - y^{(i)})\n  \\end{cases}\n  $$\n\n- **结果可视化**：绘制损失函数随迭代次数的下降曲线，以及最终拟合的直线与原始数据的对比。\n\n<div style=\"display: flex; gap: 30px;\"><img src=\"/images/assets//image-20241215191141713.png\" width=\"240\"><img src=\"/images/assets//image-20241215191208453.png\" width=\"240\"><img src=\"/images/assets//image-20241215191239632.png\" width=\"240\"></div>\n\n## 结果分析\n\n运行上述可视化图，可以观察到：\n\n- 损失函数随着迭代次数的增加逐渐减小，算法收敛。\n- 最终得到的参数 $w$ 和 $b$ 与真实参数接近。\n- 拟合的直线较好地描述了数据的分布。\n\n# 总结\n\n梯度下降作为一种基础的优化算法，具有简单易实现的特点，但在实际应用中也存在一些缺点，例如收敛速度慢、容易陷入局部最小值、对学习率敏感等。为了提高算法性能，出现了许多改进算法，如动量法、自适应学习率方法等。可参考：\n\n{% postLinkCard ti2a4z75  \"auto\" %}\n\n{% postLinkCard u9c9ki5q  \"auto\" %}\n\n{% postLinkCard ysibbt0p  \"auto\" %}\n","categories":["小小知识"]},{"title":"优化器和损失函数","url":"/2024/09/01/nyeno8kr/","content":"\n在深度学习和机器学习中，`优化器`和`损失函数`是模型训练的核心要素。\n\n- 优化器决定了模型的参数如何更新，以最小化损失函数\n- 损失函数度量了模型预测值和真实值之间的差异\n\n下面将详细介绍常用的优化器和损失函数。\n\n---\n\n# 优化器（Optimizers）\n\n## 梯度下降（Gradient Descent，GD）\n\n**原理：**\n\n梯度下降是最基本的优化算法。其核心思想是在参数空间中沿着损失函数梯度的反方向移动，以找到损失函数的最小值。\n\n**公式：**\n\n$$\n\\theta = \\theta - \\alpha \\cdot \\nabla_{\\theta} J(\\theta)\n$$\n\n- $\\theta$：模型参数\n- $\\alpha$：学习率（步长）\n- $\\nabla_{\\theta} J(\\theta)$：损失函数关于参数的梯度\n\n**特点：**\n\n- 需要遍历整个训练集，计算量大，收敛速度慢。\n- 适用于小规模数据集。\n\n## 随机梯度下降（Stochastic Gradient Descent，SGD）\n\n**原理：**\n\n为了加速计算，每次随机抽取一个样本计算梯度，更新参数。\n\n**公式：**\n\n$$\n\\theta = \\theta - \\alpha \\cdot \\nabla_{\\theta} J(\\theta; x^{(i)}; y^{(i)})\n$$\n\n- $x^{(i)}, y^{(i)}$：第 $i$ 个样本的数据和标签\n\n**特点：**\n\n- 更新频率高，计算速度快。\n- 更新方向噪声大，可能导致收敛不稳定。\n\n## 小批量梯度下降（Mini-batch Gradient Descent）\n\n**原理：**\n\n在每次更新时，使用一个小批量（batch）的样本计算梯度，折中批量和随机的优点。\n\n**特点：**\n\n- 平衡了计算效率和收敛稳定性。\n- 通常是深度学习中最常用的优化方式。\n\n## 动量（Momentum）\n\n**原理：**\n\n引入动量的概念，结合过去梯度的指数加权平均，更新时不仅考虑当前梯度，还考虑过去梯度的累积。\n\n**公式：**\n\n$$\nv = \\beta v + (1 - \\beta) \\nabla_{\\theta} J(\\theta)\n$$\n\n$$\n\\theta = \\theta - \\alpha v\n$$\n\n- $v$：速度（动量项）\n- $\\beta$：动量系数，通常取值接近1（如0.9）\n\n**特点：**\n\n- 能够加速收敛，减少震荡。\n- 对于鞍点和局部极小值有更好的越过能力。\n\n## Nesterov加速梯度（Nesterov Accelerated Gradient，NAG）\n\n**原理：**\n\n在动量的基础上，先对参数进行一个预估，然后计算梯度，提供更精确的更新方向。\n\n**公式：**\n\n$$\nv = \\beta v + \\alpha \\nabla_{\\theta} J(\\theta - \\beta v)\n$$\n\n$$\n\\theta = \\theta - v\n$$\n\n**特点：**\n\n- 比标准动量方法有更快的收敛速度。\n- 能够更加准确地调整方向，避免过冲。\n\n## Adagrad（Adaptive Gradient）\n\n**原理：**\n\n根据参数的历史梯度平方和自适应地调整学习率，参数的更新步长与过去的梯度相关。\n\n**公式：**\n\n$$\nr_t = r_{t-1} + \\nabla_{\\theta} J(\\theta)_t^2\n$$\n\n$$\n\\theta = \\theta - \\frac{\\alpha}{\\sqrt{r_t} + \\epsilon} \\nabla_{\\theta} J(\\theta)\n$$\n\n- $r_t$：历史梯度的累计平方和\n- $\\epsilon$：防止除零的小常数\n\n**特点：**\n\n- 对于稀疏数据有优势，能自动适应学习率。\n- 学习率单调递减，可能在训练后期过小无法更新。\n\n## Adadelta\n\n**原理：**\n\n对Adagrad的改进，使用窗口内的梯度平方和，避免累积量无限增长。\n\n**公式：**\n\n$$\nE[g^2]_t = \\rho E[g^2]_{t-1} + (1 - \\rho) \\nabla_{\\theta} J(\\theta)_t^2\n$$\n\n$$\n\\Delta \\theta = - \\frac{\\sqrt{E[\\Delta \\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\nabla_{\\theta} J(\\theta)\n$$\n\n$$\nE[\\Delta \\theta^2]_t = \\rho E[\\Delta \\theta^2]_{t-1} + (1 - \\rho) (\\Delta \\theta_t)^2\n$$\n\n**特点：**\n\n- 不需要手动设置全局学习率。\n- 能够适应学习率，但计算复杂度增加。\n\n## RMSProp\n\n**原理：**\n\n与Adadelta类似，采用指数加权移动平均的方法来调整学习率。\n\n**公式：**\n\n$$\nE[g^2]_t = \\beta E[g^2]_{t-1} + (1 - \\beta) \\nabla_{\\theta} J(\\theta)_t^2\n$$\n\n$$\n\\theta = \\theta - \\frac{\\alpha}{\\sqrt{E[g^2]_t} + \\epsilon} \\nabla_{\\theta} J(\\theta)\n$$\n\n**特点：**\n\n- 适用于非平稳目标，能处理学习率的调整。\n- 是深度学习中常用的优化器之一。\n\n## Adam（Adaptive Moment Estimation）\n\n**原理：**\n\n结合了动量和RMSProp的思想，既考虑梯度的一阶矩（动量），也考虑二阶矩（梯度平方）。\n\n**公式：**\n\n- 梯度的一阶矩估计：\n\n  $$\n  m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_{\\theta} J(\\theta)_t\n  $$\n\n- 梯度的二阶矩估计：\n\n  $$\n  v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla_{\\theta} J(\\theta)_t)^2\n  $$\n\n- 偏差修正：\n\n  $$\n  \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n  $$\n\n  $$\n  \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n  $$\n\n- 参数更新：\n\n  $$\n  \\theta = \\theta - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n  $$\n\n**特点：**\n\n- 适用于大规模数据和参数的优化。\n- 效果稳定，收敛速度快，是目前最常用的优化器之一。\n\n## Adamax\n\n**原理：**\n\nAdam的变体，使用无偏估计的无穷范数来替代二阶矩。\n\n**公式：**\n\n$$\nu_t = \\max(\\beta_2 u_{t-1}, |\\nabla_{\\theta} J(\\theta)_t|)\n$$\n\n$$\n\\theta = \\theta - \\frac{\\alpha}{u_t + \\epsilon} m_t\n$$\n\n**特点：**\n\n- 对于某些问题，Adamax比Adam表现更好。\n- 能够处理稀疏梯度。\n\n## Nadam（Nesterov-accelerated Adam）\n\n**原理：**\n\n结合了NAG和Adam的思想，在Adam的基础上加入Nesterov动量。\n\n**公式：**\n\n更新方式类似于Adam，但在计算动量时采用了Nesterov加速。\n\n**特点：**\n\n- 比Adam有更好的收敛性能。\n- 能够更快地达到最优解。\n\n## AMSGrad\n\n**原理：**\n\n针对Adam可能不收敛的问题，提出了AMSGrad，通过在更新中引入了历史最大二阶矩。\n\n**公式：**\n\n$$\nv_t' = \\max(v_{t-1}', v_t)\n$$\n\n$$\n\\theta = \\theta - \\alpha \\frac{m_t}{\\sqrt{v_t'} + \\epsilon}\n$$\n\n**特点：**\n\n- 改进了Adam的收敛性。\n- 在某些情况下有更好的性能。\n\n## 参考链接\n\n如果要详细了解这些优化器的原理，代码实现等，可参考：\n\n{% postLinkCard m6jm8qpi  \"auto\" %}\n\n{% postLinkCard ti2a4z75  \"auto\" %}\n\n{% postLinkCard u9c9ki5q  \"auto\" %}\n\n{% postLinkCard ysibbt0p  \"auto\" %}\n\n# 损失函数（Loss Functions）\n\n## 均方误差（Mean Squared Error，MSE）\n\n**定义：**\n\n计算预测值和真实值之差的平方和的平均值。\n\n**公式：**\n\n$$\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n$$\n\n**特点：**\n\n- 对异常值敏感，误差平方会放大偏差大的样本的影响。\n- 常用于回归问题。\n\n## 平均绝对误差（Mean Absolute Error，MAE）\n\n**定义：**\n\n计算预测值和真实值之差的绝对值的平均值。\n\n**公式：**\n\n$$\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n$$\n\n**特点：**\n\n- 对异常值不如MSE敏感。\n- 反映误差的平均大小。\n\n## 交叉熵损失（Cross-Entropy Loss）\n\n**定义：**\n\n衡量两个概率分布之间的差异，常用于分类问题。\n\n**二分类交叉熵：**\n\n$$\n\\text{Loss} = - \\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log \\hat{y}_i + (1 - y_i) \\log (1 - \\hat{y}_i)]\n$$\n\n**多分类交叉熵：**\n\n$$\n\\text{Loss} = - \\sum_{i=1}^{n} \\sum_{j=1}^{k} y_{ij} \\log \\hat{y}_{ij}\n$$\n\n- $k$：类别数\n\n**特点：**\n\n- 当预测概率接近真实标签时，损失较小。\n- 对于分类问题，能够更好地衡量模型性能。\n\n## Hinge损失\n\n**定义：**\n\n主要用于支持向量机（SVM），用于最大化分类间隔。\n\n**公式：**\n\n$$\n\\text{Loss} = \\sum_{i=1}^{n} \\max(0, 1 - y_i \\hat{y}_i)\n$$\n\n- $y_i$：真实标签，取值为$-1$或$1$\n- $\\hat{y}_i$：预测值\n\n**特点：**\n\n- 强调正确分类的同时有足够的间隔。\n- 对于硬分类（hard margin）问题效果较好。\n\n## Huber损失\n\n**定义：**\n\n结合MSE和MAE的优点，对异常值有一定的鲁棒性。\n\n**公式：**\n\n对于误差$\\delta$：\n\n- 当$|y - \\hat{y}| \\leq \\delta$时：\n\n  $$\n  \\text{Loss} = \\frac{1}{2} (y - \\hat{y})^2\n  $$\n\n- 当$|y - \\hat{y}| > \\delta$时：\n\n  $$\n  \\text{Loss} = \\delta (|y - \\hat{y}| - \\frac{1}{2} \\delta)\n  $$\n\n**特点：**\n\n- 对小误差采用MSE，对大误差采用MAE。\n- 平衡了对异常值的敏感性和收敛速度。\n\n## Log-Cosh损失\n\n**定义：**\n\n计算预测误差的双曲余弦的对数，总是平滑且对异常值不太敏感。\n\n**公式：**\n\n$$\n\\text{Loss} = \\sum_{i=1}^{n} \\log (\\cosh(\\hat{y}_i - y_i))\n$$\n\n**特点：**\n\n- 类似于MSE，但对异常值更鲁棒。\n- 导数行为良好，方便优化。\n\n## Poisson损失\n\n**定义：**\n\n用于计数数据的模型，如泊松回归。\n\n**公式：**\n\n$$\n\\text{Loss} = \\sum_{i=1}^{n} (\\hat{y}_i - y_i \\log \\hat{y}_i)\n$$\n\n**特点：**\n\n- 适用于预测事件发生次数的问题。\n- 假设预测值为正。\n\n## Kullback-Leibler散度（KL散度）损失\n\n**定义：**\n\n衡量两个概率分布之间的差异。\n\n**公式：**\n\n$$\n\\text{Loss} = \\sum_{i=1}^{n} y_i (\\log y_i - \\log \\hat{y}_i)\n$$\n\n**特点：**\n\n- 在概率分布估计中常用。\n- 非对称，$D_{\\text{KL}}(P||Q) \\neq D_{\\text{KL}}(Q||P)$。\n\n## Sigmoid交叉熵损失\n\n**定义：**\n\n结合Sigmoid函数和交叉熵，用于多标签分类问题。\n\n**公式：**\n\n$$\n\\text{Loss} = - \\sum_{i=1}^{n} [y_i \\log \\sigma(\\hat{y}_i) + (1 - y_i) \\log (1 - \\sigma(\\hat{y}_i))]\n$$\n\n- $\\sigma(\\hat{y}_i)$：Sigmoid函数\n\n**特点：**\n\n- 适用于每个样本可能属于多个类别的情况。\n- 将每个类别的预测视为独立的二分类问题。\n\n## Softmax交叉熵损失\n\n**定义：**\n\n结合Softmax函数和交叉熵，用于多分类问题。\n\n**公式：**\n\n$$\n\\text{Loss} = - \\sum_{i=1}^{n} \\sum_{j=1}^{k} y_{ij} \\log \\left( \\frac{e^{\\hat{y}_{ij}}}{\\sum_{l=1}^{k} e^{\\hat{y}_{il}}} \\right)\n$$\n\n**特点：**\n\n- 能够处理多类别互斥的情况。\n- 模型输出经过Softmax后表示为概率分布。\n\n---\n\n# 总结\n\n优化器和损失函数的选择对于模型的训练效果至关重要。优化器决定了参数更新的方式，影响模型的收敛速度和收敛效果；损失函数则定义了模型的优化目标，影响模型对误差的敏感性和预测精度。在实际应用中，需要根据具体的问题特性、数据规模和模型结构，选择合适的优化器和损失函数，以达到最佳的训练效果。\n","categories":["小小知识"]},{"title":"QQ/微信批量发送自定义新年祝福2.0版本！","url":"/2023/12/18/etv5ffjj/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard QQ/微信批量发送自定义新年祝福2.0版本！ https://mp.weixin.qq.com/s/yAC_d-lrQeaB6ZocaN_Dfw /images/wechat.jpg %}","categories":["Python"]},{"title":"长沙---相亲数据爬取教程","url":"/2023/11/20/7rldprc2/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard  长沙---相亲数据爬取教程 https://mp.weixin.qq.com/s/YEeo3cXKQTUzLr9nYUQ_tA /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"长沙最新相亲数据揭秘！","url":"/2023/11/20/kddlbfj6/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 长沙最新相亲数据揭秘！ https://mp.weixin.qq.com/s/xkB_b0LzGOw6rX6ZdNCbRQ  /images/wechat.jpg %}","categories":["Python"]},{"title":"AI---引领者---文心一言---初体验！","url":"/2023/11/02/zuxtytxt/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard AI---引领者---文心一言---初体验！  https://mp.weixin.qq.com/s/zfsafnPdDOLLEk3jjjSX7g /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"万物皆可爬之-----mhy你好呀！","url":"/2023/07/18/omewvjj2/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 万物皆可爬之-----mhy你好呀！ https://mp.weixin.qq.com/s/Pk3jQUWAZVFY9MdLFyMcTA /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"24考研的我......能通过初试吗？","url":"/2023/04/02/ippex6hn/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 24考研的我......能通过初试吗？ https://mp.weixin.qq.com/s/vE3OesVXaZtHZ5ON_DyAEw  /images/wechat.jpg %}","categories":["Python"]},{"title":"今天你emo了吗？--- 网易云emo评论爬取","url":"/2023/03/31/aylspiub/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 今天你emo了吗？--- 网易云emo评论爬取 https://mp.weixin.qq.com/s/KCS3U092mBGQk_2eICp4HA?poc_token=HA4PU2ej-hkn4ITIC-sVAgPfofbr9cIHTDdBwbvh /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"AI“横行”的今天，我们将何去何从？","url":"/2023/03/25/g6ibh000/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard AI“横行”的今天，我们将何去何从？ https://mp.weixin.qq.com/s/PW8qOqTHJ27rhq-ScajljQ  /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"Python打工记：论绘制词云图的五重境界","url":"/2023/03/20/r8op3xi6/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard Python打工记：论绘制词云图的五重境界 https://mp.weixin.qq.com/s/GqL21VS0kTKwGqBaaALQFQ /images/wechat.jpg %}","categories":["Python"]},{"title":"stylecloud词云图模版爬取","url":"/2023/03/20/xmahi0fd/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard stylecloud词云图模版爬取 https://mp.weixin.qq.com/s/zDWj4uWFj9fX7NHVc2_RTQ /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"你可能真的不会用baidu！","url":"/2023/03/02/mqqa55yl/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 你可能真的不会用baidu！ https://mp.weixin.qq.com/s/INDOADuxC_orexxZ31krdw  /images/wechat.jpg %}","categories":["科技杂谈"]},{"title":"ChatGPT进阶用法之---Cosplay我最强","url":"/2023/02/19/1e2erdhe/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard ChatGPT进阶用法之---Cosplay我最强 https://mp.weixin.qq.com/s/4AB0wZYEYgFy4-QQ40XIQw /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"故事新编之---我在人间的日子","url":"/2023/02/12/rsniaqvf/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 故事新编之---我在人间的日子 https://mp.weixin.qq.com/s/z0qa2iCWRolAgOvfE0P9VA  /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"超级好玩的API接口，你知道哪些呢？","url":"/2023/02/05/9nz0zbs4/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 超级好玩的API接口，你知道哪些呢？ https://mp.weixin.qq.com/s/9j2K5bp9mBTXOhIONRTZKQ /images/wechat.jpg %}","categories":["科技杂谈"]},{"title":"且看我以假乱真～(●''●)","url":"/2023/01/24/zqik298o/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 且看我以假乱真～(●''●) https://mp.weixin.qq.com/s/LqvgS41B8hwxBHGg4ohjTQ  /images/wechat.jpg %}","categories":["Python"]},{"title":"Python打工记：给QQ好友批量发送新年祝福语","url":"/2023/01/13/hrc28f59/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard Python打工记：给QQ好友批量发送新年祝福语 https://mp.weixin.qq.com/s/-s3I29uVrj5f7sAWoenoCg /images/wechat.jpg %}","categories":["Python"]},{"title":"ChatGPT，我愿称之为神","url":"/2023/01/02/i34quuh3/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard ChatGPT，我愿称之为神 https://mp.weixin.qq.com/s/WBcDDjWOKsxeg9rNxAm84g /images/wechat.jpg %}","categories":["科技杂谈","AI工具"]},{"title":"忆2022","url":"/2022/12/31/yg4kmt8a/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 忆2022 https://mp.weixin.qq.com/s/sKvNH62dyYZQsVjjl0zy_A  /images/wechat.jpg %}","categories":["有感而发"]},{"title":"七夕啦～专属程序员们的浪漫～～～","url":"/2022/08/04/otv2j290/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 七夕啦～专属程序员们的浪漫～～～ https://mp.weixin.qq.com/s/C6bpAi6yaL3cPat0SYp93w /images/wechat.jpg %}","tags":["CSS","HTML"]},{"title":"二维码，你真的认识它吗？","url":"/2022/05/16/nhlh5qhv/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 二维码，你真的认识它吗？ https://mp.weixin.qq.com/s/up5I9GOanwXx9RgKV2PbNg /images/wechat.jpg %}","categories":["科技杂谈"]},{"title":"QQ，永远的回忆！","url":"/2022/04/20/z6l1gagw/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard QQ，永远的回忆！ https://mp.weixin.qq.com/s/ZS0LvxcVxiQikeZAYM_Krg  /images/wechat.jpg %}","categories":["科技杂谈"]},{"title":"Python：你好，酷狗","url":"/2022/04/12/84qev7l2/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard Python：你好，酷狗 https://mp.weixin.qq.com/s/UvyIayW93GDs5VurgewzLQ  /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"听说you-get和python更配？","url":"/2022/04/08/mnq371jx/","content":"\n小小白公众号：「胡扯王国」\n\n微信公众号文章：\n\n{% externalLinkCard 听说you-get和python更配？ https://mp.weixin.qq.com/s/9Eb77CZpl6kuIrf2F55MTw /images/wechat.jpg %}","categories":["Python","爬虫"]},{"title":"B站视频弹幕提取","url":"/2022/03/31/j347xv4l/","content":"\n# 前言\n\n全网都在追的2022年新剧《开端》🤣......不会有人看了几十分钟的弹幕吧......我想了想，看弹幕不太方便，所以干脆爬下来......\n\n# 网页分析\n\n在`b站`，很容易找到弹幕的接口：\n\n> https://api.bilibili.com/x/v1/dm/list.so?oid={oid/cid} \n\n这个接口需要一个参数`oid`，这其实是`b站`的每个视频的独一无二的编号，怎么搞到这个编号呢？\n\n我们来瞧瞧`b站`随便一个视频的`url地址`： ![watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5piT5p6c5ZWl56yU,size_20,color_FFFFFF,t_70,g_se,x_16](images/assets/46d392614ad11419d6a9b837c851bf27-20241206160548801.png)\n\n其实，`b站`每个视频的`URL`中都有一串`bvid`字符编号，比如`BV1wq4y1C785`，通过这个`bvid编号`，我们可以轻松获得视频对应的`oid编号`，这是因为......`b站`又给我们提供了一个另一个接口：\n\n>  https://api.bilibili.com/x/player/pagelist?bvid=BV1wq4y1C785\n\n如上，我们将这串字符输进去，在浏览器中输入回车，看到以下结果：\n\n![watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5piT5p6c5ZWl56yU,size_20,color_FFFFFF,t_70,g_se,x_16](/images/assets/ac52226250a191a8d35f1ac9f2347443-20241206160548572.png)可以看到`b站服务器`返回的`response`是一个`json格式`的文本，里面有一个`键cid`，它的值就是我们想要的`cid编号`。将此编号输入前述的弹幕接口地址中：\n\n> https://api.bilibili.com/x/v1/dm/list.so?oid=489314781\n\n浏览器打开，可以看到如下结果：\n\n ![watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5piT5p6c5ZWl56yU,size_20,color_FFFFFF,t_70,g_se,x_16](/images/assets/0315020edb56939162fbbeb9556e21db-20241206160548783.png)\n\n由此看出，咱可爱的`b站`把弹幕集中放在了一个xml文件中......从这个文件中提取弹幕不算太难，可以使用正则提取。此外， 我们关注的还有弹幕发布的时间，其实xml文件中有，只不过不太明显.......\n\n> 1642863060\n\n这是一个用Unix时间戳表示的时间，简单来说就是`从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数（不考虑闰秒）`，至于如何计算，就交给Python吧。\n\n# 代码编写\n\n准备工作完毕，我们就开始爬了，这个爬虫非常容易，使用`requests库`即可完成：\n\n```python\nimport re\nimport time\nimport requests\nimport json\n\n\ndef get_comments(bvid):\n    \"\"\"\n    通过视频的bvid获得视频的cid\n    输入：视频的bvid\n    输出：弹幕发布时间及弹幕内容\n    \"\"\"\n    url = 'https://api.bilibili.com/x/player/pagelist?bvid=%s' % bvid\n    res = requests.get(url)\n    # 获取cid编号\n    cid = res.json()['data'][0]['cid']\n\n    # 通过https://api.bilibili.com/x/v1/dm/list.so?oid= 接口获得包含弹幕的xml文件\n    url = 'https://api.bilibili.com/x/v1/dm/list.so?oid=%d' % cid\n    res = requests.get(url)\n    res.encoding = 'utf-8'\n    text = res.text\n\n    result = []  # 用于存储解析结果\n    # 用正则表达式提取\n    comments = re.findall('<d p=\"(.*?)\">(.*?)</d>', text)\n    for comment in comments:\n        item = {}  # 每条弹幕数据\n        # <p>标签的第五个数据为时间戳，使用time库处理为友好的格式\n        comment_date = int(comment[0].split(',')[4])  \n        item['评论时间'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(comment_date))\n        item['弹幕内容'] = comment[1]\n        result.append(item)\n    # 为了便于观看，转化为json\n    comments_json = json.dumps(result, indent=0, ensure_ascii=False)\n    return comments_json\n\n\nif __name__ == '__main__':\n    # 随便传入一个b站的bvid即可：\n    comments = get_comments(\"BV1y34y1B7q9\")  # 解析弹幕\n    print(comments)\n```\n\n# 运行程序\n\n跑一下，结果如下（部分）：\n\n![watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5piT5p6c5ZWl56yU,size_20,color_FFFFFF,t_70,g_se,x_16](/images/assets/3acc0059d5b3015889334bee48b5529b-20241206160548672.png)\n\n# 使用scrapy实现\n\n习惯使用`scrapy框架`的小伙伴们，也可以使用`scrapy`实现（当然有点大材小用了）：\n\n```python\nimport time\nimport scrapy\nimport re\n\n\nclass KaiduanSpider(scrapy.Spider):\n    name = 'kaiduan'\n    allowed_domains = ['api.bilibili.com']\n    start_urls = [\n        'https://api.bilibili.com/x/player/pagelist?bvid=BV1wq4y1C785',\n    ]\n\n    def parse(self, response):\n        cid = re.findall('\"cid\":(d+)', response.body.decode())[0]\n        yield scrapy.Request(\n            'https://api.bilibili.com/x/v1/dm/list.so?oid=' + cid,\n            callback=self.parse_comments\n        )\n\n    def parse_comments(self, response):\n        \"\"\"\n            解析视频弹幕\n            输入：视频弹幕的原数据\n            输出：弹幕的解析结果\n        \"\"\"\n        # 用正则表达式提取\n        comments = re.findall('<d p=\"(.*?)\">(.*?)</d>', response.text)\n        for comment in comments:\n            item = {}  # 每条弹幕数据\n            # <p>标签的第五个数据为时间戳\n            comment_date = int(comment[0].split(',')[4])  \n            item['评论时间'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(comment_date))\n            item['弹幕内容'] = comment[1]\n            yield item\n```\n\n终端运行程序，输入命令 `scrapy crawl kaiduan -o comments.csv`回车，运行完之后，得到如下`csv文件`：    ![watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5piT5p6c5ZWl56yU,size_20,color_FFFFFF,t_70,g_se,x_16](/images/assets/cbab2792b1d8541f808929a652e1de8c-20241206160548826.png)哈哈，是不是挺有乐趣的呢？ \n","categories":["Python","爬虫"]},{"title":"selenium爬取图片的保姆级教程","url":"/2022/03/30/0jh1h2dc/","content":"\n# 前言\n\n现在疫情当前，卑微的我只能乖乖的宅在家里敲代码了🙁。之前有朋友让我帮他在网上下载一些图片，那几千张图片手动一个一个下载显然不太实际。所以搬出我们的重量级工具：\n\n> 人生苦短，我用python\n\n就个人使用体验来说，用`python`批量下载图片确实要比手动下载快得多，但这一切的前提是建立在你有一定的爬虫基础之上，如果基础不够，就像我刚开始学的那样，折腾了一两个小时还没有手动下载的快。但是，这是每个人都必须要经历的一个过程，谁一开始不是个小白呢？\n\n🤣着实无聊，所以我顺便也把爬取的过程记录了下来。作成此篇。\n\n笔者的专业不是爬虫，所以也用不到什么非常专业的理论技术。只是一些比较简单的库或者框架而已。对于爬虫，就学习生活上的问题而言，我们只需了解 **Python+requests+selenium** 这三个组合就完全够用了。总结说来，笔者所遇到的爬虫问题，大多可以分为以下三类：\n\n# 纯Html静态页面\n\n这种页面是一种最为简单的页面。简单来说，纯`Html`静态页面未使用`js渲染`，而浏览器一次性渲染得到的纯`Html文`本，只需简单的`xml定位`即可获取对应信息，使用`Python`的**requests**库即可搞定。\n\n# 渲染动态页面\n\n页面采用`js`动态渲染，是部分网站应对爬虫的举措之一。什么是`js渲染动态页面`呢？简单举个例子，网易云音乐。如果网页允许使用`js渲染`，则网易云的官网长这个样子：\n\n![img](/images/assets/81c501722de9010c26123883a7cc855f.png)\n\n`谷歌浏览器`提供了一个有用的插件 ----- **Toggle JavaScript**，使用它可以禁止网页使用`js`进行渲染，我们来看看禁用`js`后的网易云页面（注意右上角的按钮）：\n\n![img](/images/assets/f60026df6a88045ebfda42c66eea4c47.png)\n\n一旦禁用`js`，你看到的只是其官网上的一些静态`Html元素`，而往往这些元素对我们没有用处。这说明网页上对我们有用的信息，大多都是通过`js`实时渲染出来的，因而这类信息的爬取，**requests**库就无能为力了。\n\n再如，图片类网站，我们的鼠标不断往下滑的时候，图片也慢慢地增加并显示，这种页面，显然不可能是静态的，也无法用**requests**库爬取。\n\n所谓魔高一尺道高一丈，自动化测试工具 **selenium**可以帮助我们解决这个问题。当然这个工具的主要应用领域不在爬虫，但我们仍然可以使用它来帮助我们渲染`js`页面。\n\n# Ajax请求数据\n\n学过前端的小伙伴们应该很清楚，前端页面上的数据，大多需要从`后端服务器`上获取，一般使用**Ajax请求**，而且，这些通过`Ajax请求`从后端获得的数据往往正是我们所需要的。\n\n就如我之前写的批量爬取四六级成绩文章，里面的爬虫程序其实非常简单 ，就访问了一个接口而已：\n\n> http://cachecloud.neea.cn/api/latest/results/cet?e=CET_202112_DANGCI&km=2&xm=%E7%BD%97%E9%A2%96&no=4311...&v=\n\n访问类似这种的接口，其服务器的响应大多是以`json串`或者`xml数据`的格式，其中就包含着我们想要的数据。\n\n这种接口一般是网站提供的，由于前端页面的数据填充展示过程中需要用到这个接口返回的数据，因此这个接口往往都是开放的，我们可以访问，爬虫程序当然也可以（部分网站为了`反爬`，会混淆接口参数） 。\n\n所以，这种类型的爬虫程序，难点不在于代码编写（使用**requests**库即可实现），而在于如何找到这种接口，即`分析页面`的过程。\n\n当然，在实际的爬取过程中，也许会同时用到上面的`两种或者三种`，这需要我们灵活运用。\n\n# 爬取百度图片\n\n下面开始我们的正片.....今天来爬取`百度图片`。百度输入“图片” ：\n\n![img](/images/assets/085cf7669181ccc94050ea4f9f30970b.png)\n\n进入第一个搜索结果，图片尺寸选择特大尺寸（注意图片尺寸那里，不同的尺寸选择得到的`url地址`不同，说明是不同页面)： \n\n![img](/images/assets/2cdeb3c86938d9ad1c6a3846bd52bedc.png)\n\n我们针对百度图片中的“`特大尺寸`”的图片进行爬取 。单击搜索地址栏，可以看到此页面完整的`url地址`：\n\n> https://image.baidu.com/search/index?ct=201326592&z=9&tn=baiduimage&word=图片&pn=&spn=&ie=utf-8&oe=utf-8&cl=2&lm=-1&fr=ala&se=&sme=&width=0&height=0&cs=&os=&objurl=&di=&gsm=1e&dyTabStr=MCwzLDYsMSw0LDIsNSw3LDgsOQ%3D%3D\n\n这就是我们待会要爬取的入口页面地址。\n\n## selenium安装\n\n之前提到过，这种图片页面往下滑会不断的更新出图片，我们猜测这应该是个`动态页面`。事实上，如果`禁用js`，你会发现页面直接跳转到了百度图片网站的首页，这说明，刚看到的整个页面都是由`js渲染`出来的.....所以**requests**库就无能为力了......需要用到**selenium**。\n\n关于`selenium`的安装和使用，本文就不再介绍了。网上的教程讲的都非常详细......比如这位大佬：\n\n> [selenium用法详解【从入门到实战】【Python爬虫】【4万字】](https://blog.csdn.net/qq_43965708/article/details/120658713)\n>\n> **selenium**是最广泛使用的开源 Web UI（用户界面）自动化测试套件之一。Selenium 支持的语言包括C#，Java，Perl，PHP，Python 和 Ruby。目前，Selenium Web 驱动程序最受 Python 和 C＃欢迎。 \n\n依据此博文的步骤，安装**selenium**驱动后，再下载`python`的**selenium**支持库：\n\n> pip install selenium\n\n安装完成之后，就可以开始使用了。\n\n## 分析页面\n\n分析页面除了一些基本的工具和技巧之外呢，大部分都是**熟能生巧**，当爬的多了，自然就能猜到大概应该怎么去分析。\n\n比如，图片的这种展示，有很多张，我们最为直观的猜测便是，一张图片放在一个 **li** 标签里。因此我们在分析网页的时候，会更加关注 **li** 标签。\n\n再比如，平台上的评论数据一般都会提供一个接口供访问，找到接口就已经解决一半的问题了。\n\n利用`谷歌浏览器`自带的`开发者工具`（按`F12`弹出，对网页的分析，基本上都需要这个），我们随便找一张图片，右键点击“`检查`”，就能迅速定位到图片元素所在的`Html标签`：\n\n![img](/images/assets/d02dafec02153d9c1f6490b9d1da6663.png)\n\n很容易找到这张图片的`url地址`（`img标签`的`src属性`） ，同时，每张图片下面还有一段文字说明，我们就用这段文字来命名这张图片。\n\n这样看来，我们还需要爬取图片下面的那段文字，可以使用图片同样的方法，右键文字段处点击“`检查`”，定位到文字元素所在的`Html标签`，不过那段文字在`Html文本`中出现的地方有很多，我们随便取一个，比如：\n\n![img](/images/assets/ceb4a0c9b9e52f41d20ad69830187bcd.png)\n\n这段`Html源码`印证了我们之前的猜测 ------- 一张图片放在一个 **li** 标签里。而且不止图片，它下面的文字段也包含在对应的 **li** 标签里。\n\n这样，我们对要爬取的内容就有了一个直观的了解。\n\n## XPath Helper\n\n一般而言，Html标签元素的定位使用的大多是`xpath`或者`css表达式`，这是爬虫最为基础的内容，如果小伙伴们还不太清楚的话，可以先去学一学基本语法，再来看本章内容。\n\n`谷歌浏览器`提供了一个插件 ------ **XPath Helper**，它允许我们在浏览器上的某页面直接执行`xpath语法`定位对应元素并提供结果展示。因此大多数情况下，我们都会使用 **XPath Helper**来验证我们的猜想，比如上述图片的`url地址`的定位，xpath语法应该这样写：\n\n> //img[@class=\"main_img img-hover\"]/@src\n\n可以看到浏览器返回的结果： \n\n![img](/images/assets/ac2039e13ea07780efd3d2c865af09a7.png)\n\n可以看到，我们成功的获取到了所有39张图片的`url地址`，这说明我们的`xpath表达式`符合要求。\n\n再来思考一个问题，为什么只有39张呢？\n\n之前说过，这是个动态页面，我们在鼠标往下滑动之前，浏览器使用`js`仅渲染了部分图片，此时渲染页面得到的`Html源码`中只有39个 **li** 标签，因此`xpath表达式`就只找到了39个`url地址`，那我们想要更多的图片`url地址`怎么办呢？\n\n简单，让鼠标往下滑就行了。我们来验证我们的想法：\n\n![img](/images/assets/13c9637ad99117cb528c2549482dc703.png)\n\n显然，往下滑之后，同一个`xpath表达式`找到了更多的`url地址`，有了更多的 **li** 标签。这也同时说明了这个页面的`Html文本`是使用`js实时`渲染出来的。\n\n# 代码编写\n\n有了以上的分析，结合**Python+requests+selenium** ，我们就可以开始爬取代码的编写了：\n\n首先导入相关的库：\n\n```python\nimport re\nimport time\nimport os\nimport requests\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n```\n\n**re库**用于正则提取；**time库**用于强制休眠，防止爬取过快ip被封； **os库**操作文件及文件夹，用于保存图片；**requests，selenium**用于爬取数据。基本上，爬虫所需要的所有库都在这了。\n\n在当前目录下建一个`images`文件夹，用于存放下载的图片（当然也可以自定义下载路径）：\n\n```python\nif not os.path.exists('images'):\n    os.mkdir('images')\n```\n\n接着初始化 **selenium**：\n\n```python\n# options = Options()\n# options.add_argument('--headless')\n# options.add_argument('--disable-gpu')\n# options.add_experimental_option('excludeSwitches', ['enable-automation'])\n# driver = webdriver.Chrome(options=options)\n\ndriver = webdriver.Chrome()\n\ndriver.implicitly_wait(4)\n\n# 图片所在网址\ndriver.get('https://image.baidu.com/search/index?ct=201326592&z=9&tn=baiduimage&word=%E5%9B%BE%E7%89%87&pn=&spn=&ie=utf-8&oe=utf-8&cl=2&lm=-1&fr=ala&se=&sme=&width=0&height=0&cs=&os=&objurl=&di=&gsm=3c&dyTabStr=MCwzLDYsMSw0LDIsNSw3LDgsOQ%3D%3D')\n```\n\n如果不想自动打开谷歌浏览器，可将注释段代码替换第一行代码。\n\n接着我们来思考一个问题，如何实现鼠标下滑的操作呢？**selenium**的自动化测试功能，其**webdriver**类提供了一个**execute_script()**方法可以用于执行`js脚本`，而在`JavaScript`中，要实现下滑操作太容易了，我们定义一个函数：\n\n```python\ndef scroll(driver, px='document.body.scrollHeight'):\n    driver.execute_script(\n        \"\"\"\n            (function () {\n                var y = 0;\n                var step = 100;\n                window.scroll(0, 0);\n                function f() {\n                    if (y < %s) {\n                        y += step;\n                        window.scroll(0, y);\n                        setTimeout(f, 100);\n                    } else {\n                        document.title += \"scroll-ok\";\n                }\n            }\n            setTimeout(f, 1000);\n            })();\n    \"\"\"\n        % px\n    )\n    print(\"下拉中......\")\n    # time.sleep(180)\n    while True:\n        if \"scroll-ok\" in driver.title:\n            print(\"已拉到指定位置......\")\n            break\n        else:\n            print(\"还没有拉到指定位置......\")\n            time.sleep(3)\n```\n\n函数很简单，在此就不多做解释了。现在，我们在上述爬取代码中调用该函数：\n\n```python\nscroll(driver, '10000')\n\nprint('等待5s......')\ntime.sleep(5)\n```\n\n我们让鼠标下滑，让页面往下翻10000像素， 如果你想下载更多的图片，调整这个数值即可。此外需要注意的是，此处一定需要等待几秒后再进行之后的爬取工作，由于网络缓慢等原因，下滑后页面的`Html`还没有完全渲染出来，这时如果立即进行`xpath表达式`爬取就会漏掉部分还未被渲染出来的li标签，导致数据信息丢失。 \n\n接着来爬取图片的**url地址**和**文字段说明**。\n\n爬取过程中总会出现各种各样的错误和不足。这需要我们慢慢修正我们的代码。比如`url地址`，使用`xpath表达式`\n\n> //img[@class=\"main_img img-hover\"]/@src\n\n提取到的不一定都是有效的`url格式`，比如实际提取过程中，匹配到了下述内容：\n\n> data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAFLAfQDASIAAhEBAxEB/8QAHAAAAgIDAQEAAAAAAAAAAAAABAUDBgACBwEI/8\n\n这显然不是我们想要的`url格式`，因此在获取到某个`url地址`内容后，我们需要做一个判断，最简单的判断方式---------判断这玩意是不是以“`http`“开头的，我们使用**re模块**：\n\n```python\nif re.match(r'^(http)', img.get_attribute('src')):\n    # 再进行数据处理\n```\n\n好了，现在可以将爬取到的url地址使用**requests**库进行下载保存了：\n\n```python\n# li标签作为根标签，使用xpath表达式\nelements = driver.find_elements_by_xpath('//li[@class=\"imgitem normal\"]')\n# 遍历每个li标签\nfor element in elements:\n    img = element.find_element_by_xpath('.//img[@class=\"main_img img-hover\"]')\n    if re.match(r'^(http)', img.get_attribute('src')):\n        # 以流的方式打开\n        image = requests.get(img.get_attribute('src'), stream=True).content\n        # 去掉<strong></strong>标签\n        title = re.sub(r'[</strong> ]', '', element.get_attribute('data-title'))\n        try:\n            with open(f'{os.getcwd()}/images/%s.jpg' % title, \"wb\") as jpg:\n                jpg.write(image)\n            print(f'已下载{title}.jpg......')\n        except IOError:\n            print(\"下载{title}.jpg错误......\")\n\nprint('下载完毕.')\n```\n\n## 完整代码\n\n下面是完整代码：\n\n```python\nimport re\nimport time\nimport os\nimport requests\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\ndef scroll(driver, px='document.body.scrollHeight'):\n    driver.execute_script(\n        \"\"\"\n            (function () {\n                var y = 0;\n                var step = 100;\n                window.scroll(0, 0);\n                function f() {\n                    if (y < %s) {\n                        y += step;\n                        window.scroll(0, y);\n                        setTimeout(f, 100);\n                    } else {\n                        document.title += \"scroll-ok\";\n                }\n            }\n            setTimeout(f, 1000);\n            })();\n    \"\"\"\n        % px\n    )\n    print(\"下拉中......\")\n    # time.sleep(180)\n    while True:\n        if \"scroll-ok\" in driver.title:\n            print(\"已拉到指定位置......\")\n            break\n        else:\n            print(\"还没有拉到指定位置......\")\n            time.sleep(3)\n\nif not os.path.exists('images'):\n    os.mkdir('images')\n\ndef main():\n    options = Options()\n    options.add_argument('--headless')\n    options.add_argument('--disable-gpu')\n    options.add_experimental_option('excludeSwitches', ['enable-automation'])\n    driver = webdriver.Chrome(options=options)\n\n    driver.implicitly_wait(4)\n\n    driver.get(\n        'https://image.baidu.com/search/index?ct=201326592&z=9&tn=baiduimage&word=%E5%9B%BE%E7%89%87&pn=&spn=&ie=utf-8&oe=utf-8&cl=2&lm=-1&fr=ala&se=&sme=&width=0&height=0&cs=&os=&objurl=&di=&gsm=3c&dyTabStr=MCwzLDYsMSw0LDIsNSw3LDgsOQ%3D%3D')\n\n    scroll(driver, '10000')\n\n    print('等待5s......')\n    time.sleep(5)\n\n    # li标签作为根标签\n    elements = driver.find_elements_by_xpath('//li[@class=\"imgitem normal\"]')\n    # 遍历每个li标签\n    for element in elements:\n        img = element.find_element_by_xpath('.//img[@class=\"main_img img-hover\"]')\n        if re.match(r'^(http)', img.get_attribute('src')):\n            # 以流的方式打开\n            image = requests.get(img.get_attribute('src'), stream=True).content\n            title = re.sub(r'[</strong> ]', '', element.get_attribute('data-title'))\n            try:\n                with open(f'{os.getcwd()}/images/%s.jpg' % title, \"wb\") as jpg:\n                    jpg.write(image)\n                print(f'已下载{title}.jpg......')\n            except IOError:\n                print(\"下载{title}.jpg错误......\")\n\n    print('下载完毕.')\n\nif __name__ == '__main__':\n    main()\n```\n\n## 运行程序\n\n![img](/images/assets/9ef441b337e3c9b6a535fcb174240e4f.png)\n\n结束后，在当前目录下生成`images`文件夹，里面存着爬取到的图片：\n\n![img](/images/assets/8c5e5c0bb48081536d9eafad61420429.png)\n\n过程感觉挺长的，但是大多时间还是花在思考上，代码本身编写不难，难在整个分析过程。基本上使用上述爬取流程，可以爬取当下90%以上的网站图片了。 ","categories":["Python","爬虫"]},{"title":"六级成绩批量查询","url":"/2022/02/24/5cs0uw3v/","content":"\n# 前言\n\n又到了一年两度的四六级成绩查询的时候啦，不知道小伙伴们过了没有呢？\n\n今天我们来介绍如何使用`python`来批量查询四六级成绩。听起来好像很高大上，但实现起来非常容易哦......\n\n之前的爬虫博文中我也说过，爬虫最重要的一步不是如何编写程序，而是分析网页的结构。\n\n四六级成绩查询可以使用如下网址：\n\n> http://cet.neea.edu.cn/html1/folder/22023/595-1.htm\n\n# 分析网页\n\n浏览器打开，随便进入一个入口，该网页中，按`F12`，我们来分析一下这个查询页面：\n\n![img](/images/assets/219d2c6ca153f936dd19e21eb4de97ed.png)\n\n输入相关信息后，点击查询，可以看到对应的成绩，我们在控制台中，找找有什么好的接口可以直接查询到成绩，不一会儿，我们找到了下面这个文件：\n\n![img](/images/assets/3d360389eea98f58dcfd1175e6c8d8f5.png)\n\n这个文件的请求地址是：\n\n> http://cachecloud.neea.cn/api/latest/results/cet?e=CET_202112_DANGCI&km=2&xm=%E7%BD%97%E9%A2%96&no=4311******&v=\n>\n\n这个`url`地址有几个参数，我们关心的是`xm`（姓名）和`no`（身份证号），我们来看看这个请求的响应长什么样子：\n\n![img](/images/assets/0ff2fdd86483212730c53c38746c0122.png)\n\n显然，该请求返回的是一`json`串，我们来观察这个`json`串：\n\n> ​    {\n>\n> ​        \"xx\":\"******大学\",   （考生所在大学）\n>\n> ​        \"tlmk\":0,                \n>\n> ​        \"km\":2,\n>\n> ​        \"ky_sco\":\"\",\n>\n> ​        \"zkzh\":\"43003******\",  （准考证号）\n>\n> ​        \"sfz\":\"43110******\",   （身份证号）\n>\n> ​        \"score\":\"401\",      （六级成绩）\n>\n> ​        \"sco_lc\":\"94\",         （听力部分成绩）\n>\n> ​        \"ky_zkz\":\"--\",\n>\n> ​        \"xm\":\"***\",           （姓名）\n>\n> ​        \"sco_rd\":\"175\",     （阅读部分成绩）\n>\n> ​        \"sco_wt\":\"132\",     （写作部分成绩）\n>\n> ​        \"id\":\"212243003004401\",\n>\n> ​        \"cjd\":0,\n>\n> ​        \"code\":200        （状态码）\n>\n>    }\n\n这里...... \"`zkzh`\" 表示 \"准考证号\"，\"`sfz`\" 表示 \"身份证\"，多少有点大病哈哈。。。\n\n此外，如果查询不到（即没有参加六级考试或输入的信息有误），响应会是什么样的呢？\n\n![img](/images/assets/1e50ecd5200e62059cce52571c242b80.png)\n\n很显然，我们可以使用 **\"`code`\"** 这个键来判断某个学生是否参加了当次的六级考试（当然，前提是你的学生信息表中的信息没有错误......)。 \n\n# 爬取成绩\n\n有了以上分析，我们就可以开始我们批量爬取六级成绩了。\n\n首先，我们需要批量的考生信息数据，载体有很多，比如最常见的，`excel`表：\n\n![img](/images/assets/1e8192b167b27d7f98dc9be803e9cbed.png)\n\n在数据导入的过程中需要一点 `pandas` 的知识，不会的小伙伴们可以去学一学哦。\n\n在使用 `pandas` 处理得到的 `DataFrame` 中，我们添加几个字段用于存储爬取到的信息：\n\n![img](/images/assets/80ab4a5f21815c19a1239dcee7384863.png)\n\n值得注意的是，如果直接调用之前分析的那个接口，会显示错误码`403`，这说明对方的服务器把我们已经将我们视为爬虫。一般的方法是，在请求的过程中，我们添加请求头，模拟我们使用浏览器进行查询。\n\n请求头怎么弄呢？控制台上有现成的：\n\n![img](/images/assets/9852f4cd721778e347f320f4f969b450.png)\n\n请求头中的所有属性中，最重要的是 **`Cookie属性`**（有兴趣的小伙伴们可以去查一查），简单来说，Cookie就是由服务器发给客户端（此处为浏览器）的特殊信息，这些信息存放在客户端（浏览器），然后客户端（浏览器）每次向服务器发送请求的时候都会带上这些特殊的信息，向浏览器表明自己的身份。\n\n通俗来说，正因有了`Cookie`，对方的服务器才不会认为当前的请求是一个爬虫发出的，也就不会响应错误码`403`了，这样我们便可以拿到我们想要的数据。其余的属性，大家可选择性复制粘贴：\n\n```python\nheaders = {\n    'Accept': '*/*',\n    'Accept-Encoding': 'gzip, deflate',\n    'Accept-Language': 'zh-CN,zh;q=0.9',\n    'Connection': 'keep-alive',\n    'Host': 'cachecloud.neea.cn',\n    'Origin': 'http://cet.neea.cn',\n    'Referer': 'http://cet.neea.cn/',\n    'Cookie': 'Hm_lvt_dc1d69ab90346d8ee02f18510292577=1629958972,1629961007,1629989056,1629992054; community=Home; language=1; http_waf_cookie=f27d75db-23f7-4aa938445a95fb8092bcad0ba73630744bd3',\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) '\n                  'Chrome/98.0.4758.102 Safari/537.36 '\n}\n```\n\n接着，就是一些简单的爬取代码了。我们使用 `requests` 库来完成爬取工作。完整代码如下：\n\n```python\nfrom time import sleep\nimport requests\nimport pandas as pd\n\n\"\"\"\n:author: 易果啥笔\n:date: 2022-01-24\n:apiNote: 批量查询四六级成绩\n\n\"\"\"\n\n# 学生信息表data.xls，与源文件放在同一目录下\ndata = pd.read_excel('data.xls')\n\n# 添加几个字段，用于存储爬取到的信息，\n# 注意从7（索引从0开始）开始，因为我的表中前面已经有7个字段，这里需要根据自己的信息表调整\ndata.insert(7, '准考证号', '')\ndata.insert(8, '六级成绩', '')\ndata.insert(9, '听力部分', '')\ndata.insert(10, '阅读部分', '')\ndata.insert(11, '写作部分', '')\n\n# 添加请求头\nheaders = {\n    'Accept': '*/*',\n    'Accept-Encoding': 'gzip, deflate',\n    'Accept-Language': 'zh-CN,zh;q=0.9',\n    'Connection': 'keep-alive',\n    'Host': 'cachecloud.neea.cn',\n    'Origin': 'http://cet.neea.cn',\n    'Referer': 'http://cet.neea.cn/',\n    'Cookie': 'Hm_lvt_dc1d69ab90346d48ee2f18510292577=1629958972,1629961007,1629989056,1629992054; community=Home; language=1; http_waf_cookie=f27d75db-23f7-4aa938445a95fb8092bcad0ba73630744bd3',\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) '\n                  'Chrome/98.0.4758.102 Safari/537.36 '\n}\n\n# 由于是批量，用一个列表存储所有考生的参数\nparams_list = []\nfor i in range(len(data)):\n    params_list.append({\n        'e': 'CET_202112_DANGCI',\n        'km': 2,\n        'xm': data.iloc[i, 2],\n        'no': data.iloc[i, 6]\n    })\n\n# 四六级成绩查询网址\nurl = \"http://cachecloud.neea.cn/api/latest/results/cet\"\n\n# 遍历每一个考生的数据\nfor i in range(len(data)):\n    # requests.get(url,params,**args) **args可传入请求头headers\n    response = requests.get(url, params_list[i], headers=headers)\n    print(\"*******************************************************************\")\n    print(\"开始爬取%s的六级成绩......\" % params_list[i]['xm'])\n    # 由于response是json格式，可用response.json()接受\n    json_data = response.json()\n\n    # 判断学生是否参加了考试\n    if json_data['code'] == 200:\n        # 是，便开始存储成绩信息\n        data.iloc[i, 7] = json_data['zkzh']  # 准考证号\n        data.iloc[i, 8] = json_data['score']  # 六级分数\n        data.iloc[i, 9] = json_data['sco_lc']  # 听力部分\n        data.iloc[i, 10] = json_data['sco_rd']  # 阅读部分\n        data.iloc[i, 11] = json_data['sco_wt']  # 写作部分\n        info = '%d：%s查询成功，成绩为：%s' % ((i + 1), params_list[i]['xm'], json_data['score'])\n        print(info)\n    else:\n        # 否，输出相关信息\n        print('%d：%s未参加六级考试...' % ((i + 1), params_list[i]['xm']))\n    print(\"*******************************************************************\")\n\n    # 休息0.3秒，防止爬取过快IP被封\n    sleep(0.3)\n\nprint(\"已全部查询完毕，正在导出到csv......\")\n# 导出至csv文件中\ndata.to_csv('grade.csv')\nprint(\"导出完毕.\")\n```\n\n运行截图：\n\n![img](/images/assets/d2bdea239ce7ca1bc46125ae2c9b57a5.png)程序跑完后，在当前目录下会生成指定的 `grade.csv` 文件，里面有所有学生的六级详细成绩。涉及隐私问题，这里就不截图了哈。\n\n是不是挺简单的呢？\n","categories":["Python","爬虫"]},{"title":"Python正则表达式功能汇总","url":"/2022/01/18/f0pjrais/","content":"\n# 前言\n\n今天给大家分享一下 `python` 的正则表达式。\n\n众所周知，`python` 的正则表达式这类的工具类知识经常不用的话，容易忘记，所以我把它放在了代码中，需要用时，看看代码即可，里面的注释非常完整，详细，欢迎大家复制～～～\n\n# re模块详解\n\n我们主要介绍`re模块`：\n\n```python\nimport re\n\n\"\"\"\n:author 易果啥笔\n:apiNote re模块主要定义了9个常量、12个函数\n:data 2022.01.18\n\n\"\"\"\n\n\ndef regex_flags(flag):\n    # 9个常量\n    if flag == 'IGNORECASE':\n        '''\n        语法： re.IGNORECASE\n        作用： 进行忽略大小写匹配。\n        '''\n        text = '易果啥笔a'\n        pattern = r'易果啥笔A'\n        print(\"默认模式：\", re.findall(pattern, text))\n        print(\"忽略大小写模式：\", re.findall(pattern, text, re.IGNORECASE))\n\n    if flag == 'ASCII':\n        '''\n        语法： re.ASCII\n        作用： 顾名思义，ASCII表示ASCII码，\n            让 \\w, \\W, \\b, \\B, \\d, \\D, \\s 和 \\S 只匹配ASCII，\n            而不是Unicode。\n            在默认匹配模式下\\w+匹配到了下面例子的所有字符串，\n            而在ASCII模式下，只匹配到了a、b、c（ASCII编码支持的字符）。\n        注意：这只对字符串匹配模式有效，对字节匹配模式无效。\n        '''\n        text = 'a易果啥笔b易果啥笔c'\n        pattern = r'\\w+'\n        print(\"默认模式Unicode：\", re.findall(pattern, text))\n        print(\"ASCII模式：\", re.findall(pattern, text, re.ASCII))\n\n    if flag == 'DOTALL':\n        '''\n        语法： re.DOTALL\n        作用： DOT表示.，ALL表示所有，连起来就是 .匹配所有，\n            包括换行符\\n。默认模式下.是不能匹配换行符\\n的。\n            \n        '''\n        text = 'a易果啥笔\\n易果啥笔c'\n        pattern = r'.*'\n        print(text)\n        print(\"默认模式：\", re.findall(pattern, text))\n        print(\"DOTALL模式：\", re.findall(pattern, text, re.DOTALL))\n\n    if flag == 'MULTILINE':\n        '''\n        语法： re.MULTILINE\n        作用： 多行模式，当某字符串中有换行符\\n，默认模式下是不支持换行符特性的，\n            比如：行开头 和 行结尾，而多行模式下是支持匹配行开头的。\n            下面的例子中，正则表达式中^表示匹配行的开头，\n            默认模式下它只能匹配字符串的开头；而在多行模式下，它还可以匹配换行符\\n后面的字符。\n        注意：正则语法中^匹配行开头、\\A匹配字符串开头，\n                单行模式下它两效果一致，多行模式下\\A不能识别\\n。\n        '''\n        text = '易果啥笔\\n易果啥笔'\n        pattern = r'^易果啥笔'\n        print(text)\n        print(\"默认模式：\", re.findall(pattern, text))\n        print(\"MULTILINE模式：\", re.findall(pattern, text, re.MULTILINE))\n\n    if flag == 'VERBOSE':\n        '''\n        语法： re.VERBOSE\n        作用： 详细模式，简单来说，在正则表达式中可以加注释\n        默认模式下并不能识别正则表达式中的注释，而详细模式是可以识别的。\n        当一个正则表达式十分复杂的时候，详细模式能为你提供另一种注释方式，\n        '''\n        text = '易果啥笔'\n        pattern = r'''\n                    ^易果     # 量词\n                    啥笔      # 名词\n                '''\n        print(text)\n        print(\"默认模式：\", re.findall(pattern, text))\n        print(\"MULTILINE模式：\", re.findall(pattern, text, re.VERBOSE))\n\n    if flag == 'LOCALE':\n        '''\n        语法： re.LOCALE\n        作用： 由当前语言区域决定 \\w, \\W, \\b, \\B 和大小写敏感匹配，\n            这个标记只能对byte样式有效。官方已经不推荐使用，\n        '''\n    if flag == 'UNICODE':\n        '''\n        语法： re.UNICODE\n        作用： 与 ASCII 模式类似，匹配unicode编码支持的字符，\n            但是 Python 3 默认字符串已经是Unicode，所以有点冗余。\n        '''\n    if flag == 'DEBUG':\n        '''\n        语法： re.DEBUG\n        作用： 显示编译时的debug信息，目前这个debug信息笔者不太清楚\n        '''\n        text = '异国傻逼a'\n        pattern = r'异国傻逼A'\n        print(\"DEBUG模式：\", re.findall(pattern, text, re.DEBUG | re.IGNORECASE))\n\n    if flag == 'TEMPLATE':\n        '''\n        语法： re.TEMPLATE\n        作用： 没搞懂TEMPLATE的具体用处，\n            源码注释中写着：disable backtracking(禁用回溯)\n        '''\n    '''\n    常量总结：\n    1. 9个常量中，前5个（IGNORECASE、ASCII、DOTALL、MULTILINE、VERBOSE）有用处，\n        两个（LOCALE、UNICODE）官方不建议使用、\n        两个（TEMPLATE、DEBUG）试验性功能，不能依赖。\n    2. 常量在re模块的常用函数中都可以使用，查看源码可得知。\n    3. 常量可叠加使用，因为常量值都是2的幂次方值，\n        所以是可以叠加使用的，叠加时请使用 | 符号，请勿使用 + 符号\n    \n    '''\n\n\ndef regex_function(funcition_name):\n    \"\"\"\n        re模块有12个函数\n    \"\"\"\n\n    \"\"\"\n    1.查找一个匹配项\n        查找并返回一个匹配项的函数有3个：search、match、fullmatch，\n        他们的区别分别是：\n        search： 查找任意位置的一个匹配项\n        match： 必须从字符串开头匹配\n        fullmatch： 整个字符串与正则完全匹配\n        查找一个匹配项 返回的都是一个匹配对象（Match）,其含有的方法有：\n        1. group(index)     某个组匹配的结果（无匹配时调用会报错）\n        2. groups()     所有分组的匹配结果，每个分组组成的结果以列表返回（无匹配时调用会报错）\n        3. groupdict()      返回组名作为key，每个分组的匹配结果作为value的字典\n        4. span([group])        获取组的开始和结束位置\n        5. expand(template)     使用组的匹配结果来替换template中的内容，并把替换后的字符串返回\n    \"\"\"\n\n    if funcition_name == 'one_match':\n        text = 'I have 9 students.'\n        # (?P<label>...）可以给正则中的组添上一个标签label，这样match对象可以使用标签名来访问对应组的匹配结果\n        pattern = r'(?P<one>\\w+) (?P<two>\\w+) (?P<three>\\d+) (?P<four>\\w+)'  # 四个组\n        print(\"search：\", re.search(pattern, text).group(0))  # 所有的组   I have 9 students\n        print(\"search：\", re.search(pattern, text).groups())  # 所有的组   ('I', 'have', '9', 'students')\n        print(\"search：\", re.search(pattern, text).group(1))  # 第一组   I\n        print(\"search：\", re.search(pattern, text).group(2))  # 第二组   have\n        print(\"search：\", re.search(pattern, text).group(3))  # 第三组   9\n        print(\"search：\", re.search(pattern, text).groupdict()['one'])  # I\n        # groupdict() 调用结果：{'one': 'I', 'two': 'have', 'three': '9', 'four': 'students'}\n\n        # print(\"match：\", re.match(pattern,text))\n        # print(\"fullmatch：\", re.fullmatch(pattern,text))\n\n    if funcition_name == 'many_match':\n        \"\"\"\n        2.查找多个匹配项\n            查找多项函数主要有：findall函数 与 finditer函数：\n            1. findall： 从字符串任意位置查找，返回一个列表\n            2. finditer：从字符串任意位置查找，返回一个迭代器\n            两个方法基本类似，\n            只不过一个是返回列表，一个是返回迭代器。\n            列表是一次性生成在内存中，而迭代器是需要使用时一点一点生成出来的，内存使用更优。\n            如果可能存在大量的匹配项的话，建议使用finditer函数，一般情况使用findall函数基本没啥影响。\n        \"\"\"\n        text = '我的电话号码是：17377762736，我的妹妹的电话号码是：18976562836，我们都住在3601寝室，我的帐号是11290378914。'\n        pattern = r'(?P<phone>1[2-9][1-9]{9})'\n        print(re.findall(pattern, text))\n        # ['17377762736', '18976562836']\n        match_list = list(re.finditer(pattern, text))\n        # match_list中是若干个match对象：\n        # [<re.Match object; span=(8, 19), match='17377762736'>, <re.Match object; span=(31, 42), match='18976562836'>]\n\n    if funcition_name == 'split':\n        \"\"\"\n        3.分割\n            re.split(pattern, string, maxsplit=0, flags=0) 函数：\n            用 pattern 分开 string ， maxsplit表示最多进行分割次数，值为0表示不限分割次数 \n            flags表示模式，就是上面的常量！\n        \"\"\"\n        text = 'Haha,Heihei，Hehe.哈哈'\n        pattern = r'[,，.]'\n        print(\"正则表达式进行分割：\", re.split(pattern, text, maxsplit=0, flags=0))\n        # ['Haha', 'Heihei', 'Hehe', '哈哈']\n\n        \"\"\"\n        注意：str模块也有一个 split函数 ，那这两个函数该怎么选呢？\n            str.split函数功能简单，不支持正则分割，而re.split支持正则。\n            在 不需要正则支持 且 数据量和数次不多 的情况下使用str.split函数更合适，\n            反之则使用re.split函数。\n        \"\"\"\n\n    if funcition_name == 'replace':\n        \"\"\"\n        4.替换\n            替换主要有sub函数 与 subn函数，他们功能类似\n            sub函数的用法：\n            re.sub(pattern, repl, string, count=0, flags=0) \n            函数参数讲解：repl替换掉string中被pattern匹配的字符， \n            count表示最大替换次数，flags表示正则表达式的常量。\n        \"\"\"\n        text = 'Haha,Heihei，Hehe.哈哈'\n        pattern = r'[,，.]'\n        print(\"sub函数替换：\", re.sub(pattern, '...', text, count=0, flags=0))\n        # sub函数替换： Haha...Heihei...Hehe...哈哈\n\n        '''\n        re.subn(pattern, repl, string, count=0, flags=0) \n        返回一个元组，第一个元素即为sub()的返回值，第二个元素表示匹配成功的次数。\n        '''\n        print(\"subn函数替换：\", re.subn(pattern, '...', text, count=0, flags=0))\n        # ('Haha...Heihei...Hehe...哈哈', 3)\n\n        \"\"\"\n        如果想要对替换的所有字符串中的某个字符串单独替换成其他字符串，可以传入repl的函数形式：\n        \"\"\"\n        matchobj = lambda matchobj: '......' if matchobj.group(0) != ',' else '。'\n        print(\"函数替换：\", re.sub(pattern, matchobj, text, flags=re.IGNORECASE))\n        # Haha。Heihei......Hehe......哈哈\n\n\ndef pattern_obj():\n    \"\"\"\n    前面我们一直使用的是re.啥啥啥，这个re我们也可以自定义，这就是Pattern对象，即正则对象Pattern。\n    \"\"\"\n    text = '我的电话号码是：17377777777，我的妹妹的电话号码是：18977777777，我们都住在3601寝室，我的帐号是11111111111。'\n    pattern = r'(?P<phone>1[2-9][0-9]{9})'\n    pattern_obj = re.compile(pattern)  # pattern_obj = re.compile(r'(?P<phone>1[2-9][1-9]{9})')\n    # 此时得到的pattern_obj就相当于re，可以调用其split(),sub(),match(),search()函数等\n    match_result1 = pattern_obj.findall(text)  # 已有正则，只需传入待查找的文本即可\n    print(match_result1)\n\n    \"\"\"\n    既然有re就够了，为什么还要有pattern对象呢？\n    官方文档推荐：在多次使用 \"一个正则表达式\" 时推荐使用正则对象Pattern以增加复用性，\n    因为通过 re.compile(pattern) 编译后的模块级函数会被缓存。。。\n    比如前面的pattern_obj这个pattern对象，用于从一串文本中找出电话号码，我们可以反复使用这个对象：\n    \"\"\"\n    text2 = '我爸爸的电话号码是11011011101，我姐姐的电话号码是12345678910，呀呀呀'\n    # 反复使用pattern_obj对象\n    match_result2 = pattern_obj.findall(text2)\n    print(match_result2)\n\n\n\"\"\"\n常量也可以简写，具体参考下面的re模块源码：\n\nclass RegexFlag(enum.IntFlag):\n    ASCII = A = sre_compile.SRE_FLAG_ASCII # assume ascii \"locale\"\n    IGNORECASE = I = sre_compile.SRE_FLAG_IGNORECASE # ignore case\n    LOCALE = L = sre_compile.SRE_FLAG_LOCALE # assume current 8-bit locale\n    UNICODE = U = sre_compile.SRE_FLAG_UNICODE # assume unicode \"locale\"\n    MULTILINE = M = sre_compile.SRE_FLAG_MULTILINE # make anchors look for newline\n    DOTALL = S = sre_compile.SRE_FLAG_DOTALL # make dot match newline\n    VERBOSE = X = sre_compile.SRE_FLAG_VERBOSE # ignore whitespace and comments\n    # sre extensions (experimental, don't rely on these)\n    TEMPLATE = T = sre_compile.SRE_FLAG_TEMPLATE # disable backtracking\n    DEBUG = sre_compile.SRE_FLAG_DEBUG # dump pattern after compilation\n\n\"\"\"\n\nif __name__ == '__main__':\n    \"\"\"\n        注意：Python中字符串前面加上r表示原生字符串，试比较下面两行：\n    \"\"\"\n    # print(\"\\\\\\\\\")  # \\\\\n    # print(r'\\\\\\\\')  # \\\\\\\\\n\n    # pattern_obj()\n    # regex_function(\"replace\")\n    # regex_flags(\"MULTILINE\")\n```\n","categories":["Python"]},{"title":"随机组卷功能模拟","url":"/2021/12/04/oucxjgcx/","content":"\n# 前言\n\n今天我们来聊一聊随机组卷。相信大家对这个词语都不陌生。\n\n最常见的情况，许多在线课程的考试试题都是`随机组卷`产生的。比如某慧树：\n\n![img](/images/assets/5f5b53be1738443c4205c08ab8c738ea.png)\n\n由于网课的学生群体巨大，不可能为每一位学生单独命制试题，因此导致了`随机组卷`的诞生。\n\n简单解释就是，各大教育平台都有自己的试题数据库，通过程序从试题库中随机抽取部分试题来组成一份试卷，这样能极大的提高出卷的时效性。\n\n# 模拟随机组卷\n\n下面，我们使用 `python` 来模拟一个简单的随机组卷的过程。\n\n首先，我们得有一个`试题库，为简便起见，我们使用下面的字典作为试题库：\n\n```python\ncapitals = {\n            '黑龙江省':'哈尔滨市',\n            '吉林省':'长春市',\n            '辽宁省':'沈阳市',\n            '北京市':'北京',\n            '天津市':'天津',\n            '内蒙古自治区':'呼和浩特市',\n            '山西省':'太原市',\n            '陕西':'西安市',\n            '青海省':'西宁市',\n            '甘肃':'兰州市',\n            '新疆维吾尔自治区':'乌鲁木齐市',\n            '四川':'成都市',\n            '重庆市':'重庆',\n            '云南省':'昆明市',\n            '贵州省':'贵州市',\n            '广西壮族自治区':'南宁市',\n            '广东省':'广州市',\n            '湖南省':'长沙市',\n            '湖北省':'武汉市',\n            '河南省':'郑州市',\n            '河北省':'石家庄市',\n            '山东省':'济南市',\n            '安徽省':'合肥市',\n            '江苏省':'南京市',\n            '浙江省':'杭州市',\n            '上海市':'上海',\n            '江西省':'南昌市',\n            '福建省':'福州市',\n            '西藏':'拉萨市',\n            '海南省':'三亚市',\n            '宁夏回族自治区':'银川市',\n            '台湾省':'台北市'\n        }\n```\n\n没错，我们的试题就是找到我国`各个省的省会城市的名称`。当然，实际上的试题都来自各教育平台庞大的数据库。我们在这仅使用字典来学习和借鉴。有了试题库，我们就可以开始组卷了：\n\n## 第一步，用一个列表来存储所有省名并打乱该列表元素的顺序\n\n```python\n# states存储所有省名\nstates = list(capitals.keys())\n# 随机打乱states列表元素的顺序\nrandom.shuffle(states)\n```\n\n## 第二步，构建每个问题的四个选项（1正确答案+3错误答案）并打乱顺序\n\n```python\n# 正确答案，questionNum为题目编号\ncorrectAnswer = capitals[states[questionNum]]\n# 错误答案列表\nwrongAnswers = list(capitals.values())\n# 当然，在错误答案中需去掉正确答案\ndel wrongAnswers[wrongAnswers.index(correctAnswer)]\n# 错误答案从错误答案列表wrongAnswers中随机抽取三个\nwrongAnswers = random.sample(wrongAnswers, 3)\n# 一个正确答案和三个错误答案构成四个选项\nanswerOptions = wrongAnswers + [correctAnswer]\n# 打乱四个选项的顺序\nrandom.shuffle(answerOptions)\n```\n\n## 第三步，编写试卷文件（包括测试卷和答案卷）开头\n\n每份试卷都有一部分相同的内容，比如`标题，姓名，学号`等：\n\n```python\nquizFile = open('省会城市及省的简称测验%s.txt'%(quizNum + 1),'w')\nanswerKeyFile = open('省会城市及省的简称测验答案%s.txt'%(quizNum + 1),'w')\n\n# 试卷标题\nquizFile.write((' '*20) + '省会城市及省的简称测验 (试卷 %s)' % (quizNum + 1))\nquizFile.write('\\n\\n姓名:__________________日期:__________________时间:_________________')\nquizFile.write('\\n\\n')\n```\n\n## 第四步，添加随机试题和答案\n\n```python\n# 向试题文件中写入问题\nquizFile.write('%s.%s的省会城市是 ?\\n' % (questionNum + 1, states[questionNum]))\nfor i in range(4):\n       quizFile.write(' %s. %s\\n' % ('ABCD'[i], answerOptions[i]))\n       quizFile.write('\\n')\n\n# 向答案文件中写入正确答案\nanswerKeyFile.write('%s.%s\\n' % (questionNum + 1, 'ABCD'[answerOptions.index(correctAnswer)]))\n```\n\n## 完整代码\n\n```python\nimport random\n\ncapitals = {\n            '黑龙江省':'哈尔滨市',\n            '吉林省':'长春市',\n            '辽宁省':'沈阳市',\n            '北京市':'北京',\n            '天津市':'天津',\n            '内蒙古自治区':'呼和浩特市',\n            '山西省':'太原市',\n            '陕西':'西安市',\n            '青海省':'西宁市',\n            '甘肃':'兰州市',\n            '新疆维吾尔自治区':'乌鲁木齐市',\n            '四川':'成都市',\n            '重庆市':'重庆',\n            '云南省':'昆明市',\n            '贵州省':'贵州市',\n            '广西壮族自治区':'南宁市',\n            '广东省':'广州市',\n            '湖南省':'长沙市',\n            '湖北省':'武汉市',\n            '河南省':'郑州市',\n            '河北省':'石家庄市',\n            '山东省':'济南市',\n            '安徽省':'合肥市',\n            '江苏省':'南京市',\n            '浙江省':'杭州市',\n            '上海市':'上海',\n            '江西省':'南昌市',\n            '福建省':'福州市',\n            '西藏':'拉萨市',\n            '海南省':'三亚市',\n            '宁夏回族自治区':'银川市',\n            '台湾省':'台北市'\n        }\n\n\n# 产生十份随机试卷\nfor quizNum in range(10):\n    quizFile = open('省会城市及省的简称测验%s.txt'%(quizNum + 1),'w')\n    answerKeyFile = open('省会城市及省的简称测验答案%s.txt'%(quizNum + 1),'w')\n\n    # 试卷标题\n    quizFile.write((' '*20) + '省会城市及省的简称测验 (试卷 %s)' % (quizNum + 1))\n    quizFile.write('\\n\\n姓名:__________________日期:__________________时间:_________________')\n    quizFile.write('\\n\\n')\n\n    # states存储所有省名\n    states = list(capitals.keys())\n    # 随机打乱states列表元素的顺序\n    random.shuffle(states)\n\n    # 每份试题随机产生15个问题：\n    for questionNum in range(15):\n        # 正确答案\n        correctAnswer = capitals[states[questionNum]]\n        # 错误答案列表\n        wrongAnswers = list(capitals.values())\n        # 当然错误答案中去掉正确答案\n        del wrongAnswers[wrongAnswers.index(correctAnswer)]\n        # 错误答案从错误答案列表wrongAnswers中随机抽取三个\n        wrongAnswers = random.sample(wrongAnswers, 3)\n        # 一个正确答案和三个错误答案构成四个选项\n        answerOptions = wrongAnswers + [correctAnswer]\n        # 打乱四个选项的顺序\n        random.shuffle(answerOptions)\n\n        # 向试题文件中写入问题\n        quizFile.write('%s.%s的省会城市是 ?\\n' % (questionNum + 1, states[questionNum]))\n        for i in range(4):\n            quizFile.write(' %s. %s\\n' % ('ABCD'[i], answerOptions[i]))\n        quizFile.write('\\n')\n\n        # 向答案文件中写入正确答案\n        answerKeyFile.write('%s.%s\\n' % (questionNum + 1, 'ABCD'[answerOptions.index(correctAnswer)]))\n\n    # 关闭流\n    quizFile.close()\n    answerKeyFile.close()\n```\n\n# 随机组卷测试\n\n运行程序，可以在当前目录下看到我们产生的10份`随机试卷及答案`：\n\n![img](/images/assets/d9bb9c830afcc46e5a5f23a9bd36323c.png)\n\n![img](/images/assets/b6c522cbfe35d685d9d11d42a9f9c101.png)\n","categories":["Python"]},{"title":"爬虫框架Scrapy速成","url":"/2021/12/02/9bh6zzdd/","content":"\n# 前言\n\n趁着闲暇的时间，我们来系统学习一个`python`非常流行的框架-----`Scrapy`。`Scrapy`是一个使用`python`编写，基于`Twisted`框架的开源网络爬虫框架，目前由`Scrapingphub Ltd`维护。\n\n`Scrapy`的最大特点，四个字：`简单实用`。\n\n简单到什么程度，一天的学习即可掌握核心知识，并应用到实际中去。由于`Scrapy`灵活易扩展，开发社区活跃，跨平台支持，使得其使用群体广泛。\n\n本着实用的原则，本教程不涉及`Scrapy`框架的底层实现讲解，对于一些不太好理解的地方，偶尔会涉及到`Scrapy`的底层原理，以便于理解。\n\n# 安装Scrapy\n\n安装`Scrapy`非常地简单，在任意操作系统下，均可以使用pip命令安装：\n\n> pip install scrapy\n\n测试是否安装成功，可以在`cmd(控制台)`里输入`scrapy`：\n\n![img](/images/assets/476181bd88754274b314718325b67120.png)\n\n# 第一个Scrapy爬虫程序\n\n下面我们来编写第一个`Scrapy`爬虫程序。\n\n爬虫，首先得有“地”可爬。大家都听过，“爬虫学的好，牢饭少不了”，\n\n我们不去爬取网站的私密信息，仅仅是为了学习和交流。\n\n在这，有一个专供爬虫初学者训练爬虫技术的网站，网址为： [All products | Books to Scrape - Sandbox](http://books.toscrape.com)\n\n我们来瞧瞧这个网站的主界面：\n\n![img](/images/assets/ce982840828181ebe83f4ac1745365bd.png)\n\n可以看到，里面有许多关于书籍的信息。\n\n下面，我们就使用`Scrapy`框架来爬取这些书籍信息。咱分几步完成：\n\n## 第一步：分析页面\n\n编写爬虫程序前，我们首先要分析这个页面，这需要一点简单的`html知识`，现在主流的浏览器中都带有分析网站页面的工具或插件，个人比较推荐`Chrome浏览器`的开发者工具，因为它的功能实在是太强大了！\n\n在`Chrome浏览器`中打开书籍信息所在的网页，接着按`F12`，即可调出谷歌的`开发者工具`，我们来看看这个网页的`HTML`源代码：\n\n![img](/images/assets/3fe9d95f8f2ffebcab382b797aa61454.png)\n\n谷歌浏览器小技巧：如果你想找到页面某个内容所在的`HTML`代码，可以右键该内容，选择“审查元素”，即可定位到该内容所在的`HTML`代码。 （其他浏览器也有类似的方式）\n\n从源代码中可以看到，所有的书籍信息放在了一个`ol`（无序标签）下， 其中的每一本书放在一个 `li` 块中，所有的书籍信息包裹在`<article class=\"product_pod\">`元素中，具体信息有：\n\n- 书名信息：其下 `h3 > a`元素的 `title` 属性中\n- 书价信息：其下` <p class=\"price_color\">`元素的文本中\n\n当然网页中书籍信息还有许多，此处我们先爬取这两个信息。 \n\n## 第二步：创建项目\n\n同其他框架一样，使用`Scrapy`，首先得新建一个`Scrapy项目`，在`cmd`（控制台）中使用如下指令创建一个`Scrapy项目`：\n\n> scrapy startproject 项目名\n\n![img](/images/assets/b930bc3ccdf6af338fa956e806814c63.png)根据执行结果（红框所述)，先`cd`到项目中，再执行如下命令：\n\n> scrapy genspider 爬虫名 待爬取的网站域名\n>\n\n![img](/images/assets/4d73dd9cbbd1002af0a87d5e3aee5a62.png)这样，在项目存储位置处，我们可以看到项目的文件结构：\n\n![img](/images/assets/4274c6bb1300cee0fdf09a0a5b8e1082.png)\n\n这些文件的具体作用，我们随着学习的深入会一一了解。\n\n我们使用`pycharm`来打开这个项目，注意这个项目的`python解释器`中需要导入`scrapy包`：\n\n![img](/images/assets/90b3ce924a49390c1b8ba354ce237ef5.png)\n\n### 项目结构\n\n设置好环境后，我们来分析这个项目中的文件，可以看到如下这个**`getbooks.py`**文件：\n\n![img](/images/assets/5afc1470a19c6e4160e444e24a3ebac2.png)\n\n这个文件就是我们编写`Spider`的核心文件了。基本上我们所有的逻辑代码都在这个文件中。什么逻辑呢？在写任何一个爬虫之前，我们考虑如下三个问题：\n\n- 爬取的时候从哪个或者哪些页面开始爬取呢？\n- 对于一个已下载待爬取的页面，提取其中的哪些数据呢？\n- 爬取完当前页面后，接下来该爬取哪个或者哪些页面呢？\n\n当回答完上述问题，一个爬虫也就开发出来了。 \n\n一般而言，编写一个Spider只需如下四个步骤：\n\n> 1. 继承scrapy.Spider；\n> 2. 为Spider取名（爬虫名）；\n> 3. 设定起始爬取点（网址列表）；\n> 4. 实现页面解析函数；\n>\n\n我们来分析一下这个核心文件中的代码：\n\n![img](/images/assets/46e4cf426a382cba474ba5f9c6bc3a20.png)这段代码虽只有10行，但已经囊括了上述的四个步骤，解释如下： \n\n> 1. `Scrapy`框架提供了一个`Spider`基类，我们编写的`Spider`只需要继承它即可（代码第四行）\n> 2. 有时候我们编写的爬虫不止一个，因此，爬虫名的设置便非常重要，`Spider`基类有一个 **`name`** 属性，用来指定爬虫名，如代码第五行，设置此爬虫程序的爬虫名为 “`getbooks`”。（此处的爬虫名在前面使用命令行创建项目的时候就已经指定了，此处为代码自动生成）\n> 3. `Spider`基类还有一个 **`allowed_domains`** 属性用于设定爬取网站的域名（亦在创建项目的时候指定了），**`start_urls`** 属性用于指定爬取的起始网页（可以有多个，采用列表存储）。\n> 4. 页面解析函数名默认为 **`parse`** ，代码中使用`pass`占位，需由我们编写。\n>\n\n### Scrapy框架流程\n\n简单介绍一下`Scrapy框架`的爬取流程。\n\n首先，`Scrapy引擎`根据`start_urls`中的`url地址`向对应网页发送一个`request下载请求`，用于下载该网页，接着该网页所在网站返回一个`response对象`，并将该对象作为参数传递给页面解析函数`parse()`，作为该函数的参数，接下来的爬取工作主要在页面解析函数中进行。\n\n值得关注的是，下载该网页所返回的`response对象`中，包含了这个网页完整的`html代码`，那么我们如何选择到指定的`html标签呢`？\n\n### **css**选择器和**xpath**选择器\n\n`Scrapy框架`给此`response对象`添加了两种选择器函数：**css**选择器和**xpath**选择器。首先说明，这两种选择器并无优劣之分。一般而言，在语法上，`css选择器`要比`xpath选择器`简洁一些，但`xpath选择器`在功能上更强大一点。而且实际上，当我们调用`css选择器`函数时，在`python`内部会使用**cssselect**库将`css表达式`翻译成`xpath表达式`。关于这两种选择器的使用，列举如下：\n\n**CSS选择器常用语法**\n\n| **表达式**        | **作用**                                         | **举例**          |\n| ----------------- | ------------------------------------------------ | ----------------- |\n| *****             | **选中所有元素**                                 | *****             |\n| **E**             | **选中E元素**                                    | **p**             |\n| **E1,E2**         | **选中E1和E2元素**                               | **div,span**      |\n| **E1 E2**         | **选中E1后代元素中的E2元素**                     | **div p**         |\n| **E1>E2**         | **选中E1子元素中的E2元素**                       | **div>p**         |\n| **E1+E2**         | **选中E1兄弟元素中的E2元素**                     | **p+span**        |\n| **.classname**    | **选中属性class的值为classname的元素**           | **.info**         |\n| **#idname**       | **选中属性id的值为idname的元素**                 | **#main**         |\n| **[attr]**        | **选中包含attr属性的元素**                       | **[href]**        |\n| **[attr=value]**  | **选中包含attr属性且其值为value的元素**          | **[method=get]**  |\n| **E:first-child** | **选中E元素，且E元素为其父元素的第一个子元素**   | **a:first-child** |\n| **E:last-child**  | **选中E元素，且E元素为其父元素的最后一个子元素** | **a:last-child**  |\n| **E:empty**       | **选中没有子元素的E元素**                        | **div:empty**     |\n| **E:text**        | **选中E元素的文本内容**                          | **p:tex**         |\n\n**xpath选择器常用语法**\n\n| 表达式   | 作用                                | 举例           |\n| -------- | ----------------------------------- | -------------- |\n| /        | 选中文档的根                        | /              |\n| .        | 选中当前元素                        | .              |\n| ..       | 选中父元素                          | img/..         |\n| E        | 选中当前元素的子元素中的所有E元素   | ./a            |\n| //E      | 选中根元素的后代元素中的所有E元素   | //a            |\n| .//E     | 选中当前元素的后代元素中的所有E元素 | .//a           |\n| *        | 选中所有子元素                      | //div/*/img    |\n| E/text() | 选中E元素的文本内容                 | //div/a/text() |\n| @attr    | 选中包含attr属性的元素              | //img/@src     |\n| @*       | 选中所有属性的元素                  | //img/@*       |\n\n### 编写页面解析函数\n\n依据前面的页面分析，我们来编写页面解析函数： \n\n```python\nimport scrapy\n\nclass GetbooksSpider(scrapy.Spider):\n    name = 'getbooks'\n    allowed_domains = ['books.toscrapy.com']\n    start_urls = ['http://books.toscrape.com/']\n\n    def parse(self, response):\n        for books in response.css(\"article.product_pod\"):\n            name = books.xpath(\"./h3/a/@title\").extract_first()\n            price = books.css(\"p.price_color::text\").extract_first()\n            yield {\n                \"name\" : name,\n                \"price\" : price,\n            }\n```\n\n**`response.css()`函数和`response.xpath()`函数**均返回一个列表，由符合选择条件的`Selector对象`组成的列表，均提供 **extract函数**（获取所有符合条件的`html标签`），**extract_first函数**（获取第一个符合条件的`html标签`)。`yield`用于提交对应内容给`Scrapy引擎`。\n\n## 第三步：运行项目\n\n代码编写完毕后，我们来运行这个项目：\n\n![img](/images/assets/2285e70136b268325dd9087b43606f64.png)\n\n当出现类似如下信息时，即为爬取成功：\n\n![img](/images/assets/1d6820a5babc69ac172af664aa66c58b.png)\n\n运行结束后，在我们指定的目录下，可以看到生成的`books.csv文件`：\n\n![img](/images/assets/6312f08b943872fba2dc133611f8124c.png)\n\n 一个简单的爬虫程序就开发出来了。\n\n当然这只是一个最为简单的爬虫，随着接下来的深入学习，我们能够实现一些更为复杂的爬取工作。\n","categories":["Python","爬虫"]},{"title":"超级简单的打jar包教程","url":"/2021/11/03/86ticoox/","content":"\n今天我们来聊聊`jar`包。作为`Java`程序员，日常工作就是打自己的`jar`包和学别人的`jar`包。\n\n# 什么是jar包？\n\n`jar包`，` Java Archive File`，顾名思义，它与` Java` 息息相关的，是` Java` 的一种文档格式，同时也是一种与平台无关的文件格式，可将多个文件合成一个`jar`文件。\n\n大伙会觉得它与`zip包`非常类似，确实，确切地说，它就是` zip 包`。`jar` 与` zip` 唯一的区别就只是在` jar` 文件的`META-INF`目录下多包含了一个 `MANIFEST.MF` 文件作为jar里面的\"详情单\"，这个文件里包含了该`Jar`包的版本、创建人和类搜索路径`Class-Path`等信息，当然如果是可执行`Jar`包（包含`main()`方法），还会包含`Main-Class`属性，表明`main()`方法入口。其中较为重要的`Class-Path`和`Main-Class`。\n\n此外，由于`jar`包主要是对`.class`文件进行打包，而`java`编译生成的`.class`文件是跨平台的，这就意味着`jar`包也是跨平台的，这是`jar`包的优势。\n\n小伙伴们在平时编写代码的时候，可以把自己代码中的通用部分分离出来，积累一些通用的工具类，将其逐渐模块化，最后打成`jar`包供自己在别的项目或者模块中使用。同时可以不断完善`jar`包里面的内容，将其做得更加容易理解和使用。\n\n因此，将自己写好的通用工具类或者框架分离出来，打成`jar`包供自己或他人调用，不仅能够提升自己的编程水准，同时也能扩宽整个`Java`生态圈，这也是`Java`如此受欢迎的原因之一。\n\n#  如何打jar包？\n\n现在，我们来试着打包我们自己写好的`java`源文件。\n\n记得最早接触的一个第三方`jar`包，是 `mysql-connector-java-8.0.24.jar`，即`Java`中著名的`jdbc`驱动包\n\n虽然这个驱动包使用起来非常方便，但是仍然有许多重复的代码需要我们去编写，所以一些主流的`Java`框架会对其进行再次封装，比如`SpringBoot`框架中，我们只需要填入数据库地址，用户名，密码等基本信息即可访问我们的数据库，下面，我们就尝试着对这个驱动包进行二次封装，并把它打包成`jar`包，以下是我们的目标：\n\n- 向用户开放一个主构造方法：`ConnectMysql(String url, String username, String password)`用于连接`mysql`数据库。\n- 用户只需调用 **`insert(), delete(), update(), select()`** 四个方法即可实现对于数据库的 **增 删 改 查** 四个操作。\n\n## 二次封装\n\n首先对`jdbc`驱动包做二次封装，代码如下：\n\n```java\npackage com.sixibiheye.mysql;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\n\npublic class ConnectMysql {\n    private String url;\n    private String user;\n    private String password;\n    private Statement statement;\n\n    public ConnectMysql(String url, String user, String password) {\n        this.url = \"jdbc:mysql://\" + url + \"?useUnicode=true&characterEncoding=utf8\";\n        this.user = user;\n        this.password = password;\n        this.init();\n    }\n\n    private void init() {\n        try {\n            String driver = \"com.mysql.jdbc.Driver\";\n            Class.forName(driver);\n            Connection con = DriverManager.getConnection(this.url, this.user, this.password);\n            if (!con.isClosed()) {\n                System.out.println(\"数据库连接成功！\");\n            }\n\n            this.statement = con.createStatement();\n        } catch (ClassNotFoundException var3) {\n            System.out.println(\"对不起，无法找到驱动！\");\n            var3.printStackTrace();\n        } catch (Exception var4) {\n            var4.printStackTrace();\n        }\n\n    }\n\n    public ResultSet select(String sql) {\n        try {\n            return this.statement.executeQuery(sql);\n        } catch (SQLException var3) {\n            System.out.println(\"查询异常......\");\n            var3.printStackTrace();\n            return null;\n        }\n    }\n\n    public int insert(String sql) {\n        try {\n            int number = this.statement.executeUpdate(sql);\n            System.out.println(\"插入成功！受影响的行数：\" + number);\n            return number;\n        } catch (SQLException var3) {\n            var3.printStackTrace();\n            return 0;\n        }\n    }\n\n    public int update(String sql) {\n        try {\n            int number = this.statement.executeUpdate(sql);\n            System.out.println(\"更新成功！受影响的行数：\" + number);\n            return number;\n        } catch (SQLException var3) {\n            var3.printStackTrace();\n            return 0;\n        }\n    }\n\n    public int delete(String sql) {\n        try {\n            int number = this.statement.executeUpdate(sql);\n            System.out.println(\"删除成功！受影响的行数：\" + number);\n            return number;\n        } catch (SQLException var3) {\n            var3.printStackTrace();\n            return 0;\n        }\n    }\n```\n\n记住 **`ConnectMysql`** 这个类放在了 **`com.sixibiheye.mysql`** 包里，现在，我们尝试着将其打包成`jar`包。同样的，我们不借助任何第三方工具，采用最原生的`java`命令来打`jar`包。下面的教程假设小伙伴们已经配置好了java的基础环境。（`Mac`用户与`Windows`用户均可用）\n\n## 制作`jar`包清单材料\n\n首先，我们来看看，打包成一个`jar`包需要哪些东西：\n\n![img](/images/assets/c9fbbd1103431e625a9ffa2bd614e781.png)\n\n我们新建一个`MakeJar`文件夹（文件夹名任意），在这个文件夹中，添加三个材料： \n\n- 编译后的`.class`文件（如果有多个`.class`文件且处于不同的包里，注意放到对应的包里）\n- `MANIFEST.MF`清单文件（待会解释）\n- 打`jar`包所依赖的`jar`包（此例中由于使用到了`jdbc`驱动包，故需要将其添加进去，此外，`java`自带的`jar`包无需添加进去，如`java.sql.*`）\n\n第一，三个材料大家容易理解，这里主要介绍一下`MANIFEST.MF`清单文件， 清单文件用来指明我们打`jar`包的一些基本信息，最重要的是主区（`Main Section`）的四个属性： \n\n- **`Manifest-Version`**\n\n​    版本号，如`1.0`\n\n- **`Create-By`** \n\n​    创建者，一般格式：`jdk`版本(开发者或公司) ，如 `1.6.0_35(sum Microsystems Inc.)`，可以省略。\n\n- **`Main-Class`**\n\n可执行`jar`包（即包含`main`方法）的入口类名，如果我们编写的多个类含有多个`main`方法，此属性可指定调用`jar`包的入口类的`main`方法。如果编写的 `ConnectMysql `类中无`main()`方法，则`Main-Class`属性可以省略。值得注意的是，属性值一定要包含类所在的包名，如：\n\n`Main-Class: com.sixibiheye.mysql.ConnectMysql`\n\n- **`Class-Path`** \n\n   ` JVM`搜索依赖的`jar`包的路径，三种情况：\n\n- 如果依赖的`jar`包就在当前路径，直接使用jar包名即可；\n- 如果依赖的`jar`包不在当前路径，使用全局路径；\n- 如果依赖的`jar`包在当前路径的子路径中，使用相对路径。 \n\n如果有多个依赖的`jar`包，包与包之间用一个空格隔开即可。此处，我们所依赖的`jar`包就在当前路径，所以直接写`jar`包名即可。\n\n当然清单文件中还可以添加一些其他内容，感兴趣的小伙伴们可以去查阅有关资料。\n\n此例中，我们的`MANIFEST.MF`清单文件长这样： \n\n![img](/images/assets/794c08029f1ec5884a010804367566af.png)\n\n注意：属性与属性值之间有一个空格；最后一定要留出一空行，否则最后一行读取不到。\n\n## 打`jar`包\n\n接下来，我们开始打包，`Java`提供了 **`jar命令`** 用于打jar包。\n\n打开我们的`cmd`（控制台），将当前路径切换至`MakeJar`，接着输入如下命令：\n\n **`jar -cvfm mysql-connector-java.jar MANIFEST.MF -C ./ .`** \n\n命令中，`mysql-connector-java.jar`为生成的jar包的名称，`MANIFEST.MF` 表示使用指定此清单文件用于生成`jar`包，“` ./` ”和后面的“` .` ”之间有一空格，控制参数`c，v，f，m`的含义分别是：\n\n- -c：即`create`，创建一个`jar`包\n- -v：即`view`，生成详细的报告并输出至标准设备\n- -f：即`force`，指定生成的`jar`包的名称\n- -m：即`manifest.mf`清单文件，指定一个清单文件\n\n末尾 “ `-C` ” 参数的含义是， 转到相应的目录下执行`jar`命令，即相当于`cd`到那个目录，然后不带“` -C` ” 参数执行`jar`命令。\n\n图示如下：\n\n![img](/images/assets/148c163d7efe70644dad1593472d03ac.png)\n\n如果输出类似上述信息，则表示打包成功。\n\n在`MakeJar`文件夹中，我们可以看到生成的 **`mysql-connector-java.jar` **:\n\n![img](/images/assets/f4df857f2721a51c441484fa9c1050dc.png)\n\n一个简单的`jar`包就生成完毕了。\n\n## `jar`包测试\n\n我们来测试一下这个`jar`包好不好使，在上述目录中，编写一个`Test.java`类，代码如下：\n\n```java\npackage com.sixibiheye.mysql;\n\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\n/**\n * @author sixibiheye\n * @date 2021/11/3\n * @apiNote 自定义jar包的测试类\n */\n\npublic class Test {\n    public static void main(String[] args) throws SQLException {\n        ConnectMysql connector = new ConnectMysql(\"localhost:3306/sixibiheye\",\"everyone\",\"123456\");\n        String sql = \"select username,sex from user;\";\n        //ResultSet类，用来存放获取的结果集！！\n        ResultSet rs = connector.select(sql);\n        System.out.println(\"-----------------\");\n        System.out.println(\"执行结果如下所示:\");\n        System.out.println(\"-----------------\");\n        System.out.println(\"姓名\" + \"\\t\" + \"性别\");\n        System.out.println(\"-----------------\");\n\n        String name = null;\n        String sex = null;\n        while(rs.next()){\n            //获取stuname这列数据\n            name = rs.getString(\"username\");\n            //获取stuid这列数据\n            sex = rs.getString(\"sex\");\n\n            //输出结果\n            System.out.println(name + \"\\t\" + sex);\n        }\n        rs.close();\n\n    }\n}\n```\n\n进入`MakeJar`文件夹中，在命令行输入如下命令：\n\n![img](/images/assets/7e0c6e43bc1f179caa6a887f0d30e600.png)控制参数 “ **`-cp`** ” （即`ClassPath`)告诉`JVM`源文件编译运行时所依赖的`jar`包的路径，路径的写法与之前清单文件中的`Class-Path`类似。 \n\n可以看到，我们成功地获得了想要的数据。使用封装好的`jar`包连接数据库并获得数据的代码量要少得多。这再一次体现出封装的优越性。\n","categories":["Java"]},{"title":"游戏实战之--《ink spill》（附游戏完整源码）","url":"/2021/10/10/y1s02h4v/","content":"\n# 前言\n\n通过前两章对`Pygame`的学习，我们了解了它的基本使用，现在，我们就开始真正动手写一个游戏。\n\n这个游戏名字为：**ink spill**，中文名：`墨水溢出`。这是`Python`中一个非常典型的游戏，我们首先来看看游戏长什么样子以及应该怎么玩：\n\n![img](/images/assets/e08633e9e4d1ccb8cb7cdc46769ffe20.gif)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑\n\n小伙伴们看完后，应该差不多明白这个游戏的玩法了。现在，让我们站在“`设计者`”的角度来考虑，这个游戏应该怎么去制作。 \n\n# 如何制作游戏？\n\n一般说来，游戏制作要考虑三个方面的内容：\n\n> - 游戏道具 （图片，音效等）\n> - 逻辑控制 （游戏状态的逻辑控制）\n> - UI设计 （游戏界面的设计）\n>\n\n**游戏道具** ，主要通过两种方式获得：一是`加载图片`，二是`用代码直接绘制`。\n\n本游戏中，需要用到的图片有以下几个：\n\n<hr>\n\n![img](/images/assets/1f61b2453febda931da9dd3c2a059eab.png)\n\n![img](/images/assets/db25dc823548abd4765d73007617ae3a.png)\n\n![img](/images/assets/a8fa96360f9c800216256eee36701874.png) \n\n![img](/images/assets/dba97aff44e72f0bb5910ab3b37161fa.png)\n\n![img](/images/assets/12121b2f22433cb8ce0c9ba1d3ab80f8.png) \n\n<hr>\n其余的，咱均用代码直接绘制。\n\n# ink spill 分析\n\n## 游戏主界面\n\n![img](/images/assets/db27c81b5baa05d7a621178ac19875de.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑\n\n它主要由以下几个部分组成：\n\n> - 界面正中央的大格子\n> - 界面左边的生命“计”\n> - 界面正下方的六个不同颜色的调色板\n> - 界面右下方的“重新游戏”按钮和“设置”按钮\n>\n\n## 如何设计 ink spill 的难度？\n\n大伙首先想到的肯定是，控制小格子的数量，`数量越多，难度越大`：\n\n![img](/images/assets/bf2fe7a74c9039720990fafe822c25ea.gif)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑\n\n除此之外，关于游戏难度，咱还可以创建一个 **boxesToChange** 变量，随机将某个小格子的周围格子变成与之同色，这样的格子数用`boxesToChange`来描述，这样，“`简单难度`”就将`boxesToChange`的值设大一点（使得同色的越多），“`困难难度`”就将`boxesToChange`的值设小一点（使得同色的越少）（或者直接设为0）。\n\n## ink spill 有哪些游戏状态？\n\n前面几章说过，一个游戏会有各种各样的`游戏状态`，比如`角色的血量，武器类型`等。首先，让我们思考一下，在这个游戏中，需要哪些变量来存储哪些游戏状态呢？\n\n不知道小伙伴们能想到多少个`游戏状态`，答案在下面的代码中：\n\n```python\n# 根据设置界面，有不同的整个格子尺寸、小格子数量和生命\n\n# 小格子大小\nSMALL_BOX_SIZE = 60  # 大小以像素为单位\nMEDIUM_BOX_SIZE = 20\nLARGE_BOX_SIZE = 11\n\n# 整个格子的大小\nSMALL_BOARD_SIZE = 6  # 大小以一个小格子为单位\nMEDIUM_BOARD_SIZE = 17\nLARGE_BOARD_SIZE = 30\n\n# 最多几次操作（生命）\nSMALL_MAX_LIFE = 10\nMEDIUM_MAX_LIFE = 30\nLARGE_MAX_LIFE = 64\n\nFPS = 30\nWINDOW_WIDTH = 640\nWINDOW_HEIGHT = 480\nboxSize = MEDIUM_BOX_SIZE\nPALETTE_GAP_SIZE = 10  # 调色板间隔大小\nPALETTE_SIZE = 45\nEASY = 0  # 难度：简单\nMEDIUM = 1  # 难度：中等\nHARD = 2  # 难度：困难\n\ndifficulty = MEDIUM  # 游戏以难度“中等”模式开始\nmaxLife = MEDIUM_MAX_LIFE\nboardWidth = MEDIUM_BOARD_SIZE\nboardHeight = MEDIUM_BOARD_SIZE\n\n#            R    G    B\nWHITE = (255, 255, 255)\nDARKGRAY = (70, 70, 70)\nBLACK = (0, 0, 0)\nRED = (255, 0, 0)\nGREEN = (0, 255, 0)\nBLUE = (0, 0, 255)\nYELLOW = (255, 255, 0)\nORANGE = (255, 128, 0)\nPURPLE = (255, 0, 255)\n\n# 每个方案中的第一种颜色是背景色，接下来的六种是调色板颜色。\nCOLOR_SCHEMES = (((150, 200, 255), RED, GREEN, BLUE, YELLOW, ORANGE, PURPLE),\n                 ((0, 155, 104), (97, 215, 164), (228, 0, 69), (0, 125, 50), (204, 246, 0), (148, 0, 45),\n                  (241, 109, 149)),\n                 ((195, 179, 0), (255, 239, 115), (255, 226, 0), (147, 3, 167), (24, 38, 176), (166, 147, 0),\n                  (197, 97, 211)),\n                 ((85, 0, 0), (155, 39, 102), (0, 201, 13), (255, 118, 0), (206, 0, 113), (0, 130, 9), (255, 180, 115)),\n                 ((191, 159, 64), (183, 182, 208), (4, 31, 183), (167, 184, 45), (122, 128, 212), (37, 204, 7),\n                  (88, 155, 213)),\n                 ((200, 33, 205), (116, 252, 185), (68, 56, 56), (52, 238, 83), (23, 149, 195), (222, 157, 227),\n                  (212, 86, 185)))\n# 对颜色的处理\nfor i in range(len(COLOR_SCHEMES)):\n    assert len(COLOR_SCHEMES[i]) == 7, '颜色方案 %s 没有7种颜色！.' % (i)\n# 背景色，调色板设置默认色\nbgColor = COLOR_SCHEMES[0][0]\npaletteColors = COLOR_SCHEMES[0][1:]\n```\n\n你会看到，记录游戏状态，用到了非常多的变量。依据变量的名称，咱可以很容易推出这个变量的作用是什么。实际上，之后的游戏逻辑控制，就是在更改这些变量的值。\n\n## ink spill 游戏框架\n\n接着，我们来考虑编写整个`游戏框架`。\n\n接下来编写的代码会非常之多，请小伙伴们仔细体会每个函数的具体作用，这样才能更好的理解整个游戏。\n\n框架编写如下：\n\n```python\ndef main():\n    # 需要用到函数之外的变量\n    global FPS_CLOCK, DISPLAY_SURF, LOGO_IMAGE, SPOT_IMAGE, SETTINGS_IMAGE, SETTINGS_BUTTON_IMAGE, RESET_BUTTON_IMAGE\n    \n    # 初始化\n    pygame.init()\n\n    # 控制帧率\n    FPS_CLOCK = pygame.time.Clock()\n    \n    # 创建窗口\n    DISPLAY_SURF = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n\n    # 加载图片\n    LOGO_IMAGE = pygame.image.load('inkspilllogo.png')\n    SPOT_IMAGE = pygame.image.load('inkspillspot.png')\n    SETTINGS_IMAGE = pygame.image.load('inkspillsettings.png')\n    SETTINGS_BUTTON_IMAGE = pygame.image.load('inkspillsettingsbutton.png')\n    RESET_BUTTON_IMAGE = pygame.image.load('inkspillresetbutton.png')\n\n    # 设置窗口标题\n    pygame.display.set_caption('墨水溢出')\n\n    # 生成界面\n    mainBoard = generateRandomBoard(boardWidth, boardHeight, difficulty)\n    life = maxLife\n\n    # 记录上次点击界面下方调色板的颜色\n    lastPaletteClicked = None\n\n    while True:  # 主游戏循环\n        paletteClicked = None\n        resetGame = False\n\n        # 画屏幕\n        DISPLAY_SURF.fill(bgColor)\n\n        # 加载图标和相关按钮\n        drawLogoAndButtons()\n\n        # 加载正中央的大格子并随机初始化每个小格子的颜色\n        drawBoard(mainBoard)\n\n        # 加载左侧的\"生命计\"\n        drawLifeMeter(life)\n\n        # 加载屏幕底部的六个调色板\n        drawPalettes()\n\n        # 判断玩家是否想要退出游戏\n        checkForQuit()\n```\n\n代码中有许多函数如`generateRandomBoard()`，我们还未实现，下面我们来实现这些函数：\n\n### generateRandomBoard()\n\n产生`游戏主窗口`-----中央的整个大格子： \n\n```python\ndef generateRandomBoard(width, height, difficulty=MEDIUM):\n\n    # 为整个大格子中的每个小格子创建具有随机颜色的数据结构。\n    board = []\n    for x in range(width):\n        column = []\n        for y in range(height):\n            column.append(random.randint(0, len(paletteColors) - 1))\n        board.append(column)\n\n    # 通过将一些小格子设置为与相邻格子相同的颜色，使同色整个大格子更容易。\n\n    # 确定要更改的小格子数。\n    if difficulty == EASY:\n        if boxSize == SMALL_BOX_SIZE:\n            boxesToChange = 100\n        else:\n            boxesToChange = 1500\n    elif difficulty == MEDIUM:\n        if boxSize == SMALL_BOX_SIZE:\n            boxesToChange = 5\n        else:\n            boxesToChange = 200\n    else:\n        boxesToChange = 0\n\n    # 挂邻居格子的颜色：\n    for i in range(boxesToChange):\n        # 随机选择要复制其颜色的框\n        x = random.randint(1, width - 2)\n        y = random.randint(1, height - 2)\n\n        # 随机选择要更改的邻居格子\n        direction = random.randint(0, 3)\n        if direction == 0:  # 左，下\n            board[x - 1][y] = board[x][y]\n            board[x][y - 1] = board[x][y]\n        elif direction == 1:  # 右，上\n            board[x + 1][y] = board[x][y]\n            board[x][y + 1] = board[x][y]\n        elif direction == 2:  # 左，下\n            board[x][y - 1] = board[x][y]\n            board[x + 1][y] = board[x][y]\n        else:  # 左，上\n            board[x][y + 1] = board[x][y]\n            board[x - 1][y] = board[x][y]\n\n    return board\n```\n\n### drawLogoAndButtons()\n\n给界面加上部分`按钮和图标`：\n\n```python\ndef drawLogoAndButtons():\n    # 绘制墨水溢出徽标、设置和重置按钮。\n    # bait()函数用于将图片加载到DISPALY_SURF这个Surface对象上\n    DISPLAY_SURF.blit(LOGO_IMAGE, (WINDOW_WIDTH - LOGO_IMAGE.get_width(), 0))\n    DISPLAY_SURF.blit(SETTINGS_BUTTON_IMAGE,\n                      (WINDOW_WIDTH - SETTINGS_BUTTON_IMAGE.get_width(),\n                       WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height()))\n    DISPLAY_SURF.blit(RESET_BUTTON_IMAGE, (WINDOW_WIDTH - RESET_BUTTON_IMAGE.get_width(),\n                                           WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height() - RESET_BUTTON_IMAGE.get_height()))\n```\n\n代码中使用了大量`坐标运算`来控制图片的位置，请小伙伴们细细体会。 \n\n### drawBoard(mainBoard)\n\n加载界面`正中央的大格子`并随机初始化每个小格子的颜色：\n\n```python\ndef drawBoard(board, transparency=255):  # 透明度设置默认为255\n    # 彩色方块将绘制到临时曲面，然后绘制到DISPLAY_SURF曲面。这样我们就可以在DISPLAY_SURF的顶部绘制具有透明度的正方形了。\n    tempSurf = pygame.Surface(DISPLAY_SURF.get_size())  # 获取窗口尺寸\n    tempSurf = tempSurf.convert_alpha()   # 支持透明\n    tempSurf.fill((0, 0, 0, 0))   # 先全部处理为黑色\n\n    for x in range(boardWidth):\n        for y in range(boardHeight):\n            # 获取每个小格子左上角的坐标\n            left, top = leftTopPixelCoordOfBox(x, y)\n            r, g, b = paletteColors[board[x][y]]\n            pygame.draw.rect(tempSurf, (r, g, b, transparency), (left, top, boxSize, boxSize))\n    left, top = leftTopPixelCoordOfBox(0, 0)\n    # 为防止边缘的小格子颜色与窗口背景色相同，在整个大格子外面包一层黑色细线，厚度为1px\n    pygame.draw.rect(tempSurf, BLACK, (left - 1, top - 1, boxSize * boardWidth + 1, boxSize * boardHeight + 1), 1)\n    DISPLAY_SURF.blit(tempSurf, (0, 0))\n```\n\n代码中调用了`leftTopPixelCoordOfBox(x,y)`，实现如下：\n\n```python\ndef leftTopPixelCoordOfBox(boxx, boxy):\n    # 返回某个小格子最左上方像素的x和y。\n    # 注意整个大格子位于窗口的正中央\n    x_margin = int((WINDOW_WIDTH - (boardWidth * boxSize)) / 2)  # x_margin 为整个大格子最左边与窗口最左边的间距\n    y_margin = int((WINDOW_HEIGHT - (boardHeight * boxSize)) / 2)  # y_margin 为整个大格子最上边与窗口最上边的间距\n    return boxx * boxSize + x_margin, boxy * boxSize + y_margin\n```\n\n### drawLifeMeter(life)\n\n绘制游戏界面左边的`生命“计”`并进行简单的`生命“逻辑计算”`：\n\n```python\ndef drawLifeMeter(currentLife):\n    # '生命计' 竖直放置，与上下边缘各相距20px\n    lifeBoxSize = int((WINDOW_HEIGHT - 40) / maxLife)\n\n    # 绘制\"生命计\"的背景色，'生命计'的左上角位于坐标(20,20),宽20px，高20 + (maxLife * lifeBoxSize) px\n    pygame.draw.rect(DISPLAY_SURF, bgColor, (20, 20, 20, 20 + (maxLife * lifeBoxSize)))\n\n    for i in range(maxLife):\n        if currentLife >= (maxLife - i):  # 画一个实心的红色方框\n            pygame.draw.rect(DISPLAY_SURF, RED, (20, 20 + (i * lifeBoxSize), 20, lifeBoxSize))\n        # 加1px白色的边框\n        pygame.draw.rect(DISPLAY_SURF, WHITE, (20, 20 + (i * lifeBoxSize), 20, lifeBoxSize), 1)\n```\n\n在图形的位置定位上，我们用了大量的`坐标运算`，请小伙伴们细细体会。 \n\n### drawPalettes()\n\n给界面添上`正下方的六个调色板`并进行简单的逻辑控制： \n\n```python\ndef drawPalettes():\n    # 在屏幕底部绘制六个调色板\n    numColors = len(paletteColors)\n    x_margin = int((WINDOW_WIDTH - ((PALETTE_SIZE * numColors) + (PALETTE_GAP_SIZE * (numColors - 1)))) / 2)\n    for i in range(numColors):\n        left = x_margin + (i * PALETTE_SIZE) + (i * PALETTE_GAP_SIZE)\n        top = WINDOW_HEIGHT - PALETTE_SIZE - 10\n        pygame.draw.rect(DISPLAY_SURF, paletteColors[i], (left, top, PALETTE_SIZE, PALETTE_SIZE))\n        # 为了美观，在格子外2px再加2px厚度的对应颜色的区域\n        pygame.draw.rect(DISPLAY_SURF, bgColor, (left + 2, top + 2, PALETTE_SIZE - 4, PALETTE_SIZE - 4), 2)\n```\n\n### checkForQuit()\n\n玩家想要`退出游戏`时的处理：\n\n```python\ndef checkForQuit():\n    # 如果存在任何退出事件，则终止程序\n    for event in pygame.event.get(QUIT):  # 获取所有退出事件\n        pygame.quit()  # 如果存在任何退出事件，则终止\n        sys.exit()\n    for event in pygame.event.get(KEYUP):  # 获取所有KEYUP（按键按下）事件\n        if event.key == K_ESCAPE:\n            pygame.quit()  # 如果KEYUP（按键按下）事件是针对Esc键的，则终止\n            sys.exit()\n        pygame.event.post(event)  # 将其他KEYUP（按键按下）事件对象放回原处\n```\n\n## 逻辑控制\n\n接着，我们来考虑游戏的`主要逻辑控制`。\n\n由于我们并未创建按钮，所以当“`鼠标点击`”这个事件发生时，我们尝试着获取其点击的位置坐标（利用`Event对象`的 **`pos`** 属性：`mousex`, `mousey = event.pos`），将这个坐标与界面上某个图标的位置区域比较（使用**`pygame.Rest.collidepoint(mousex, mousey)`**函数），如果在这个区域内，就说明玩家想要点击该图标来实现对应的功能（如鼠标点击“**`reset`**”图标表示玩家想重新开始游戏），我们编写代码做出响应即可。基于这样的思想，咱可以将`main()函数`补充完整： \n\n```python\ndef main():\n    global FPS_CLOCK, DISPLAY_SURF, LOGO_IMAGE, SPOT_IMAGE, SETTINGS_IMAGE, SETTINGS_BUTTON_IMAGE, RESET_BUTTON_IMAGE\n\n    pygame.init()\n    FPS_CLOCK = pygame.time.Clock()\n    DISPLAY_SURF = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n\n    # 加载图片\n    LOGO_IMAGE = pygame.image.load('inkspilllogo.png')\n    SPOT_IMAGE = pygame.image.load('inkspillspot.png')\n    SETTINGS_IMAGE = pygame.image.load('inkspillsettings.png')\n    SETTINGS_BUTTON_IMAGE = pygame.image.load('inkspillsettingsbutton.png')\n    RESET_BUTTON_IMAGE = pygame.image.load('inkspillresetbutton.png')\n\n    # 设置窗口标题\n    pygame.display.set_caption('墨水溢出')\n    mainBoard = generateRandomBoard(boardWidth, boardHeight, difficulty)\n    life = maxLife\n    lastPaletteClicked = None\n\n    while True:  # 主游戏循环\n        paletteClicked = None\n        resetGame = False\n\n        # 画屏幕\n        DISPLAY_SURF.fill(bgColor)\n        # 加载图标和相关按钮\n        drawLogoAndButtons()\n        # 加载正中央的大格子并随机初始化每个小格子的颜色\n        drawBoard(mainBoard)\n        # 加载左侧的\"生命计\"\n        drawLifeMeter(life)\n        # 加载屏幕底部的六个调色板\n        drawPalettes()\n        # 判断玩家是否想要退出游戏\n        checkForQuit()\n\n        for event in pygame.event.get():  # 事件处理循环\n            if event.type == MOUSEBUTTONUP:  # 如果事件是鼠标点击\n                mousex, mousey = event.pos   # 获取鼠标点击的坐标\n                # 如果点击的是\"SETTINGS\"字样处\n                if pygame.Rect(WINDOW_WIDTH - SETTINGS_BUTTON_IMAGE.get_width(),\n                               WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height(),\n                               SETTINGS_BUTTON_IMAGE.get_width(),\n                               SETTINGS_BUTTON_IMAGE.get_height()).collidepoint(mousex, mousey):\n                    # 就展示设置界面\n                    resetGame = showSettingsScreen()   # showSettingsScreen() 待实现\n                # 如果点击的是\"RESET\"字样处\n                elif pygame.Rect(WINDOW_WIDTH - RESET_BUTTON_IMAGE.get_width(),\n                                 WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height() - RESET_BUTTON_IMAGE.get_height(),\n                                 RESET_BUTTON_IMAGE.get_width(),\n                                 RESET_BUTTON_IMAGE.get_height()).collidepoint(mousex, mousey):\n                    # 就重新开始游戏\n                    resetGame = True\n                else:\n                    # 检查是否点击了调色板按钮，如果点击了，返回六个调色板中点击的那一个颜色的索引\n                    paletteClicked = getColorOfPaletteAt(mousex, mousey)  # getColorOfPaletteAt()待实现\n\n        if paletteClicked is not None and paletteClicked != lastPaletteClicked:\n\n            # 单击的调色板按钮与上次单击的调色板按钮不同，防止鼠标意外单击同一调色板两次\n            lastPaletteClicked = paletteClicked\n\n            # 对大格子填充颜色，floodAnimation()待实现\n            floodAnimation(mainBoard, paletteClicked)\n            # 点击一次，\"生命\"减少1\n            life -= 1\n\n            resetGame = False\n            if hasWon(mainBoard):  # 如果赢了，hasWon()待实现\n                for i in range(4):  # 成功的界面效果：闪烁边框4次\n                    flashBorderAnimation(WHITE, mainBoard)   # flashBorderAnimation()待实现\n                # \"闪光\"结束后，重新开始游戏\n                resetGame = True\n                # 暂停2s后再开始游戏\n                pygame.time.wait(2000)\n            elif life == 0:\n                # 生命降为零，玩家失败\n                drawLifeMeter(0)\n                # 更新界面\n                pygame.display.update()\n                # 等待0.4s\n                pygame.time.wait(400)\n                # 失败的结束效果：用黑色\"闪光\"4次\n                for i in range(4):\n                    flashBorderAnimation(BLACK, mainBoard)。 # flashBorderAnimation()待实现\n                resetGame = True\n                # 暂停2s后开始重新游戏\n                pygame.time.wait(2000)\n\n        if resetGame:\n            # 重新开始游戏\n            mainBoard = generateRandomBoard(boardWidth, boardHeight, difficulty)\n            life = maxLife\n            lastPaletteClicked = None\n        # 更新界面\n        pygame.display.update()\n        # 控制帧率\n        FPS_CLOCK.tick(FPS)\n```\n\n上述主要`逻辑控制`代码中，还有部分函数未实现：\n\n### showSettingsScreen()\n\n展示`“设置”界面`并提供相应逻辑控制：\n\n![img](/images/assets/5e067161c8e70d808197ff5e0f01caf6.png)\n\n```python\ndef showSettingsScreen():\n    # 获取全局变量\n    global difficulty, boxSize, boardWidth, boardHeight, maxLife, paletteColors, bgColor\n\n    # 此函数中的像素坐标是通过将inkspillsettings.png图像加载到图形编辑器中并从中读取像素坐标获得的\n\n    origDifficulty = difficulty\n    origBoxSize = boxSize\n    screenNeedsRedraw = True\n\n    while True:\n        if screenNeedsRedraw:\n            DISPLAY_SURF.fill(bgColor)\n            # 加载\"设置\"图片\n            DISPLAY_SURF.blit(SETTINGS_IMAGE, (0, 0))\n\n            # 将\"墨迹\"图片标记放在选定的颜色左边\n            if difficulty == EASY:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (30, 4))\n            if difficulty == MEDIUM:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (8, 41))\n            if difficulty == HARD:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (30, 76))\n\n            # 将墨迹标记放置在选定尺寸旁边\n            if boxSize == SMALL_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (22, 150))\n            if boxSize == MEDIUM_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (11, 185))\n            if boxSize == LARGE_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (24, 220))\n\n            # 加载设置界面右边的颜色选择框\n            for i in range(len(COLOR_SCHEMES)):\n                drawColorSchemeBoxes(500, i * 60 + 30, i)  # 待实现\n\n            # 更新界面\n            pygame.display.update()\n\n        screenNeedsRedraw = False  # 默认情况下，不重新绘制屏幕\n        # 事件处理循环\n        for event in pygame.event.get():\n            if event.type == QUIT:\n                pygame.quit()\n                sys.exit()\n            elif event.type == KEYUP:\n                if event.key == K_ESCAPE:\n                    # 设置屏幕上的Esc键返回游戏\n                    return not (origDifficulty == difficulty and origBoxSize == boxSize)\n            elif event.type == MOUSEBUTTONUP:\n                screenNeedsRedraw = True  # 屏幕应该重新绘制\n                mousex, mousey = event.pos  # 鼠标点击的坐标\n\n                # 检查难度按钮上是否有咔嗒声\n                if pygame.Rect(74, 16, 111, 30).collidepoint(mousex, mousey):\n                    difficulty = EASY\n                elif pygame.Rect(53, 50, 104, 29).collidepoint(mousex, mousey):\n                    difficulty = MEDIUM\n                elif pygame.Rect(72, 85, 65, 31).collidepoint(mousex, mousey):\n                    difficulty = HARD\n\n                # 检查尺寸按钮上是否有点击\n                elif pygame.Rect(63, 156, 84, 31).collidepoint(mousex, mousey):\n                    # 小板尺寸设置：\n                    boxSize = SMALL_BOX_SIZE\n                    boardWidth = SMALL_BOARD_SIZE\n                    boardHeight = SMALL_BOARD_SIZE\n                    maxLife = SMALL_MAX_LIFE\n                elif pygame.Rect(52, 192, 106, 32).collidepoint(mousex, mousey):\n                    # 中板尺寸设置：\n                    boxSize = MEDIUM_BOX_SIZE\n                    boardWidth = MEDIUM_BOARD_SIZE\n                    boardHeight = MEDIUM_BOARD_SIZE\n                    maxLife = MEDIUM_MAX_LIFE\n                elif pygame.Rect(67, 228, 58, 37).collidepoint(mousex, mousey):\n                    # 大板尺寸设置：\n                    boxSize = LARGE_BOX_SIZE\n                    boardWidth = LARGE_BOARD_SIZE\n                    boardHeight = LARGE_BOARD_SIZE\n                    maxLife = LARGE_MAX_LIFE\n                elif pygame.Rect(178, 418, 215, 34).collidepoint(mousex, mousey):\n                    # 点击“Back To Game”按钮\n                    return not (origDifficulty == difficulty and origBoxSize == boxSize)\n\n                for i in range(len(COLOR_SCHEMES)):\n                    # 单击颜色方案按钮\n                    if pygame.Rect(500, 30 + i * 60, MEDIUM_BOX_SIZE * 3, MEDIUM_BOX_SIZE * 2).collidepoint(mousex,\n                                                                                                            mousey):\n                        bgColor = COLOR_SCHEMES[i][0]\n                        paletteColors = COLOR_SCHEMES[i][1:]\n```\n\n上述代码中调用了 `drawColorSchemeBoxes()`：实现如下：\n\n```python\ndef drawColorSchemeBoxes(x, y, schemeNum):\n    # 绘制“设置”屏幕上显示的颜色方案框\n    for boxy in range(2):\n        for boxx in range(3):\n            pygame.draw.rect(DISPLAY_SURF, COLOR_SCHEMES[schemeNum][3 * boxy + boxx + 1],\n                             (x + MEDIUM_BOX_SIZE * boxx, y + MEDIUM_BOX_SIZE * boxy, MEDIUM_BOX_SIZE, MEDIUM_BOX_SIZE))\n            if paletteColors == COLOR_SCHEMES[schemeNum][1:]:\n                # 将\"墨迹\"图片放置在所选配色方案旁边\n                DISPLAY_SURF.blit(SPOT_IMAGE, (x - 50, y))\n```\n\n### getColorOfPaletteAt(mousex, mousey)\n\n获取被点击的调色板颜色的`索引`：\n\n```python\ndef getColorOfPaletteAt(x, y):\n    # 返回x和y参数覆盖的调色板颜色的索引\n    numColors = len(paletteColors)\n    xmargin = int((WINDOW_WIDTH - ((PALETTE_SIZE * numColors) + (PALETTE_GAP_SIZE * (numColors - 1)))) / 2)\n    # 调色板底端距窗口底端10px\n    top = WINDOW_HEIGHT - PALETTE_SIZE - 10\n    for i in range(numColors):\n        # 六个调色板左上角的坐标：（left,top）\n        left = xmargin + (i * PALETTE_SIZE) + (i * PALETTE_GAP_SIZE)\n        r = pygame.Rect(left, top, PALETTE_SIZE, PALETTE_SIZE)\n        # 找出鼠标单击区域是否在任何调色板内\n        if r.collidepoint(x, y):\n            return i  # 如果在，则返回所点击的调色板的序号\n    # 如果x和y不在任何调色板上，则返回None\n    return None\n```\n\n### hasWon()\n\n判断玩家`是否胜利`，实现如下：\n\n```python\ndef hasWon(board):\n    # 如果整个棋盘颜色相同，则表示玩家获胜\n    for x in range(boardWidth):\n        for y in range(boardHeight):\n            # 只要发现一个颜色与左上角的颜色不同，玩家还没有赢\n            if board[x][y] != board[0][0]:\n                return False\n    return True\n```\n\n### floodAnimation(mainBoard, paletteClicked)\n\n用`paletteClicked`对应的颜色填充`mainBoard`（中央的大格子）:\n\n```python\ndef floodAnimation(board, paletteClicked, animationSpeed=25):\n    origBoard = copy.deepcopy(board)  # 深拷贝整个大格子\n    # 从左上角处的格子开始同色填充，floodFill()待实现\n    floodFill(board, board[0][0], paletteClicked, 0, 0)\n\n    for transparency in range(0, 255, animationSpeed):\n        # “新”大格子在大格子上慢慢变得不透明\n        drawBoard(origBoard)\n        # 更新透明度\n        drawBoard(board, transparency)\n        # 更新界面\n        pygame.display.update()\n        # 控制帧率\n        FPS_CLOCK.tick(FPS)\n```\n\n### floodFill()\n\n`填充算法`，实现如下：\n\n```python\ndef floodFill(board, oldColor, newColor, x, y):\n    # 洪水填充算法\n    if oldColor == newColor or board[x][y] != oldColor:\n        # 如果左上角的颜色和点击颜色没有相邻，直接返回\n        return\n    board[x][y] = newColor  # 更改当前格子的颜色\n    # 对任何相邻格子进行递归调用：\n    if x > 0:\n        floodFill(board, oldColor, newColor, x - 1, y)\n    if x < boardWidth - 1:\n        floodFill(board, oldColor, newColor, x + 1, y)\n    if y > 0:\n        floodFill(board, oldColor, newColor, x, y - 1)\n    if y < boardHeight - 1:\n        floodFill(board, oldColor, newColor, x, y + 1)\n```\n\n### flashBorderAnimation(Color, mainBoard)\n\n游戏胜利或失败的`结束画面`：\n\n```python\ndef flashBorderAnimation(color, board, animationSpeed=30):\n    # \"闪光\"效果结束后，需要回到原来（游戏刚结束）的界面，此处先保存原来的界面\n    origSurf = DISPLAY_SURF.copy()\n    flashSurf = pygame.Surface(DISPLAY_SURF.get_size())\n    flashSurf = flashSurf.convert_alpha()\n    # 实现\"闪光\"效果\n    for start, end, step in ((0, 256, 1), (255, 0, -1)):\n        # 外循环的第一次迭代将内循环的透明度设置为从0到255，第二次迭代将透明度设置为从255到0。这就是“闪光”。\n        for transparency in range(start, end, animationSpeed * step):\n            DISPLAY_SURF.blit(origSurf, (0, 0))\n            r, g, b = color\n            flashSurf.fill((r, g, b, transparency))\n            DISPLAY_SURF.blit(flashSurf, (0, 0))\n            drawBoard(board)  # 在透明层的顶部绘制板\n            # 更新界面\n            pygame.display.update()\n            # 控制帧率\n            FPS_CLOCK.tick(FPS)\n    # 绘制原来（游戏刚结束）的界面\n    DISPLAY_SURF.blit(origSurf, (0, 0))\n```\n\n我猜，大伙们可能已经懵了......但是做游戏，考虑的东西会非常之多，也许咱只有好好的理解每一个细节，才能真正做出好的游戏。\n\n# 完整代码\n\n最后，附上游戏完整代码：\n\n```python\nimport random, sys, copy, pygame\nfrom pygame.locals import *  # 将所有的 Pygame 常量导入\n\n# 根据设置界面，有不同的大格子尺寸、小格子数量和寿命\n\n# 小格子大小\nSMALL_BOX_SIZE = 60  # 大小以像素为单位\nMEDIUM_BOX_SIZE = 20\nLARGE_BOX_SIZE = 11\n\n# 整个格子的大小\nSMALL_BOARD_SIZE = 6  # 大小以一个小格子为单位\nMEDIUM_BOARD_SIZE = 17\nLARGE_BOARD_SIZE = 30\n\n# 最多几次操作（生命）\nSMALL_MAX_LIFE = 10\nMEDIUM_MAX_LIFE = 30\nLARGE_MAX_LIFE = 64\n\nFPS = 30\nWINDOW_WIDTH = 640\nWINDOW_HEIGHT = 480\nboxSize = MEDIUM_BOX_SIZE\nPALETTE_GAP_SIZE = 10  # 调色板间隔大小\nPALETTE_SIZE = 45\nEASY = 0  # 难度：简单\nMEDIUM = 1  # 难度：中等\nHARD = 2  # 难度：困难\n\ndifficulty = MEDIUM  # 游戏以难度“中等”模式开始\nmaxLife = MEDIUM_MAX_LIFE\nboardWidth = MEDIUM_BOARD_SIZE\nboardHeight = MEDIUM_BOARD_SIZE\n\n#            R    G    B\nWHITE = (255, 255, 255)\nDARKGRAY = (70, 70, 70)\nBLACK = (0, 0, 0)\nRED = (255, 0, 0)\nGREEN = (0, 255, 0)\nBLUE = (0, 0, 255)\nYELLOW = (255, 255, 0)\nORANGE = (255, 128, 0)\nPURPLE = (255, 0, 255)\n\n# 每个方案中的第一种颜色是背景色，接下来的六种是调色板颜色。\nCOLOR_SCHEMES = (((150, 200, 255), RED, GREEN, BLUE, YELLOW, ORANGE, PURPLE),\n                 ((0, 155, 104), (97, 215, 164), (228, 0, 69), (0, 125, 50), (204, 246, 0), (148, 0, 45),\n                  (241, 109, 149)),\n                 ((195, 179, 0), (255, 239, 115), (255, 226, 0), (147, 3, 167), (24, 38, 176), (166, 147, 0),\n                  (197, 97, 211)),\n                 ((85, 0, 0), (155, 39, 102), (0, 201, 13), (255, 118, 0), (206, 0, 113), (0, 130, 9), (255, 180, 115)),\n                 ((191, 159, 64), (183, 182, 208), (4, 31, 183), (167, 184, 45), (122, 128, 212), (37, 204, 7),\n                  (88, 155, 213)),\n                 ((200, 33, 205), (116, 252, 185), (68, 56, 56), (52, 238, 83), (23, 149, 195), (222, 157, 227),\n                  (212, 86, 185)))\n# 对颜色的处理\nfor i in range(len(COLOR_SCHEMES)):\n    assert len(COLOR_SCHEMES[i]) == 7, '颜色方案 %s 没有7种颜色！.' % (i)\n# 背景色，调色板设置默认色\nbgColor = COLOR_SCHEMES[0][0]\npaletteColors = COLOR_SCHEMES[0][1:]\n\n\ndef main():\n    global FPS_CLOCK, DISPLAY_SURF, LOGO_IMAGE, SPOT_IMAGE, SETTINGS_IMAGE, SETTINGS_BUTTON_IMAGE, RESET_BUTTON_IMAGE\n\n    pygame.init()\n    FPS_CLOCK = pygame.time.Clock()\n    DISPLAY_SURF = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n\n    # 加载图片\n    LOGO_IMAGE = pygame.image.load('inkspilllogo.png')\n    SPOT_IMAGE = pygame.image.load('inkspillspot.png')\n    SETTINGS_IMAGE = pygame.image.load('inkspillsettings.png')\n    SETTINGS_BUTTON_IMAGE = pygame.image.load('inkspillsettingsbutton.png')\n    RESET_BUTTON_IMAGE = pygame.image.load('inkspillresetbutton.png')\n\n    # 设置窗口标题\n    pygame.display.set_caption('墨水溢出')\n    mainBoard = generateRandomBoard(boardWidth, boardHeight, difficulty)\n    life = maxLife\n    lastPaletteClicked = None\n\n    while True:  # 主游戏循环\n        paletteClicked = None\n        resetGame = False\n\n        # 画屏幕\n        DISPLAY_SURF.fill(bgColor)\n        # 加载图标和相关按钮\n        drawLogoAndButtons()\n        # 加载正中央的大格子并随机初始化每个小格子的颜色\n        drawBoard(mainBoard)\n        # 加载左侧的\"生命计\"\n        drawLifeMeter(life)\n        # 加载屏幕底部的六个调色板\n        drawPalettes()\n        # 判断玩家是否想要退出游戏\n        checkForQuit()\n\n        for event in pygame.event.get():  # 事件处理循环\n            if event.type == MOUSEBUTTONUP:  # 如果事件是鼠标点击\n                mousex, mousey = event.pos   # 获取鼠标点击的坐标\n                # 如果点击的是\"SETTINGS\"字样处\n                if pygame.Rect(WINDOW_WIDTH - SETTINGS_BUTTON_IMAGE.get_width(),\n                               WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height(),\n                               SETTINGS_BUTTON_IMAGE.get_width(),\n                               SETTINGS_BUTTON_IMAGE.get_height()).collidepoint(mousex, mousey):\n                    # 就展示设置界面\n                    resetGame = showSettingsScreen()\n                # 如果点击的是\"RESET\"字样处\n                elif pygame.Rect(WINDOW_WIDTH - RESET_BUTTON_IMAGE.get_width(),\n                                 WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height() - RESET_BUTTON_IMAGE.get_height(),\n                                 RESET_BUTTON_IMAGE.get_width(),\n                                 RESET_BUTTON_IMAGE.get_height()).collidepoint(mousex, mousey):\n                    # 就重新开始游戏\n                    resetGame = True\n                else:\n                    # 检查是否点击了调色板按钮\n                    paletteClicked = getColorOfPaletteAt(mousex, mousey)\n\n        if paletteClicked is not None and paletteClicked != lastPaletteClicked:\n\n            # 单击的调色板按钮与上次单击的调色板按钮不同，防止播放器意外单击同一调色板两次\n            lastPaletteClicked = paletteClicked\n\n            # 填充颜色\n            floodAnimation(mainBoard, paletteClicked)\n            # 点击一次，\"生命\"减少1\n            life -= 1\n\n            resetGame = False\n            if hasWon(mainBoard):  # 如果赢了\n                for i in range(4):  # 成功的界面效果：闪烁边框4次\n                    flashBorderAnimation(WHITE, mainBoard)\n                # \"闪光\"结束后，重新开始游戏\n                resetGame = True\n                # 暂停2s后再开始游戏\n                pygame.time.wait(2000)\n            elif life == 0:\n                # 生命降为零，玩家失败\n                drawLifeMeter(0)\n                # 更新界面\n                pygame.display.update()\n                # 等待0.4s\n                pygame.time.wait(400)\n                # 失败的结束效果：用黑色\"闪光\"4次\n                for i in range(4):\n                    flashBorderAnimation(BLACK, mainBoard)\n                resetGame = True\n                # 暂停2s后开始重新游戏\n                pygame.time.wait(2000)\n\n        if resetGame:\n            # 重新开始游戏\n            mainBoard = generateRandomBoard(boardWidth, boardHeight, difficulty)\n            life = maxLife\n            lastPaletteClicked = None\n        # 更新界面\n        pygame.display.update()\n        # 控制帧率\n        FPS_CLOCK.tick(FPS)\n\n\ndef checkForQuit():\n    # 如果存在任何退出事件，则终止程序\n    for event in pygame.event.get(QUIT):  # 获取所有退出事件\n        pygame.quit()  # 如果存在任何退出事件，则终止\n        sys.exit()\n    for event in pygame.event.get(KEYUP):  # 获取所有KEYUP（按键按下）事件\n        if event.key == K_ESCAPE:\n            pygame.quit()  # 如果KEYUP（按键按下）事件是针对Esc键的，则终止\n            sys.exit()\n        pygame.event.post(event)  # 将其他KEYUP（按键按下）事件对象放回原处\n\n\ndef hasWon(board):\n    # 如果整个棋盘颜色相同，则表示玩家获胜\n    for x in range(boardWidth):\n        for y in range(boardHeight):\n            # 只要发现一个颜色与左上角的颜色不同，玩家还没有赢\n            if board[x][y] != board[0][0]:\n                return False\n    return True\n\n\ndef showSettingsScreen():\n    # 获取全局变量\n    global difficulty, boxSize, boardWidth, boardHeight, maxLife, paletteColors, bgColor\n\n    # 此函数中的像素坐标是通过将inkspillsettings.png图像加载到图形编辑器中并从中读取像素坐标获得的\n\n    origDifficulty = difficulty\n    origBoxSize = boxSize\n    screenNeedsRedraw = True\n\n    while True:\n        if screenNeedsRedraw:\n            DISPLAY_SURF.fill(bgColor)\n            # 加载\"设置\"图片\n            DISPLAY_SURF.blit(SETTINGS_IMAGE, (0, 0))\n\n            # 将\"墨迹\"图片标记放在选定的颜色左边\n            if difficulty == EASY:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (30, 4))\n            if difficulty == MEDIUM:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (8, 41))\n            if difficulty == HARD:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (30, 76))\n\n            # 将墨迹标记放置在选定尺寸旁边\n            if boxSize == SMALL_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (22, 150))\n            if boxSize == MEDIUM_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (11, 185))\n            if boxSize == LARGE_BOX_SIZE:\n                DISPLAY_SURF.blit(SPOT_IMAGE, (24, 220))\n\n            # 加载设置界面右边的颜色选择框\n            for i in range(len(COLOR_SCHEMES)):\n                drawColorSchemeBoxes(500, i * 60 + 30, i)\n\n            # 更新界面\n            pygame.display.update()\n\n        screenNeedsRedraw = False  # 默认情况下，不重新绘制屏幕\n        # 事件处理循环\n        for event in pygame.event.get():\n            if event.type == QUIT:\n                pygame.quit()\n                sys.exit()\n            elif event.type == KEYUP:\n                if event.key == K_ESCAPE:\n                    # 设置屏幕上的Esc键返回游戏\n                    return not (origDifficulty == difficulty and origBoxSize == boxSize)\n            elif event.type == MOUSEBUTTONUP:\n                screenNeedsRedraw = True  # 屏幕应该重新绘制\n                mousex, mousey = event.pos  # 鼠标点击的坐标\n\n                # 检查难度按钮上是否有咔嗒声\n                if pygame.Rect(74, 16, 111, 30).collidepoint(mousex, mousey):\n                    difficulty = EASY\n                elif pygame.Rect(53, 50, 104, 29).collidepoint(mousex, mousey):\n                    difficulty = MEDIUM\n                elif pygame.Rect(72, 85, 65, 31).collidepoint(mousex, mousey):\n                    difficulty = HARD\n\n                # 检查尺寸按钮上是否有点击\n                elif pygame.Rect(63, 156, 84, 31).collidepoint(mousex, mousey):\n                    # 小板尺寸设置：\n                    boxSize = SMALL_BOX_SIZE\n                    boardWidth = SMALL_BOARD_SIZE\n                    boardHeight = SMALL_BOARD_SIZE\n                    maxLife = SMALL_MAX_LIFE\n                elif pygame.Rect(52, 192, 106, 32).collidepoint(mousex, mousey):\n                    # 中板尺寸设置：\n                    boxSize = MEDIUM_BOX_SIZE\n                    boardWidth = MEDIUM_BOARD_SIZE\n                    boardHeight = MEDIUM_BOARD_SIZE\n                    maxLife = MEDIUM_MAX_LIFE\n                elif pygame.Rect(67, 228, 58, 37).collidepoint(mousex, mousey):\n                    # 大板尺寸设置：\n                    boxSize = LARGE_BOX_SIZE\n                    boardWidth = LARGE_BOARD_SIZE\n                    boardHeight = LARGE_BOARD_SIZE\n                    maxLife = LARGE_MAX_LIFE\n                elif pygame.Rect(178, 418, 215, 34).collidepoint(mousex, mousey):\n                    # 点击“Back To Game”按钮\n                    return not (origDifficulty == difficulty and origBoxSize == boxSize)\n\n                for i in range(len(COLOR_SCHEMES)):\n                    # 单击颜色方案按钮\n                    if pygame.Rect(500, 30 + i * 60, MEDIUM_BOX_SIZE * 3, MEDIUM_BOX_SIZE * 2).collidepoint(mousex,\n                                                                                                            mousey):\n                        bgColor = COLOR_SCHEMES[i][0]\n                        paletteColors = COLOR_SCHEMES[i][1:]\n\n\ndef drawColorSchemeBoxes(x, y, schemeNum):\n    # 绘制“设置”屏幕上显示的颜色方案框\n    for boxy in range(2):\n        for boxx in range(3):\n            pygame.draw.rect(DISPLAY_SURF, COLOR_SCHEMES[schemeNum][3 * boxy + boxx + 1],\n                             (x + MEDIUM_BOX_SIZE * boxx, y + MEDIUM_BOX_SIZE * boxy, MEDIUM_BOX_SIZE, MEDIUM_BOX_SIZE))\n            if paletteColors == COLOR_SCHEMES[schemeNum][1:]:\n                # 将\"墨迹\"图片放置在所选配色方案旁边\n                DISPLAY_SURF.blit(SPOT_IMAGE, (x - 50, y))\n\n\ndef flashBorderAnimation(color, board, animationSpeed=30):\n    # \"闪光\"效果结束后，需要回到原来（游戏刚结束）的界面，此处先保存原来的界面\n    origSurf = DISPLAY_SURF.copy()\n    flashSurf = pygame.Surface(DISPLAY_SURF.get_size())\n    flashSurf = flashSurf.convert_alpha()\n    # 实现\"闪光\"效果\n    for start, end, step in ((0, 256, 1), (255, 0, -1)):\n        # 外循环的第一次迭代将内循环的透明度设置为从0到255，第二次迭代将透明度设置为从255到0。这就是“闪光”。\n        for transparency in range(start, end, animationSpeed * step):\n            DISPLAY_SURF.blit(origSurf, (0, 0))\n            r, g, b = color\n            flashSurf.fill((r, g, b, transparency))\n            DISPLAY_SURF.blit(flashSurf, (0, 0))\n            drawBoard(board)  # 在透明层的顶部绘制板\n            # 更新界面\n            pygame.display.update()\n            # 控制帧率\n            FPS_CLOCK.tick(FPS)\n    # 绘制原来（游戏刚结束）的界面\n    DISPLAY_SURF.blit(origSurf, (0, 0))\n\n\ndef floodAnimation(board, paletteClicked, animationSpeed=25):\n    origBoard = copy.deepcopy(board)  # 深拷贝整个大格子\n    # 从左上角处的格子开始同色填充\n    floodFill(board, board[0][0], paletteClicked, 0, 0)\n\n    for transparency in range(0, 255, animationSpeed):\n        # “新”大格子在大格子上慢慢变得不透明\n        drawBoard(origBoard)\n        # 更新透明度\n        drawBoard(board, transparency)\n        # 更新界面\n        pygame.display.update()\n        # 控制帧率\n        FPS_CLOCK.tick(FPS)\n\n\ndef generateRandomBoard(width, height, difficulty=MEDIUM):\n    # 为整个大格子中的每个小格子创建具有随机颜色的数据结构。\n    board = []\n    for x in range(width):\n        column = []\n        for y in range(height):\n            column.append(random.randint(0, len(paletteColors) - 1))\n        board.append(column)\n\n    # 通过将一些小格子设置为与相邻格子相同的颜色，使解决整个大格子更容易。\n\n    # 确定要更改的小格子数。\n    if difficulty == EASY:\n        if boxSize == SMALL_BOX_SIZE:\n            boxesToChange = 100\n        else:\n            boxesToChange = 1500\n    elif difficulty == MEDIUM:\n        if boxSize == SMALL_BOX_SIZE:\n            boxesToChange = 5\n        else:\n            boxesToChange = 200\n    else:\n        boxesToChange = 0\n\n    # 挂邻居格子的颜色：\n    for i in range(boxesToChange):\n        # 随机选择要复制其颜色的框\n        x = random.randint(1, width - 2)\n        y = random.randint(1, height - 2)\n\n        # 随机选择要更改的邻居格子\n        direction = random.randint(0, 3)\n        if direction == 0:  # 左，下\n            board[x - 1][y] = board[x][y]\n            board[x][y - 1] = board[x][y]\n        elif direction == 1:  # 右，上\n            board[x + 1][y] = board[x][y]\n            board[x][y + 1] = board[x][y]\n        elif direction == 2:  # 左，下\n            board[x][y - 1] = board[x][y]\n            board[x + 1][y] = board[x][y]\n        else:  # 左，上\n            board[x][y + 1] = board[x][y]\n            board[x - 1][y] = board[x][y]\n    return board\n\n\ndef drawLogoAndButtons():\n    # 绘制墨水溢出徽标、设置和重置按钮。\n    DISPLAY_SURF.blit(LOGO_IMAGE, (WINDOW_WIDTH - LOGO_IMAGE.get_width(), 0))\n    DISPLAY_SURF.blit(SETTINGS_BUTTON_IMAGE,\n                      (WINDOW_WIDTH - SETTINGS_BUTTON_IMAGE.get_width(),\n                       WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height()))\n    DISPLAY_SURF.blit(RESET_BUTTON_IMAGE, (WINDOW_WIDTH - RESET_BUTTON_IMAGE.get_width(),\n                                           WINDOW_HEIGHT - SETTINGS_BUTTON_IMAGE.get_height() - RESET_BUTTON_IMAGE.get_height()))\n\n\ndef drawBoard(board, transparency=255):  # 透明度设置默认为255\n    # 彩色方块将绘制到临时曲面，然后绘制到DISPLAY_SURF曲面。这样我们就可以在DISPLAY_SURF的顶部绘制具有透明度的正方形了。\n    tempSurf = pygame.Surface(DISPLAY_SURF.get_size())  # 获取窗口尺寸\n    tempSurf = tempSurf.convert_alpha()   # 支持透明\n    tempSurf.fill((0, 0, 0, 0))   # 先全部处理为黑色\n\n    for x in range(boardWidth):\n        for y in range(boardHeight):\n            left, top = leftTopPixelCoordOfBox(x, y)\n            r, g, b = paletteColors[board[x][y]]\n            pygame.draw.rect(tempSurf, (r, g, b, transparency), (left, top, boxSize, boxSize))\n    left, top = leftTopPixelCoordOfBox(0, 0)\n    # 为防止边缘的小格子颜色与窗口背景色相同，在整个大格子外面包一层黑色细线，厚度为1px\n    pygame.draw.rect(tempSurf, BLACK, (left - 1, top - 1, boxSize * boardWidth + 1, boxSize * boardHeight + 1), 1)\n    DISPLAY_SURF.blit(tempSurf, (0, 0))\n\n\ndef drawPalettes():\n    # 在屏幕底部绘制六个调色板\n    numColors = len(paletteColors)\n    x_margin = int((WINDOW_WIDTH - ((PALETTE_SIZE * numColors) + (PALETTE_GAP_SIZE * (numColors - 1)))) / 2)\n    for i in range(numColors):\n        left = x_margin + (i * PALETTE_SIZE) + (i * PALETTE_GAP_SIZE)\n        top = WINDOW_HEIGHT - PALETTE_SIZE - 10\n        pygame.draw.rect(DISPLAY_SURF, paletteColors[i], (left, top, PALETTE_SIZE, PALETTE_SIZE))\n        # 为了美观，在格子外2px再加2px厚度的对应颜色的区域\n        pygame.draw.rect(DISPLAY_SURF, bgColor, (left + 2, top + 2, PALETTE_SIZE - 4, PALETTE_SIZE - 4), 2)\n\n\ndef drawLifeMeter(currentLife):\n    # '生命计' 竖直放置，与上下边缘各相距20px\n    lifeBoxSize = int((WINDOW_HEIGHT - 40) / maxLife)\n\n    # 绘制\"生命计\"的背景色，'生命计'的左上角位于坐标(20,20),宽20px，高20 + (maxLife * lifeBoxSize) px\n    pygame.draw.rect(DISPLAY_SURF, bgColor, (20, 20, 20, 20 + (maxLife * lifeBoxSize)))\n\n    for i in range(maxLife):\n        if currentLife >= (maxLife - i):  # 画一个实心的红色方框\n            pygame.draw.rect(DISPLAY_SURF, RED, (20, 20 + (i * lifeBoxSize), 20, lifeBoxSize))\n        # 加1px白色的边框\n        pygame.draw.rect(DISPLAY_SURF, WHITE, (20, 20 + (i * lifeBoxSize), 20, lifeBoxSize), 1)\n\n\ndef getColorOfPaletteAt(x, y):\n    # 返回x和y参数覆盖的调色板颜色的索引\n    numColors = len(paletteColors)\n    xmargin = int((WINDOW_WIDTH - ((PALETTE_SIZE * numColors) + (PALETTE_GAP_SIZE * (numColors - 1)))) / 2)\n    # 调色板底端距窗口底端10px\n    top = WINDOW_HEIGHT - PALETTE_SIZE - 10\n    for i in range(numColors):\n        # 六个调色板左上角的坐标：（left,top）\n        left = xmargin + (i * PALETTE_SIZE) + (i * PALETTE_GAP_SIZE)\n        r = pygame.Rect(left, top, PALETTE_SIZE, PALETTE_SIZE)\n        # 找出鼠标单击区域是否在任何调色板内\n        if r.collidepoint(x, y):\n            return i  # 如果在，则返回所点击的调色板的序号\n    # 如果x和y不在任何调色板上，则返回None\n    return None\n\n\ndef floodFill(board, oldColor, newColor, x, y):\n    # 洪水填充算法\n    if oldColor == newColor or board[x][y] != oldColor:\n        # 如果左上角的颜色和点击颜色没有相邻，直接返回\n        return\n    board[x][y] = newColor  # 更改当前格子的颜色\n    # 对任何相邻格子进行递归调用：\n    if x > 0:\n        floodFill(board, oldColor, newColor, x - 1, y)\n    if x < boardWidth - 1:\n        floodFill(board, oldColor, newColor, x + 1, y)\n    if y > 0:\n        floodFill(board, oldColor, newColor, x, y - 1)\n    if y < boardHeight - 1:\n        floodFill(board, oldColor, newColor, x, y + 1)\n\n\ndef leftTopPixelCoordOfBox(boxx, boxy):\n    # 返回某个小格子最左上方像素的x和y。\n    # 注意整个大格子位于窗口的正中央\n    x_margin = int((WINDOW_WIDTH - (boardWidth * boxSize)) / 2)  # x_margin 为整个大格子最左边与窗口最左边的间距\n    y_margin = int((WINDOW_HEIGHT - (boardHeight * boxSize)) / 2)  # y_margin 为整个大格子最上边与窗口最上边的间距\n    return boxx * boxSize + x_margin, boxy * boxSize + y_margin\n\n\nif __name__ == '__main__':\n    main()\n```\n","categories":["Python","Pygame"]},{"title":"Python不能做游戏？","url":"/2021/10/10/mcqd4jol/","content":"\n# 前言\n\n写在前面的话： \n\n有人说，`python`做不出好的游戏，个人是不赞同的，只能说，`python`可以用来写游戏，但不适合。\n\n举个最简单的例子，弹弓可以用来拔牙吗？当然可以，只不过人们不用弹弓而已。现在主流的大型游戏的制作，主要用的是`C++`或者`C#`，但是，`python`也可以写出比较好的大型游戏，比如《EVE》，《文明》等等。\n\n但，说句实话，`pytho`n有两个缺点，一是`速度慢`，二是`语法缺陷`。\n\n速度慢是`pytho`n这类`解释性语言`的通病。而语法缺陷，举个例子，一个格斗类游戏，武器有如下类型：弓箭，枪，刀等，那么在`C++`或者`C#`中，声明一把武器为对应类型可以这样写：\n\n```\n箭 A = xxx;\n枪 B = xxx;\n刀 C = xxx;\n```\n\n而若用`python`，由于`python`不需要类型声明，写出来就会是这样的：\n\n```\nA = xxx\nB = xxx\nC = xxx\n```\n\n很显然，如果用`python`编写武器实例，会让人摸不着头脑：`A`是什么武器？`B`是什么武器？当代码量超级大的时候，区分`A`到底是什么类型时，就显得非常麻烦。此外，`python`还有许多不适合做游戏的缺点，但是，对于小型游戏，加上`python`语言的简洁性，其还是有用武之地的。\n\n笔者学习编程的第一门语言，便是`python`，而学习`python`的第一个应用，便是游戏制作，可以说，是游戏制作让我喜欢上了`python`，喜欢上了编程。虽然，用`python`制作游戏已经不太推荐了，但怀着一种对`python`的热爱，我写了这系列博文。\n\n在`python`众多的第三方库中，用于制作游戏的库主要是**pygame**，下面我们来详细介绍这个库的使用。\n\n# pygame第一个窗口\n\n首先，我们来写一个世界上最无聊的游戏（看不懂的小伙伴们先放一放）：\n\n```python\nimport sys,pygame\nfrom pygame.locals import *\npygame.init()\nDISPLAY_SURF = pygame.display.set_mode((400,300))\npygame.display.set_caption(\"Hello World~\")\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n        pygame.display.update()\n```\n\n它的运行结果是这样的：\n\n![img](/images/assets/46b01ec619f65cfef3107282cd06ff3c.png)没错，就是屏幕中央的一个黑乎乎的窗口，啥都没有。但这是我们学习`python`游戏制作的第一步。\n\n# 代码详解\n\n我们来解释一下每一行代码的具体含义：\n\n```python\nimport sys,pygame\nfrom pygame.locals import *\n```\n\n第一行，导入 **sys**库（用于游戏终止退出等的控制）和 **pygame**库（用于绘制图形，播放声音，处理鼠标输入等操作） 。\n\n第二行，导入`pygame库`中定义的许多常量，同时使用“`from modulename import *`”的形式可以不加“`pygame.locals.`” 而直接调用里面的函数。\n\n```python\npygame.init()\n```\n\n第三行， 调用了`pygame库`的初始化函数`init()`，用于对`pygame库`的初始化。简单来说，就是调用这个函数后会强制要求系统检查一遍`pygame库`中的模块是否有缺失，并返回有关信息。这是保证我们写的游戏能够正常运行的基础。\n\n```python\nDISPLAY_SURF = pygame.display.set_mode((400,300))\n```\n\n第四行，调用**pygame.display.set_mode()**函数，会创建一个窗口。它的参数是一个**元组(a,b)**，这个元组告诉**set_mode()**函数，应该创建一个宽度为`a像素`，高度为`b像素`的窗口。重要的是，该函数返回一个**Surface对象（后面介绍）**，现在只需知道，之后要对这个窗口进行更新，监测等操作，都需要操作这个**Surface对象**。\n\n```python\npygame.display.set_caption(\"Hello World~\")\n```\n\n**set_caption(\"标题\")** 用于给窗口设置一个标题。\n\n```python\nwhile True:    # main game loop\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n        pygame.display.update()\n```\n\n第五行，用了一个条件始终为真的`while循环`。如果没有`while循环`，前面编写的窗口会“一闪而过”消失，为了保证窗口不消失，我们使用`while循环`。\n\n如果想要退出程序，主要有两种方式，一是执行一条`break语句`跳出循环，二是调用 `sys.exit()` 终止程序。 \n\n# 游戏循环事件\n\n大家可以看到，`while循环`后面加了一条注释 “# main game loop”。游戏循环（`game loop`，也叫做主循环，main loop），循环中主要做三件事情：\n\n> 1. 处理事件\n> 2. 更新游戏状态\n> 3. 在屏幕上绘制游戏状态\n>\n\n什么是\"`事件`\"？简单来说，诸如用户的`鼠标点击`，`键盘输入`等都可以看成一个个事件，自然，当用户发出一个“事件”后，我们的游戏需要有响应，这就是“`处理事件`”。 \n\n什么是“`游戏状态`”？游戏状态包括记录游戏中玩家的`生命值，位置，分数`等，都是游戏状态。而当任何时候，玩家的生命值，位置，分数等发生变化的时候，就称作游戏状态发生改变，自然，更新游戏状态也是游戏正常运行的基础。此外，如果玩过可以存盘类的游戏，就会理解，当暂停或退出游戏是，游戏会保存该时刻的“游戏状态”，以便下次打开游戏，它能调出之前的游戏状态并继续游戏。而这些游戏状态的记录，只需要几个变量即可搞定。\n\n**while循环**里，调用了 **pygame.event.get()** 函数。任何时候，当用户做了诸如按下一个按键，鼠标点击某个区域等操作时，`Pygame库`都会创建一个 **pygame.event.Event** 对象来保存这些操作，也就是之前说的“**事件**”，而调用**pygame.event.get()** 函数便可以获得游戏里发生了哪些事件，从而作出针对性的处理，该函数返回一个 **pygame.event.Event** 对象的列表，这个列表，包含了自上次调用 **pygame.event.get()** 函数之后所发生的所有事件。\n\n**pygame.event.Event** 对象有一个 **type** 属性，它告诉我们这个事件对象到底是何种事件，比如上述代码中的“**QUIT**”事件，当用户点击窗口上方的“`X`”退出时，会触发这个事件。\n\n所有的这些事件类型，都放在 **pygame.locals** 下，作为一个个`常量`。\n\n上述代码中，当事件是“`QUIT`”时，调用 **pygame.quit()** 函数和 **sys.exit()** 函数，`pygame.quit()`函数与`pygame.init()`函数相反，它执行完后会使`Pygame库`停止工作。而`sys.exit()`则是终止程序运行。一般而言，`pygame.quit()`函数的调用在`sys.exit()`函数之前。\n\n最后一句：“**pygame.display.update()**”用于更新屏幕显示。具体来说，它把前面的`pygame.display.set_mode()`所返回的`Surface对象`（存储在`DISPLAY_SURF`变量中）绘制到屏幕上。如果这个`Surface对象`没有做任何修改，那么每次调用`pygame.display.update()`函数后，将会重新绘制相同的黑色窗口。\n\n这样，整个程序就是让一个黑色的窗口绘制到屏幕上，然后不断地检查`QUIT事件`，不断重复地将黑色的窗口绘制到屏幕上，除此之外，啥都不干：\n\n![img](/images/assets/148ddb2c3c58cfa2303ae7a9bbfd0a5b.png)\n\n下一章，我们将学习**Surface对象**，**Color对象**，**Rect对象**，**Pygame提供的绘制函数**等内容，来了解如何将一些有趣的内容展示在这个窗口中，而不是只有黑压压的一片。\n","categories":["Python","Pygame"]},{"title":"Pygame基础知识","url":"/2021/10/10/i6nx6qzk/","content":"\n# 前言\n\n前面我们学习了第一个`Pygame`程序，接着，我们来了解`Pygame`中最为常用的几个对象。学完今天的内容，我们就可以开发一个稍微复杂一点的游戏了。\n\n# Surface 对象\n\n`Surface对象`表示的是一个矩形的`2D图像`，这个图像，实际上是由非常多的像素点组成的，比如一个`（300px , 400潘鑫）`的`Surface`对象，这个矩形`2D图像`由300*400个像素点组成。可以通过调用`Pygame`的绘制函数，来对一个`Surface对象`的某些区域进行填充，从而达到修改整个`2D图像`的效果。需要注意的是，窗口的边框，标题栏，按钮并不属于`Surface对象`的一部分。\n\n我们把通过**pygame.display.set_mode()** 函数返回的`Surface对象`，称为**显示Surface对象**，绘制到显示`Surface对象`上的任何内容，在调用`pygame.display.update()`函数后，都会显示到窗口上。\n\n游戏制作中，经常要将几个不同的内容绘制到一个`Surface对象`中，在游戏的某一次循环里，调用`pygame.display.update()`函数后，这个`Surface对象`包含的所有内容都会绘制到屏幕上，这个`Surface对象`（会频繁更新）被显示到屏幕上的次数，称为**帧数**。一般而言，计算机的运行速度很快，游戏中一般采用每秒30（60，90）帧，即30（60，90）FPS，这叫**作帧速率**，简称**帧率**。此处`30 FPS`的含义是，`1s内，游戏界面会被更新30次`。\n\n# Color对象\n\n颜色在游戏设计中是必不可少的一部分。在计算机显示器上，以光的颜色为基础，由于光有三原色-----**红**，**绿**，**蓝**，通过将这三种颜色按不同比例混合，可以形成任何其他的颜色。\n\n在`Pygame`中，我们使用三个整数的元组 **(a,b,c)** 来表示任何一种颜色，第一个整数`a`表示颜色中有多少红色，取值为0～255，同理，第二个整数对应绿色，第三个整数对应蓝色。如(0,0,255)表示蓝色，(0,255,0)表示绿色，(128,128,128)三色混合后会得到灰色。\n\n`Pygame`中创建颜色主要有两种方式。一是利用3个0～255的整数组成的元组，二是利用`pygame.Color对象`。\n\n我们用代码来演示一下：\n\n```python\nimport sys,pygame\nfrom pygame.locals import *\n\n#color      R    G    B\n\nBLACK = (   0,   0,   0)\nWHITE = ( 255, 255, 255)\nBLUE  = pygame.Color(   0,   0, 255)  # 与前面的颜色创建方式效果相同\nGREEN = pygame.Color(   0, 255,   0)\n\npygame.init()\nDISPLAY_SURF = pygame.display.set_mode((400,300))\n# 将整个显示Surface对象填充为白色\nDISPLAY_SURF.fill(WHITE)\n# 在Surface对象上，从左上角坐标(0,0)开始，绘制一个往右100px,往下100px的矩形2D区域并填充为黑色\npygame.draw.rect(DISPLAY_SURF, BLACK,(0,0,100,100))\n# 在Surface对象上，从左上角坐标(100,0)开始，绘制一个往右100px,往下100px的矩形2D区域并填充为绿色\npygame.draw.rect(DISPLAY_SURF,GREEN,(100,0,100,100))\n\npygame.display.set_caption(\"Hello World~\")\n\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n    # 将Surface对象更新到屏幕上显示\n    pygame.display.update()\n```\n\n运行结果：\n\n![img](/images/assets/f86a3c95d53b2072439ab564f36b5859.png)\n\n上面用到了一个绘制函数**pygame.draw.rect(Surface,Color,(x,y,a,b))**，它会在`Surface对象`上绘制一个矩形区域，第三个参数是一个四元元组，其前两个参数表明矩形区域左上角的坐标（`pygame`中的`XOY坐标`，以窗口左上角为原点(0,0)，向右为`x坐标`，向下为`y坐标`)，后两个参数表明矩形区域的大小，单位为`像素px`。\n\n此外，颜色除了各种颜色的混合比例之外，还有一个特征，那就是颜色的透明度。`Pygame`允许在颜色的三元元组基础之上加入第四个整数(`alpha value`，范围`0~255`)，用于表示颜色的透明度。0表示完全透明，255表示完全不透明。\n\n为了能够使用透明颜色来进行绘制，`Pygame`要求必须使用**convert_alpha()**方法来创建一个`Surface对象`。也就是说，能够使用透明颜色来进行绘制的`Surface对象`，必须用`convert_alpha()`方法创建。比如上面的代码，我们加上一句：\n\n```python\nAlpha_Surface = DISPLAY_SURF.convert_alpha()\n```\n\n上述代码表明可以在`Alpha_Surface对象`上可以使用透明颜色绘制，而`DISPLAY_SURF`上不行。\n\n#  Rect对象\n\n与颜色一样，`Pygame`提供两种方式创建一个矩形区域。\n\n 一是利用四元元组**（x,y,a,b)** ：\n\n- x ：矩形区域左上角的x坐标\n- y ：矩形区域左上角的y坐标\n- a ：矩形区域的宽度（以像素为单位）\n- b ：矩形区域的高度（以像素为单位）\n\n二是创建**pygame.Rect对象**，如：\n\n```python\nrect = pygame.Rect(100,200,100,200) # 等同于 rect = (100,200,100,200)\n```\n\n与颜色类似，上述“等同”的含义是，如果有一个针对矩形区域的函数参数的话，那么既可以传入一个四元元组，也可以传入一个`pygame.Rect`对象（底层实现是重载） 。\n\n`pygame.Rect`对象有许多属性，现将常用的列举如下：\n\n| 属性                 | 含义（返回值）                     |\n| -------------------- | ---------------------------------- |\n| **Rect.left**        | 矩形区域最左边的X坐标（int类型）   |\n| **Rect.right**       | 矩形区域最右边的X坐标（int类型）   |\n| **Rect.top**         | 矩形区域顶部的Y坐标（int类型）     |\n| **Rect.bottom**      | 矩形区域底部的Y坐标（int类型）     |\n| **Rect.centerx**     | 矩形区域中央的X坐标（int类型）     |\n| **Rect.centery**     | 矩形区域中央的Y坐标（int类型）     |\n| **Rect.width**       | 矩形区域的宽度（int类型）          |\n| **Rect.height**      | 矩形区域的高度（int类型）          |\n| **Rect.size**        | 矩形区域大小的元组：(width,height) |\n| **Rect.topleft**     | 元组(int类型)：(top,left)          |\n| **Rect.topright**    | 元组(int类型)：(top,right)         |\n| **Rect.bottomleft**  | 元组(int类型)：(bottom,left)       |\n| **Rect.bottomright** | 元组(int类型)：(bottom,right)      |\n| **Rect.midleft**     | 元组(int类型)：(left,centery)      |\n| **Rect.midright**    | 元组(int类型)：(right,centery)     |\n| **Rect.midtop**      | 元组(int类型)：(centerx,top)       |\n| **Rect.midbottom**   | 元组(int类型)：(centerx,bottom)    |\n\n# 绘制函数\n\n有了前面知识的铺垫，我们就可以用`Pygame`提供的绘制函数来绘制我们想要绘制的图形了。\n\n先上代码，在代码中注释了每个绘制函数参数的具体含义：\n\n```python\nimport pygame, sys\nfrom pygame.locals import *\n\n# 初始化pygame库\npygame.init()\n\n# 创建窗口\nDISPLAY_SURF = pygame.display.set_mode((400, 300), 0, 32)\npygame.display.set_caption('Drawing')\n\n# 设置颜色\nBLACK = (  0,   0,   0)\nWHITE = (255, 255, 255)\nRED   = (255,   0,   0)\nGREEN = (  0, 255,   0)\nBLUE  = (  0,   0, 255)\n\n# 绘制图形\n\n# 填充为白色\nDISPLAY_SURF.fill(WHITE)\n\n\n'''\n    pygame.draw.polygon(Surface,Color,pointlist,thickness)\n    在DISPLAY_SURF上，画一个多边形，\n    第三个参数为多边形顶点坐标顺次构成的元组，\n    最后的1(px)为多边形的粗细，忽略此参数或设为0，Pygame会视为用颜色填充此多边形\n'''\npygame.draw.polygon(DISPLAY_SURF, GREEN, ((146, 0), (291, 106), (236, 277), (56, 277), (0, 106)),1)\n\n\n\n'''\n    pygame.draw.line(Surface,Color,start_point,end_point,thickness)\n    在DISPLAY_SURF上，画一条线，\n    (60,60),(120,60)分别为线的起始坐标，终点坐标，\n    4(px)为线条粗细，单位为像素\n'''\npygame.draw.line(DISPLAY_SURF, BLUE, (60, 60), (120, 60), 4)\npygame.draw.line(DISPLAY_SURF, BLUE, (120, 60), (60, 120), 1)\npygame.draw.line(DISPLAY_SURF, BLUE, (60, 120), (120, 120), 4)\n\n\n'''\n    pygame.draw.circle(Surface,Color,center_point,radius,thickness)\n    在DISPLAY_SURF上，\n    画一个圆,\n    (300,50)为圆心的坐标,\n    20(px)为圆的半径，\n    0(px)指明圆的粗细，忽略此参数或者设为0，则Pygame默认将圆用颜色填充\n    \n'''\npygame.draw.circle(DISPLAY_SURF, BLUE, (300, 50), 20, 0)\n\n\n\n'''\n    pygame.draw.ellipse(Surface,Color,bounding_rectangle,thickness)\n    画一个椭圆，由于一个矩形可以唯一的确定一个椭圆，\n    故将其绑定一个Rect对象的矩形区域，\n    1(px)为椭圆的粗细，忽略此参数或者设为0，则Pygame默认将椭圆用颜色填充\n'''\npygame.draw.ellipse(DISPLAY_SURF, RED, (300, 200, 40, 80), 1)\n\n\n'''\n    pygame.draw.rect(Surface,Color,rectangle_tuple,thickness)\n    画一个矩形，\n    (200, 150, 100, 50)表示矩形左上角坐标为(200,150)，宽度100px，高度50px\n'''\npygame.draw.rect(DISPLAY_SURF, RED, (200, 150, 100, 50))\n\n# run the game loop\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n    pygame.display.update()\n```\n\n运行结果：\n\n![img](/images/assets/b6d3b43d5bc9045122f29f56b6272d03.png)代码中对每个绘制函数都有详细的注释，此处就不再赘述了。 \n\n# 制作动画 && **pygame.time.Clock 对象**\n\n动画是一个游戏的灵魂，如何产生一幅动的画面呢？\n\n前面聊过，`while循环`里如果设置帧率为`30FPS`，则屏幕上的画面会每秒更新30次，也就是说，`Pygame`会将`Surface对象`以每秒30次的速度不断重新绘制到屏幕上。\n\n这样，如果在每次绘制到屏幕之前，对`Surface对象`上的内容做略微修改，这样不就产生“动的”画面了吗？\n\n现在的问题是，我们如何控制`Surface对象`以每秒30次的速度绘制到屏幕上呢？\n\n这个不用我们考虑，`Pygame`提供了一个专门用于控制帧率的类 **pygame.time.Clock**。由于计算机运行速度极快，容易导致游戏速度过快，玩家的体验不太好，因而这个对象可以确保游戏以某一个最大的帧率运行，但有时，如果是大型游戏，代码量过多，以至于无法正常运行，来频繁的绘制到屏幕上，会使得帧率下降。\n\n**Clock对象**的用法：首先，创建Clock对象：\n\n```python\nfpsClock = pygame.time.Clock()\n```\n\n`Clock对象`会在游戏的每一次循环上都设置一个小小的暂停，确保游戏不会运行得太快。\n\n每次循坏的最后，调用`pygame.display.update()`方法将`Surface对象`绘制到屏幕上之后，应调用`Clock对象`的 **tick()** 方法：\n\n```python\n# run the game loop\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n    pygame.display.update()\n    # 调用tick()，传入30FPS\n    fpsClock.tick(FPS)\n```\n\n这样会使得，游戏以最大帧率`30FPS`运行。\n\n# “猫移动”的动画制作\n\n借`invpy官网`的一段代码，我们演示一个简单的“猫移动”的动画，我们需要一张“猫”的图片：\n\n![img](/images/assets/2db5e2c3c6aeb795863d601b27228bc4.png)\n\n代码如下：\n\n```python\nimport pygame, sys\nfrom pygame.locals import *\n\npygame.init()\n\n# 帧率设置为30FPS\nFPS = 30\n\n# 创建Clock对象\nfpsClock = pygame.time.Clock()\n\n# 创建窗口\nDISPLAY_SURF = pygame.display.set_mode((400, 300))\npygame.display.set_caption('Animation')\n\nWHITE = (255, 255, 255)\n# 加载图片\ncatImg = pygame.image.load('cat.png')\nCAT_X = 10\nCAT_Y = 10\n\n# 设置猫初始往右移动\ndirection = 'right'\n\nwhile True:  # main game loop\n\n    DISPLAY_SURF.fill(WHITE)\n\n    # 简单地方向控制\n    if direction == 'right':\n        CAT_X += 5\n        if CAT_X == 280:\n            direction = 'down'\n    elif direction == 'down':\n        CAT_Y += 5\n        if CAT_Y == 220:\n            direction = 'left'\n    elif direction == 'left':\n        CAT_X -= 5\n        if CAT_X == 10:\n            direction = 'up'\n    elif direction == 'up':\n        CAT_Y -= 5\n        if CAT_Y == 10:\n            direction = 'right'\n\n    # 利用blit()方法将图片复制到Surface对象中\n    # 图片的左上角位于(CAT_X, CAT_Y)\n    DISPLAY_SURF.blit(catImg, (CAT_X, CAT_Y))\n\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            pygame.quit()\n            sys.exit()\n\n    # 将Surface对象绘制到屏幕上\n    pygame.display.update()\n    # 设置帧率：30FPS\n    fpsClock.tick(FPS)\n```\n\n运行结果：\n\n![img](/images/assets/f1630c397f26536fa975fdaff2624b71.gif)\n\n到这，`Pygame`的基础知识就介绍完了，内容也许比较多，小伙伴们多多理解和实践。\n","categories":["Python","Pygame"]},{"title":"王者荣耀英雄皮肤图片爬取","url":"/2021/10/07/1a5zkopn/","content":"\n# 前言\n\n众所周知，`python`在`爬虫领域`有着得天独厚的优势，今天，我们来用`python`爬取王者荣耀英雄皮肤图片。\n\n本章中，我会着重带大家了解爬取网页的`基本流程`。\n\n# 网页分析\n\n首先，咱去王者荣耀的官网瞧瞧：[王者荣耀官方网站-腾讯游戏](https://pvp.qq.com) （建议用`谷歌浏览器`），我们的目标是，找到英雄皮肤的`url地址`，如下图，官网是这样的：\n\n![img](/images/assets/56be4a7335dfed23e6644382fd8ea2d8.png)\n\n发现图中的红框部分-----`英雄资料`，点进去看看：\n\n![img](/images/assets/fa5e28d0d0b0c04cc5fed5a2b030b6ac.png)\n\n往下滑，我们可以发现好多的`英雄头像`，点一个进去看看，比如貂蝉姐姐：\n\n![img](/images/assets/28bc8a8458dc85e91e6381a6bc2105af.png)\n\n如上图，我们看到了貂蝉的所有皮肤， 现在我们要找到这些皮肤的`url地址`，鼠标放至皮肤图片处，在谷歌浏览器中，按`F12`调出`开发者工具`，可以看到如下内容：\n\n![img](/images/assets/3dca030d3ef32e77d017b74c471e91f5.png)\n\n我们找到了这个皮肤的`url地址`：\n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/141/141-bigskin-7.jpg\n>\n\n再换一个皮肤试试：\n\n![img](/images/assets/e9360bfa95789d8cd5a868890f3ec505.png)\n\n她的`url地址`为：\n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/141/141-bigskin-6.jpg\n>\n\n## 探索url地址的规律\n\n对比这两张皮肤图片的`url地址`：\n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/141/141-bigskin-7.jpg\n>\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/141/141-bigskin-6.jpg\n>\n\n我们发现，这两个`url地址`，仅仅是最后一个数字不同，我们猜测，这个数字应该是不同皮肤的某种编号。\n\n接着，我们继续看看其他英雄的皮肤图片，如百里守约，同貂蝉的一样，我们找到了百里的几个皮肤的`url地址`如下：\n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/196/196-bigskin-2.jpg\n>\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/196/196-bigskin-3.jpg\n>\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/196/196-bigskin-4.jpg\n>\n\n从这三个`url地址`可以发现，百里的皮肤`url地址`，也仅仅最后一个数字不同， 同样，我们猜测这应该代表着百里不同皮肤的编号。\n\n接着，我们对比一下貂蝉和百里的皮肤url地址有何不同： \n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/141/141-bigskin-6.jpg\n>\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/196/196-bigskin-2.jpg\n>\n\n我们发现，两个英雄皮肤除了编号（最后一个数字）不同，最大的不同是` /hero-info/` 后面的整数，貂蝉的是`141`，而百里的是`196`，据此猜测，这个整数应该是代表的是英雄的编号，至此，我们猜测，所有英雄皮肤的`url地址`的命名路径应该长下面这个样子：\n\n> https://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/{英雄编号}/{英雄编号}-bigskin-{皮肤编号}.jpg\n>\n\n## 寻找所有英雄编号\n\n地址找到了，现在的问题是，如何找到所有英雄的编号呢？\n\n我们继续逛逛王者荣耀的官网，找找针对王者里的英雄还有哪些数据可以利用，几番寻找，我们发现了一个叫 `herolist.json` 的文件。地址为：\n\n> https://pvp.qq.com/web201605/js/herolist.json\n\n![img](/images/assets/6abdd1c92d17c20b0bd38c41f29ee899.png)\n\n用浏览器打开这个`json文件`，神奇的事情发生了：\n\n![img](/images/assets/72ef05a53a4e3654138e7c280ad8f66d.png)\n\n![img](/images/assets/5bfd690874924b17e090f09797a23654.png)\n\n不知道大家对上图中貂蝉的“**ename**”属性的值“141”这个数据还有没有印象，没错！它不正是貂蝉的编号嘛！\n\n上图中，百里的编号“196”也印证了我们的猜测。\n\n# 编写代码\n\n有了上述的分析，要爬取所有英雄的皮肤图片，就轻松多了。\n\n在这，我们采用最基础的 **requests** 库来完成我们的爬取工作，代码如下：\n\n```python\nimport requests\nimport os\nimport json\n\n\ndef download_wzry_hero_picture():\n    url1 = 'https://pvp.qq.com/web201605/js/herolist.json'\n    response = requests.get(url1).text  # 获取url页面内容，此处为json文本\n    dict_hero_info = json.loads(response)  # 将json格式的数据转化为字典\n    for key in dict_hero_info:  # 遍历字典\n        name = key['cname']  # 英雄名字\n        id = key['ename']  # 英雄编号\n        # 如果没有skin_name，则输出：\"无图片\"\n        skin_name_default = key.setdefault('skin_name', '无图片')\n        print(skin_name_default)\n        count = skin_name_default.count('|')  # 利用 count() 查询字符出现的次数\n        skin_name_list = skin_name_default.split('|')  # 利用 split() 分割字符返回列表\n        if not os.path.exists(name):  # 创建图片保存的文件夹\n            os.mkdir(name)\n        for i in range(1, count + 1):\n            # 构造英雄皮肤地址\n            url2 = 'http://game.gtimg.cn/images/yxzj/img201606/skin/hero-info/%s/%s-bigskin-%d.jpg' % (id, id, i)\n            img = requests.get(url2)  # 获取图片的二进制数据\n            print(url2)\n            pictName = skin_name_list[i]\n            # 下载并保存图片\n            with open(name + '/' + pictName + '.jpg', 'wb') as f:\n                f.write(img.content)  # 写入图片\n                print('成功下载并保存图片～')\n\n\n# 程序入口\nif __name__ == '__main__':\n    download_wzry_hero_picture()\n```\n\n# 运行程序\n\n点击运行，在控制台可以看到下载进度：\n\n![img](/images/assets/af2e62a22e2e93fc23431949c0ae2ec6.png)\n\n下载完成后，在当前目录下，我们能看到生成的英雄皮肤图片的文件夹： \n\n![img](/images/assets/4dc1260bc2f2cad4c74accef06a2428a.png)\n\n下面，就让我们尽情的欣赏英雄们的图片吧～ \n\n![img](/images/assets/841278c79b141022ee4b9875dec5d230.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)![img](images/assets/79328ef551fd789ba0047d36a3b3715c.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)![img](images/assets/e58b1a4fcdbe1b317847e9da8f109f84.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)![img](/images/assets/fd8e7d3c028a56b46bd7279dca08d046.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)\n","categories":["Python","爬虫"]},{"title":"你会几种“复制”文本的方式？","url":"/2021/09/15/ijbekjky/","content":"\n# 前言\n\n最近有一位朋友学习了`I/O`流，他提出了这样一个问题：现在有一个简单的`haha.txt`文件，利用`IO流`将`haha.txt`中的所有文本复制到第二个`txt`文件：`haha2.txt`中，问有多少种方式？\n\n`I/O流`是`Java`中一个比较重要的模块，但是`jdk`中与`IO流`有关的类比较繁多，大伙记忆起来也比较繁琐，推荐大家多敲代码，在敲代码的过程中，对记忆这些类会轻松许多。\n\n借那位朋友的问题，我们来复习一下`IO流`中四种最基本的流。\n\n# 四种最基本的IO流\n\n## **FileInputStream 和 FileOutputStream**\n\n第一种方式：\n\n利用 **`FileInputStream 和 FileOutputStream`** --->>\n\n```java\nimport java.io.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/11\n * @apiNote \"复制\"文本的方式一 FileInputStream && FileOutputStream\n */\npublic class FileInputStream$FileOutputStream {\n    public static void main(String[] args) throws IOException {\n        File input = new File(\"haha.txt\");\n        File output = new File(\"haha2.txt\");\n\n        FileInputStream fileInputStream = new FileInputStream(input);\n        FileOutputStream fileOutputStream = new FileOutputStream(output);\n\n        int c;\n        while((c = fileInputStream.read()) != -1){\n            fileOutputStream.write(c);\n        }\n\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n上述代码需要注意的有两点：\n\n1. `haha.txt` 和 `haha2.txt` 必须放在程序当前目录下，如果不在当前目录，需提供全局路径；\n\n2. `read()` 方法会读取某一个字节并返回（返回值为整型），如果返回值为`-1`，则代表文件读取完毕 。\n\n##  **FileReader** 和 FileWriter\n\n第二种方式：\n\n利用 **`FileReader 和 FileWriter`** --->>\n\n```java\nimport java.io.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/11\n * @apiNote \"复制\"文本的方式二 FileReader && FileWriter\n */\npublic class FileReader$FileWriter {\n    public static void main(String[] args) throws IOException {\n        FileReader fileReader = new FileReader(\"haha.txt\");\n        FileWriter fileWriter = new FileWriter(\"haha2.txt\");\n        int c;\n        while((c = fileReader.read()) != -1){\n            fileWriter.write(c);\n            System.out.print((char) c);\n        }\n        fileReader.close();\n        fileWriter.close();\n    }\n}\n```\n\n上述代码中添加了一句：“`System.out.print((char) c);`”，用于在控制台输出`haha.txt`中的文本内容。\n\n## BufferedInputStream 和 BufferedOutputStream\n\n第三种方式：\n\n利用 **`BufferedInputStream 和 BufferedOutputStream`** --->>\n\n```java\nimport java.io.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/11\n * @apiNote \"复制\"文本的方式三 BufferedInputStream && BufferedOutputStream\n */\npublic class BufferedInputStream$BufferedOutputStream {\n    public static void main(String[] args) throws IOException {\n        File input = new File(\"haha.txt\");\n        File out = new File(\"haha2.txt\");\n\n        BufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream(input));\n        BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(out));\n\n        int c;\n        while((c = bufferedInputStream.read()) != -1){\n            bufferedOutputStream.write(c);\n            System.out.print((char) c);\n        }\n\n        bufferedInputStream.close();\n        bufferedOutputStream.close();\n    }\n}\n```\n\n上述的缓冲流，把数据从原始流成块读入或把数据积累到一个大数据块后再成批写出，通过减少系统资源的读写次数来加快程序的执行。推荐使用。\n\n## BufferedReader 和 BufferedWriter\n\n第四种方式：\n\n利用 **`BufferedReader 和 BufferedWriter`** --->>\n\n```java\nimport java.io.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/11\n * @apiNote \"复制\"文本的方式四 BufferedReader && BufferedWriter\n */\n\npublic class BufferedReader$BufferedWriter {\n    public static void main(String[] args) throws IOException {\n        File input = new File(\"haha.txt\");\n        File output = new File(\"haha2.txt\");\n        \n        BufferedReader bufferedReader =  new BufferedReader(new InputStreamReader(new FileInputStream(input)));\n        BufferedWriter bufferedWriter =  new BufferedWriter(new OutputStreamWriter(new FileOutputStream(output)));\n\n        String s;\n        while((s = bufferedReader.readLine()) != null){\n            bufferedWriter.write(s);\n            bufferedWriter.newLine();\n        }\n\n        bufferedReader.close();\n        bufferedWriter.close();\n    }\n}\n```\n\n上述的 **`BufferedReader`** 方式，在读取文本的时候多了一种方法：**`readLine()`** 用于读取一行的文本，值得注意的是，**`readLine()` 不会读取每一行的换行符**，所以在使用 **`BufferedWriter`** 进行写入的时候，`JDK`提供了一个 **`newLine()`** 方法用于产生一个换行符，保证我们读取文本数据的原始性。\n\n同前一种方式，**`BufferedReader 和 BufferedWriter`** 操作纯文本的效率上要比第一，二种方式高，推荐使用。\n\n当然，`IO流`实现上述效果的类还有许多，这四种方式是最基本也是最原始的方式。\n","categories":["Python"]},{"title":"Java多线程详解（线程池）","url":"/2021/09/03/jy2j7lo4/","content":"\n# 前言\n\n上一章我们介绍了`Java`中的`Thread类`里一些常用的方法。本节我们就来聊一聊`线程池`。\n\n说到“池”，大家或许都不陌生，在`java`中，我们有见过数据库连接池，Java常量池，对象池等等，将实体进行“池化”，这种“池化”思想，有助于我们`对实体进行统一的管理，监控和调用`。\n\n本章的主要内容有：\n\n> - 创建线程池\n> - 构造方法的参数解读\n> - 四种功能性线程池\n> - 关闭线程池\n>\n\n作为经常被面试的一个模块，线程池的概念不是那么通俗易懂，但在实际开发应用中，线程池对程序性能优化有着不可磨灭的贡献。\n\n# 线程池\n\n## 线程池效率对比\n\n首先，我们来对比下面两个程序运行的效率。程序一，使用前面我们学过的一般线程：\n\n```java\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.concurrent.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/2\n * @apiNote 线程池初识\n */\npublic class ThreadPoolDemo1 {\n    public static void main(String[] args) throws InterruptedException {\n        Long start = System.currentTimeMillis();\n        Random random = new Random();\n        List<Integer> list = new ArrayList<Integer>();\n        for (int i = 0; i < 100000; i++) {\n            Thread thread = new Thread( () -> {\n                list.add(random.nextInt());\n            });\n            thread.start();\n            thread.join();\n        }\n        Long end = System.currentTimeMillis();\n        System.out.println(\"耗时：\" + (end - start) + \"ms\");\n        System.out.println(\"大小：\" + list.size());\n    }\n}\n```\n\n简单理解就是创建100000个线程来对`list`添加数据，最后输出添加所需的总时间和` list `的大小。我们来看运行结果：\n\n![img](/images/assets/b1f72f29d491bf2fd4397cbc0c8c9107.png)程序二，使用线程池（不理解的小伙伴们可以先跳过往下看)： \n\n```java\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * @author sixibiheye\n * @date 2021/9/2\n * @apiNote 线程池初识\n */\npublic class ThreadPoolDemo2 {\n    public static void main(String[] args) throws InterruptedException {\n        Long start = System.currentTimeMillis();\n        Random random = new Random();\n        List<Integer> list = new ArrayList<>();\n        ExecutorService executorService = Executors.newSingleThreadExecutor();\n        for (int i = 0; i < 100000; i++) {\n            executorService.execute( () -> {\n                list.add(random.nextInt());\n            });\n        }\n        executorService.shutdown();\n        executorService.awaitTermination(1, TimeUnit.DAYS);\n        Long end = System.currentTimeMillis();\n        System.out.println(\"耗时：\" + (end - start) + \"ms\");\n        System.out.println(\"大小：\" + list.size());\n    }\n}\n```\n\n运行结果：\n\n![img](/images/assets/6121614d30c6b076d2ca9cac9f81871f.png)从耗时来看，使用`线程池`所需的时间比使用一般线程所需的时间足足减少了100多倍！由此看来，`线程池`对于程序的优化有着重大的意义。\n\n实际上，从原理上理解，使用一般的线程，都需要经历`创建，使用，销毁`三个步骤，当创建的线程数非常大的时候，这种操作对内存的消耗比较大，导致效率低下。因此我们希望`创建好的线程能够在指定时间内继续执行其他的任务`，通过减少创建和销毁线程的消耗，以此来提高效率。\n\n## 类比“银行办理业务排队”\n\n其实，线程池概念的提出与我们的生活有密切关系（许多算法，概念的提出都能够在生活中找到对应的例子）。\n\n如果要理解`线程池`，咱就必须提到“银行办理业务排队”的场景逻辑，这是一个`非常非常非常`典型的例子，请大家务必看懂，对`线程池`的理解非常有帮助：\n\n去过银行办理业务的朋友们都知道，银行里有多个窗口来办理业务，此外还有等候区供人们休息。我们现在假设有这样一个场景 ：\n\n![img](/images/assets/9d99dfa72554ce082cc9ca48eb2880d1.png)\n\n如上图，假设现在某银行有3个窗口（1，2，3号），2个备用窗口（4，5号)，和可供3人休息的等候区。\n\n现在有1人来办理业务， 这1个人带着“任务1”去了1号窗口办理业务：\n\n![img](/images/assets/6a75312b7ddc1f8767a16a5896f35adf.png)接着，第2，3个人也来办理业务，他们带着任务2，3分别去了2，3号窗口：\n\n![img](/images/assets/fc4b69b97f2adb470316f2701846ef88.png)这时，如果银行来了第4个人，他只能去等候区等候，第5，6个人亦是如此：\n\n![img](/images/assets/6c7bacb40d99905bd786c6cea4522b04.png)此时，等候区人数已满，如果再来第7个人，银行行长只能开启备用窗口-----4号窗口，并让还在等候区等候的第4个人到4号窗口办理业务，等候区（队列)往前“挪一个”使得第7个人能够进入等候区：\n\n![img](/images/assets/845d3943893b04138ae3baf6fbc1e32b.png)同理，如果再来第8个人，那就只能开启第二个备用窗口-----5号窗口，并让第5个人到5号窗口办理业务，等候区（队列)往前“挪一个”使得第8个人能够进入等候区：\n\n![img](/images/assets/f7be0b8d67e7edf98cd050b1dd4cb6b8.png)这时，不论是窗口数，还是等待区容量，都已经满了，如果来了第9个人，怎么办呢？\n\n![img](/images/assets/24a9eae9bb29e26be4505830c23a081d.png)对于第9个人，银行只能采取拒绝的方式，因为就当前情况，不管是窗口，还是等候区，都容不下第9个人了。 \n\n## 如何理解线程池？\n\n上述的这个简单的银行排队流程，我们把它搬到线程里，描述如下：\n\n`线程池`（银行）里有最多5个线程数，有3个是`核心线程`（1，2，3号窗口），另外2个是`备用线程`（4，5号窗口，或者叫非核心线程），当核心线程全被使用后，就将多余的任务以队列的形式放入“`任务队列`”（等候区）中，如果任务队列也满了，就开启`备用线程`（非核心线程），如果备用线程也全部被使用了，那么剩下多余的任务，就只能拒绝执行了。\n\n理解完上述过程，理解线程池，就轻松多了。在Java中，线程池的真正实现类是`ThreadPoolExecutor`，翻阅源码，它有如下几种构造方法：\n\n![img](/images/assets/a6080631f951e584054db0c5f0addf33.png)\n\n![img](/images/assets/c871c9858ffe18208f4c79d642bedd10.png)\n\n![img](/images/assets/03a3aefd94914d3d31a23818f8dec842.png)\n\n![img](/images/assets/bcb26b693bb30c231cbe6c250eedc62c.png)\n\n![img](/images/assets/0923f22dcfe48cbd90668837310ae913.png)\n\n## 线程池的七个参数\n\n上面四种构造方法中，最多的构造方法有七个参数，我们来看看这七个参数的具体含义：\n\n> 1. **corePoolSize (必需) : `核心线程数`（类比银行的1，2，3号窗口）。默认情况下，核心线程会一直存活，除非将`allowCoreThreadTimeout`设置为`true`，这样超时后，核心线程也会被回收。**\n>\n> 2. **`maxmumPoolSize` (必需) : `最大线程数`（类比银行的所有窗口）。对于非核心线程（4，5号窗口），在下面的`keepAliveTime`设定的时间超过之后，会被回收。同样的，将`allowCoreThreadTimeout`设置为`true`的话，这样超时后，核心线程也会被回收。**\n>\n> 3. **`keepAliveTime` (必需) : 如上，设定非核心线程的闲置时间，超时后，非核心线程会被回收。**\n>\n> 4. **`unit` (必需) : 指定上面`keepAliveTime`参数的单位，常用的有：**\n>\n>    - **TimeUnit.MILLISECONDS（毫秒）**\n>\n>    - **TimeUnit.SECONDS（秒）**\n>\n>    - **TimeUnit.MINUTES（分）**\n>\n> 5. **`workQueue` (必需) : 任务队列（类比银行的等待区）。通过线程池中的`execute()`方法提交的Runnable对象将存储在该对象中。一般使用`阻塞队列`。**\n>\n> 6. **`threadFactory` (可选) :** 线程工厂-----指定新线程创建的方式，自定义`ThreadFactory`的话可以修改线程名，线程组，优先级，是否为守护线程等等，如果不想自定义，使用默认的**`Executors.defaultThreadFactory()` **即可。\n>\n> 7. **`handler` (可选) : ** 当线程池创建的线程数达到最大值时，需要执行的`拒绝策略`。`拒绝策略`需要实现`RejectedExecutionHandler`接口，并重写`rejectedExecution(Runnable r , ThreadPoolExecutor executor)`方法。\n\n**Executors框架为我们提供了四种常见的拒绝策略：**\n\n- **1.AbortPolicy (默认) ：丢弃任务并抛出 RejectedExecutionException 异常**\n- **2.CallerRunsPolicy ：丢给调度线程处理该任务**\n- **3.DiscardPolicy ：丢弃任务但不抛出异常。一般用于自定义处理模式。**\n- **4.DiscardOldestPolicy ：丢弃队列最早的未处理完的任务，然后尝试执行新任务。**\n\n请注意： 虽然指定了核心线程数和最大线程数，但是`当线程池被创建后，线程不会立即创建，其会根据任务队列中是否有新任务要执行来实时地创建`。\n\n## ThreadPoolExecutor\n\n下面我们来认识一下 **ThreadPoolExecutor** 这个类，来看源码：\n\n首先，最底层是一个函数式接口（`只有一个抽象方法`） **Executor ：**\n\n![img](/images/assets/1ffa860cec2a32b0e18aedb22f8f4874.png)\n\n接着有一个叫 **ExecutorService** 的接口继承了 **Executor** ，其扩展了一些方法，如 `isShutdown() , shutdown() , awaitTermination()`等等：\n\n![img](/images/assets/62577835bbbbdb5db52fbdecb0df7dc7.png)然后，有一个叫 **AbstractExecutorService** 的类实现了 **ExecutorService** ，提供了一些方法的实现：\n\n![img](/images/assets/df68cb196ce9b1b84a5744617762491b.png)最后， 咱 **ThreadPoolExecutor** 类继承了 **AbstractExecutorService** ，并实现了 **execute()** 等重要的方法：\n\n![img](/images/assets/813e139d6baed01a9141b4874c09c591.png)\n\n![img](/images/assets/779a2821c9339371f8c7ca6b5fe7a8c0.png)现在，我们来看一个简单的程序：     \n\n```java\nimport java.util.concurrent.*;\n\n/**\n * @author sixibiheye\n * @date 2021/9/2\n * @apiNote 线程池\n */\npublic class CustomThreadPool {\n    public static void main(String[] args) {\n\n        ExecutorService executorService = new ThreadPoolExecutor(25,50,1L, TimeUnit.SECONDS,new ArrayBlockingQueue<>(50),Executors.defaultThreadFactory(),new ThreadPoolExecutor.AbortPolicy());\n        for (int i = 1; i <= 100; i++) {\n            executorService.execute(new TaskDemo4(i));\n        }\n        //当所有任务执行完之后，结束线程池服务\n        executorService.shutdown();\n    }\n}\nclass TaskDemo4 implements Runnable{\n    private int i = 0;\n    public TaskDemo4(int i){\n        this.i = i;\n    }\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \"线程做了第\" + i + \"个任务\");\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n上述程序中，通过`for循环`产生了100个任务，请大家细细体会 `ThreadPoolExecutor()`构造方法中的7个参数如何取定。\n\n如果已有任务数超过了线程池的最大线程数与任务队列容量之和，线程池就会执行`拒绝策略`，默认为上述第一种拒绝策略。比如将上述代码中的线程池创建参数---任务队列修改如下：\n\n```java\nnew ArrayBlockingQueue<>(49)\n```\n\n则会抛出 **RejectedExecutionException** 异常：\n\n![img](/images/assets/69c949ddf3d7d0807e133ffc6b9cfb9a.png)\n\n## 任务队列\n\n七个参数中，大家比较模糊的是 **workQueue** ---- `任务队列`。\n\n下面我们来看看 `workQueue` 如何取定。任务队列是基于`阻塞队列`实现的，采用的是`生产者-消费者模式`，在Java中需要实现 **BlockingQueue** 接口，当然我们可以自定义实现类，但`JDK`已经为我们提供了7种阻塞队列的实现类，我们简单的介绍其中最常用的三种：\n\n> 1. **ArrayBlockingQueue** ：一个由顺序表结构组成的有界(需指明容量)阻塞队列，\n>\n> 2. **LinkedBlockingQueue** ：一个由链表结构组成的阻塞队列。可以指明容量，未指明容量时，默认为无界（`Integer.MAX_VALUE`）.\n>\n> 3. **SynchronousQueue** ：一个不存储任何元素的同步阻塞队列。\n\n请注意`有界队列`与`无界队列`的区别：如果使用有界队列，当已有任务数超过了线程池的`最大线程数`与该`队列容量`之和后就会执行拒绝策略；而如果使用无界队列，队列容量无限大，已有任务数不可能超过该队列容量，所以设置 `maxmunPoolSize` 没有意义。\n\n## 封装的线程池\n\n基于 **ThreadPoolExecutor** 的七个参数值的不同设定，**Executors**类 （`Executor接口`的工具类）给我们封装了几个常用的创建线程池的方法：\n\n### 可缓存线程池**（**CachedThreadPool）\n\n![img](/images/assets/0d577658d1c05f2d55b8ebdad45f53e0.png)\n\n![img](/images/assets/431e6b846c0337d763844e989e773316.png)\n\n- 特点：无核心线程，非核心线程无限大，线程闲置60s后被回收，任务队列为不存储任何元素的同步阻塞队列\n- 适用场景：`执行大量且耗时的操作`\n\n### 定长线程池**（**FixedThreadPool）\n\n![img](/images/assets/b24efcbe7878d5b2cbcdb6d2c9c47b9e.png)\n\n![img](/images/assets/00bac0861b1c04a142d4fa1b43a1b303.png)\n\n- 特点：只有核心线程，线程一旦闲置立即被回收，任务队列为链表结构的无界阻塞队列\n- 适用场景：`需要控制线程最大并发数的地方`     \n\n### 定时线程池**（**ScheduledThreadPool）\n\n![img](/images/assets/2d3b319396e3f9ea4eb77e524905b625.png)\n\n![img](/images/assets/655d69c5bfb03df009ca8740faffd45a.png)\n\n![img](/images/assets/c94bb55e37c586bcd48c93d43f8dc1d8.png)![img](images/assets/fce5fbdb2209e476936065ef651cbcd8.png)\n\n![img](/images/assets/e13e51280660b9b164b1eafd38f40ea5.png)\n\n- 特点：核心线程固定，线程闲置10ms后被回收，任务队列为延时阻塞队列\n- 适用场景：`执行定时或周期性的任务`\n\n### 单线程化线程池**（**SingleThreadExecutor）\n\n![img](/images/assets/d647ec38758454177d66f24ecf2b9d7b.png)\n\n![img](/images/assets/01b3c5d05d7871b8aa11d0a3246f05a4.png)\n\n- 特点：核心线程固定为1个，没有非核心线程，线程一旦闲置立即被回收，任务队列为链表结构的无界阻塞队列\n- 适用场景：`串行执行所有任务`\n\n# 建议\n\n总结起来，虽然使用`Executors框架`的4个功能线程池非常的方便，但是现在已经不建议使用了，而是采用最原始的方式：通过 **ThreadPoolExecutor** 来手动创建。\n\n原因有两点：\n\n> 1. 使用原始的 **ThreadPoolExecutor** 可以使我们更加明确线程池的运行机制，减少对资源的浪费。\n>\n> 2. 使用上述四种线程池还有自己的弊端：\n> 3. **FixedThreadPool  &** **SingleThreadExecutor** ：由于任务队列可以为无界队列，当任务过多时，可能会导致`OOM`（内存溢出）。\n> 4. **CachedThreadPool & ScheduledThreadPool** ：由于最大线程数为无限大，当线程创建过多时，可能会导致`CPU`利用率接近100%。\n\n# 关闭线程池\n\n最后，我们来简单地介绍一下如何`关闭线程池`。\n\n在介绍如何关闭线程池之前，我们来看看线程池的五个状态：\n\n![img](/images/assets/a359355d4fa98d456abf7431567db3bf.png)我们来简单认识一下这五种状态：\n\n## RUNNING\n\n​    **特点**：线程池处在 **RUNNING** 状态时，能够接收新任务，能够执行已添加的任务。\n\n- 线程池一旦被创建，就处于 **RUNNING** 状态，并且线程池中的任务数为0。\n\n## SHUTDOWN\n\n​    **特点**：线程池处在 **SHUTDOWN** 状态时，不接收新任务，但能处理已添加的任务。\n\n- 调用线程池的shutdown()方法时，线程池状态转变：**RUNNING** --> **SHUTDOWN**。\n\n## STOP\n\n​    **特点**：线程池处在 **STOP** 状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。\n\n- 调用线程池的 shutdownNow()方法 时，线程池状态转变：（ **RUNNING** or **SHUTDOWN** ) --> **STOP**。\n\n## TIDYING\n\n​    **特点**：当所有的任务都已中止或结束后，ctl记录的“任务数量”为0，线程池会变为 **TIDYING** 状态。\n\n- 当线程池在 **SHUTDOWN** 状态下，任务阻塞队列为空并且线程池中执行的任务也为空时，就会由 **SHUTDOWN** 变为 **TIDYING**。\n- 当线程池在 **STOP** 状态下，线程池中执行的任务为空时，就会由 **STOP** 变为 **TIDYING**。\n\n## TERMINATED\n\n​    **特点**：线程池彻底终止，就变成**TERMINATED**状态。\n\n- 线程池处在 **TIDYING** 状态时，执行完terminated()方法后，就会由 **TIDYING** 变为 **TERMINATED**。\n\n接着，查阅源码，我们可以看到，JDK在**ThreadPoolExecutor类**中提供了几种关闭线程池的方法，源码如下：\n\n![img](/images/assets/6cbcc817c76f9d6a9b9647bef9f5080d.png)\n\n![img](/images/assets/01b2d49e84251a49141a2defc0e29dd1.png)\n\n## 状态解读\n\n从上述源码结合前面学的知识可以发现： \n\n- 当线程池创建以后，初始时，线程池处于 **RUNNING** 状态，此时线程池中的任务为0；\n- 如果调用 **shutdown()** 方法，则线程池变为 **SHUTDOWN** 状态，此时线程池不能够接受新  的任务，它会等待所有任务执行完毕；\n- 如果调用 **shutdownNow()** 方法，则线程池处于 **STOP** 状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；\n- 当所有的任务已中止或结束后，“任务数量”为0，线程池会变为 **TIDYING** 状态。接着会执行 **terminated()** 函数。\n- 线程池处在 **TIDYING** 状态时，执行完 **terminated()** 之后，线程池就被设置为**TERMINATED**状态。\n\n其实，关于多线程，JDK中提供的**Thread类**和**ThreadPoolExecutor类**中还有许多我们可以学习的东西，如果小伙伴们感兴趣的话可以去翻阅有关源码和资料。","categories":["Java","Java多线程"]},{"title":"Java多线程详解（深究Thread类）","url":"/2021/09/02/99n7yacb/","content":"\n# 前言\n\n上一章咱介绍了线程同步，了解了解决线程安全的基本思想----“`队列与锁`”。\n\n在前几章的介绍中，我们时不时地会使用到`sleep()`这个方法，知道它可以通过使线程休眠来扩大问题发生的可能性，使开发者能够迅速定位到bug的位置。它是`Thread类`中一个比较重要的静态方法，那么本章就来介绍一下`Thread类`中一些常用的方法。\n\n在介绍`Thread类`里面的方法之前，我们来回顾一下线程的五大状态：\n\n![img](/images/assets/61482e4003bc2b532d7f9e936575b922.png)请注意体会，当调用下面的这些方法时，`线程的状态是如何变化的`。 \n\n# sleep()\n\nsleep()方法有两种重载：\n\n> 1. public static native void sleep(long millis)\n> 2. public static native void sleep(long millis , int nanos)    \n\n我们之前使用的都是第一种，它的参数单位使用的是`毫秒(ms)`，表示让当前线程休眠多少毫秒。\n\n如果你想更为精确，可以采用第二种，它第二个参数为第一个参数的基础上附加多少纳秒（取值在0～999999之间），源码如图： \n\n![img](/images/assets/a0ff1b5d1c06cb3e6533d1046d0aaf28.png)对于`sleep()`，我们需要了解一下内容：\n\n> 1. 当线程调用`Thread.sleep()`方法时，会立即使当前线程进入指定时间的休眠，变成`阻塞状态`，时间一过，该线程会立即进入`可运行态`（注意不是运行态），之后的运行看`CPU调度`。\n>\n> 2. 在实现多线程的各种方式中，除了继承`Thread类`的线程类可以直接调用`sleep()`方法，其它方式都需要通过`Thread.sleep()`方式来调用。\n>\n> 3. sleep()的作用：\n>\n>      1). 通过使线程休眠来扩大问题发生的可能性，使开发者能够迅速定位到bug的位置\n>\n> ​\t2). 适用于程序要求频率慢的场景。比如在做网页爬虫搜集资料时，部分网页接口的请求频率有一定限制。如果调用接口频率太快，容易被错误识别导致封号。因此咱可以用`sleep()`方法随机休眠来保证调用安全。\n>\n> 4. `调用sleep()方法不会释放对象的锁`。\n\n\n\n# yield()\n\n`yield`意为“礼让”，该方法作用是`让当前线程放弃CPU的资源`，将它让给`相同优先级`的其他线程。调用`yield`方法后，当前线程会立即进入`可运行态`。\n\n我们来看一个例子：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/29\n * @apiNote yield()方法用法示例\n */\n\npublic class Yield implements Runnable{\n    //测试礼让线程\n    //注意：礼让不一定成功，礼让会使当前线程进入可运行态，执行谁，看CPU调度\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName()+\"线程开始执行～\");\n        //礼让\n        Thread.yield();\n        System.out.println(Thread.currentThread().getName()+\"线程结束执行～\");\n    }\n    public static void main(String[] args) {\n        Yield myyield = new Yield();\n        new Thread(myyield,\"A\").start();\n        new Thread(myyield,\"B\").start();\n    }\n}\n```\n\n上述程序的输出结果为：\n\n![img](/images/assets/b1896ba62f664e3da1009995e3427c63.png)上述结果表明，`A线程`确实成功地将`CPU使用权`“礼让”给了`B线程`。 但是由于`A线程`放弃的时间不确定，也许刚刚放弃CPU的使用权，就又获得了CPU的使用权。所以虽然有时发出了“礼让”请求，也会出现“礼让失败”的情况：\n\n![img](/images/assets/2bbd94ac02feb7583919854d3e7fa52a.png)所以使用`yield()`的实际意义不大，了解即可。\n\n# setPriority() & getPriority()\n\n在`java`中，每个线程都有一个优先级，当`CPU`调度新的线程时，会优先调度优先级高的线程。优先级设置为1～10的整数，`数字越大，优先级越高`，被CPU调度执行的机会越大。此外`Java`中也提供了三个常量来代表三个常用的优先级：\n\n- 最低优先级 1 ：`MIN_PRIORITY`\n- 普通优先级 5 ：`NORM_PRIORITY`\n- 最高优先级 10 : `MAX_PRIORITY`\n\n请注意，`Java`中默认的线程优先级是`父线程`的优先级（不是普通优先级NORM_PRIORITY），虽然主线程的优先级默认是普通优先级`NORM_PRIORITY` 。\n\n可以使用`Thread类`中的 **setPriority() 和 getPriority()** 方法来设置和获取某线程的优先级。我们来看一个简单的例子：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/9/1\n * @apiNote  设定线程优先级\n */\npublic class setPriority extends Thread{\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \"线程启动～，优先级为：\" + Thread.currentThread().getPriority());\n    }\n    public static void main(String[] args) {\n\n        Thread threadA = new setPriority();\n        Thread threadB = new setPriority();\n        Thread threadC = new setPriority();\n\n        threadA.setPriority(MAX_PRIORITY);\n        threadB.setPriority(NORM_PRIORITY);\n        threadC.setPriority(MIN_PRIORITY);\n\n        threadA.start();\n        threadB.start();\n        threadC.start();\n    }\n}\n```\n\n运行结果：\n\n![img](/images/assets/a56052d19b541d7b07248b97a17a7748.png)可以看到，优先级越高的线程会优先被`CPU`调度执行。但是本质上讲，这与`操作系统`以及`jvm的版本`有关，有可能即使设置了线程优先级也不会产生任何作用。 \n\n比如上面那个程序，多运行几次，你会发现，设置优先级不一定能输出理想的结果：\n\n![img](/images/assets/b011ec97adade5597aebb5bf8b76bbbc.png)如上图，甚至恰恰相反的结果都有可能出现。因此，在实际应用中，优先级使用的意义也不大。 \n\n# wait() & notify() & notifyAll()\n\n`wait() & notify()`是线程通信里两个非常常用的方法，它们是`Object类`中的方法，却与线程通信息息相关。关于线程通信，前面学过的`synchronized`可以主动协调线程间的执行关系，但是，两个线程间，有时还存在被动的通信关系。\n\n比如在一个餐馆里，服务员和厨师的关系便是一个典型的`被动通信`关系。在厨师没有做完菜肴之前，服务员只能处于等待状态，只有当厨师做完菜肴并且给服务员发出一个通知-----菜做完毕，服务员收到“通知”后才能开始上菜。\n\n这种“`等待与通知`”的被动通信关系广泛存在于生产生活之中。\n\n映射到线程里就是，`如果一个线程需要使用到另外一个线程的执行结果，那么它就必须处于等待状态，直到另一个线程执行完毕并给它发出通知，它收到通知之后，才开始执行`。\n\n这种“等待与通知”的被动通信关系在许多地方也叫**生产者和消费者模式**。我们来看一段代码：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/9/1\n * @apiNote wait()的使用\n */\npublic class Wait_Notify {\n    public static void main(String[] args) throws InterruptedException {\n        Object obj = new Object();\n        Thread thread1 = new ThreadDemo1(obj);\n        thread1.start();\n    }\n}\n\nclass ThreadDemo1 extends Thread{\n    private Object obj = new Object();\n    public ThreadDemo1(Object obj){\n        this.obj = obj;\n    }\n    @Override\n    public void run() {\n        synchronized (obj){\n            System.out.println(\"A线程等待前的一行...\");\n            //让A线程等待\n            try {\n                obj.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"A线程等待后的一行...\");\n        }\n    }\n}\n```\n\n运行结果：\n\n![img](/images/assets/ff77a08e3c8b196c8e99d89971784209.png)注意左边的红色正方形按钮，说明程序还未终止，一直处于`等待状态`。 \n\n在`java`中，对于上述的“等待和通知”的被动通信关系，`等待对应于wait()`，`通知对应于notify()和notifyAll()`。\n\n关于`wait()`，有以下几个要点需要注意：\n\n> - `wait()`方法是`Object类`中的方法，其作用是使当前线程进入`wait状态`（将当前线程放入该对象的“预执行队列”中，等待状态可以理解为`阻塞状态`），并且在`wait()`方法所在代码行处停止执行，直到被 `notify()` 或 `notifyAll()` 通知或被中断为止。\n> - 在调用`wait()`方法前，当前线程必须获得该对象的锁，也就是说，`只能在同步方法或者同步代码块中调用wait()方法`。\n> - 在调用`wait()`方法后，当前线程会立即释放该对象的锁，使得处于`wait状态`的线程能获得这把锁。\n\n关于`notify()和notifyAll()`，也有几个要点需要注意：\n\n> - `notify()`方法是用来通知处于`wait状态`的线程-----可以取得当前对象的锁了。\n> - 调用`notify()`方法之后，如果处于`wait状态`的线程不止一个，则CPU会随机调度一个线程向其发出通知------可以取得当前对象的锁了。\n> - `notifyAll()`则是通知所有处于`wait状态`的线程------你们可以开始竞争当前对象的锁了。\n> - 与调用`wait()`方法不同，在调用`notify()`或`notifyAll()`方法后，当前线程不会立即释放该对象的锁，而是要等当前线程执行完`synchronized代码块`后，才会释放锁，这时处于`wait状态`的线程才能获取到锁。\n\n请看下面的代码，从代码里理解上述内容：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/9/1\n * @apiNote wait()/notify()的使用\n */\npublic class Wait_Notify {\n    public static void main(String[] args) throws InterruptedException {\n        Object obj = new Object();\n        Thread thread1 = new ThreadDemo1(obj);\n        thread1.start();\n        Thread.sleep(1000);\n        Thread thread2 = new ThreadDemo2(obj);\n        thread2.start();\n    }\n}\n\nclass ThreadDemo1 extends Thread{\n    private Object obj = new Object();\n    public ThreadDemo1(Object obj){\n        this.obj = obj;\n    }\n    @Override\n    public void run() {\n        synchronized (obj){\n            System.out.println(\"A线程等待前的一行...\");\n            //让A线程等待\n            try {\n                obj.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"A线程等待后的一行...\");\n        }\n    }\n}\n\nclass ThreadDemo2 extends Thread{\n    private Object obj = new Object();\n    public ThreadDemo2(Object obj){\n        this.obj = obj;\n    }\n    @Override\n    public void run() {\n        synchronized (obj){\n            System.out.println(\"B线程通知前的一行...\");\n            //B线程唤醒其它线程\n            obj.notify();\n            System.out.println(\"B线程通知后的一行...\");\n        }\n    }\n}\n```\n\n运行结果：\n\n![img](/images/assets/6c144bebd5499f41be4430a3616c15b0.png)这个运行结果完美地诠释了上面的几个要点，请小伙伴们细细体会。 \n\n此外，`wait()`方法可以有一个参数：`wait(long millis)`。比如`wait(1000)`，它的含义是，将对象的锁释放，同时使自己进入1000ms的`阻塞状态`，1000ms过后如果锁没有被其他线程占用，则再次得到锁，然后`wait()`方法结束，执行后面的代码。如果1000ms内锁被其他线程占用，则等待其他线程释放锁，自己进入`可运行态`。\n\n与无参的`wait()`方法不同的是，有参的`wait()`方法并不需要其他线程执行 `notify()`或者 `notifyAll()` 来唤醒，只要超过了设定时间，线程会自动解除`阻塞状态`。 \n\n#  join()\n\n`join()`方法出现的一个原因是，当主线程创建并启动子线程后，如果子线程中要进行大量的耗时运算，主线程往往早于子线程结束。如果主线程想等待子线程执行完之后再结束，比如子线程处理一个数据，主线程要获得这个处理后的数据，就必须让子线程执行完毕之后，再结束主线程。\n\n不知小伙伴们发现了没有，这里面也蕴含了“等待和通知”的思想，那就是，在得到子线程“通知”之前，主线程只能处于“等待”状态。因此咱可以用wait()方法来实现。不过，这个不需要我们操心了，`Thread` 类里提供了`join()`方法来实现这个功能。\n\n查看`join()`方法的源码，它的方法体中调用了`wait()方法`：\n\n![img](/images/assets/529c4141297f89e5e7f6d61258ab0182.png)我们通过一个简单的例子来学习一下`join()`的使用：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/29\n * @apiNote join()方法用法示例\n */\n\npublic class Join extends Thread{\n    private int count;\n    //getCount()用于主线程获取子线程的数据\n    public int getCount() {\n        return count;\n    }\n    public Join(int count){\n        this.count = count;\n    }\n    @Override\n    public void run() {\n        for (int i = 0; i < 50000; i++) {\n            count++;\n        }\n\n        System.out.println(\"count的值为：\" + count);\n\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        System.out.println(\"main线程开始启动~\");\n        Join thread = new Join(0);\n        thread.start();\n        System.out.println(\"main线程执行完毕～，count的值为：\" + thread.getCount());\n    }\n}\n```\n\n上述代码中，子线程要对变量`count`进行50000次累加操作，显然主线程(`main线程`)结束的更快，当主线程结束时子线程还没处理完`count`，主线程调用`count`的值就会出现意外：\n\n![img](/images/assets/7c19b604c11ac9d9faad3eec244fb8f0.png)如上图，主线程输出的`count值`明显不是预料的结果50000。 这时就需要让主线程等待子线程执行完毕之后，再结束主线程。将上述的`main()`方法修改如下（加上`join()`方法)：\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n        System.out.println(\"main线程开始启动~\");\n        Join thread = new Join(0);\n        thread.start();\n        //测试join方法，线程执行join()后，其他线程处于阻塞状态\n        thread.join();\n        System.out.println(\"main线程执行完毕～，count的值为：\" + thread.getCount());\n}\n```\n\n运行结果：\n\n![img](/images/assets/33f6623352008977decdb4b5aab02b80.png)这样便达到了预想的结果。 \n\n# 其它\n\n`Thread类`中还有一些不常用或比较简单的方法，现列举如下：\n\n> 1. Thread Thread.currentThread() ：获得当前线程的引用。\n> 2. int Thread.activeCount()：当前线程所在线程组中活动线程的数目。\n> 3. int enumerate(Thread[] tarray) ：将当前线程的线程组及其子组中的每一个活动线程复制到指定的数组中。\n> 4. boolean holdsLock(Object obj) ：当且仅当当前线程在指定的对象上保持有锁时，才返回 true。\n> 5. boolean interrupted() ：测试当前线程是否已经中断。\n> 6. void checkAccess() ：判定当前运行的线程是否有权修改该线程。                 \n> 7. getContextClassLoader() ：返回该线程的上下文 ClassLoader。\n> 8. long getId() ：返回该线程的标识符。\n> 9. String getName() ：返回该线程的名称。\n> 10. Thread.State getState() ：返回该线程的状态。\n> 11. ThreadGroup getThreadGroup() ：返回该线程所属的线程组。\n> 12. void interrupt() ：中断线程。\n> 13. boolean isAlive() ：测试线程是否处于活动状态。\n> 14. boolean isDaemon() ：测试该线程是否为守护线程。\n> 15. boolean isInterrupted()：测试线程是否已经中断。\n> 16. void run() ：线程启动后执行的方法。\n> 17. void setContextClassLoader(ClassLoader cl) ：设置该线程的上下文 ClassLoader。\n> 18. void setDaemon(boolean on) ：将该线程标记为守护线程或用户线程。\n> 19. void start()：使该线程开始执行；Java 虚拟机调用该线程的 run 方法。\n> 20. String toString()：返回该线程的字符串表示形式，包括线程名称、优先级和线程组。\n\n# sleep() 和 wait() 方法的区别\n\n这个是在多线程中经常被面试的问题。以下可供参考：\n\n> - `sleep()`是`Thread类`中的一个静态方法，作用于当前线程。而`wait()`是`Object类`中的方法，任何实例对象均可以调用，作用于对象本身。\n> - `sleep()`不会释放锁，也不会占用锁。而`wait()`会释放锁，而且调用它的前提是当前线程持有锁。\n> - `sleep()`方法可以在任何合法的地方调用。而`wait()`只能在同步方法或同步代码块中调用。\n> - 对于含参的`sleep()`，不管设定时间内有没有其他线程占用锁，设定时间过后都会使当前线程进入`可运行态`。而含参的`wait()`在设定时间超过之后，如果有线程占用了锁，则原线程立即进入`可运行态`；如果没有线程占用锁，则原线程继续执行（`运行态`）。\n\n本章的内容比较多，一时消化不了，需要慢慢理解并且多敲代码加以运用。","categories":["Java","Java多线程"]},{"title":"Java多线程详解（线程同步）","url":"/2021/08/31/8ajv7uz8/","content":"\n# 前言\n\n上一章，我们通过几个例子介绍了`线程安全`问题，而说到线程安全就不得不提到`线程同步`，它是解决线程安全的一种重要方法。本章就来简单地介绍一下线程同步。\n\n从上一章的学习我们知道，当多个线程操作一个资源的时候，有可能由于线程的不确定切换出现数据不一致的安全问题，因此，我们要解决这个问题，就得想办法使得`资源在某个时间戳只能被一个线程访问`。基于这样的思想，我们提出了“**队列与锁**”的策略：\n\n通俗理解，就是`将所有线程排成一个队列，给要共享的资源上把锁，只有线程获得该资源的锁之后，才能访问该资源`。\n\n这也是线程同步的基本思想。所谓线程同步，是指同一进程中的多个线程相互协调工作从而达到一致性。使用线程同步，在解决线程安全问题的同时还能提高程序的性能。\n\n基于“队列与锁”的思想，`JDK`中封装了一些用于实现线程同步的类和关键字。我们主要介绍`synchronized` 和 `lock` 两种。\n\n# synchronized\n\n在`java`中，`每个对象都有一把唯一的锁`，这也是`synchronized`实现线程同步的基础。总的来说，`synchronized`实现`线程同步`主要有三种形式：\n\n| 形式             | 特点                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| **实例同步方法** | 锁的是当前实例对象，执行同步代码前必须获得当前实例的锁       |\n| **静态同步方法** | 锁的是当前类的class对象，执行同步代码前必须获得当前类对象的锁 |\n| **同步代码块**   | 锁的是括号里的对象，对给定对象加锁，执行同步代码块必须获得给定对象的锁 |\n\n当两个线程同时对一个对象的某个方法进行调用时，`只有一个线程能够抢到该对象的锁`，因为一个对象只有一把锁。**抢到该对象的锁之后，其他线程就无法访问该对象的所有synchronized方法，但仍可以访问该对象中的非synchronized方法**。\n\n下面，我们用代码来演示`synchronized`的三种用法。为了突出`synchronized`在线程安全方面的作用，我们采用对比（`有synchronized和无synchronized`）的方式来介绍。\n\n## 修饰实例同步方法\n\n首先，来看一个简单的程序：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote synchronized用法举例\n */\n\npublic class Synchronized implements Runnable{\n    //公共资源\n    static int count = 0;\n    public void increase(){\n        count++;\n    }\n    @Override\n    public void run() {\n        for (int i = 0; i < 10000; i++) {\n            increase();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        new Thread(new Synchronized(),\"A\").start();\n        new Thread(new Synchronized(),\"B\").start();\n        Thread.sleep(2000);\n        System.out.println(count);\n    }\n}\n```\n\n如果小伙伴们学习了上一章的内容，应该很容易看出这个程序是存在`线程安全问题`的，它的输出结果如下：\n\n![img](/images/assets/29411a7c70cfd986f0f789825d53b24e.png)\n\n上一篇博文中说到，对于“`count++`”，`JVM`是这样处理的：\n\n> 1. 某线程从内存中读取count值到寄存器\n> 2. 某线程在寄存器中修改count的值\n> 3. 某线程将修改后的count值写入内存\n\n简单解释一下，我们开启了两个线程去执行`increase()`方法，如果没有任何保护机制，假设，当`count`的值累加到1000时，`A线程`从主内存中读取到寄存器的`count值`为1000，执行完“`count++`”操作后，寄存器中的`count值`为1001，刚想写入内存，`B线程`正好抢到了`CPU的使用权`，开始执行`run()方法`，由于未写入内存，`B线程`从内存中读取到的`count值`为仍为1000，执行完“`count++`”操作后，`B线程`成功地将1001写入内存，接着`A线程`将自己寄存器中的`count值`1001写入内存（覆盖了`B线程`的1001），由此导致，虽然执行了两个线程，但`count的值`只累加了一次，这样的情况多发生几次，计算结果自然就低于20000了。\n\n为了避免以上情况发生，我们给`increase()`方法加上修饰符`synchronized`，使得两个线程无法同时调用`increase()`方法，以保证上面的三步中的任何一步都不会被另外一个线程打断。\n\n这样，“`count++`”操作就永远不会因线程切换而出错。代码如下：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote synchronized用法举例\n */\n\npublic class Synchronized implements Runnable{\n    //公共资源\n    static int count = 0;\n    //synchronized实现线程同步\n    public synchronized void increase(){\n        count++;\n    }\n    @Override\n    public void run() {\n        for (int i = 0; i < 10000; i++) {\n            increase();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        new Thread(new Synchronized(),\"A\").start();\n        new Thread(new Synchronized(),\"B\").start();\n        Thread.sleep(2000);\n        System.out.println(count);\n    }\n}\n```\n\n现在来看运行结果：\n\n![img](/images/assets/5126e07f89f5a53f384f76688f203569.png)没有任何问题。\n\n此外，使用`synchronized`时，有几个需要注意的地方，请看下面的代码：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote synchronized用法举例\n */\n\npublic class Synchronized implements Runnable{\n    public synchronized void running() throws InterruptedException {\n        System.out.println(\"1\");\n        Thread.sleep(1000);\n        System.out.println(\"2\");\n    }\n    @Override\n    public void run() {\n        try {\n            running();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        //用同一个类创建两个对象\n        Synchronized sync1 = new Synchronized();\n        new Thread(sync1).start();\n        Synchronized sync2 = new Synchronized();\n        new Thread(sync2).start();\n    }\n}\n```\n\n如果我们使用不同的对象访问，那么结果有可能是不同步的：\n\n![img](/images/assets/d1b9c6b045c8c40c95e2d6432cae285d.png)因为`synchronized修饰实例方法时锁的对象是this对象`，而使用两个对象去访问，不是同一把锁。如果我们用同一对象访问：\n\n```java\n//只创建一个对象\nSynchronized sync = new Synchronized();\nnew Thread(sync).start();\nnew Thread(sync).start();\n```\n\n那结果是同步的：\n\n![img](/images/assets/6e667c8471fe06132dc6a0c2811d186f.png)\n\n## synchronized修饰静态方法\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote synchronized用法举例\n */\n\npublic class Synchronized implements Runnable{\n    public static synchronized void running() throws InterruptedException {\n        System.out.println(\"1\");\n        Thread.sleep(1000);\n        System.out.println(\"2\");\n    }\n    @Override\n    public void run() {\n        try {\n            running();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        //用同一个类创建两个对象\n        Synchronized sync1 = new Synchronized();\n        new Thread(sync1).start();\n        Thread.sleep(2000);\n        Synchronized sync2 = new Synchronized();\n        new Thread(sync2).start();\n    }\n}\n```\n\n虽然有`sync1`，`sync2`两个对象，但是它们是同一个类对象(`Synchronized.class`)产生的，而`synchronized`修饰静态方法时，锁的是 `Synchronized.class`，因此两个线程仍然是同步的：\n\n![img](/images/assets/078c82b3e93a6f3296953241ab14b570.png)\n\n## synchronzied修饰同步代码块\n\n它可以锁`任何指定的对象`，语法示例如下：\n\n```java\nsynchronized (this){\n      System.out.println(\"1\");\n      Thread.sleep(1000);\n      System.out.println(\"2\");\n}\n```\n\n`this`指代当前实例对象，可以换为任何对象。\n\n那么为什么要使用同步代码块呢？\n\n在某些情况下，我们编写的方法体可能比较庞大，同时又有一些耗时的操作，如果对整个方法体进行同步，效率会大大降低，所以我们希望能够只同步必要的代码块，`对于一些不需要同步的或者耗时较长的操作，放到同步代码块之外`，比如：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote synchronized用法举例\n */\n\npublic class Synchronized implements Runnable{\n    public void running() throws InterruptedException {\n        for (int i = 0; i < 5; i++) {\n            System.out.println(\"这是耗时操作。\");\n        }\n        //需要同步的代码块写下面\n        synchronized (this){\n            System.out.println(\"1\");\n            Thread.sleep(1000);\n            System.out.println(\"2\");\n        }\n    }\n    @Override\n    public void run() {\n        try {\n            running();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Synchronized sync = new Synchronized();\n        new Thread(sync).start();\n        new Thread(sync).start();\n    }\n}\n```\n\n运行结果如下：\n\n![img](/images/assets/2655b05904e68985fc2ac2a59aa252c7.png)再运行一次：\n\n![img](/images/assets/687ed6b485c2c1e857cde6d86b298cd5.png)结果表明，需要同步的代码块确实实现了同步。 \n\n# lock\n\n前面使用的`synchronized关键字`可以实现多线程间的同步互斥，其实，在`JDK1.5`后新增的**ReentrantLock** 类同样可以实现这个功能，而且在使用上比 **synchronized** 更为灵活。\n\n翻阅源码，可以看到 **ReentrantLock** 类实现了`Lock接口`：\n\n![img](/images/assets/fc2073ef31c562e1a8a2baf45757fb89.png)\n\n下面我们用`ReentrantLock类`来实现简单的线程同步：\n\n```java\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author sixibiheye\n * @date 2021/8/31\n * @apiNote ReentrantLock实现线程同步\n */\npublic class LockDemo implements Runnable{\n    private Lock lock = new ReentrantLock();\n    /**\n     * \n     * 按照规范，\n     * lock()后面应紧跟try代码块，\n     * 并将unlock()放到finally块的第一行\n     * \n     */\n    @Override\n    public void run() {\n        //上锁\n        lock.lock();\n        try {\n            for (int i = 0; i < 5; i++) {\n                System.out.println(Thread.currentThread().getName() + \"线程中的i=\" + i);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            //释放锁\n            lock.unlock();\n        }\n    }\n    public static void main(String[] args) \n        new Thread(new LockDemo(),\"A\").start();\n        new Thread(new LockDemo(),\"B\").start();\n    }\n}\n```\n\n其实关于**Lock** 和 **ReentrantLock**，还有许多其他的用法，限于篇幅，就不一一介绍了，有兴趣的小伙伴们可以查阅相关资料。\n\n# 线程同步示例\n\n了解了`synchronized`和`ReentrantLock`，对于上一章提出的三个线程安全问题，便可以轻松地解决了。下面提供使用`synchronized`的解决方式：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/28\n * @apiNote 线程安全问题一-------取钱问题\n */\npublic class UnsafeBank {\n\n    public static void main(String[] args) {\n        //账户\n        Account account = new Account(100,\"买房基金\");\n        //你和你的妻子都要取钱\n        Drawing you = new Drawing(account,50,\"你\");\n        Drawing girlFriend = new Drawing(account,100,\"妻子\");\n        you.start();\n        girlFriend.start();\n    }\n}\n\n//账户\nclass Account{\n    int money; //余额\n    String name; //卡名\n    public Account(int money,String name){\n        this.money = money;\n        this.name = name;\n    }\n}\n\n//银行\nclass Drawing extends Thread{\n    Account account; //账户\n    int drawingMoney; //取的钱\n    int nowMoney; //现手上有的钱\n    public Drawing(Account account,int drawingMoney,String name){\n        super(name);\n        this.account = account;\n        this.drawingMoney = drawingMoney;\n    }\n    @Override\n    public void run() {\n        //注意锁的是account对象，而不是this\n        synchronized (account){\n            if(account.money - drawingMoney < 0){\n                System.out.println(Thread.currentThread().getName() + \"钱不够了，取不了！\");\n                return;\n            }\n            try {\n                sleep(3000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            //卡内余额\n            account.money = account.money - drawingMoney;\n            //手里的钱\n            nowMoney = nowMoney + drawingMoney;\n            //打印\n            System.out.println(account.name + \"余额为：\" + account.money);\n            System.out.println(Thread.currentThread().getName() + \"手里的钱：\" + nowMoney);\n        }\n        }\n}\n```\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/27\n * @apiNote 线程安全问题一-------买票问题\n */\npublic class UnsafeBuyTicket {\n    public static void main(String[] args) {\n        BuyTicket buyTicket = new BuyTicket();\n        new Thread(buyTicket,\"小红\").start();\n        new Thread(buyTicket,\"小白\").start();\n        new Thread(buyTicket,\"小黑\").start();\n    }\n}\n\nclass BuyTicket implements Runnable{\n    //票数\n    private int tickets = 10;\n    //线程停止的标志位\n    private boolean flag = true;\n    //直接同步实例方法即可\n    private synchronized void buy() throws InterruptedException {\n        //判断是否有票\n        if(tickets <= 0){\n            flag = false;\n            return;\n        }\n        //模拟延时，保证多人都能买到票\n        Thread.sleep(20);\n        //买票\n        System.out.println(Thread.currentThread().getName() + \"拿到了第\" + tickets-- +\"张票\");\n\n    }\n    @Override\n    public void run() {\n        while (flag){\n            try {\n                buy();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n```java\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n * @author sixibiheye\n * @date 2021/8/28\n * @apiNote 线程安全问题一-------列表问题\n */\n\npublic class UnsafeList {\n    public static void main(String[] args) throws InterruptedException {\n        List<String> list = new ArrayList<String>();\n        for (int i = 0; i < 10000; i++) {\n            new Thread( () -> {\n                //同步需要修改的list对象\n                synchronized (list){\n                    list.add(Thread.currentThread().getName());\n                }\n            }).start();\n        }\n        //sleep保证上述for循环跑完再输出\n        Thread.sleep(3000);\n        //输出列表大小\n        System.out.println(list.size());\n    }\n}\n```\n\n小伙伴们可以思考一下如果使用**ReentrantLock**应该如何解决。\n\n下一章，我们将着重介绍`Thread类`中的一些常用方法，好啦～本章的内容到这就结束了。","categories":["Java","Java多线程"]},{"title":"Java多线程详解（线程不安全案例）","url":"/2021/08/29/vnzopy0j/","content":"\n# 前言\n\n通过前面两章的学习，我们了解了线程的基本概念和创建线程的四种方式。\n\n这一章，我们来谈谈线程安全问题。\n\n也许小伙伴们刚听到这个词语的时候，是一脸懵逼，笔者初学线程安全也是这样的。所以本章从几个案例入手，让小伙伴们尽可能地理解什么是线程安全。\n\n# sleep()方法\n\n在学习线程安全之前，我们首先得简单地介绍`Thread类`中的一个静态方法----`sleep()`\n\n首先我们要知道，程序运行的速度是非常快的，当`CPU`调度某个线程开始执行时，由于运行速度太快，此线程可能执行完之后`CPU`才开始调度其他线程，这样显然不符合`并发`的特点，因此我们希望能阻塞某个线程的运行，使得其他线程有执行的“机会”，这时我们可以考虑`sleep()`方法。\n\n在某个线程的`run()`方法里调用`Thread.sleep(1000)`后，会使当前正在运行的线程立即进入`阻塞状态`，1000ms后，阻塞状态解除，进入`可运行态`，等待CPU的`再次调度`。在这段时间里，其它线程有可能获取CPU的使用权，从而达到`并发`的效果。\n\n调用`sleep()`方法可以扩大多线程执行时问题的发生性，以便开发者能够迅速发现bug，解决bug。\n\n最后，请记住一句话（后几章会解释）：Java中**`每个对象有且只有一把锁，调用sleep()不会释放锁`**。\n\n# 问题一：多人取钱\n\n了解完`sleep()`方法后，我们来看第一个案例-----多人取钱问题。\n\n假设现在，你和你妻子有100万存款，现在你俩同时去取钱，你想取50万，你妻子想取100万。就上述这个场景，我们用代码来模拟一下：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/28\n * @apiNote 线程安全问题一-------取钱问题\n */\n\npublic class UnsafeBank {\n    public static void main(String[] args) {\n        //账户\n        Account account = new Account(100,\"买房基金\");\n        //你和你的妻子都要取钱\n        Drawing you = new Drawing(account,50,\"你\");\n        Drawing girlFriend = new Drawing(account,100,\"妻子\");\n        you.start();\n        girlFriend.start();\n    }\n}\n\n//账户\nclass Account{\n    int money; //余额\n    String name; //卡名\n    public Account(int money,String name){\n        this.money = money;\n        this.name = name;\n    }\n}\n\n//银行\nclass Drawing extends Thread{\n    Account account; //账户\n    int drawingMoney; //取的钱\n    int nowMoney; //现手上有的钱\n    public Drawing(Account account,int drawingMoney,String name){\n        super(name);\n        this.account = account;\n        this.drawingMoney = drawingMoney;\n    }\n    @Override\n    public void run() {\n        if(account.money - drawingMoney < 0){\n            System.out.println(Thread.currentThread().getName() + \"钱不够了，取不了！\");\n            return;\n        }\n        //卡内余额\n        account.money = account.money - drawingMoney;\n        //手里的钱\n        nowMoney = nowMoney + drawingMoney;\n        //打印\n        System.out.println(account.name + \"余额为：\" + account.money);\n        System.out.println(Thread.currentThread().getName() + \"手里的钱：\" + nowMoney);\n    }\n}\n```\n\n代码本身比较简单，我们来看它的运行结果：\n\n![img](/images/assets/248c8fc8d6e90bc81e0d5f3eac1f0007.png)\n\n再运行一次： \n\n![img](/images/assets/aefb1231ebd7d25b969325895cc6b990.png)粗略看来，上述运行结果好像没有什么问题，但是，我在前面说过，如果程序运行太快，两个线程可能是顺序执行的，因此我们考虑在程序中加入`sleep()`方法来`模拟延时`，以此扩大问题发生的可能性： \n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/28\n * @apiNote 线程安全问题一-------取钱问题\n */\n\npublic class UnsafeBank {\n    public static void main(String[] args) {\n        //账户\n        Account account = new Account(100,\"买房基金\");\n        //你和你的妻子都要取钱\n        Drawing you = new Drawing(account,50,\"你\");\n        Drawing girlFriend = new Drawing(account,100,\"妻子\");\n        you.start();\n        girlFriend.start();\n    }\n}\n\n//账户\nclass Account{\n    int money; //余额\n    String name; //卡名\n    public Account(int money,String name){\n        this.money = money;\n        this.name = name;\n    }\n}\n\n\n//银行\nclass Drawing extends Thread{\n    Account account; //账户\n    int drawingMoney; //取的钱\n    int nowMoney; //现手上有的钱\n    public Drawing(Account account,int drawingMoney,String name){\n        super(name);\n        this.account = account;\n        this.drawingMoney = drawingMoney;\n\n    }\n    @Override\n    public void run() {\n        if(account.money - drawingMoney < 0){\n            System.out.println(Thread.currentThread().getName() + \"钱不够了，取不了！\");\n            return;\n        }\n        //模拟延时，保证多人都有机会取到钱\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //卡内余额\n        account.money = account.money - drawingMoney;\n        //手里的钱\n        nowMoney = nowMoney + drawingMoney;\n        //打印\n        System.out.println(account.name + \"余额为：\" + account.money);\n        System.out.println(Thread.currentThread().getName() + \"手里的钱：\" + nowMoney);\n    }\n}\n```\n\n这时，我们来看程序的运行结果：\n\n![img](/images/assets/d29bca10f98bc9e51495a8626ad63ec6.png)再运行一次：     ![img](images/assets/e20c7d6dbcb162b4d0f5b13bff7cf0db.png)你会惊奇地发现，余额竟然出现了负数！ 为什么会出现负数呢？\n\n小伙伴们可以停下来想一想原因。首先，我们来了解一下JVM中的线程是如何处理“`count--`”这个指令的。咱可以简单地分为三步：\n\n> 1. -->某线程从内存中读取count到自己的寄存器\n> 2. -->某线程在寄存器中修改count的值\n> 3. -->某线程将修改后的count值写入内存(刷新内存)\n\n在`多线程环境`下，由于`线程会共享进程中的资源`，上述三步中任何一步都有可能被其他线程打断，也就是说，有可能`count值`还没来得及写入内存，就被其他线程读取或写入了。理解这个之后，就不难理解` -50（万）`出现的原因了。\n\n假设“妻子的线程”先被`CPU`调度执行，在妻子的`run()`方法中，首先执行`if判断`，条件为假，继续执行下一句。假设刚要执行下一句\n\n> account.money = account.money - drawingMoney\n\n时，“妻子的线程”强行被“你的线程”打断，“你的线程”读取到的`account.money`值仍然是原来的 100（万），这使得“你的线程”通过执行\n\n> account.money = account.money - drawingMoney\n\n使得`account.money`的值变为了\n\n> 100（万）- 50（万）= 50（万）\n\n并成功写入了内存里。“你的线程”执行完之后，`CPU`继续调度“妻子的线程”。妻子读取到的`account.money`值为被“你的线程”修改后的 50（万），由于此前已执行过`if判断`，故“妻子的线程”接着执行\n\n> account.money = account.money - drawingMoney\n\n使得`account.money`变成了\n\n> 50（万）- 100（万）= -50（万）\n\n并也成功地写入了内存，最后输出，就出现了-50（万）这个结果。请小伙伴们细细体会～。\n\n# 问题二：多人购票\n\n如果你已经理解了一丢丢，我们继续举第二个例子-----多人购票问题：\n\n假设现在，某铁路局某线仅有10张票了，小红，小白，小黑都想要买票，就这个场景，我们来模拟一下买票的过程，同上，我们仍然用`sleep()`模拟延时，扩大问题发生的可能性：\n\n```java\n/**\n * @author sixibiheye\n * @date 2021/8/27\n * @apiNote 线程安全问题一-------买票问题\n */\npublic class UnsafeBuyTicket {\n    public static void main(String[] args) {\n        BuyTicket buyTicket = new BuyTicket();\n        new Thread(buyTicket,\"小红\").start();\n        new Thread(buyTicket,\"小白\").start();\n        new Thread(buyTicket,\"小黑\").start();\n    }\n    \n}\n\nclass BuyTicket implements Runnable{\n    //票数\n    private int tickets = 10;\n    //线程停止的标志位\n    private boolean flag = true;\n    private void buy() throws InterruptedException {\n        //判断是否有票\n        if(tickets <= 0){\n            flag = false;\n            return;\n        }\n        //模拟延时，保证多人都能买到票\n        Thread.sleep(10);\n        //买票\n        System.out.println(Thread.currentThread().getName() + \"拿到了第\" + tickets-- +\"张票\");\n    }\n    @Override\n    public void run() {\n        while (flag){\n            try {\n                buy();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n 不知道小伙伴们在这个程序里发现了哪些问题，我们来看运行结果：\n\n![img](/images/assets/8329e0a91cc04f6de8d305a7d026f7b1.png)\n\n![img](/images/assets/7e498b724664f66560c93fd48f4f903a.png)这儿有两个问题：\n\n> 1. 三人同时抢到了同一张票！\n>\n> 2. 有人抢到了第 -1 张票！\n>\n\n小伙伴们可以仔细思考一下，下面，我给出问题2的一个解释。为了便于解释，我们将小红，小黑，小白三个线程记作`A`，`B`，`C`三个线程。当还剩下最后一张票的时候，我们可以脑补一下程序的执行过程：\n\n在`A线程`里，刚执行完`if语句判断`，便被`B线程`打断，`B线程`刚执行完`if语句判断`，又被`C线程`打断，`C线程`未被打断，成功执行完`run()`方法输出最后一张票同时将`count`(票数)更新成了0，`C线程`结束。之后假设CPU调度`A线程`，由于之前在`A线程`里已执行过`if语句判断`，那么再次调度会接着`if`语句后面的代码执行，从而输出了第0张票同时使得`count`(票数)更新成了-1，`A线程`结束。最后`CPU`调度`B线程`，同理，由于之前在`B线程`里已执行过`if`语句判断，那么再次调度会接着`if`语句后面的代码执行，从而输出了第`-1`张票。\n\n至于三人同时抢到了同一张票，小伙伴们自行思考一下吧......\n\n上述两个例子中，问题出现的核心原因，咱概括来说，就是`线程间不确定地切换使得if语句失去了原有的作用`，程序未及时终止而出错。\n\n# 问题三：ArrayList\n\n最后，我们举一个`JDK`中线程不安全的例子，以`ArrayList`为例：\n\n```java\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n * @author sixibiheye\n * @date 2021/8/28\n * @apiNote 线程安全问题一-------ArrayList安全问题\n */\npublic class UnsafeList {\n    public static void main(String[] args) throws InterruptedException {\n        List<String> list = new ArrayList<String>();\n        for (int i = 0; i < 10000; i++) {\n            new Thread( () -> {\n                list.add(Thread.currentThread().getName());\n            }).start();\n        }\n        //sleep保证上述for循环跑完再输出\n        Thread.sleep(3000);\n        //输出列表大小\n        System.out.println(list.size());\n    }\n}\n```\n\n如果你认为输出结果是10000的话，那就大错特错了，请看运行结果：\n\n![img](/images/assets/77c220c94f097d93d275bd7c1bd144f0.png)再运行一次： \n\n![img](/images/assets/7818a5e82e09aaad57f779a9a15a2ec6.png)这个问题比较简单：虽然开启了10000个线程往`ArrayList`里加数据，但有可能出现：`某两个线程往ArrayList添加数据的时候，添加在了ArrayList的同一位置`（ 比如`ArrayList[5666] `)，这样`ArrayList`的大小自然就不足10000了。\n\n希望小伙伴们能够认真地理解上面介绍的三个线程不安全的案例。只有对问题足够了解，才有可能解决问题。下一章，我们将介绍如何解决上面的线程不安全问题。\n\nPS：It so difficult to write this......能够借鉴的资料实在有限，查阅了大量资料，修改了十几遍，才成此篇，部分解释可能不太严谨，欢迎指正～","categories":["Java","Java多线程"]},{"title":"Java多线程详解（如何创建线程）","url":"/2021/08/28/ntvsm7il/","content":"\n# 前言\n\n前面一章，我们了解了线程的基本概念，从这一章，我们开始学习如何创建一个线程。总的说来，在`java`中，有四种创建线程的方式：\n\n> 1. 继承Thread类\n> 2. 实现Runnable接口\n> 3. 实现Callable接口\n> 4. 使用线程池\n\n上述四种创建线程的方式中，我们着重介绍 1，2 ，对于 3，4，小伙伴们作为了解即可。下面用代码来实现这几种创建方式。\n\n# 继承Thread类\n\n下面的代码中使用了`sleep()`方法，不太理解的同学可以先放一放，后面我们会详细介绍这个方法。\n\n```java\n/**\n *\n * @author sixibiheye\n * @date 2021.08.28\n * @apiNote 继承Thread类\n *\n */\npublic class Thread1 extends Thread {\n    private String name;\n    public Thread1(String name){\n        this.name = name;\n    }\n    //需要重写Thread类的run()方法\n    @Override\n    public void run() {\n        for(int i = 0; i < 5; i++){\n            System.out.println(name+\"运行：\"+i);\n            try {\n                sleep(100);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    public static void main(String[] args) {\n        //通过创建对象的方式来创建两个线程\n        Thread1 thread1_1 = new Thread1(\"thread1_1\");\n        Thread1 thread1_2 = new Thread1(\"thread1_2\");\n        //启动线程\n        thread1_1.start(); //当CPU调度thread1_1时，会执行thread1_1对应的run()方法\n        thread1_2.start(); //当CPU调度thread1_2时，会执行thread1_2对应的run()方法\n    }\n}\n```\n\n上一章的学习我们知道，调用线程的`start()`方法后，上述的两个线程就都进入了`可运行态`，注意此时两个线程均还没有运行。\n\n只有当`CPU调度`之后，才能开始执行。至于两个线程到底谁先运行，完全取决于某一刻谁获得了`CPU的使用权`。因此，程序的运行结果是相对随机的，每一次运行的结果都有可能不同。比如，第一次运行结果：\n\n![img](/images/assets/57615fd47934646187f5ae2fa1d12872-20241206201640739.png)第二次运行结果：\n\n![img](/images/assets/be415c563537a6d10006e5edbabaf175-20241206201640739.png)\n# 实现Runnable接口\n\n下面的代码中，`Thread.currentThread().getName()`可以获得当前线程的名字，此外注意导入`sleep()方法`所在的包：\n\n```java\nimport static java.lang.Thread.sleep;\n\n/**\n *\n * @author sixibiheye\n * @date 2021.08.28\n * @apiNote 实现Runnable接口\n *\n */\npublic class Thread2 implements Runnable {\n    //仍然需要重写Thread类的run()方法\n    @Override\n    public void run() {\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName()+\"运行：\"+i);\n            try {\n                sleep( 100);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    public static void main(String[] args) {\n        //类似创建对象的方式来创建线程\n        Thread2 thread = new Thread2();\n        //启动线程\n        new Thread(thread,\"线程A\").start(); //当CPU调度线程A时，会执行线程A对应的run()方法\n        new Thread(thread,\"线程B\").start(); //当CPU调度线程B时，会执行线程B对应的run()方法\n    }\n}\n```\n\n上述创建线程的方式使用到了一种设计模式-----静态代理模式来创建线程。不太清楚的可以去参考一下 `JAVA` tag 下的相关文章。\n\n同样的，由于`CPU何时调度哪个线程`是不确定的，上述方式得到的运行结果也不尽相同，比如第一次运行结果：\n\n![img](/images/assets/764bb69a9867df4bf87d5f7f9e2361f0-20241206201640743.png)第二次运行结果：\n\n![img](/images/assets/b7a8feeb918360b567f9b457f11258ca-20241206201640717.png)\n# 实现Callable接口\n\n实现`Callable接口`和实现`Runnable接口`的区别在于，实现`Callable接口`允许用户`自定义返回值`和`抛出异常`，而实现`Runnable接口`无返回值且不能抛出异常：\n\n```java\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.FutureTask;\n\n/**\n * @author sixibiheye\n * @date 2021.08.28\n * @apiNote 实现 Callable 接口\n *\n */\n\npublic class Thread3 implements Callable<Integer> {\n    private int count3 = 10;\n    @Override\n    public Integer call() throws Exception{\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName()+\"运行：\" + count3--);\n        }\n        return 200;\n    }\n    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        //创建Callable的对象\n        Callable<Integer> callable = new Thread3();\n        //开始线程(FutureTask类同时实现了Future接口和Runnable接口)\n        FutureTask<Integer> futureTask = new FutureTask<Integer>(callable);\n        new Thread(futureTask).start();\n        //打印返回值\n        System.out.println(futureTask.get());\n    }\n}\n```\n\n上述实现`Callable接口`来创建线程的方式只需了解即可。此外Callable接口还可通过线程池来创建线程，与线程池有关的内容，参见同tag下的其他文章。\n\n现阶段我们只需掌握前两种创建方式（继承`Thread类`，实现`Runnable接口`）即可。\n\n# 1，2方式的对比\n\n最后，我们来对比一下`继承Thread类`，`实现Runnable接口`两种创建线程的方式：\n\n实现`Runnable接口`可以实现`资源共享`，而`继承Thread类`不行。此外，实现Runnable接口还可以避免Java单继承带来的局限性。\n\n因此，一般采用实现Runnable接口来实现多线程。最后，关于`实现Runnable接口`可以实现资源共享的说法，大家可以参见下面一段代码：\n\n```java\nimport static java.lang.Thread.sleep;\npublic class Thread2 implements Runnable{\n    //票数\n    private int count = 15;\n    @Override\n    public void run() {\n        for(int i = 0; i < count; i++){\n            System.out.println(Thread.currentThread().getName()+\"抢到了第：\" + i++ +\"张票\");\n            try {\n                sleep(100);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    public static void main(String[] args) {\n        new Thread(new Thread2(),\"A\").start();\n        new Thread(new Thread2(),\"B\").start();\n    }\n\n}\n```\n\n上面代码中的`票数count`便是一个公共资源，`实现Runnable接口`可以很轻松地实现资源共享。\n\n下一章我们将会介绍多线程里必须要解决的一个问题-----`线程安全`。","categories":["Java","Java多线程"]},{"title":"Java多线程详解（基本概念）","url":"/2021/08/28/h7v44fdq/","content":"\n# 前言\n\n从本章开始，我们就要开始介绍`Java`中一个非常重要的概念-----`多线程`。`线程化思想`是计算机领域的重要思想，有了线程，咱编写的程序才能更为高效准确地运行起来。\n\n首先，咱来了解一下为什么会有线程以及多线程的出现？\n\n实际上，最早出现的计算机主要是为了解决一些`复杂的计算问题`，这个时期的计算机只能识别一些特定的指令，由于计算机无法存储指令，当用户未输入任何指令的时候，计算机就不会工作，因此很多情况下计算机都处于暂停状态，这样计算机本身的资源并未得到有效的利用。\n\n后来随着科学计算的需要，科学家们开始试着给计算机写入`一系列指令`，让计算机执行完之后从另一台设备中输出，这样虽然提高了计算机本身资源的利用，但又会造成一个问题，那就是，`如果一条指令还未执行完，那么下一条指令就无法执行`（即使下一条指令与该指令无任何依赖关系），系统的资源仍然无法得到有效的利用，就是在这样的背景之下，涵育了多线程的出现。\n\n了解线程的历史，我们便知晓了线程出现的原因：`对于两个不相干（相干亦可）的指令，为何不让它们拥有自己的内存单独去运行呢？这样既提高了系统资源的利用率，也提高了程序的性能`。\n\n# 线程，进程，程序和CPU\n\n说到线程，就不得不介绍`线程，进程和程序`三者的联系和区别：\n\n> 1. 程序：\n>\n> 指令集，简单说来就是我们编写的代码，它是一个静态的概念，没有执行的含义。\n>\n> 2. 进程：\n>\n> 程序无法单独地运行，只有将程序加载到内存中，系统为其分配资源后才能执行，这种执行的程序便称为进程，也就是说，进程是系统进行资源分配和调度的独立单元，每个进程都有自己独立的地址空间。\n>\n> 3. 线程：\n>\n> 一个进程可以包含多个线程。系统在运行时会为每个进程分配不同的内存区域，但是不会为线程分配内存（线程所使用的资源是它所属的进程的资源），这些线程既独立又相互协作共同完成一个进程。说独立是因为每个线程都有自己的独立内存空间（此空间为其进程所占空间的某一部分），说相互协作是因为通过线程间通信，能够更高效地完成一个进程。\n\n我们还可以通过一个图来理解`线程，进程以及CPU`的关系：\n\n![img](/images/assets/6938deef801396ae303f17ce08362cee.png)对于`CPU`，我们可以将其简单分为`单核`和`多核`两种。\n\n对于`单核CPU`，实际上是无法实现在同一时刻执行多个线程的，只是因为执行速度过快，感觉像是“同时执行”（此乃**`并发`**）。\n\n当然，现在企业用的服务器大多都是`多核处理器`，它们可以真正实现在同一时刻执行多个线程（此乃**`并行`**）。\n\n# 线程的五种状态\n\n现在，我们已经了解线程的由来及一些基本的概念，下面，我们来看一张图：\n\n![img](/images/assets/9be844ed1a3f86bb27fbaed1969f1b40.png)上面这个图如果您能够理解，那么关于`多线程`您已经学会了一半了！当然看不太懂也没关系！学完多线程后，您就会有一个新的认识！但至少，您需要知道这五大状态的基本特点。\n\n下几章，我们开始介绍在java中如何创建一个线程以及线程的应用。","categories":["Java","Java多线程"]},{"title":"java中出现的静态代理模式","url":"/2021/08/26/6uusvnnz/","content":"\n# 前言\n\n本章我们来介绍，`java`中出现的静态代理模式。\n\n代理，对应于英语单词-----`Proxy`，从字面上理解，就是在实现代理目标(`Target`)所有的需求的同时，还能够实现代理目标无法做到的事情，比如为目标添加`审查和监控`功能，主要包括前置处理和后置处理。\n\n# 代理如何理解？\n\n咱从网上找到了一个典型的例子，在这分享给大家，请大家从下面的例子中细细体会：\n\n话说啊我们可爱的小明同志马上就要结婚啦，可是，许多的琐事诸如场地布置，鲜花摆放，婚礼流程等等，他自己操办不过来，于是，他找到了一家婚庆公司，由婚庆公司代替他去操办所有的琐事，而他自己，只需要专注于自己的事情就行了（比如努力工作挣足够的钱来办婚礼^_^）。\n\n这样一个浅显的例子，咱可以用一段代码描述：\n\n```java\npublic class Wedding {\n    public static void main(String[] args) {\n        //小明----真实角色\n        Marry xiaoming = new XiaoMing();\n        //婚庆公司----代理角色\n        Marry marryCompany = new MarryCompany(xiaoming);\n        //用婚庆公司的marry()方法代替小明的marry()方法\n        marryCompany.marry();\n    }\n}\n\n//结婚接口\ninterface Marry{\n    void marry();\n}\n\n//小明----真实角色\nclass XiaoMing implements Marry{\n    //小明应该做的事情\n    @Override\n    public void marry() {\n        System.out.println(\"小明结婚啦～\");\n    }\n}\n\n\n//婚庆公司----代理角色\nclass MarryCompany implements Marry{\n    private Marry target; //要代理的真实角色（比如小明）\n    public MarryCompany(Marry target){\n        this.target = target;\n    }\n    @Override\n    public void marry() {\n        //前置处理\n        before(); //代理角色不同于真实角色的新功能\n        //代理目标该做的事情\n        this.target.marry();\n        //后置处理\n        after(); //代理角色不同于真实角色的新功能\n    }\n    private void before() {\n        System.out.println(\"布置场地和鲜花～\");\n    }\n    private void after() {\n        System.out.println(\"小明该付尾款了～\");\n    }\n}\n```\n\n这段代码使用了`静态代理模式`，简单说来，使用代理，有以下优点：\n\n> 1. 代理对象可以做许多代理目标做不到的事情（比如本例子中的场地布置，鲜花摆放，婚礼流程等等）\n>\n> 2. 代理目标可以只专注于自己的事情。（比如本例子中，小明只需要考虑挣够钱来还尾款）\n\n在这，我们扩展一点点知识，上面代码段里，有如下代码：\n\n```java\n//婚庆公司----代理角色\nMarry marryCompany = new MarryCompany(xiaoming);\n        \n//用婚庆公司的marry()方法代替小明的marry()方法\nmarryCompany.marry();\n```\n\n咱可以使用`匿名`的方式，将两句合为一句，用一个图来说明：\n\n![img](images/assets/ad1213a7f4cab00a32739b86343d61b8.png)\n\n# Thread类中的代理模式\n\n其实，之所以介绍代理方面的知识，是为了引出接下来的东西，\n\n我们来看一看`JDK`里关于`Thread类`的一段源码：\n\n![img](/images/assets/f98dda2f523ae6a14658ab30b0289b10.png)显然，这是`Thread类`的某一个构造方法，细心的小伙伴们可能看到了熟悉的“`target`”字样！没错！！！这个构造方法便是使用了代理模式编写， 如果你已经对上面那个例子中的代码比较熟悉，那么对于下图中所表示的`Java线程启动`方式就有了更深刻的理解了：（图中的`NewThread`实现了`Runnable接口`)\n\n![img](/images/assets/7a75461d735472aeaa7dfe587caf6bf7.png)\n\n甚至，结合`Lambda表达式`，小伙伴们也能够看懂下面的代码：\n\n```java\n  new Thread( () -> System.out.println(\"我是易果啥笔\") ).start();\n```\n\n代理模式也是设计模式的一种。 了解代理模式的特点，有助于我们理解一些底层原理的实现。\n","categories":["Java"]},{"title":"Lambda表达式初识","url":"/2021/08/25/i6oaz2pg/","content":"\n# 前言\n\n之前有一个小伙伴给我发了一段代码，说是看不懂，这段代码是这样的：\n\n```java\npublic class Aha  {\n    public static void main(String[] args) {\n        Care iCare = () -> System.out.println(\"Hahahahaha~\");\n        iCare.care();\n    }\n}\n\ninterface Care{\n    void care();\n}\n```\n\n如果屏幕面前的你也不是很能够理解，那就听我细讲吧。首先，在理解上述代码之前，我们需要了解一个概念-----`函数式接口`。\n\n# 函数式接口\n\n> 函数式接口，指只定义了一个抽象方法的接口。\n\n比如如下的接口便是一个最简单的函数式接口：\n\n```java\ninterface Care{\n    void care();\n}\n```\n\n如果你对`jdk`的源码有过研究的话，会发现`JDK`中也提供了许多`函数式接口`，比如我们熟悉的 **Runnable** 接口和 **Callable** 接口：\n\n![img](/images/assets/3a6dc871ac66ca583054dfa3e9ae4094.png)\n\n![img](/images/assets/6dfbcb5b21d7070c046ff6bd6f2ff882.png)细心的小伙伴会发现，上面两段源码中均对接口加上了一个注解：`@FunctionalInterface` ，顾名思义，这表示该接口会被设计成一个函数式接口，不符合规范的话，编译时会报错。 \n\n再比如线程池中的 **Executor** 接口：\n\n![img](/images/assets/bb000d37da01e25e0ae8725ac9a6f3ef.png)\n\n# 函数式接口的用处\n\n那么问题来了，将接口设计成函数式接口有什么好处呢？\n\n我们通过一个例子来领会它的妙处，首先，上一段简单的代码：\n\n```java\npublic class Haha  {\n    public static void main(String[] args) {\n        ILike iLike = new Like();\n        iLike.like();\n    }\n}\n\ninterface ILike{\n    void like();\n}\n\n//普通实现类\nclass Like implements ILike{\n    @Override\n    public void like() {\n        System.out.println(\"我是易果啥笔\");\n    }\n}\n```\n\n相信学过接口的小伙伴们能够很轻松地看懂上面这段代码。\n\n现在我们深入地想一想，如果`ILike`这个接口仅仅是在`Haha`这个类中使用，那我们没必要新建一个`外部Like实现类`，一个很自然的想法便是将`Like`实现类设计成`静态内部类`：\n\n```java\npublic class Haha  {\n    //静态内部类\n    static class Like implements ILike{\n        @Override\n        public void like() {\n            System.out.println(\"我是易果啥笔\");\n        }\n    }\n    public static void main(String[] args) {\n\n        ILike iLike = new Like();\n        iLike.like();\n        }\n    }\n}\n\ninterface ILike{\n    void like();\n}\n```\n\n既然想到了设计成`静态内部类`，为何不干脆设计成`局部内部类`呢：\n\n```java\npublic class Haha  {\n    public static void main(String[] args) {\n        ILike iLike = new Like();\n        iLike.like();\n        //局部内部类\n        class Like implements ILike{\n            @Override\n            public void like() {\n                System.out.println(\"我是易果啥笔\");\n            }\n        }\n    }\n}\n\ninterface ILike{\n    void like();\n}\n```\n\n进一步，如果你学过`匿名内部类`的话，咱还可以把实现类的类名`Like`省略，简化成：\n\n```java\npublic class Haha  {\n    public static void main(String[] args) {\n        ILike iLike = new ILike() {\n            @Override\n            public void like() {\n                System.out.println(\"我是易果啥笔\");\n            }\n        }; //注意此处要有一个分号结尾\n\n        iLike.like();\n    }\n}\n\ninterface ILike{\n    void like();\n}\n```\n\n 现在，我们来看核心代码：\n\n```java\nILike iLike = new ILike() {\n            @Override\n            public void like() {\n                System.out.println(\"我是易果啥笔\");\n            }\n        };\n```\n\n上面这段代码，已经把实现接口的类的类名给省略了，我们想一想，还能不能省略点东西？\n\n# Lambda表达式\n\n实际上，`iLike`前面已有`ILike`修饰，故后面的“`new ILike`”字样完全可以省略，不会产生歧义。\n\n而且，重点来了！！！由于`ILike`本身是一个`函数式接口`，它只有一个抽象方法 `like()` ，所以上面的代码中完全可以把重写的`like()`方法中的“固定代码”去掉而不会产生歧义，甚至花括号也可以去掉，直接写成：\n\n>  ILike iLike = ()  System.out.println ( \" 我是易果啥笔 \" ) ;\n\n当然，在`jdk8`（或更高）规范中，需要我们加上一个小箭头“ `->` ”：\n\n```java\nILike iLike = () ->  System.out.println(\"我是易果啥笔\");\n```\n\n到这，我们已经将一个复杂的代码块缩短成了最简单的一行代码，这种用“`->`”符号来编写的表达式，便称为`匿名表达式`，也叫Lambda表达式。\n\n从上述过程可以看出，`Lambda表达式`的优点在于能够使代码变得更为简洁。注意，能够将代码缩短至一行是有一定条件的，下面的代码列举的应该包含绝大多数情况了：\n\n```Java\n//如果接口实现的语句不止一个，则必须加上花括号{}，这与if，for，while语法类似：\nILike iLike = () -> {\n    System.out.println(\"我是易果啥笔\");\n    System.out.println(\"我是易果啥笔2\");\n};\n\n//如果接口含且仅含有一个参数（比如含有int a,这时可以省略括号和申明：int）\nILike iLike = a -> System.out.println(\"我是易果啥笔\");\n\n//如果接口含有多个参数(比如含有int a,String b，这时不能省略括号，但仍可以省略申明:int和String)\nILike iLike = (a,b) -> System.out.println(\"我是易果啥笔\");\n```\n\n到这，本文最开始给出的那段代码就很好理解了，其实就是一个简单的`Lambda表达式`而已：\n\n```java\npublic class Aha  {\n    public static void main(String[] args) {\n        Care iCare = () -> System.out.println(\"Hahahahaha~\");\n        iCare.care();\n    }\n}\n\ninterface Care{\n    void care();\n}\n```\n\n事实上，`Lambda表达式`的应用远不止这些，有兴趣的小伙伴可以去查询更多的资料了解`Lambda表达式`的其他应用。\n","categories":["Java"]},{"title":"java的设计模式","url":"/2021/08/24/fvb12szr/","content":"\n# 前言\n\n今天，给大家简单地介绍一下`设计模式`。关于设计模式，网上的资料有许多，结合笔者自己的理解，简单地谈一谈。\n\n# 什么是设计模式？\n\n查阅了许多资料，他们给出的定义基本一致：\n\n**`设计模式`**`是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结`。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。\n\n合理地使用设计模式能够使代码编制真正`工程化`。经过好几辈科学家的探索和实践，他们总结出了许多合理且高效的模式和思想，比如“`优先使用对象的组合而不使用继承`”，再比如“`针对接口编程，依赖于抽象而不依赖于具体`”等等。\n\n`设计模式是软件工程的基石`。在现实生活中所见到的许多原理，在设计模式中均有体现，设计模式是对客观存在事物的一种认知的结果，从现实生活中获得设计的灵感，然后应用于现实。\n\n# 设计模式的基本原则有哪些？\n\n网上对于设计模式的介绍，都会提到设计模式的“`六大原则`”，笔者在此谈谈自己对“六大原则”的理解。\n\n## 开闭原则（Open Close Principle）\n\n**对扩展开放，对修改关闭**。现在的许多大型的应用开发，都会要求自己的程序扩展性好，所谓扩展性好，就是指在不修改原有代码的基础上，能够扩展新的功能。简单来说就一个目的：便于维护和升级。从当前主流开发模式中可以看到，要实现开闭原则，使用的都是接口和抽象类。通过编写接口和抽象类来维护已有的程序块，同时达到扩展业务功能的作用。\n\n## 里氏代换原则（Liskov Substitution Principle）\n\n`里氏代换原则`本是面向对象设计的基本原则之一。 简单来说就是，`子类可以扩展父类的功能，但不能改变父类原有的功能`。换句话说，在一个程序里，将某个基类换成它的任何一个子类，程序仍然能够正常地运行。由于使用基类对象的地方均可以使用子类对象，因此在程序中应尽量使用基类类型来对对象进行定义。里氏代换原则是实现开闭原则的重要方式之一，也是对实现抽象化的具体步骤的规范。\n\n## 依赖倒转原则（Dependence Inversion Principle）\n\n作为开闭原则的基础，就如笔者前面提到的：`针对接口编程，依赖于抽象而不依赖于具体`。也就是说，`上层模块不应该依赖底层模块，而它们都应该依赖于抽象`。\n\n咱可以举个例子加以理解。比如我们想要实现一家球店，实现一家球店，有许多的依赖：篮球，足球，羽毛球等，也就是说，如果缺少篮球，足球，羽毛球等（底层模块），球店（上层模块）便无法营业，这便是一个典型的“上层模块依赖底层模块”事例。\n\n现在我们换个角度，从底层模块考虑，篮球，足球，羽毛球等能够抽象成什么？\n\n其实，它们均能够抽象成-----球。这样设计的话，你会发现，球店（上层模块），篮球，足球，羽毛球（底层模块），它们均依赖于----球（抽象）。这就很好诠释了“上层模块不应该依赖底层模块，而它们都应该依赖于抽象”。\n\n这样有什么好处呢？如果球店想要扩展业务范围，比如原来不卖某球的，现在想卖刚引进的某球，这时，你只需要实现球-----这个抽象就行了，比如，你可以将球实现为排球，实现为乒乓球......在实现的过程中，你会发现，你没有修改原有的底层模块，仅仅是扩展了球这一个抽象类，这不正好符合“开闭原则”吗？\n\n## 接口隔离原则（Interface Segregation Principle）\n\n这个原则很好理解，大致意思是：`使用多个独立接口，比使用单个接口要好`。如果只使用单个接口，由该接口实现的类与类之间，会有或多或少的依赖关系，比如子类与父类的关系，当一个项目比较大的时候，整个程序的所有类耦合在一起，一旦需要修改某个类，那么与这个类具有依赖关系的所有类，均会受到影响，在开发中应尽量避免这种情况。因此它还有一个意思：`降低类之间的耦合度`。\n\n## 迪米特法则，又称最少知道原则（Demeter Principle）\n\n最少知道原则是指：`一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立`。前面的“接口隔离原则”说到，同一接口，类与类之间会有一定的依赖关系，而“**迪米特法则**”则要求，`尽量减少甚至消除这种依赖关系`。\n\n## 合成复用原则（Composite Reuse Principle）\n\n合成复用原则很简单：`尽量使用合成的方式，而不是使用继承`。\n\n通常类的复用分为`继承复用`和`合成复用`两种，继承复用虽然有简单和易实现的优点，但它也存在以下缺点：\n\n> 1. 继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类来说是透明的，这不符合“封装性”要求。\n> 2. 子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这显然不利于类的扩展与维护。\n> 3. 限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，在运行时不可能发生变化，灵活性不高。\n\n\n采用`组合`或`聚合复用`时，可以将已创建的对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已创建对象的功能，因此它有如下优点：\n\n> 1. 维持了类的封装性。因为成员对象的内部细节对新对象而言是看不见的，从而保证了类的封装性。\n> 2. 新旧类之间的耦合度降低。这种复用所需的依赖较少，新对象存取成员对象的唯一方法是通过成员对象的接口。\n> 3. 复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成员对象类型相同的对象。\n","categories":["Java"]},{"title":"Java连接MySQL数据库","url":"/2021/08/24/j8s0eiwy/","content":"\n# 前言\n\n本章我们介绍，如何用java实现连接`MySQL数据库`并实现基本的`增，删，改，查`操作。\n\n为了便于演示，首先我们使用`Navicat Premium`新建一个`user表`并添加如下数据：\n\n![img](/images/assets/548204d15e7589b29487da6241133f81.png)\n\n# 导入jdbc驱动包\n\n我们需要导入连接`MySQL`所需要的`jar包: jdbc驱动包`。` jdbc驱动包`有多个版本，请根据自己的项目需要选择适合的版本（点击跳转至官网下载）：[jdbc驱动包官网下载](https://downloads.mysql.com/archives/c-j/) 。\n\n根据自己的电脑对应的系统下载：\n\n![img](/images/assets/6d115f836102f40caeb1d0235aac86a3.png)\n\n以`Mac`为例，解压下载文件，找到下图中的圈红的`jar包`：  \n\n![img](/images/assets/48da64e32e6ca8071f8403fb4037c965.png)\n\n即为连接`MySQL`所需的`jdbc驱动包`，接着在自己的项目中添加此驱动包。\n\n# 查询操作\n\n添加完成后，我们来编写一个简单的`查询操作`：\n\n```java\npackage com.connect_mysql.example;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\n\npublic class DButil {\n    public static void main(String[] args) {\n        //声明Connection对象\n        Connection con;//驱动程序名\n        String driver = \"com.mysql.jdbc.Driver\";\n        //URL指向要访问的数据库名--sixibiheye,（自行更改成自己的库名）\n        String url = \"jdbc:mysql://localhost:3306/sixibiheye\";\n        //MySQL配置时的用户名（自行更改成自己的用户名）\n        String user = \"everyone\";\n        //MySQL配置时的密码（自行更改成自己的密码）\n        String password = \"123456\";\n        //遍历查询结果集\n        try {\n            //加载驱动程序\n            Class.forName(driver);\n            //1.getConnection()方法，连接MySQL数据库！！\n            con = DriverManager.getConnection(url,user,password);\n            if(!con.isClosed())\n                System.out.println(\"Succeeded connecting to the Database!\");\n            //2.创建statement类对象，用来执行SQL语句！！\n            Statement statement = con.createStatement();\n            //要执行的SQL语句\n            String sql = \"select username,sex from user;\";\n            //3.ResultSet类，用来存放获取的结果集！！\n            ResultSet rs = statement.executeQuery(sql);\n            System.out.println(\"-----------------\");\n            System.out.println(\"执行结果如下所示:\");\n            System.out.println(\"-----------------\");\n            System.out.println(\"姓名\" + \"\\t\" + \"性别\");\n            System.out.println(\"-----------------\");\n\n            String name = null;\n            String sex = null;\n            while(rs.next()){\n                //获取stuname这列数据\n                name = rs.getString(\"username\");\n                //获取stuid这列数据\n                sex = rs.getString(\"sex\");\n\n                //输出结果\n                System.out.println(name + \"\\t\" + sex);\n            }\n            rs.close();\n            con.close();\n        } catch(ClassNotFoundException e) {\n            //数据库驱动类异常处理\n            System.out.println(\"Sorry,can`t find the Driver!\");\n            e.printStackTrace();\n        } catch(Exception e) {\n            //数据库连接失败异常处理\n            e.printStackTrace();\n        }// TODO: handle exception\n    }\n}\n```\n\n对于上面的查询操作，使用到的是`Statement对象`的`executeQuery(String sql)`方法，其返回一个`ResultSet对象`（结果集），可以通过调用其`getString(\"字段名\")`方法来获取数据，其`next()`方法表示指针指向下一行，如果有数据就返回`true`，此外还有`first()指向第一行数据`，`last()指向最后一行数据`等等方法。\n\n运行之后，会得到如下结果：\n\n![img](/images/assets/feff6ae751bfd384ec4c6f8ea4b2f8c7.png)\n\n# 添加操作\n\n接着，我们来实现`添加数据`的操作： \n\n```java\npackage com.connect_mysql.example;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\n\npublic class DButil {\n    public static void main(String[] args) {\n        //声明Connection对象\n        Connection con;//驱动程序名\n        String driver = \"com.mysql.jdbc.Driver\";\n        //URL指向要访问的数据库名--sixibiheye,（自行更改成自己的库名）\n        String url = \"jdbc:mysql://localhost:3306/sixibiheye\";\n        //MySQL配置时的用户名（自行更改成自己的用户名）\n        String user = \"everyone\";\n        //MySQL配置时的密码（自行更改成自己的密码）\n        String password = \"123456\";\n        //遍历查询结果集\n        try {\n            //加载驱动程序\n            Class.forName(driver);\n            //1.getConnection()方法，连接MySQL数据库！！\n            con = DriverManager.getConnection(url,user,password);\n            if(!con.isClosed())\n                System.out.println(\"Succeeded connecting to the Database!\");\n            //2.创建statement类对象，用来执行SQL语句！！\n            Statement statement = con.createStatement();\n            //要执行的SQL语句\n            String sql = \"insert into user(id,username,sex) values(5,'HaHa','boy');\";\n\n            //executeUpdate(String sql)的返回值是一个int,指受影响的行数。\n            int number = statement.executeUpdate(sql);\n            System.out.println(\"插入成功！受影响的行数：\" + number);\n\n            con.close();\n        } catch(ClassNotFoundException e) {\n            //数据库驱动类异常处理\n            System.out.println(\"Sorry,can`t find the Driver!\");\n            e.printStackTrace();\n        } catch(Exception e) {\n            //数据库连接失败异常处理\n            e.printStackTrace();\n        }// TODO: handle exception\n\n    }\n\n}\n```\n\n上述插入操作中，使用了`Statement对象`的`executeUpdate(String sql)`方法来执行插入操作。其返回值为一个`int`型数据，表示的是`受影响的行数`（即更新计数）。\n\n运行之后，得到如下结果：\n\n![img](/images/assets/5fe1406d4e2ad3c8f63f7824a9e1a8ee.png)\n\n在`Navicat Premium`里我们能看到新增的数据：\n\n![img](/images/assets/385279fdc59e8f9f8296a0008975662e.png)\n\n对于`删除`和`更新`操作，与上面的插入操作基本相同，就不具体演示了。小伙伴们可以自己动手试一试。\n\n# executeQuery(String sql)，executeUpdate(String sql)，execute(String sql)\n\n最后，附上executeQuery(String sql)，executeUpdate(String sql)，execute(String sql)三者的区别：\n\n> 1. executeQuery(String sql)：\n>\n> 用于产生单个结果集的语句，典型的便是`SELECT语句`。这是执行`SQL语句`使用得最多的方法，主要用来执行`SELECT语句`。其返回的是一个`ResultSet对象`（结果集），可以通过调用其`getString(\"字段名\")`方法来获取数据，调用其`next()`方法使指针指向下一行（如果有数据就返回`true`），调用其`first()`方法指向第一行数据，`last()`方法指向最后一行数据。\n>\n> 2. executeUpdate(String sql)：\n>\n> 用于执行`SQL语句`中的`DDL`（数据定义语言）语句，比如`INSERT , UPDATE , DETELE , CREATE TABLE , DROP TABLE`等等，其返回值为一个`int`型数据，表示的是`受影响的行数`（即更新计数），对于`CREATE TABLE , DROP TABLE`等不影响行的操作，返回值总为`0`）。\n>\n> 3. execute(String sql):\n>\n> 如果说`executeQuery`返回的是单个结果集，则`execute(String sql)`将会产生多个结果集，但其返回值是一个`boolean`类型，如果执行后有结果集，返回`true`，否则返回`false`。可以通过`getResultSet()`方法来获得第一个结果集。如果要获得第二个结果集，需先调用`getMoreResults()`方法，再调用`getResultSet()方法。如果已知某次执行返回两个更新计数，则应先调用getUpdateCount()`方法，再依次调用`getMoreResults()`方法 , `getResultSet()`方法。\n>\n> 对于不知道返回结果的语句，情况则更为复杂。因此，在大多的应用中，很少使用`execute(String sql)`方法。\n\n尽管在实际的开发中，不会使用如此原生的方式来连接数据库，但了解最原始的连接方式，对理解许多框架连接`MySQL`的方式会很有帮助。\n","categories":["Java"]},{"title":"数据结构与算法之-----图（代码实现）","url":"/2021/08/22/58nr6yi6/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 图的三大搜索算法构建\n\n上一章我们介绍了图的`拓扑排序以及拓扑序列`，本章我们来了解如何用代码去实现图的三大算法：\n\n> 1. 广度优先搜索算法\n>\n> 2. 深度优先搜索算法\n>\n> 3. 拓扑排序算法\n\n我们先新建一个`Graph.h`，本章依然从构建一个完整的图的角度来编写代码： \n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.22\n * 内容：图的头文件\n *\n *\n */\n\n#ifndef STACK_GRAPH_H\n#define STACK_GRAPH_H\n#define hca(x) (fTime(x)) \n#include \"Stack.h\"\n#include \"Queue.h\"\n\nusing VStatus = enum { UNDISCOVERED, DISCOVERED, VISITED }; //顶点状态\nusing EType = enum { UNDETERMINED, TREE, CROSS, FORWARD, BACKWARD }; //边在遍历树中所属的类型\n\ntemplate <typename Tv, typename Te> //顶点类型、边类型\nclass Graph { //图Graph模板类\n    private:\n        void reset() { //所有顶点、边的辅助信息复位\n               for ( int i = 0; i < n; i++ ) { //所有顶点的\n                      status ( i ) = UNDISCOVERED; dTime ( i ) = fTime ( i ) = -1; //状态，时间标签\n                      parent ( i ) = -1; priority ( i ) = INT_MAX; //（在遍历树中的）父节点，优先级数\n                      for ( int j = 0; j < n; j++ ) //所有边的\n                             if ( exists ( i, j ) ) type ( i, j ) = UNDETERMINED; //类型\n                   }\n        }\n        void BFS(int,int&);\n        void DFS(int,int&);\n        bool TSort(int,int&,Stack<Tv>*);\n     public:\n        // 顶点\n        int n; //顶点总数\n        virtual int insert ( Tv const& ) = 0; //插入顶点，返回编号\n        virtual Tv remove ( int ) = 0; //删除顶点及其关联边，返回该顶点信息\n        virtual Tv& vertex ( int ) = 0; //顶点v的数据（该顶点的确存在）\n        virtual int inDegree ( int ) = 0; //顶点v的入度（该顶点的确存在）\n        virtual int outDegree ( int ) = 0; //顶点v的出度（该顶点的确存在）\n        virtual int firstNbr ( int ) = 0; //顶点v的首个邻接顶点\n        virtual int nextNbr ( int, int ) = 0; //顶点v的（相对于顶点j的）下一邻接顶点\n        virtual VStatus& status ( int ) = 0; //顶点v的状态\n        virtual int& dTime ( int ) = 0; //顶点v的时间标签dTime\n        virtual int& fTime ( int ) = 0; //顶点v的时间标签fTime\n        virtual int& parent ( int ) = 0; //顶点v在遍历树中的父亲\n        virtual int& priority ( int ) = 0; //顶点v在遍历树中的优先级数\n        // 边：这里约定，无向边均统一转化为方向互逆的一对有向边，从而将无向图视作有向图的特例\n        int e; //边总数\n        virtual bool exists ( int, int ) = 0; //边(v, u)是否存在\n        virtual void insert ( Te const&, int, int, int ) = 0; //在顶点v和u之间插入权重为w的边e\n        virtual Te remove ( int, int ) = 0; //删除顶点v和u之间的边e，返回该边信息\n        virtual EType & type ( int, int ) = 0; //边(v, u)的类型\n        virtual Te& edge ( int, int ) = 0; //边(v, u)的数据（该边的确存在）\n        virtual int& weight ( int, int ) = 0; //边(v, u)的权重\n        // 算法\n        void bfs ( int ); //广度优先搜索算法\n        void dfs ( int ); //深度优先搜索算法 \n        Stack<Tv>* tSort ( int ) //拓扑排序算法\n\n };\n\n\ntemplate <typename Tv, typename Te> //广度优先搜索BFS算法（全图）\nvoid Graph<Tv, Te>::bfs ( int s ) { //assert: 0 <= s < n\n        reset(); int clock = 0; int v = s; //初始化\n        do //逐一检查所有顶点\n               if ( UNDISCOVERED == status ( v ) ) //一旦遇到尚未发现的顶点\n                  BFS ( v, clock ); //即从该顶点出发启动一次BFS\n        while ( s != ( v = ( ++v % n ) ) ); //按序号检查，故不漏不重\n     }\n\ntemplate <typename Tv, typename Te> //广度优先搜索BFS算法（单个连通域）\nvoid Graph<Tv, Te>::BFS ( int v, int& clock ) { //assert: 0 <= v < n\n     Queue<int> Q; //引入辅助队列\n     status ( v ) = DISCOVERED; Q.enqueue ( v ); //初始化起点\n     while ( !Q.empty() ) { //在Q变空之前，不断\n           int v = Q.dequeue(); dTime ( v ) = ++clock; //取出队首顶点v\n           for ( int u = firstNbr ( v ); -1 < u; u = nextNbr ( v, u ) ) //枚举v的所有邻居u\n                 if ( UNDISCOVERED == status ( u ) ) { //若u尚未被发现，则\n                      status ( u ) = DISCOVERED; Q.enqueue ( u ); //发现该顶点\n                      type ( v, u ) = TREE; parent ( u ) = v; //引入树边拓展支撑树\n                 } else { //若u已被发现，或者甚至已访问完毕，则\n                      type ( v, u ) = CROSS; //将(v, u)归类于跨边\n                 }\n                 status ( v ) = VISITED; //至此，当前顶点访问完毕\n           }\n}\n\n\ntemplate <typename Tv, typename Te> //深度优先搜索DFS算法（全图）\nvoid Graph<Tv, Te>::dfs ( int s ) { //assert: 0 <= s < n\n        reset(); int clock = 0; int v = s; //初始化\n        do //逐一检查所有顶点\n               if ( UNDISCOVERED == status ( v ) ) //一旦遇到尚未发现的顶点\n                  DFS ( v, clock ); //即从该顶点出发启动一次DFS\n        while ( s != ( v = ( ++v % n ) ) ); //按序号检查，故不漏不重\n}\n\n\ntemplate <typename Tv, typename Te> //深度优先搜索DFS算法（单个连通域）\nvoid Graph<Tv, Te>::DFS ( int v, int& clock ) { //assert: 0 <= v < n\n        dTime ( v ) = ++clock; status ( v ) = DISCOVERED; //发现当前顶点v\n        for ( int u = firstNbr ( v ); -1 < u; u = nextNbr ( v, u ) ) //枚举v的所有邻居u\n               switch ( status ( u ) ) { //并视其状态分别处理\n                  case UNDISCOVERED: //u尚未发现，意味着支撑树可在此拓展\n                         type ( v, u ) = TREE; parent ( u ) = v; DFS ( u, clock ); break;\n                      case DISCOVERED: //u已被发现但尚未访问完毕，应属被后代指向的祖先\n                         type ( v, u ) = BACKWARD; break;\n                      default: //u已访问完毕（VISITED，有向图），则视承袭关系分为前向边或跨边\n                         type ( v, u ) = ( dTime ( v ) < dTime ( u ) ) ? FORWARD : CROSS; break;\n                   }\n        status ( v ) = VISITED; fTime ( v ) = ++clock; //至此，当前顶点v方告访问完毕\n}\n\n\ntemplate <typename Tv, typename Te> //基于DFS的拓扑排序算法\nStack<Tv>* Graph<Tv, Te>::tSort ( int s ) { //assert: 0 <= s < n\n        reset(); int clock = 0; int v = s;\n        Stack<Tv>* S = new Stack<Tv>; //用栈记录排序顶点\n        do {\n               if ( UNDISCOVERED == status ( v ) )\n                      if ( !TSort ( v, clock, S ) ) { //clock并非必需\n                         while ( !S->empty() ) //任一连通域（亦即整图）非DAG\n                                S->pop(); break; //则不必继续计算，故直接返回\n                      }\n            } while ( s != ( v = ( ++v % n ) ) );\n        return S; //若输入为DAG，则S内各顶点自顶向底排序；否则（不存在拓扑排序），S空\n     }\n\ntemplate <typename Tv, typename Te> //基于DFS的拓扑排序算法（单趟）\nbool Graph<Tv, Te>::TSort ( int v, int& clock, Stack<Tv>* S ) { //assert: 0 <= v < n\n        dTime ( v ) = ++clock; status ( v ) = DISCOVERED; //发现顶点v\n        for ( int u = firstNbr ( v ); -1 < u; u = nextNbr ( v, u ) ) //枚举v的所有邻居u\n               switch ( status ( u ) ) { //并视u的状态分别处理\n                  case UNDISCOVERED:\n                         parent ( u ) = v; type ( v, u ) = TREE;\n                         if ( !TSort ( u, clock, S ) ) //从顶点u处出发深入搜索\n                        return false; //若u及其后代不能拓扑排序（则全图亦必如此），故返回并报告\n                         break;\n                      case DISCOVERED:\n                         type ( v, u ) = BACKWARD; //一旦发现后向边（非DAG），则\n                         return false; //不必深入，故返回并报告\n                      default: //VISITED (digraphs only)\n                         type ( v, u ) = ( dTime ( v ) < dTime ( u ) ) ? FORWARD : CROSS;\n                         break;\n                   }\n        status ( v ) = VISITED; S->push ( vertex ( v ) ); //顶点被标记为VISITED时，随即入栈\n        return true; //v及其后代可以拓扑排序\n}\n\n#endif //STACK_GRAPH_H\n```\n\n代码中对各个算法都有比较详细的注释，请读者细细体会三大算法的实现。\n\n前面说过，图的结构为：`V和E集合`，其中，`V`是顶点，`E`是边。简单来说，可以用一个`一维数组`存放图中所有顶点数据；用一个`二维数组`存放顶点间关系（边或弧）的数据，这个二维数组称为`邻接矩阵`。\n\n下面我们通过邻接矩阵来构建一个完整的图结构，为了能够与三大算法联系起来，我们在下面的`GraphMatrix.h`文件中`include`上面的`Graph.h`：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.22\n * 内容：邻接矩阵的头文件\n *\n *\n */\n\n#ifndef STACK_GRAPHMATRIX_H\n#define STACK_GRAPHMATRIX_H\n#include \"Vector.h\" //引入向量\n#include \"Graph.h\" //引入图ADT\n\ntemplate <typename Tv> struct Vertex { //顶点对象（为简化起见，并未严格封装）\n        Tv data; int inDegree, outDegree; VStatus status; //数据、出入度数、状态\n        int dTime, fTime; //时间标签\n        int parent; int priority; //在遍历树中的父节点、优先级数\n        Vertex ( Tv const& d = ( Tv ) 0 ) : //构造新顶点\n           data ( d ), inDegree ( 0 ), outDegree ( 0 ), status ( UNDISCOVERED ),\n           dTime ( -1 ), fTime ( -1 ), parent ( -1 ), priority ( INT_MAX ) {} //暂不考虑权重溢出\n};\n\ntemplate <typename Te> struct Edge { //边对象（为简化起见，并未严格封装）\n        Te data; int weight; EType type; //数据、权重、类型\n        Edge ( Te const& d, int w ) : data ( d ), weight ( w ), type ( UNDETERMINED ) {} //构造\n     };\n\ntemplate <typename Tv, typename Te> //顶点类型、边类型\nclass GraphMatrix : public Graph<Tv, Te> { //基于向量，以邻接矩阵形式实现的图\n     private:\n        Vector< Vertex< Tv > > V; //顶点集（向量）\n        Vector< Vector< Edge< Te > * > > E; //边集（邻接矩阵）\n     public:\n        GraphMatrix() { n = e = 0; } //构造\n        ~GraphMatrix() { //析构\n               for ( int j = 0; j < n; j++ ) //所有动态创建的\n                      for ( int k = 0; k < n; k++ ) //边记录\n                         delete E[j][k]; //逐条清除\n            }\n     // 顶点的基本操作：查询第i个顶点（0 <= i < n）\n        virtual Tv& vertex ( int i ) { return V[i].data; } //数据\n        virtual int inDegree ( int i ) { return V[i].inDegree; } //入度\n        virtual int outDegree ( int i ) { return V[i].outDegree; } //出度\n        virtual int firstNbr ( int i ) { return nextNbr ( i, n ); } //首个邻接顶点\n        virtual int nextNbr ( int i, int j ) //相对于顶点j的下一邻接顶点（改用邻接表可提高效率）\n        { while ( ( -1 < j ) && ( !exists ( i, --j ) ) ); return j; } //逆向线性试探\n        virtual VStatus& status ( int i ) { return V[i].status; } //状态\n        virtual int& dTime ( int i ) { return V[i].dTime; } //时间标签dTime\n        virtual int& fTime ( int i ) { return V[i].fTime; } //时间标签fTime\n        virtual int& parent ( int i ) { return V[i].parent; } //在遍历树中的父亲\n        virtual int& priority ( int i ) { return V[i].priority; } //在遍历树中的优先级数\n     // 顶点的动态操作\n        virtual int insert ( Tv const& vertex ) { //插入顶点，返回编号\n               for ( int j = 0; j < n; j++ ) E[j].insert ( NULL ); n++; //各顶点预留一条潜在的关联边\n               E.insert ( Vector<Edge<Te>*> ( n, n, ( Edge<Te>* ) NULL ) ); //创建新顶点对应的边向量\n               return V.insert ( Vertex<Tv> ( vertex ) ); //顶点向量增加一个顶点\n            }\n        virtual Tv remove ( int i ) { //删除第i个顶点及其关联边（0 <= i < n）\n               for ( int j = 0; j < n; j++ ) //所有出边\n                      if ( exists ( i, j ) ) { delete E[i][j]; V[j].inDegree--; e--; } //逐条删除\n               E.remove ( i ); n--; //删除第i行\n               Tv vBak = vertex ( i ); V.remove ( i ); //删除顶点i\n               for ( int j = 0; j < n; j++ ) //所有入边\n                      if ( Edge<Te> * x = E[j].remove ( i ) ) { delete x; V[j].outDegree--; e--; } //逐条删除\n               return vBak; //返回被删除顶点的信息\n            }\n     // 边的确认操作\n        virtual bool exists ( int i, int j ) //边(i, j)是否存在\n        { return ( 0 <= i ) && ( i < n ) && ( 0 <= j ) && ( j < n ) && E[i][j] != NULL; }\n     // 边的基本操作：查询顶点i与j之间的联边（0 <= i, j < n且exists(i, j)）\n        virtual EType & type ( int i, int j ) { return E[i][j]->type; } //边(i, j)的类型\n        virtual Te& edge ( int i, int j ) { return E[i][j]->data; } //边(i, j)的数据\n        virtual int& weight ( int i, int j ) { return E[i][j]->weight; } //边(i, j)的权重\n     // 边的动态操作\n        virtual void insert ( Te const& edge, int w, int i, int j ) { //插入权重为w的边e = (i, j)\n               if ( exists ( i, j ) ) return; //确保该边尚不存在\n               E[i][j] = new Edge<Te> ( edge, w ); //创建新边\n               e++; V[i].outDegree++; V[j].inDegree++; //更新边计数与关联顶点的度数\n            }\n        virtual Te remove ( int i, int j ) { //删除顶点i和j之间的联边（exists(i, j)）\n               Te eBak = edge ( i, j ); delete E[i][j]; E[i][j] = NULL; //备份后删除边记录\n               e--; V[i].outDegree--; V[j].inDegree--; //更新边计数与关联顶点的度数\n               return eBak; //返回被删除边的信息\n            }\n};\n#endif //STACK_GRAPHMATRIX_H\n```\n\n至此，一个完整的`图结构`就构建完毕了。\n\n图作为数学领域与计算机领域交汇的内容，不论是在数学领域，还是在计算机领域，都有着非常多的应用，这些应用不仅推动了数学和计算机的发展，更是体现着人类的独高智慧。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----图（拓扑排序）","url":"/2021/08/22/hpat9fh6/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 如何理解拓扑排序？\n\n上一篇笔者介绍了图中两种重要的搜索算法-----`BFS和DFS`，这一章，我们来了解一下图中的另一个重要知识：拓扑排序。许多人可能听说过这个术语，但是不太了解，它是一种排序算法吗？不是。 简单来说，拓扑排序，实质是对有向图的节点排成一个线性序列。\n\n为什么会出现拓扑排序这一概念呢？我们来举个例子，假如你想学习`jeecg-boot`这个框架，你可能需要学习以下内容：\n\n> java, html, css, javascript, vue, ant-design-vue, springboot, jeecgboot......\n\n你会发现，这些东西，学习的顺序是有一定限制的，比如，你必须先学`html`，之后才能学`vue`；你必须先学习`springboot`，之后才能学习`jeecgboot`。\n\n这样，我们自然就会问，我按怎样的顺序学习这些内容才是合理的呢？其实，我们可以用一个简单的有向图来表示学习的顺序关系：\n\n![img](/images/assets/88bfd91f225dbc9b390b00a5a73bd06b.png)\n\n从这个流程图中，我们能够清晰地看出，应该先学什么，后学什么。 进一步，如果你给一个小白介绍`jeecg-boot`框架应该如何学，你只需跟他说，按照以下路线学习就OK了：\n\n>  java-->html-->css-->javascript-->vue-->springboot-->ant-->jeecg\n\n上面这个序列可以看成是流程图按照某种遍历方式进行遍历得到的一个结果序列。这种遍历方式，咱取个名字，就称为`拓扑排序`；得到的线性序列，称为`拓扑序列`。\n\n从上述的过程来看，拓扑序列是不唯一的，比如：\n\n>  java-->html-->javascript-->css-->vue-->springboot-->ant-->jeecg\n\n>  java-->html-->javascript-->css-->springboot-->vue-->ant-->jeecg    \n\n均是正确的`拓扑序列`。 \n\n将上述的流程图抽象成一般的有向图，就引入了图中的拓扑排序以及拓扑序列的概念。\n\n# 拓扑图示示例\n\n下面我们来看，对于图，其进行拓扑排序的步骤：\n\n> 1. 从有向图中找出没有前驱节点的节点，直接输出（如果有多个，不考虑顺序，均输出）\n> 2. 删除以该节点为起点的所有边（如果节点不止一个，均删除）\n> 3. 重复上述过程，直至最后一个节点被输出。（如果还有节点未输出，说明有环！）\n\n我们还是用一系列图示来帮助理解拓扑排序的步骤：\n\n首先，找到没有前驱节点的节点`A`，`B`，将其输出至序列（或者使用优先队列存储起来），并删除以节点`A`，`B`为起点的所有边：\n\n![img](/images/assets/aeaddbbd57c6f9ebd093e19cf5881acb.png)\n ​​​​​​​接着，继续找没有前驱节点的节点`C`，`D`，`G`，将其输出至序列，并删除以节点`C`，`D`，`G`为起点的所有边：\n\n![img](/images/assets/00b18ec2c7a7b7896375746f2e82235d.png)\n\n重复以上操作。`E`，`F`无前驱节点，将其输出至序列，并删除以节点`E`，`F`为起点的所有边：\n\n![img](/images/assets/e9bc43f1b4fe070748191ab4338501f2.png)\n\n最后，节点`H`无前驱节点，将其输出至序列，节点`H`无边，遍历结束。\n\n好的关于图的拓扑排序，就介绍到这里了。有兴趣的小伙伴们可以去查询更多资料了解拓扑排序的应用。到这，关于图的三大算法，已经全部介绍完毕了。 \n\n下一章，我们开始用代码来实现图的三大算法。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----图（搜索算法）","url":"/2021/08/22/sgmtiui8/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n上一章我们了解了图的一些基本概念，\n\n本章我们来介绍图的两种最重要的搜索算法：`广度优先搜索算法和深度优先搜索算法`。\n\n#  广度优先搜索算法\n\n`广度优先搜索`（也叫宽度优先搜索，缩写`BFS`）是连通图的一种遍历算法，这一算法也是很多重要的图的算法的原型。下几章将要介绍的`Dijkstra单源最短路径算法`和`Prim最小生成树算法`都采用了和广度优先搜索类似的思想。这是一种盲目搜索法，它并不考虑结果的可能位置，而是彻底地搜索整张图，直到找到结果为止。一般用`队列结构`来辅助实现BFS算法。\n\n广度优先搜索的核心思想：`对于某个节点，BFS总是先遍历该节点的所有邻接节点`。\n\n下面我们用一系列图示来理解`BFS`的遍历过程： \n\n![img](/images/assets/75ed11d09a3768cdad4bacee2c93b412.png)    \n\n上图中，我们从`节点A`出发，进行`BFS`搜索，首先，遍历`A`节点（标灰)：\n\n![img](/images/assets/629133b79f339b40d5b7985e70fa9d2c.png)\n\n​    然后，遍历`A节点`的所有邻接节点----`B`和`D`： \n\n![img](/images/assets/195c056e2bfe88ca7c58bc692d494f1e.png)\n\n对于已遍历的`B`和`D`，遍历`B`的所有邻接节点`C`（注意，对于`B`的已访问的邻接节点`A`，`D`，不会再次进行访问），遍历`D`的所有邻接节点`E`（对于`D`的已访问的邻接节点`A`，`B`，不会再次进行访问）（此外先遍历`B`或`D`均可）：\n\n![img](/images/assets/26c2c8f70f19ce0182e4df74650eed1b.png)\n\n继续同上，遍历`C`，`E`的所有邻接节点 ，由于`C`的所有邻接节点均已访问，故节点`C`的遍历结束。`E`还有未被访问的邻接节点`F`，故遍历`F`：\n\n![img](/images/assets/6cf25155205e1b3eddb515bc657423a3.png)\n\n此时节点`F`的所有邻接节点均已被访问，故节点`F`的遍历结束。\n\n之后，全图搜索是否还有未被访问的节点，如何有，选取任意一个未被访问的节点，重复上述遍历，直至所有的节点均被访问，`BFS`结束。\n\n此时，该图的一种`BFS`搜索的结果序列为：`A-->B-->D-->C-->E-->F`。\n\n从上述的过程可以看出，BFS搜索的结果序列是不唯一的，读者可以想一想下面的序列是不是BFS搜索得到的？\n\n> - 1. A-->D-->B-->C-->E-->F\n> - 2. A-->B-->D-->C-->E-->F\n> - 3. A-->B-->D-->E-->F-->C\n>\n\n​    （答案在文末）\n\n# 深度优先搜索算法\n\n深度优先搜索（`DFS，Depth First Search`）是针对图的一种遍历算法。利用深度优先搜索算法可以产生对应图的`拓扑排序表`，利用其拓扑排序表可以方便地解决很多相关的图问题。一般用`栈结构`来辅助实现`DFS算法`。\n\n深度优先搜索的核心思想：对某一条路径，`DFS`会一直深入到不能深入为止，接着回溯至上一节点继续搜索。\n\n同样的，我们已一系列图示来理解`DFS`的搜索过程：\n\n用上面同样的图：\n\n![img](/images/assets/5c4b17667b32bd78599b401f9ace5f5f.png)\n\n随机取一个节点，比如节点`A`，访问它，将其标灰：\n\n![img](/images/assets/60c877b6ab19dfb7a432bca9eaffc57f.png)\n\n然后，从节点`A`开始，沿某一条路径一直深入（顺次访问路上的每个节点）直至不能深入为止，如`A-->B-->D-->E-->F`，注意遍历至`F`后不会再遍历`B`，同一节点只能访问一次：\n\n![img](/images/assets/a7d3889f62ed62648d9bfeabfae1026f.png)\n\n此时，`DFS`已搜索至节点`F`，由于节点F已经没有未被访问的分支来继续深入，这时，`DFS`搜索会“**回溯”**到节点`F`的上一个节点-----`E`，如果节点E还有未被访问的分支，继续访问并深入直至不能深入为止；如果节点`E`的分支均已被访问，则继续“**回溯”**到节点E的上一个分支，重复以上操作。这样，一直回溯到节点`B`的时候，发现节点`B`有一个未被访问的分支：`B-->C`，因此访问并深入这条路径：\n\n![img](/images/assets/90039e395f65652ebf9301d8754fe1b4.png)\n\n重复上述过程（深入+回溯），当回溯到起始路径（**`A-->B-->D-->E-->F`**）的起始节点`A`时，节点`A`没有未被访问的分支，从而这条路径搜索完毕。\n\n接着，全局搜索是否还有未被访问的节点，如果有，任意取一个未被访问的节点，继续上述过程，直至回溯到该节点......；如果没有，则全图搜索完毕。\n\n我们得到了`DFS`的搜索结果序列：`A-->B-->D-->E-->F-->C`。\n\n同`BFS`一样，`DFS`搜索的结果序列是不唯一的。请读者思考下面的序列是不是`DFS`的搜索结果？\n\n> - 4. A-->B-->D-->C-->E-->F\n> - 5. A-->D-->B-->C-->F-->E\n> - 6. A-->D-->E-->F-->B-->C\n>\n\n最后，请读者细细体会`BFS`和`DFS`的原理，尤其是`DFS`中关于回溯的过程，这是算法领域里一种非常重要的思想。这两种搜索方式不仅适用于图，也适用于树等具有关联特性的结构。掌握这两种搜索方式，是学习图中其他内容的基础。\n\n最后，附上文前答案：（BFS搜索结果：1，2；DFS搜索结果：3，5，6）\n\n下一章，我们将介绍图中另外一个重要的概念-----`拓扑排序`。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----图（基本概念）","url":"/2021/08/22/es1fnkdu/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 图的基本概念\n\n这一章，我们来看一种新的数据结构-----图。\n\n图是离散数学分支的内容，对图的描述，可以用一个`有序二元组(V,E)`表示，其中`V`称为顶集(`Vertices Set`)，`E`称为边集(`Edges set`)，`E`与`V`不相交。它们亦可写成`V(G)`和`E(G)`。其中，顶集的元素被称为顶点(`Vertex`)，边集的元素被称为边(`edge`)。图可记为 `G` 。\n\n关于图中涉及的许多概念，读者可以查询有关资料深入了解。\n\n在此只浅显列举部分：\n\n> 1. 阶（`Order`）：图`G`中点集`V`的大小称作`图G的阶`。\n>\n> 2. 子图（`Sub-Graph`）：当图`G'=(V',E')`其中`V‘`包含于`V，E’`包含于`E`，则`G'`称作图`G=(V,E)`的子图。每个图都是本身的子图。\n>\n> 3. 生成子图（`Spanning Sub-Graph`）：指满足条件`V(G') = V(G)`的`G`的子图`G'`。\n>\n> 4. 导出子图（`Induced Subgraph`）：以图`G`的顶点集`V`的`非空子集V1`为顶点集，以两端点均在`V1`中的全体边为边集的`G`的子图，称为`V1`导出的导出子图；以`图G`的`边集E`的`非空子集E1`为边集，以`E1`中边关联的顶点的全体为顶点集的`G`的子图，称为`E1`导出的导出子图。\n>\n> 5. 度（`Degree`）：一个顶点的度是指与该顶点相关联的边的条数，`顶点v`的度记作`d(v)`。\n>\n> 6. 入度（`In-degree`）和出度（`Out-degree`）：对于有向图来说，一个顶点的度可细分为入度和出度。一个顶点的入度是指与其关联的各边之中，以其为终点的边数；出度则是指以该顶点为起点的边数。\n>\n> 7. 自环（`Loop`）：若一条边的两个顶点为同一顶点，则此边称作自环。\n>\n> 8. 路径（`Path`）：从u到v的一条路径是指一个序列`v0,e1,v1,e2,v2,...ek,vk`，其中`ei`的顶点为`vi`及`vi - 1`，`k`称作路径的长度。如果它的起止顶点相同，该路径是“闭”的，反之，则称为“开”的。\n>\n> 9. 简单路径(`simple path`)：路径中除起始与终止顶点可以重合外，所有顶点两两不等。 \n>\n> 10. 连通：在无向图中，如果从顶点`vi`到顶点`vj`有路径，则称`vi`和`vj`连通。\n>\n> 11. 连通图：无向图中任意两个顶点之间都连通。\n>\n> 12. 连通分量：无向图的极大连通子图。\n>\n> 13. 强连通图：在有向图中，对于每一对顶点`vi`和`vj`，从`vi`到`vj`和从`vj`到`vi`都有路径。\n>\n> 14. 强连通分量：有向图的极大连通子图。\n\n图作为一种复杂的数据结构，研究图的搜索方式具有非常重要的意义，下一章，我们来探讨图的两种搜索方式。\n\n\n\n\n\n​               \n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----二叉树（二）","url":"/2021/08/20/fon3vuca/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 二叉树构建\n\n上一篇笔者介绍了二叉树的一些基本概念，本节主要介绍如何构建二叉树。\n\n二叉树的构建相比前面学的数据结构更为复杂，代码中提供了详尽的注释，请读者细细体会。\n\n二叉树中最重要的三种算法：\n\n-   先序遍历\n-   中序遍历\n-   后序遍历\n\n下面的BinNode.h描述了二叉树结点具有的基本结构：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：二叉树结点模版类\n *\n *\n */\n\n#ifndef STACK_BINNODE_H\n#define STACK_BINNODE_H\n\n#include <cstdlib>\n#include \"Queue.h\"\n#include \"Stack.h\"\n/******************************************************************************************\n* BinNode状态与性质的判断\n******************************************************************************************/\n#define IsRoot(x) ( ! ( (x).parent ) )\n#define IsLChild(x) ( ! IsRoot(x) && ( & (x) == (x).parent->lc ) )\n#define IsRChild(x) ( ! IsRoot(x) && ( & (x) == (x).parent->rc ) )\n#define HasParent(x) ( ! IsRoot(x) )\n#define HasLChild(x) ( (x).lc )\n#define HasRChild(x) ( (x).rc )\n#define HasChild(x) ( HasLChild(x) || HasRChild(x) ) //至少拥有一个孩子\n#define HasBothChild(x) ( HasLChild(x) && HasRChild(x) ) //同时拥有两个孩子\n#define IsLeaf(x) ( ! HasChild(x) )\n\n/******************************************************************************************\n* 与BinNode具有特定关系的节点及指针\n******************************************************************************************/\n#define sibling( p ) ( IsLChild( * (p) ) ? (p)->parent->rc : (p)->parent->lc ) /*兄弟*/\n#define uncle( x ) ( sibling( (x)->parent ) ) /*叔叔*/\n#define FromParentTo( x ) /*来自父亲的引用*/ ( IsRoot(x) ? _root : ( IsLChild(x) ? (x).parent->lc : (x).parent->rc ) )\n#define stature(p) ((p) ? (p)->height : -1) //其余BST中节点的高度（NUll视作空树，对应于-1）\n\ntemplate <typename T> struct BinNode { //二叉树节点模板类\n// 成员\n    T data; //数值\n    BinNode<T>* parent;\n    BinNode<T>* lc;\n    BinNode<T>* rc; //父节点及左、右孩子\n    int height; //高度（通用）\n// 构造函数\n    BinNode() :\n            parent (nullptr) , lc (nullptr) , rc ( nullptr ), height ( 0 ) { }\n    BinNode ( T e, BinNode<T>* p = nullptr, BinNode<T>* lc = nullptr, BinNode<T>* rc = nullptr,\n              int h = 0, int l = 1) :\n            data ( e ), parent ( p ), lc ( lc ), rc ( rc ), height ( h ){ }\n// 操作接口\n    BinNode<T>* succ(); //取当前结点的直接后继\n    BinNode<T>* insertAsLC ( T const & ); //作为当前节点的左孩子插入新节点\n    BinNode<T>* insertAsRC ( T const & ); //作为当前节点的右孩子插入新节点\n    void travLevel ( void (* visit)(T&) ); //子树层次遍历\n    void travPre ( void (* visit)(T&) ); //子树先序遍历\n    void travIn ( void (* visit)(T&) ); //子树中序遍历\n    void travPost ( void (* visit)(T&) ); //子树后序遍历\n};\n\n\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.21\n * 内容：二叉树结点模版类接口的实现\n *\n *\n */\n\ntemplate <typename T> BinNode<T>* BinNode<T>::insertAsLC ( T const& e )\n{ return lc = new BinNode ( e, this ); } //将e作为当前节点的左孩子插入二叉树\n\ntemplate <typename T> BinNode<T>* BinNode<T>::insertAsRC ( T const& e )\n{ return rc = new BinNode ( e, this ); } //将e作为当前节点的右孩子插入二叉树\n\ntemplate <typename T> BinNode<T>* BinNode<T>::succ() { //定位节点v的直接后继\n    BinNode<T> *s = this; //记录后继的临时变量\n    if (rc) { //若有右孩子，则直接后继必在右子树中，具体地就是\n        s = rc; //右子树中\n        while (HasLChild (*s)) s = s->lc; //最靠左（最小）的节点\n    } else { //否则，直接后继应是“将当前节点包含于其左子树中的最低祖先”，具体地就是\n        while (IsRChild (*s)) s = s->parent; //逆向地沿右向分支，不断朝左上方移动\n        s = s->parent; //最后再朝右上方移动一步，即抵达直接后继（如果存在）\n    }\n    return s;\n}\n/*\n *\n * 先序遍历\n *\n */\n\n//递归版\ntemplate <typename T>\nvoid travPre_R(BinNode<T>* x,void (* visit)(T&)){ //递归版\n    if(!x){ return;}\n    visit(x->data);\n    travPost_R(x->lc,visit);\n    travPost_R(x->rc,visit);\n\n}\n//迭代版1\ntemplate <typename T>\nvoid travPre_I1(BinNode<T>* x,void (* visit)(T&)){\n    Stack<BinNode<T>*> S;\n    if(x){S.push(x); };\n    while(!S.Empty()){\n        x = S.pop();\n        visit(x->data);\n        if(HasRChild(*x)) S.push(x->rc);\n        if(HasLChild(*x)) S.push(x->lc);\n    }\n}\n\n//迭代版2\n//从当前节点出发，沿左分支不断深入，直至没有左分支的节点；沿途节点遇到后立即访问\ntemplate <typename T>\nstatic void visitAlongVine ( BinNode<T>* x, void (* visit)(T&), Stack<BinNode<T>*>& S ) {\n    while ( x ) {\n       visit ( x->data ); //访问当前节点\n       S.push ( x->rc ); //右孩子入栈暂存（可优化：通过判断，避免空的右孩子入栈）\n       x = x->lc;  //沿左分支深入一层\n    }\n}\ntemplate <typename T>\nvoid travPre_I2 ( BinNode<T>* x, void (* visit)(T&) ) {\n    Stack<BinNode<T>*> S; //辅助栈\n    while ( true ) {\n       visitAlongVine ( x, visit, S ); //从当前节点出发，逐批访问\n       if ( S.Empty() ) break; //直到栈空\n       x = S.pop(); //弹出下一批的起点\n    }\n}\n\ntemplate <typename T>\nvoid BinNode<T>::travPre ( void (* visit)(T&) ) { //二叉树先序遍历算法统一入口\n    switch ( rand() % 3 ) { //此处暂随机选择以做测试，共三种选择\n        case 0: travPre_I1 ( this, visit ); break; //迭代版1\n        case 1: travPre_I2 ( this, visit ); break; //迭代版2\n        default: travPre_R ( this, visit ); break; //递归版\n    }\n}\n\n/*\n *\n * 中序遍历\n *\n */\n\n//递归版\ntemplate <typename T> //元素类型、操作器\nvoid travIn_R(BinNode<T>* x,void (* visit)(T&)){\n    if(!x){ return;}\n    travPost_R(x->lc,visit);\n    visit(x->data);\n    travPost_R(x->rc,visit);\n\n}\n\n//迭代版1\ntemplate <typename T> //从当前节点出发，沿左分支不断深入，直至没有左分支的节点\nstatic void goAlongVine ( BinNode<T>* x, Stack<BinNode<T>*>& S ) {\n    while ( x ) { S.push ( x ); x = x->lc; } //当前节点入栈后随即向左侧分支深入，迭代直到无左孩子\n}\ntemplate <typename T>\nvoid travIn_I1 ( BinNode<T>* x, void (* visit)(T&) ) {\n    Stack<BinNode<T>*> S; //辅助栈\n    while ( true ) {\n       goAlongVine ( x, S ); //从当前节点出发，逐批入栈\n       if ( S.Empty() ) break; //直至所有节点处理完毕\n       x = S.pop(); visit ( x->data ); //弹出栈顶节点并访问之\n       x = x->rc; //转向右子树\n    }\n}\n\n//迭代版2\ntemplate <typename T>\nvoid travIn_I2 ( BinNode<T>* x, void (* visit)(T&) ) {\n    Stack<BinNode<T>*> S; //辅助栈\n    while ( true )\n       if ( x ) {\n          S.push ( x ); //根节点进栈\n          x = x->lc; //深入遍历左子树\n       } else if ( !S.Empty() ) {\n          x = S.pop(); //尚未访问的最低祖先节点退栈\n          visit ( x->data ); //访问该祖先节点\n          x = x->rc; //遍历祖先的右子树\n       } else\n          break; //遍历完成\n}\n\n//迭代版3\ntemplate <typename T>\nvoid travIn_I3 ( BinNode<T>* x, void (* visit)(T&) ) {\n    bool backtrack = false; //前一步是否刚从左子树回溯——省去栈，仅O(1)辅助空间\n    while ( true )\n       if ( !backtrack && HasLChild ( *x ) ) //若有左子树且不是刚刚回溯，则\n          x = x->lc; //深入遍历左子树\n       else { //否则——无左子树或刚刚回溯（相当于无左子树）\n          visit ( x->data ); //访问该节点\n          if ( HasRChild ( *x ) ) { //若其右子树非空，则\n             x = x->rc; //深入右子树继续遍历\n             backtrack = false; //并关闭回溯标志\n          } else { //若右子树空，则\n             if ( ! ( x = x->succ() ) ) break; //回溯（含抵达末节点时的退出返回）\n             backtrack = true; //并设置回溯标志\n          }\n       }\n}\n\n//二叉树中序遍历算法统一入口\ntemplate <typename T>\nvoid BinNode<T>::travIn ( void (* visit)(T&) ) {\n    switch ( rand() % 4 ) { //此处暂随机选择以做测试，共四种选择\n       case 0: travIn_I1 ( this, visit ); break; //迭代版1\n       case 1: travIn_I2 ( this, visit ); break; //迭代版2\n       case 2: travIn_I3 ( this, visit ); break; //迭代版3\n       default: travIn_R ( this, visit ); break; //递归版\n    }\n }\n\n/*\n*\n* 后序遍历\n*\n*/\n\n//递归版\ntemplate <typename T> //元素类型、操作器\nvoid travPost_R(BinNode<T>* x,void (* visit)(T&)){\n    if(!x){ return;}\n    travPost_R(x->lc,visit);\n    travPost_R(x->rc,visit);\n    visit(x->data);\n}\n\n//迭代版\ntemplate <typename T> //在以S栈顶节点为根的子树中，找到最高左侧可见叶节点\nstatic void gotoLeftmostLeaf ( Stack<BinNode<T>*>& S ) { //沿途所遇节点依次入栈\n    while ( BinNode<T>* x = S.top() ) //自顶而下，反复检查当前节点（即栈顶）\n       if ( HasLChild ( *x ) ) { //尽可能向左\n          if ( HasRChild ( *x ) ) S.push ( x->rc ); //若有右孩子，优先入栈\n          S.push ( x->lc ); //然后才转至左孩子\n       } else //实不得已\n          S.push ( x->rc ); //才向右\n    S.pop(); //返回之前，弹出栈顶的空节点\n}\n\ntemplate <typename T>\nvoid travPost_I ( BinNode<T>* x, void (* visit)(T&) ) { //二叉树的后序遍历（迭代版）\n    Stack<BinNode<T>*> S; //辅助栈\n    if ( x ) S.push ( x ); //根节点入栈\n    while ( !S.Empty() ) { //x始终为当前节点\n       if ( S.top() != x->parent ) ////若栈顶非x之父（而为右兄）\n          gotoLeftmostLeaf ( S ); //则在其右兄子树中找到HLVFL（相当于递归深入）\n       x = S.pop(); visit ( x->data ); //弹出栈顶（即前一节点之后继），并访问之\n    }\n}\n\n\ntemplate <typename T>\nvoid BinNode<T>::travPost ( void (* visit)(T&) ) { //二叉树中序遍历算法统一入口\n    switch ( rand() % 2 ) { //此处暂随机选择以做测试\n        case 0: travPost_I ( this, visit ); break; //迭代版\n        default: travPost_R ( this, visit ); break; //递归版\n    }\n}\n\n/*\n *\n * 层次遍历\n *\n */\n\ntemplate<typename T>\nvoid BinNode<T>::travLevel(void (* visit)(T&)) { //二叉树层次遍历算法\n    Queue<BinNode<T>*> Q;  //辅助队列\n    Q.enqueue(this); //根结点入队\n    while (!Q.empty()){\n        BinNode<T>* x = Q.dequeue();\n        visit(x->data);\n        if(HasLChild(*x)) Q.enqueue(x->lc);\n        if(HasRChild(*x)) Q.enqueue(x->rc);\n    }\n}\n\n#endif //STACK_BINNODE_H\n```\n\n在该算法中，对于先序遍历，中序遍历，后序遍历，笔者提供了多种实现（迭代+递归），请读者细细体会不同算法间有何相同，相异之处，效率是否相同。\n\n此外，算法中还包含了前面学过的`Stack.h`，`Queue.h`等头文件，具体可参考本tag的其他文章。\n\n接着，来构建二叉树结点之间的逻辑关系：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.21\n * 内容：二叉树模版类\n *\n *\n */\n\n#ifndef STACK_BINTREE_H\n#define STACK_BINTREE_H\n#include \"BinNode.h\"\n\ntemplate <typename T> class BinTree {\n    protected:\n        int _size_; BinNode<T>* _root; //规模、根节点\n        virtual int updateHeight ( BinNode<T>* x ); //更新节点x的高度\n        void updateHeightAbove ( BinNode<T>* x ); //更新节点x及其祖先的高度\n    public:\n        BinTree() : _size_ ( 0 ), _root ( NULL ) { } //构造函数\n        ~BinTree() { if ( 0 < _size_ ) remove ( _root ); } //析构函数\n        int size() const { return _size_; } //规模\n        bool empty() const { return !_root; } //判空\n        BinNode<T>* root() const { return _root; } //树根\n        BinNode<T>* insert ( T const & ); //插入根节点\n        BinNode<T>* insert ( T const &, BinNode<T>* ); //插入左孩子\n        BinNode<T>* insert ( BinNode<T>*, T const & ); //插入右孩子\n        int remove ( BinNode<T>* ); //子树删除\n        BinTree<T>* secede ( BinNode<T>* ); //子树分离\n        void travLevel ( void (* visit)(T&) ) { if ( _root ) _root->travLevel ( visit ); } //层次遍历\n        void travPre ( void (* visit)(T&) ) { if ( _root ) _root->travPre ( visit ); } //先序遍历\n        void travIn ( void (* visit)(T&) ) { if ( _root ) _root->travIn ( visit ); } //中序遍历\n        void travPost ( void (* visit)(T&) ) { if ( _root ) _root->travPost ( visit ); } //后序遍历\n        bool operator< ( BinTree<T> const& t ) //比较器\n        { return _root && t._root && lt ( _root, t._root ); }\n        bool operator== ( BinTree<T> const& t ) //判等器\n        { return _root && t._root && ( _root == t._root ); }\n }; //BinTree\n\n/*\n*\n* 作者：易果啥笔\n* 时间：2021.8.21\n* 内容：二叉树模版类接口的实现\n*\n*\n*/\n\ntemplate <typename T> int BinTree<T>::updateHeight ( BinNode<T>* x ) //更新节点x高度\n { return x->height = 1 + max ( stature ( x->lc ), stature ( x->rc ) ); } //具体规则，因树而异\n\ntemplate <typename T> void BinTree<T>::updateHeightAbove ( BinNode<T>* x ) //更新高度\n { while ( x ) { updateHeight ( x ); x = x->parent; } } //从x出发，覆盖历代祖先。可优化\n\ntemplate <typename T> BinNode<T>* BinTree<T>::insert ( T const& e )\n { _size_ = 1; return _root = new BinNode<T> ( e ); } //将e当作根节点插入空的二叉树\n\ntemplate <typename T> BinNode<T>* BinTree<T>::insert ( T const& e, BinNode<T>* x )\n { _size_++; x->insertAsLC ( e ); updateHeightAbove ( x ); return x->lc; } //e插入为x的左孩子\n\ntemplate <typename T> BinNode<T>* BinTree<T>::insert ( BinNode<T>* x, T const& e )\n { _size_++; x->insertAsRC ( e ); updateHeightAbove ( x ); return x->rc; } //e插入为x的右孩子\n\ntemplate <typename T> //删除二叉树中位置x处的节点及其后代，返回被删除节点的数值\nint BinTree<T>::remove ( BinNode<T>* x ) { //assert: x为二叉树中的合法位置\n    FromParentTo ( *x ) = NULL; //切断来自父节点的指针\n    updateHeightAbove ( x->parent ); //更新祖先高度\n    int n = removeAt ( x ); _size_ -= n; return n; //删除子树x，更新规模，返回删除节点总数\n}\n\ntemplate <typename T> //删除二叉树中位置x处的节点及其后代，返回被删除节点的数值\nstatic int removeAt ( BinNode<T>* x ) { //assert: x为二叉树中的合法位置\n    if ( !x ) return 0; //递归基：空树\n    int n = 1 + removeAt ( x->lc ) + removeAt ( x->rc ); //递归释放左、右子树\n    free ( x ); return n; //释放被摘除节点，并返回删除节点总数\n }\n\ntemplate <typename T> //二叉树子树分离算法：将子树x从当前树中摘除，将其封装为一棵独立子树返回\nBinTree<T>* BinTree<T>::secede ( BinNode<T>* x ) { //assert: x为二叉树中的合法位置\n    FromParentTo ( *x ) = NULL; //切断来自父节点的指针\n    updateHeightAbove ( x->parent ); //更新原树中所有祖先的高度\n    BinTree<T>* S = new BinTree<T>; S->_root = x; x->parent = NULL; //新树以x为根\n    S->_size_ = size(); _size_ -= S->_size_; return S; //更新规模，返回分离出来的子树\n}\n\n#endif //STACK_BINTREE_H\n```\n\n这样，二叉树便构建完毕。我们用一个`main.cpp`来测试一下：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.21\n * 内容：二叉树模版类的使用\n *\n *\n */\n\n#include <iostream>\n#include \"BinTree.h\"\n\n\ntemplate<typename T> void print(T a){\n    std::cout<<a<<\"  \";\n}\n\nint main(){\n    //构建二叉树\n    BinTree<int> binTree;\n\n    //添加数据\n    binTree.insert(1);\n    binTree.insert(binTree.root(),3);\n    binTree.insert(2,binTree.root());\n    binTree.insert(4,binTree.root()->succ());\n    binTree.insert(binTree.root()->succ(),5);\n    binTree.insert(6,binTree.root()->succ()->succ());\n    binTree.insert(binTree.root()->succ()->succ(),7);\n\n    //remove()删除指定结点及其子树\n    binTree.remove(binTree.root()->succ()->succ());\n    //四种遍历方式\n    cout<<\"层次遍历：\";\n    binTree.travLevel(print);\n    cout<<endl;\n    cout<<\"先序遍历：\";\n    binTree.travPre(print);\n    cout<<endl;\n    cout<<\"中序遍历：\";\n    binTree.travIn(print);\n    cout<<endl;\n    cout<<\"后序遍历：\";\n    binTree.travPost(print);\n    cout<<endl;\n    //size()返回二叉树结点总数\n    cout<<\"该二叉树共有\"<<binTree.size()<<\"个结点.\"<<endl;\n    //secede()分离子树\n    BinTree<int>* S = binTree.secede(binTree.root()->succ());\n    S->travLevel(print);\n\n    return 0;\n}   \n```\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----二叉树（一）","url":"/2021/08/20/qqkjp9oi/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 二叉树基本概念\n\n上一章，我们介绍了队列结构。从本章开始，我们会陆续接触到一些非线性数据结构，由前面的学习我们知道，对一个数据系统而言，如果查找操作比较频繁的话，一般采用顺序结构存储；如果删除，插入操作比较频繁的话，一般采用链式结构存储；\n\n那我们想一想，有没有这样一种数据结构，其`兼有顺序结构和链式结构的优点`？\n\n有！树形结构！。\n\n树形结构中最基础，最重要的，非二叉树莫属。本节主要介绍二叉树中的一些基本概念：    \n\n> 1. 定义：\n>         二叉树是`每个结点最多有两个子树`的树结构。\n>\n> 2. 概念：\n>         `节点的度`：一个节点含有的子树的个数称为该节点的度；\n>        ` 叶节点`：度为0的节点称为叶节点；\n>         `双亲节点或父节点`：若一个节点含有子节点，则这个节点称为其子节点的父节点；\n>         `孩子节点或子节点`：一个节点含有的子树的根节点称为该节点的子节点；\n>         `兄弟节点`：具有相同父节点的节点互称为兄弟节点；\n>         `树的度`：一棵树中，最大的节点的度称为树的度；\n>         `节点的层次`：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；\n>         `树的高度`：树中节点的最大层次；\n>         `兄弟节点`：双亲在同一层的节点互为兄弟节点；\n>         `节点的祖先`：从根到该节点所经分支上的所有节点；\n>         `子孙`：以某节点为根的子树中任一节点都称为该节点的子孙。\n>         `森林`：由m棵互不相交的树的集合称为森林；\n>  3. 基本性质：\n>          性质1：二叉树第i层上的结点数目最多为`2^i-1(i>=1)`;\n>          性质2：深度为k的二叉树至多有`2k-1个结点(k>=1)`;\n>          性质3：包含n个结点的二叉树的高度至少为`[log2n]+1`; (向下取整)\n>          性质4：在任意一棵二叉树中，若叶结点的个数为`n1`，度为`2`的结点数为`n2`，则`n1=n2+1`;\n>  4. 特殊二叉树：\n>          -- `满二叉树`\n>             定义：高度为h，并且由2^h-1个结点组成的二叉树，称为满二叉树\n>          -- `完全二叉树`\n>             定义：一棵二叉树中，只有最下面两层结点的度可以小于`2`，\n>                   并且最下层的叶结点集中在靠左的若干位置上，这样的二叉树称为`完全二叉树`。\n>             特点：叶子结点只能出现在`最下层和次下层`，且最下层的叶子结点集中在`树的左部`。\n>          显然，`满二叉树必定是完全二叉树，而完全二叉树未必是满二叉树`。\n>  5. 二叉树的三种遍历：\n>          -- 前序遍历：`根节点->左子树->右子树`。\n>                     在遍历左右子树时，仍然先访问根节点，再遍历左子树，最后遍历右子树。\n>          -- 中序遍历：`左子树->根节点->右子树`。\n>                     在遍历左右子树时，仍然先遍历左子树，再遍历根节点，最后遍历右子树。\n>          -- 后序遍历：`左子树->右子树->根节点`。\n>                     在遍历左右子树时，仍然先遍历左子树，再遍历右子树，最后访问根节点。\n\n下一章将介绍二叉树的构建过程。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----队列（Queue）","url":"/2021/08/20/lxkb7wbo/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 队列（Queue）\n\n上几章，我们介绍了栈的几个应用。本章来学习另外一种数据结构-----队列。队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（队首）进行删除操作，在表的后端（队尾）进行插入操作。\n\n和栈一样，队列也是一种操作受限的`线性表`。特点：`先进先出（FIFO）`。\n\n# 队列构建\n\n下面我们来看队列的构建，继承自`List.h`，List.h参考同tag下的链表那篇文章，读者可以思考这样一个问题：为什么栈的父类使用的是`Vector.h`，而队列的父类使用的是`List.h` ？\n\n`Queue.h`：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：队列模版类\n *\n *\n */\n\n#ifndef STACK_QUEUE_H\n#define STACK_QUEUE_H\n#include \"List.h\"\n#include \"ListNode.h\"\n\ntemplate <typename T> class Queue : public List<T> {\n    public:\n        void enqueue(T const& e){\n            this->insertAsLast(e);\n        }\n        T dequeue(){\n            return this->remove(this->first());\n        }\n        T& front(){\n            return this->first()->data;\n        }\n};\n\n#endif //STACK_QUEUE_H\n```\n\n 队列的`main.cpp`文件：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：队列模版类\n *\n *\n */\n\n#include <iostream>\n#include \"Queue.h\"\n\n//遍历函数print\ntemplate <typename T> void print(T& e){ std::cout<<e; };\n\nint main(){\n    Queue<int> queue;\n    //入队\n    queue.enqueue(1);\n    queue.enqueue(2);\n    queue.enqueue(3);\n    queue.enqueue(4);\n    queue.enqueue(5);\n    //遍历\n    queue.traverse(print);\n    std::cout<<std::endl;\n    //出队\n    queue.dequeue();\n    //遍历\n    queue.traverse(print);\n    std::cout<<std::endl;\n    //打印队首元素\n    std::cout<<queue.front()<<std::endl;\n\n    return 0;\n\n}\n```\n\n简单来说，由于队列主要对表的`首尾元素`进行操作，如果继承`List.h`，只需常数级时间复杂度即可实现，相比较继承`Vector.h`而言，复杂度更低，效率更高。\n\n而对于栈，继承`List.h`还是`Vector.h`，复杂度基本相同，读者可以尝试用`List.h`作为栈的父类来构建一个栈。\n\n此外，队列也有很多方面的应用，比如`队列快速排序，消息队列`等，这些应用涉及的知识比较广，在此就不展开解释了，有兴趣的小伙伴们可以查阅有关资料。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----栈的应用（三）","url":"/2021/08/20/77dg3314/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 栈的应用（三）\n\n本章为栈的第三个应用：\n\n> 问题描述：如何计算一个字符串表达式的值？\n>\n\n咱也可以从另一个角度来认识这个问题： ---`如何制作一个简易的计算器？`，实际上，要想实现一个计算器的功能，是一个非常复杂的问题，\n\n下面我们将问题简化一下，假设此表达式中，运算符只有：`“+”，“-”，“*”，“/”，阶乘，方幂`，这六种再加上括号，于是，我们有以下的栈结构实现（`EvaluAlgor.h`）：\n\n本质来说，该算法并不算完善，读者可以思考一下，该算法中存在什么问题？\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的典型应用三：求一个字符串表达式的数值\n *\n */\n\n#ifndef STACK_EVALUALGOR_H\n#define STACK_EVALUALGOR_H\n#define N_OPTR 9 //运算符总数\n#include \"Stack.h\"\n#include <cmath>\n#include \"ParenMatch.h\"\n\ntypedef enum {ADD,SUB,MUL,DIV,POW,FAC,L_P,R_P,EOE} Operator;\n\n//将运算符与上述枚举对应\nOperator optrRank(char optr){\n    switch (optr) {\n        case '+' : return ADD;\n        case '-' : return SUB;\n        case '*' : return MUL;\n        case '/' : return DIV;\n        case '^' : return POW;\n        case '!' : return FAC;\n        case '(' : return L_P;\n        case ')' : return R_P;\n        case '\\0' : return EOE;\n        default: exit(-1);\n\n    }\n}\n\n\n//pri[]数组用于描述不同运算符之间的优先级关系\nconst char pri[N_OPTR][N_OPTR] = {\n        '>','>','<','<','<','<','<','>','>',\n        '>','>','<','<','<','<','<','>','>',\n        '>','>','>','>','<','<','<','>','>',\n        '>','>','>','>','<','<','<','>','>',\n        '>','>','>','>','>','<','<','>','>',\n        '>','>','>','>','>','>',' ','>','>',\n        '<','<','<','<','<','<','<','=',' ',\n        ' ',' ',' ',' ',' ',' ',' ',' ',' ',\n        '<','<','<','<','<','<','<',' ','=',\n};\n\n//readNumber()用于获取从某数字字符开始的完整一个数\n\nvoid readNumber(char*& S,Stack<float>& p){\n    p.push((float)(*S-'0'));\n    while(isdigit(*(++S)))\n        p.push(p.pop()*10+(*S-'0')); //整数部分，注意到 '123' - '0' = 123\n    if('.' != *S) return;\n    float xiaoshu = 1;\n    while(isdigit(*(++S)))\n        p.push(p.pop()+(*S-'0')*(xiaoshu/=10)); //小数部分\n}\n\n//orderBetween()用于判定操作符之间的优先级关系\nchar orderBetween(char optr1,char optr2){\n    return pri[optrRank(optr1)][optrRank(optr2)]; //直接比较\n}\n\n\n//calcu()函数用于求一个(阶乘)或两个数的运算\n\n//先求阶乘\nint factorial(int n){\n    if(n<0)\n        exit(-1);\n    else if(n == 1) return 1;\n    else return n*factorial(n-1); //递归实现\n}\n\nint calcu(char optr,int pOpnd){return factorial(pOpnd); }\n\n//重载calcu()方法使之适用于两个数之间的运算\n\n\nfloat calcu(float pOpnd1,char optr,float pOpnd2) {\n    if (optr == '/' && pOpnd2 == 0) exit(-1); //除数不能为零\n    switch (optr) {\n        case '+' :\n            return pOpnd1 + pOpnd2;\n            break;\n        case '-' :\n            return pOpnd1 - pOpnd2;\n            break;\n        case '*' :\n            return pOpnd1 * pOpnd2;\n            break;\n        case '/' :\n            return pOpnd1 / pOpnd2;\n            break;\n        case '^' :\n            return pow(pOpnd1, pOpnd2); //借用cmath库中的求幂函数pow()\n        default:\n            exit(-1);\n    }\n}\n\n\n//evaluate()为求值核心算法\n    float evaluate(char *S) {\n        if( ! paren(S,0,length(S)) ) exit(-1); //不匹配时\n        else{\n            Stack<float> opnd;\n            Stack<char> optr; //运算符栈，操作符栈\n            optr.push('\\0');\n            while (!optr.Empty()) {\n                if (isdigit(*S)) {\n                    readNumber(S, opnd);\n                } else\n                    switch (orderBetween(optr.top(), *S)) {\n                        case '<':\n                            optr.push(*S);\n                            S++;\n                            break;\n                        case '=':\n                            optr.pop();\n                            S++;\n                            break;\n                        case '>':\n                            char op = optr.pop();\n                            if ('!' == op) {\n                                float pOpnd = opnd.pop();\n                                if ((int) pOpnd == pOpnd) {\n                                    opnd.push(calcu(op, (int) pOpnd));\n                                } else exit(-1); //小数没有阶乘\n\n                            } else {\n                                float pOpnd2 = opnd.pop(), pOpnd1 = opnd.pop();\n                                opnd.push(calcu(pOpnd1, op, pOpnd2));\n                            }\n                            break;\n                    }\n            }\n            return opnd.pop();\n        }\n    }\n\n#endif //STACK_EVALUALGOR_H\n```\n\n在`evaluate()`数值求解算法中，先使用了`Paren()`方法验证括号是否匹配（参考栈的应用二）。请读者细细体会栈在这种算法中所起的作用。\n\n在`main.cpp`文件中我们可以验证它的正确性：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的应用\n *\n */\n\n#include <iostream>\n#include \"Stack.h\"\n#include \"ParenMatch.h\"\n#include \"EvaluAlgor.h\"\n\nusing namespace std;\n\n//遍历函数print\ntemplate <typename T> void print(T& e){ cout<<e; };\n\nint main() {\n    \n    //应用三：求一个字符串表达式的值\n    char expression2[40] = \"10^3+23/2-(56*7)+5!\";\n    cout<<\"10^3+23/2-(56*7)+5!表达式的值为：\"<<evaluate(expression2)<<\"  \"<<(10*10*10+23/2.0-(56*7)+5*4*3*2*1)<<endl;\n\n    return 0;\n}\n```\n\n仔细思考，你可以发现，这个算法是`不支持负数参与计算`的，这也是我前文所说的问题所在。读者可以思考一下，如何修改代码，使之支持负数参与运算。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----栈的应用（二）","url":"/2021/08/20/owcwnqac/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 栈的应用（二）\n\n本章我们来看看栈的第二个应用：\n\n> 问提描述：如何判断一个表达式中的 (), [], {} 是否匹配？\n>\n\n比如，表达式“ `3*(8+3*2)` ”是匹配的，表达式“` (3*4+33` ”是不匹配的。 \n\n问题解决（`ParenMatch.h`）：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的典型应用二：判断括号(),[],{}是否匹配\n *\n */\n\n#ifndef STACK_PARENMATCH_H\n#define STACK_PARENMATCH_H\n#include \"Stack.h\"\n\n//length()函数用于求数组中表达式的字符数\nint length(const char exp[]){\n    static int count = 0;\n    for(int i = 0 ; exp[i]!='\\0'; i++){\n        count++;\n    }\n    return count;\n}\n\n\n//trans()函数将bool值转换为人性化语言\nvoid trans(bool _bool) {\n    if(_bool)cout<<\"匹配\"<<endl;\n    else cout<<\"不匹配\"<<endl;\n}\n\n\n//paren()函数用于判断表达式中括号是否匹配\nbool paren(const char exp[],int lo,int hi) {\n    Stack<char> S;\n    for(int i = lo ; i < hi ; i++){\n        switch (exp[i]) {\n            case '(' :\n            case '[' :\n            case '{' : S.push(exp[i]); break;\n            case ')' :if( ( S.Empty() ) || ( '(' != S.pop() )) return false; break;\n            case ']' :if( ( S.Empty() ) || ( '[' != S.pop() )) return false; break;\n            case '}' :if( ( S.Empty() ) || ( '{' != S.pop() )) return false; break;\n            default: break;\n        }\n    }\n\n    return S.Empty();\n}\n\n#endif //STACK_PARENMATCH_H\n```\n\n匹配算法的核心思想是，一旦遇到左括号` (, [, {, `便将其压入栈中；如果遇到右括号` ), ], }, `便验证此时它前面的括号（也就是`栈顶元素`）是否与之匹配，如果不匹配，直接返回`false`；如果匹配，继续往下扫描，直至栈为空。\n\n我们来验证此算法的正确性：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的应用\n *\n */\n\n#include <iostream>\n#include \"Stack.h\"\n#include \"ParenMatch.h\"\nusing namespace std;\n\n//遍历函数print\ntemplate <typename T> void print(T& e){ cout<<e; };\n\nint main() {\n    \n\n    //应用二：判断一个表达式中括号(),[],{}是否匹配\n    char expression1[40] = \"(1+23*4-56*7))\";\n    cout<<\"'(1+23*4-56*7))'中的括号是否匹配？：\";trans(paren(expression1,0,length(expression1)));\n\n    return 0;\n}\n```\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----栈的应用（一）","url":"/2021/08/20/bgn2eg0h/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 栈的应用（一）\n\n上一章我们简单的介绍了栈这种数据结构，下面，我们来看看它的第一个应用：\n\n> 问题：如何将一个十进制数转化为n进制数？\n>\n\n代码实现较为容易：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的应用一： 任给一个十进制数n，将其转换为某进制的表示形式\n *\n */\n\n#ifndef STACK_BASECONVERSION_H\n#define STACK_BASECONVERSION_H\n#include \"Stack.h\"\n\n//递归实现\n\n//    void convert(Stack<char>& S,__int64_t n,int base){\n//        static char digit[]\n//            ={'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};\n//        if(n<0){\n//            convert(S,n/base,base);\n//            S.push(digit[n/base]); //输出低位\n//        }\n//    }\n\n\n//迭代实现\nvoid convert(Stack<char>& S,int n,int base){\n    static char digit[]\n            ={'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};\n    while(n>0){\n        int remainder = (int) (n%base);\n        S.push(digit[remainder]);\n        n /= base;\n    }\n}\n\n//新进制下，出栈的元素与真实结果的方向相反，故Stack.h的父类Vector类里需修改traverse的输出方向\n\n#endif //STACK_BASECONVERSION_H\n```\n\n笔者提供了两种实现方式，递归和迭代，两种方式各有优点：\n\n- 递归能使代码变得更简洁，但内存开销相对较大；\n\n- 迭代代码虽相对复杂，但内存开销相对较小。\n\n此应用相对比较容易实现，无需过多的解释。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----栈（Stack）","url":"/2021/08/20/jmfv0vdh/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 栈的基本特点\n\n上一篇我们介绍了链表，本章我们接着来看另外一种数据结构-----栈。\n\n栈是一种非常重要的数据结构，在许多系统级的架构中，大量使用了栈。\n\n栈的核心：`后进先出（LIFO）`，简单说来，就是对于栈，我们`只能操作栈顶元素（出栈，压栈等）`，我们可以从两个例子里理解栈的特点：\n\n> 1. 网页的回退操作\n>\n> 当浏览一个网页想回退时，你会发现回退的永远是上一次浏览的页面，而不是最开始打开的页面，这里面就用到了“后进先出”的思想。浏览器的底层实现中，把用户浏览的网页用“栈”这种数据结构缓存起来，一旦用户想要返回上一页（此处的“上一页”便是该栈的“栈顶元素”），直接调用栈顶元素即可。请读者仔细体会一下。\n>\n> 2. 粘贴操作\n>\n> 同1一样的思想，系统在底层实现中，将待粘贴的内容用“栈”存储起来，这样能使得用户粘贴的内容，永远是最近一次复制的内容。\n\n# 栈的结构实现\n\n了解了栈的基本特点之后，我们来看看栈这种数据结构的代码实现。\n\n学了前面的向量之后，构建一个栈非常容易。在这，笔者着重介绍栈的几个应用。\n\n在应用之前，我们先来简单地构建一个栈：\n\n下面的`Stack.h`继承了`Vector类`，`Vector类`来自于同tag下的`Vector文章`：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.20\n * 内容：栈的头文件\n *\n */\n\n#ifndef STACK_STACK_H\n#define STACK_STACK_H\n#include \"Vector.h\"\ntemplate <typename T> class Stack: public Vector<T> {\n    public:\n        void push(T const& e){this->insert(this->size(),e);}//入栈\n        T pop(){return this->remove(this->size()-1);}//删除栈顶元素，出栈\n        T& top(){return (*this)[(this->size()-1)];} //取出栈顶元素\n};\n#endif //STACK_STACK_H\n```\n\n需要注意的是，\n\n根据栈的特点，我们需要对`Vector.h`中的`traverse方法`修改一下，修改如下：\n\n```cpp\ntemplate <typename T> \nvoid Vector<T>::traverse(void (*visit)(T &)) {\n    for(int i = _size-1 ; i >= 0 ; i--) visit(_elem[i]) ; //利用函数指针机制的遍历\n}\n```\n\n后面，我们会着重介绍栈的几个应用。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----总览","url":"/2021/08/20/7fn94eed/","content":"\n# 为什么会有数据结构和算法的出现？\n\n本tag着重从`开发者的角度`去介绍算法和数据结构，需要读者有一定的算法编程能力。\n\n本tag的部分代码比较长，建议查询有关资料的小伙伴们，有选择性的浏览即可；而对于初识数据结构的小伙伴们，希望你们能仔细地理解每一句代码，对数据结构和算法一定会有一个新的认识！\n\n# 计算机的基础：数据结构\n\n在上世纪，许多人还没有认识到数据结构的重要性，认为只要代码能够无误的运行起来，实现公司的业务需求，就算是成功的代码了，但是，随着业务处理的数据越来越庞大，效率要求越来越高，已有的存储机制以及运行性能已经不太能够处理如此庞大的数据了。\n\n渐渐地，计算机领域的科学家开始寻找更为有效的`数据结构`。数据结构从一百多年到现在，已经是一门非常成熟且完善的科学了。\n\n# 计算机的灵魂：算法\n\n对于算法，人们始终在不懈地寻找更高效的算法，将其运用到实际的应用开发中，基本上所有算法设计都是一个目的：`提高性能，提高效率`。\n\n一个好的算法，不仅能够降低存储和运行的成本，对于计算机领域的发展和完善，也是功不可没的。从海量数据处理到人工智能，从三维计算到语音识别，算法永远是核心，可以说，没有算法，计算机便缺少了“灵魂”。\n\n如果只是学会一门编程语言，只能称之为“学徒”，而掌握数据结构和算法，才能称为“大师”。\n\n所以，请以一种接受的态度来学习数据结构和算法，这是成为“大师”的必经之路。 \n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----链表（List)","url":"/2021/08/18/jzasferb/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 向量与链表的区别\n\n本章的主要内容：链表。\n\n上一篇文章笔者分享了数据结构中最为基础的结构-----`向量（顺序表）`，它的特点是，数据存储在内存的一块`连续区域`中，如果该区域末端的内存区域已被占用，再使用扩容操作就可能会导致意外结果。\n\n再比如说，如果一个业务逻辑中，`插入和删除操作比较频繁`，使用向量结构的话，会使得效率变低，综合多种因素考虑，我们产生了一种新的数据结构-----`链表`：\n\n> 向量与链表的基本区别：\n>\n> - 向量：数据存储在内存的一块连续区域中；\n>\n> - 链表：数据存储在内存的非连续区域中；\n>\n\n如上所言，插入和删除操作比较频繁，则选择链表，而如果查询操作更为频繁，则应采用向量结构存储。\n\n# 构建链表\n\n下面，我们来看链表的一些基本运算。我们先来看链表结点模版类，在该类中，定义了`链表结点`的一些基本操作：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.19\n * 内容：链表结点模版类\n *\n *\n */\n#ifndef LINKLIST_LISTNODE_H\n#define LINKLIST_LISTNODE_H\n\ntypedef int Rank ; //秩\n\ntemplate <typename T> struct ListNode { //链表结点模版类----双向链表\n    //成员\n    T data ; ListNode<T>* pred ; ListNode<T>* succ ; //数据，前驱，后继\n    //构造函数\n    ListNode() {} ; //针对header和trailer的构造\n    ListNode( T e , ListNode<T>* p = NULL , ListNode<T>* s = NULL) : data(e),pred(p),succ(s) {} //参数初始化列表\n    //操作接口\n    ListNode<T>* insertAsPred(T const& e) ; //紧靠当前结点之前插入新结点\n    ListNode<T>* insertAsSucc(T const& e) ; //紧靠当前结点之后插入新结点\n};\n\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.18\n * 内容：链表结点模版类的实现\n *\n *\n */\n\ntemplate <typename T> ListNode<T>* ListNode<T>::insertAsPred(const T &e) {\n    ListNode<T>* x = new ListNode(e,pred, this); //创建新结点\n    pred->succ = x ;\n    pred = x ;\n    return x; //返回新结点的位置\n}\n\ntemplate <typename T> ListNode<T>* ListNode<T>::insertAsSucc(const T &e) {\n    ListNode<T>* x = new ListNode(e,this,succ); //创建新结点\n    succ->pred = x ;\n    succ = x;\n    return x;\n}\n\n#endif //LINKLIST_LISTNODE_H\n```\n\n接着，我们定义`链表模版类`，用于定义结点与结点之间的结构关系：\n\n```cpp\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.19\n * 内容：链表模版类\n *\n *\n */\n\n#ifndef LINKLIST_LINKLIST_H\n#define LINKLIST_LINKLIST_H\n#include <cstdlib>\n#include \"ListNode.h\"\n\ntemplate <typename T> class List {\n    private:\n\n        int _size ; ListNode<T>* header ; ListNode<T>* trailer ; //规模，头哨兵，尾哨兵\n\n    protected:\n\n        void init() ; //链表创建时的初始化\n        int clear() ; //清除所有结点\n        void swap(T& x,T& y){T temp = x ; x = y ; y = temp ; } //用于双向链表的倒置\n        void copyNodes(ListNode <T>* p , int n) ; //复制链表中自位置p起的n项\n        void merge(ListNode <T>* & , int , List<T>& , ListNode<T>* , int) ; //有序链表区间归并\n        void mergeSort(ListNode <T>* & p , int n) ; //对从p开始的连续的n个结点归并排序\n        void insertionSort(ListNode <T>*,int); //对从p开始的连续的n个结点插入排序\n        void selectionSort(ListNode <T>*,int); //对从p开始的连续的n个结点选择排序\n\n    public:\n\n        //构造函数\n        List(){ init();} ; //默认构造函数\n\n        //析构函数\n        ~List() ; //释放（包含头，尾哨兵在内的）所有结点\n\n        //只读访问接口\n        Rank size() const {return _size;} ; //规模\n\n        bool empty() const {return _size<=0;} ; //判空\n\n        T& operator[](int r) const ; //重载，支持循秩访问\n\n        ListNode<T>* first() const {return header->succ ;} ; //首结点位置\n\n        ListNode<T>* last() const {return trailer->pred ;} ; //末结点位置\n\n        bool valid(ListNode<T>* p) //判断位置p是否对外合法\n        {return p && (trailer != p) && (header != p) ;} ; //将头尾结点等同于NULL\n\n        int disordered() const ; //判断链表是否已经排序\n\n        ListNode<T>* find(T const& e) const  {return find(e,_size,trailer); }//无序链表查找\n\n        ListNode<T>* find(T const& e,int n,ListNode<T>* p) const ; //无序区间查找\n\n        ListNode<T>* search(T const& e) const {return search(e,_size,trailer); } ; //有序链表查找\n\n        ListNode<T>* search(T const& e,int n,ListNode<T>* p) const ; //有序区间查找\n\n        ListNode<T>* selectMax(ListNode<T>* p,int n) ;\n\n        ListNode<T>* selectMax(){return selectMax(header->succ,_size) ;} ;//返回整体最大者\n\n        //可写访问接口\n        ListNode<T>* insertAsFirst(T const& e) ; //将e当作首结点插入\n\n        ListNode<T>* insertAsLast(T const& e) ; //将e当作末结点插入\n\n        ListNode<T>* insertAsBefore(ListNode<T>*,T const& e) ; //将e当作p的前驱插入\n\n        ListNode<T>* insertAsAfter(ListNode<T>*,T const& e) ; //将e当作p的后继插入\n\n        T remove(ListNode<T>* p); //删除合法位置p处的结点，返回被删除结点的数据项\n\n        void merge(List<T>& L){merge(first(),_size,L,L.first(),L._size);}//全链表归并\n\n        void sort(ListNode<T>* p,int n); //链表区间排序\n\n        void sort(){sort(first(),_size);}; //链表整体排序\n\n        int deduplicate(); //无序去重\n\n        int uniquify(); //有序去重\n\n        void reverse(); //前后倒置\n\n        //遍历\n        void traverse(void (*) (T&));\n\n};\n\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.18\n * 内容：链表模版类的实现\n *\n *\n */\n\n/*\n * protected方法\n */\n\ntemplate <typename T> void List<T>::init() { //链表初始化，在创建链表对象是统一调用\n    header = new ListNode<T>;\n    trailer = new ListNode<T>;\n    header->succ = trailer;\n    header->pred = NULL;\n    trailer->pred = header;\n    trailer->succ = NULL;\n    _size = 0;\n\n}\n\ntemplate <typename T> int List<T>::clear() {\n    int oldSize = _size ;\n    while(0 < _size) remove(header->succ);\n    return oldSize ; //返回原来的总结点数\n}\n\ntemplate<typename T> void List<T>::copyNodes(ListNode <T>* p, int n){\n    init();\n    while(n--){\n        insertAsLast(p->data) ; p = p->succ ;\n    }\n}\n\n\ntemplate <typename T> void List<T>::insertionSort(ListNode<T> * p, int n) {\n    for(int r = 0 ; r < n ; r++){\n        insertAsAfter(search(p->data,r,p),p->data) ; //查找适当的位置并插入\n        p = p->succ ; remove(p->pred); //转向下一结点\n    }\n}\n\n\ntemplate <typename T> ListNode<T>* List<T>::selectMax(ListNode<T>* p,int n) {\n    ListNode<T>* max = p ;\n    for(ListNode<T>* cur = p ; 1 < n ; n--){\n        if((cur = cur->succ)->data >= max->data)\n            max = cur ;\n    }\n    return max ; //返回最大结点位置\n}\n\ntemplate <typename T> void List<T>::selectionSort(ListNode<T>* p, int n) {\n    ListNode<T>* head = p->pred ;\n    ListNode<T>* tail = p ;\n    for(int i = 0 ; i < n ; i++) tail = tail->succ ;\n    while(1 < n) {\n        ListNode<T>* max = selectMax(head->succ,n) ;\n        insertAsBefore(tail,remove(max));\n        tail = tail->pred ; n-- ;\n    }\n}\n\n\ntemplate <typename T> void List<T>::merge(ListNode<T> *& p, int n, List<T> & L, ListNode<T> * q, int m) {\n    ListNode<T>* pp = p->pred ;\n    while(0 < m)\n        if((0 < n) && (p->data <= q->data)){\n            if(q == (p = p->succ)) break ; n-- ;\n        }\n        else{\n            insertAsBefore(p,L.remove((q = q->succ)->pred)) ; m-- ;\n        }\n    p = pp->succ ;\n\n}\n\ntemplate <typename T> void List<T>::mergeSort(ListNode<T> *&p, int n) {\n    if(n < 2) return ;\n    int m = n >> 1;\n    ListNode<T>* q = p ;\n    for(int i = 0 ; i < m ; i++) q = q->succ ;\n    mergeSort(p,m) ;\n    mergeSort(q,n-m );\n    merge(p,m,*this,q,n-m); //归并\n}\n\n/*\n * public方法\n */\n\ntemplate <typename T> List<T>::~List(){\n    clear() ; delete header ; delete trailer ;\n}\n\n\ntemplate <typename T> ListNode<T>* List<T>::find(T const& e,int n,ListNode<T>* p) const {\n    while(0 < n--)\n        if(e == (p = p->pred)->data) return p; //逐个比对，直至命中或范围越界\n    return NULL; //失败时，返回NULL\n}\n\ntemplate <typename T> ListNode<T>* List<T>::search(T const& e,int n,ListNode<T>* p) const {\n    while(0 <= n--) //在结点p的n个前驱结点中查找，找到不大于e的最后者\n        if(((p = p->pred)->data) <= e) break;\n    return p; //返回终止的位置\n\n}\n\ntemplate <typename T> ListNode<T>* List<T>::insertAsFirst(T const& e){\n    _size++ ; return header->insertAsSucc(e); //e当作首结点插入\n}\ntemplate <typename T> ListNode<T>* List<T>::insertAsLast(T const& e){\n    _size++ ; return trailer->insertAsPred(e); //e当作尾结点插入\n}\ntemplate <typename T> ListNode<T>* List<T>::insertAsBefore(ListNode<T>* p , T const& e){\n    _size++ ; return p->insertAsPred(e); //e当作p的前驱结点插入\n}\ntemplate <typename T> ListNode<T>* List<T>::insertAsAfter(ListNode<T>* p , T const& e){\n    _size++ ; return p->insertAsSucc(e); //e当作p的后继结点插入\n}\n\ntemplate <typename T> T List<T>::remove(ListNode<T>* p){\n    T e = p->data;\n    p->pred->succ = p->succ;\n    p->succ->pred = p->pred;\n    delete p ; _size-- ;\n    return e ; //返回备份的数据项\n}\n\n\ntemplate <typename T> int List<T>::deduplicate(){\n    if(_size < 2) return 0;\n    int oldSize = _size ;\n    ListNode<T>* p = header ; Rank r = 0 ;\n    while(trailer != (p = p->succ)){\n        ListNode<T>* q = find(p->data,r,p);\n        q ? remove(q) : r++ ;\n    }\n    return oldSize - _size ; //返回被删除总数\n}\n\ntemplate <typename T> int List<T>::uniquify(){\n    if(_size < 2) return 0;\n    int oldSize = _size;\n    ListNode<T>* p ; ListNode<T>* q ;\n    for(p = header,q = p->succ ; trailer != q ; p = q , q = q->succ) //从自左向右扫描\n        if(p->data == q->data){remove(q) ; q = p ;}\n    return oldSize - _size ; //返回被删除总数\n}\n\n\ntemplate <typename T> void List<T>::traverse(void (*visit) (T&)){\n    for(ListNode<T>* p = header->succ ; p != trailer ; p = p->succ)\n        visit(p->data);\n}\n\ntemplate <typename T> void List<T>::sort(ListNode<T>* p,int n) { //链表区间排序\n    switch (random() % 3)\n    {\n        case 1:\n            insertionSort(p,n) ; break; //插入排序\n        case 2:\n            selectionSort(p,n) ; break; //选择排序\n        default:\n            mergeSort(p,n) ; break; //归并排序\n\n    }\n}\n\ntemplate <typename T> T& List<T>::operator[] (int r) const {\n    ListNode<T>* p = first() ;\n    while(0 < r--) p = p->succ ;\n    return p->data ;\n}\n\ntemplate<typename T> int List<T>::disordered() const {\n    int count = 0 ;\n    for(ListNode<T>* p = header->succ ; p->succ != trailer ; p = p->succ){\n        if(p->data > p->succ->data)\n            count++;\n    }\n    return count ; //返回逆序的个数\n}\n\ntemplate<typename T> void List<T>::reverse() {\n    ListNode<T>* begin  = header;\n    ListNode<T>* end = trailer;\n    while( ( begin != end ) && ( end->succ != begin ) ){\n        swap(begin->data,end->data);\n        begin = begin->succ;\n        end = end->pred;\n    }\n}\n\n\n#endif //LINKLIST_LIST_H\n```\n\n代码比较长，\n\n> - 如果是查阅有关资料，可以选择性的浏览；\n>\n> - 如果是学习数据结构，笔者建议尽量全部理解并且自己能够动手写一个“微型版”的链表，这对数据结构的学习非常有帮助。\n>\n\n\n下面是`链表`的有关使用：\n\n```c++\n/*\n *\n * 作者：易果啥笔\n * 时间：2021.8.19\n * 内容：链表的使用\n *\n *\n */\n\n#include <iostream>\n#include \"List.h\"\n#include <ctime>\n\nusing namespace std;\n\ntemplate <typename T> void print(T& e){\n    cout<<e<<\"\\t\";\n}\n\nint main(){\n    clock_t start[10],finish[10];\n\n    List<int> list; //建立链表\n\n    //测试插入耗时\n    start[0] = clock();\n    list.insertAsFirst(1);\n    finish[0] = clock();\n    cout<<\"插入耗时：\"<<(double)(finish[0] - start[0])/CLOCKS_PER_SEC<<'s'<<endl;\n\n    list.insertAsFirst(2);\n    list.insertAsFirst(3);\n    list.insertAsFirst(4);\n    list.insertAsFirst(5);\n    list.insertAsFirst(6);\n    list.insertAsFirst(7);\n    list.insertAsFirst(8);\n    list.insertAsFirst(9);\n    list.insertAsFirst(10);\n    list.insertAsFirst(11);\n\n    cout<<\"第一个结点的地址为：\"<<list.first()<<endl; //返回一个地址\n\n    //测试无序查找耗时\n    start[1] = clock();\n    cout<<\"数据'4'的地址为：\"<<list.find(4)<<endl;\n    finish[1] = clock();\n    cout<<\"无序查找耗时：\"<<(double)(finish[1] - start[1])/CLOCKS_PER_SEC<<'s'<<endl;\n\n\n    list.insertAsBefore(list.find(4),100);\n    list.insertAsAfter(list.find(100),678);\n    list.remove(list.find(678));\n    list.traverse(print);\n    cout<<\"\\n\";\n\n    //测试排序耗时\n    start[2] = clock();\n    list.sort();\n    finish[2] = clock();\n    cout<<\"排序耗时：\"<<(double)(finish[2] - start[2])/CLOCKS_PER_SEC<<'s'<<endl;\n\n    list.traverse(print);\n    cout<<\"\\n\";\n\n    //测试有序查找耗时\n    start[3] = clock();\n    list.search(100);\n    finish[3] = clock();\n    cout<<\"有序查找耗时：\"<<(double)(finish[3] - start[3])/CLOCKS_PER_SEC<<'s'<<endl;\n\n    //cout<<list.search(3,11,list.find(100)) <<endl;\n\n    list.insertAsAfter(list.search(3),333);\n    list.traverse(print);\n    cout<<endl;\n    //测试双向链表的倒置耗时\n    start[4] = clock();\n    list.reverse();\n    finish[4] = clock();\n    cout<<\"倒置耗时：\"<<(double)(finish[4] - start[4])/CLOCKS_PER_SEC<<'s'<<endl;\n\n    list.traverse(print);\n    cout<<endl;\n\n    list.sort();\n    list.reverse();\n\n    cout<<list.disordered()<<\"\\t\"<<list.size()<<endl;\n    return 0;\n\n}\n```\n\n好了，链表的有关知识就介绍到这了，如果有什么错误之处，欢迎在评论区指出。\n","categories":["数据结构与算法"]},{"title":"数据结构与算法之-----向量（Vector)","url":"/2021/08/18/90yp97bw/","content":"\n# 前言\n\n写在前面的话：数据结构与算法。\n\n> 1. 对于初识数据结构的小伙伴们，鉴于后面的数据结构的构建会使用到同tag前面的内容，包括具体数据结构的应用，所使用到的数据结构，也是自己构建的，未使用系统的库文件，因此，建议这类小伙伴们按顺序进行学习；\n>\n> 2. 对于想查询有关资料的小伙伴们，可以选择性地浏览。希望大家都能有所收获～\n\n# 向量构建\n\n本章的主要内容：数据结构之-----**向量**\n\n数据结构中最基础也是最重要的一个数据结构----`向量`。笔者大学所学的数据结构貌似与当前流行的学习内容有些不同，如果将数据按逻辑结构来简单划分的话，可以分为`线性结构`和`非线性结构`，线性结构里有一个`顺序表`的概念，其实，您可以把向量看成是`顺序表`的实例。\n\n下面我们来看向量的`C++实现`：\n\n先来看头文件，头文件中的内容非常之多，基本囊括了向量中大部分的知识，包括多种`查询算法`，`插入算法`，`删除算法`等等。\n\n为了代码的高可用性，笔者使用了`模版类`，如果您对于某段代码不太理解，可以先放一放，去查询一下相关资料，此外，如果代码中有错误之处，敬请指出，谢谢！\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.18\n * 内容：向量模板类的头文件\n *\n */\n\n#ifndef VECTOR_VECTOR_H\n#define VECTOR_VECTOR_H\n#include <cstdlib>\n#include \"Vector.h\"\n#include <iostream>\nusing namespace std;\n\ntypedef int Rank;  //秩\n#define DEFAULT_CAPACITY 3   //默认的初始容量\n\ntemplate <typename T>\nclass Vector    {   //向量模板类\n    protected:\n        Rank _size{} ; int _capacity{} ; T* _elem ; //规模，容量，数据区\n        void copyForm(T const* A , Rank lo , Rank hi) ; //复制数组区间A[lo,hi)\n    \tvoid expand() ; //空间不足时扩容\n        void shrink() ; //装填因子过小时压缩\n        bool bubble(Rank lo , Rank hi) ; //扫描交换\n        void swap(T& e1,T& e2) ; //交换元素\n        void bubbleSort(Rank lo , Rank hi) ; //起泡排序算法\n        void selectionSort(Rank lo , Rank hi) ; //选择排序算法\n        void merge(Rank lo ,Rank mi, Rank hi) ; //归并算法\n        void mergeSort(Rank lo,Rank hi) ; //归并排序算法\n        Rank partition(Rank lo , Rank hi) ; //轴点构造算法\n        void quickSort(Rank lo , Rank hi) ; //快速排序算法\n        void insertionSort(Rank lo , Rank hi) ; //插入排序算法\n    public:\n        //构造函数\n        explicit Vector(int c = DEFAULT_CAPACITY , int s = 0 , T v = 0){\n            _elem = new T[_capacity  = c] ;\n            for (_size = 0 ; _size < s ; _elem[_size++] = v);\n            \n        } //容量为c,规模为s,所有元素初始为v\n        Vector(T const* A , Rank lo , Rank hi){\n            copyForm(A,lo,hi) ; //数组区间复制\n        }\n        Vector(T const* A , Rank n){\n            copyForm(A,0,n) ; //数组整体复制\n        }\n        Vector(Vector<T> const* V , Rank lo , Rank hi){\n            copyForm(V->_elem,lo,hi) ; //向量区间复制\n        }\n        Vector(Vector<T> const* V){\n            copyForm(V->_elem,0,V->_size) ; //向量整体复制\n        }\n\n        //析构函数\n        ~Vector(){ delete [] _elem ; } //释放内部空间\n\n        //只读访问接口\n        Rank size() const {return _size ; } //规模\n        bool isEmpty() const {return _size;} //判空\n        int disordered() const ; //判断向量是否已排序\n        Rank find(T const& e) const {return find(e,0,(Rank)_size) ; } //无序向量整体查找\n        Rank find(T const& e , Rank lo , Rank hi) const ; //无序向量区间查找\n        Rank search(T const& e ) const {return (0 >= _size) ? -1 : search(e,(Rank)0,(Rank)_size) ; } //有序向量整体查找\n        Rank search(T const& e , Rank lo , Rank hi) const ; //有序向量区间查找\n\n        //可写访问接口\n        T& operator[](Rank r) const ; //重载[]运算符，可以类似数组形式引用各元素\n        Vector<T> & operator=(Vector<T> const&) ; //重载赋值操作符，以便直接克隆向量\n        T remove(Rank r) ; //删除秩为r的元素\n        Rank remove(Rank lo , Rank hi) ; //删除秩在[lo,hi)之内的元素\n\n        Rank insert(Rank r , T const& e) ; //插入元素\n        Rank insert(T const& e) {return insert(_size,e) ; } //默认作为末元素插入\n        void sort(Rank lo , Rank hi) ; //对[lo,hi)排序\n        void sort() {sort(0,_size) ; } //整体排序\n        void unsort(Rank lo , Rank hi) ; //对[lo,hi)置乱\n        void unsort() {unsort(0,_size) ; } //整体置乱\n        int deduplicate() ; //无序去重\n        int uniquify() ; //有序去重\n\n        //遍历\n        void traverse(void (* visit)(T&)); //遍历(使用函数指针，只读或局部性修改)\n        //template<typename VST> void traverse(VST &) ; //遍历(使用函数对象，可全局性修改)\n\n\n}; // Vector\n\n/*\n *\n * 静态方法\n *\n *\n */\n\n\n\n//Fibonacci数列的构造\ntemplate <typename T> static void fibonacci(T *f,int MAXSIZE)\n{\n    f[0] = 0;\n    f[1] = 1;\n    for(int i = 2;i < MAXSIZE;++i)\n        f[i] = f[i - 2] + f[i - 1];\n}\n\n/*\n *\n * protected方法\n *\n */\n\ntemplate <typename T>  Rank binSearch(T* A,T const& e,Rank lo,Rank hi){\n    while(lo < hi){\n        Rank mi = (lo+hi) >> 1 ; //以中点为轴点\n        (e < A[mi]) ? hi = mi : lo = mi + 1 ; //成功查找不能提前终止\n    }\n    return --lo ;\n} //查找失败时，能指示失败的位置\n\ntemplate <typename T>  Rank fibSearch(T* A,T const& e,Rank lo,Rank hi){\n    Rank n = hi-lo , k = 0 , *array;\n    array = new T[n] ;\n    fibonacci(array,n) ;\n    while(n > array[k] - 1) //计算出n在斐波那契中的数列\n        ++k;\n    for(int i = n ; i < array[k] - 1 ; ++i) //把数组补全\n        array[i] = array[n-1];\n    while(lo < hi){\n        Rank mi = lo + array[k-1] - 1 ; //找轴点\n        if(e <A[mi]) hi = mi ;\n        else if(A[mi] < e) lo = mi + 1 ;\n        else return mi ;\n    }\n    return -1 ; //查找失败返回-1\n}\n\ntemplate <typename T> void Vector<T>::copyForm(const T *A, Rank lo, Rank hi) {\n    _elem = new T[_capacity = (hi-lo)<<1] ; _size = 0 ;//分配空间，规模清零\n    while(lo < hi)\n        _elem[_size++] = A[lo++] ; //复制至_elem[0,hi-lo)\n}\n\ntemplate <typename T> void Vector<T>::expand() {\n    if(_size < _capacity)return;\n    if(_capacity < DEFAULT_CAPACITY) _capacity = DEFAULT_CAPACITY ; //不低于最小容量\n    T* oldElem  = _elem ; _elem = new T[_capacity <<= 1] ; //容量加倍\n    for(int i = 0 ; i < _size ; i++)\n        _elem[i] = oldElem[i] ; //复制原向量内容(T为基本类型，或已经重载赋值操作符\"=\")\n    delete [] oldElem ; //释放原空间\n}\n\ntemplate <typename T> void Vector<T>::shrink() { //装填因子过小时压缩向量所占空间\n    if(_capacity < DEFAULT_CAPACITY << 1) return; //不至于收缩到DEFAULT_CAPACITY以下\n    if(_size << 2 > _capacity) return; //以25%为界\n    T* oldElem = _elem ; _elem = new T[_capacity >>= 1] ; //容量减半\n    for(int i = 0 ; i< _size ; i++) {_elem[i] = oldElem[i];}//复制原向量内容\n    delete [] oldElem ;\n}\n\ntemplate<typename T> void Vector<T>::swap(T &e1, T &e2) {\n    int temp ;\n    temp = e1 ;\n    e1 = e2 ;\n    e2 = temp ;\n\n}\n\n\ntemplate<typename T> bool Vector<T>::bubble(Rank lo, Rank hi) { //一趟扫描交换\n    bool sorted = true ;\n    while (++lo < hi)\n        if(_elem[lo-1] > _elem[lo]){\n            sorted = false ;\n            swap(_elem[lo-1],_elem[lo]) ; //通过交换使局部有序\n        }\n    return sorted ; //返回有序标志\n}\n\ntemplate<typename T> void Vector<T>::bubbleSort(Rank lo, Rank hi) {\n    while (!bubble(lo,hi--)) ; //逐趟做扫描交换，直至全序\n}\n\ntemplate<typename T> void Vector<T>::selectionSort(Rank lo, Rank hi) {\n    while(lo < hi){\n        Rank temp = lo ;\n        for(Rank i = lo+1 ; i < hi ; i++){\n            if(_elem[temp] > _elem[i]) temp = i ;\n        }\n        swap(_elem[lo++],_elem[temp]) ;\n    }\n}\n\ntemplate<typename T> void Vector<T>::insertionSort(Rank lo , Rank hi) {\n    for(int i = 0 ; i < hi - lo ; i++){\n        insert(binSearch(_elem,_elem[lo],lo-i,lo)+1,_elem[lo]);\n        lo++ ; remove(lo--) ;\n    }\n}\n\ntemplate<typename T> void Vector<T>::merge(Rank lo, Rank mi, Rank hi) { //有序向量的归并，以mi为界，各自有序的子向量[lo,mi)和[mi,hi)\n    T* A = _elem + lo ; //合并后的向量A[0,hi - lo) = _elem[lo,hi)\n    int lb = mi - lo ; T* B = new T[lb] ; //前子向量B[0,lb) = _elem[lo,mi)\n    for(Rank i = 0 ; i < lb ; i++)\n        B[i] = A[i] ; //复制前子向量\n    int lc = hi - mi ; T* C = _elem + mi ; //后子向量C[0,lc) = _elem[mi,hi)\n    for(Rank i = 0 , j = 0 , k = 0 ; (j < lb) || (k < lc) ; ){ //将B[j]和C[k]中的小者续至A末尾\n        if ( (j < lb) && (!(k < lc) || (B[j] <= C[k]) ) ) A[i++] = B[j++] ;\n        if ( (k < lc) && (!(j < lb) || (C[k] < B[j]) ) ) A[i++] = C[k++] ;\n    }\n    delete [] B ;\n}\n\ntemplate<typename T> void Vector<T>::mergeSort(Rank lo, Rank hi) { //向量归并排序\n    if (hi - lo < 2) return ;\n    int mi = (lo + hi) >> 1 ; //以中点为界\n    mergeSort(lo,mi) ; mergeSort(mi,hi) ; merge(lo,mi,hi) ; //分别对前后半段排序，然后归并\n}\n\ntemplate<typename T> Rank Vector<T>::partition(Rank lo, Rank hi) { //轴点构造算法：通过调整元素位置构造区间[lo,hi]的轴点，并返回其秩\n    swap(_elem[lo],_elem[lo + rand() % (hi -lo +1)]) ; //任意一个元素与首元素交换\n    T pivot = _elem[lo] ; //以首元素为候选轴点-----经以上交换，等效于随机选取\n    while(lo < hi){ //以向量的两端交替地向中间扫描\n        while((lo < hi))\n            if(pivot < _elem[hi]) //在大于的pivot前提下\n                hi--; //向左扩展右端子向量\n            else //直至遇到不大于pivot者\n            {_elem[lo++] = _elem[hi] ; break ;} //将其归入左端子向量\n        while ((lo < hi))\n            if(_elem[lo] < pivot)\n                lo++;\n            else\n                {_elem[hi--] = _elem[lo] ; break ;}\n    }\n    _elem[lo] = pivot ; //将备份的轴点记录置于前，后子向量之间\n    return lo ; //返回轴点的秩\n\n}\ntemplate<typename T> void Vector<T>::quickSort(Rank lo, Rank hi) {\n    if(hi - lo < 2) return ;\n    Rank mi = partition(lo,hi - 1) ;\n    quickSort(lo,mi) ;\n    quickSort(mi + 1,hi) ;\n}\n\n/*\n *\n * public方法\n *\n */\n\ntemplate <typename T> Vector<T>& Vector<T>::operator=(const Vector<T> & V) {\n    if(_elem) delete [] _elem ; //释放原有内容\n    copyForm(V._elem,0,V.size()) ; //整体复制\n    return *this ; //返回当前对象的引用，以便链式赋值\n}\n\ntemplate <typename T> T& Vector<T>::operator[](Rank r) const {\n    return _elem[r] ; // 0 <= r < _size\n}\n\n\ntemplate <typename T> void Vector<T>::unsort(Rank lo, Rank hi) {\n    T* V = _elem + lo ; //将子向量_elem[lo,hi)视作另一向量V[0,hi-lo)\n    for(Rank i = hi - lo ; i > 0 ; i--) //自后向前\n        swap(V[i-1],V[random() % i]) ; //V[i - 1]与V[0 , i]中某一随机元素交换\n}\n\ntemplate <typename T> Rank Vector<T>::find(const T &e, Rank lo, Rank hi) const {\n    while((lo < hi--) && (e != _elem[hi])) ; //从后向前，顺序查找\n    return hi ; //若hi < lo，则意味着失败，否则将返回hi即为命中元素的秩\n}\n\ntemplate <typename T> Rank Vector<T>::insert(Rank r, const T &e) {\n    expand() ; //若有必要，扩容\n    for(int i = _size ; i > r ; i--) _elem[i] = _elem[i-1] ; //自后向前，后继元素顺次后移一个单元\n    _elem[r] = e ; _size++ ; //置入新元素并更新容量\n    return r ; //返回秩\n}\n\ntemplate <typename T> Rank Vector<T>::remove(Rank lo, Rank hi) {\n    if(lo == hi) return 0 ; //出于效率考虑，单独处理退化情况，比如remove(0,0);\n    while(hi < _size) _elem[lo++] = _elem[hi++] ; //[hi,_size)顺次前移hi-lo个单元\n    _size = lo ; //更新规模，直接丢弃尾部[lo,_size = hi)区间\n    shrink() ; //若有必要，则缩容\n    return hi - lo ; //返回被删除的元素个数\n}\n\ntemplate <typename T> T Vector<T>::remove(Rank r) {\n    T e = _elem[r] ; //备份被删除元素\n    remove(r,r+1) ; //调用区间删除算法，等效于对区间[r,r+1)的删除\n    return e ; //返回被删除的元素\n}\n\ntemplate <typename T> Rank Vector<T>::deduplicate() {\n    int oldSize = _size ; //记录原规模\n    Rank i = 1 ; //从_elem[1]开始\n    while(i < _size)\n        ( find(_elem[i] , 0 , i) < 0) ? //在其前缀中寻找与之雷同者(至多一个)\n        i++ : remove(i) ; //若无雷同者则继续考察其后继，否则就删除雷同者\n    return oldSize - _size ; //返回被删除元素的总数\n}\n\ntemplate <typename T> void Vector<T>::traverse(void (*visit)(T &)) {\n    for(int i = 0 ; i < _size ; i++) visit(_elem[i]) ; //利用函数指针机制的遍历\n}\n\n//template <typename T> template <typename VST>\n//Rank Vector<T>::traverse(VST & visit) {\n   //for(int i = 0 ; i < _size ; i++) visit(_elem[i]) ; //利用函数对象机制的遍历\n//}\n\ntemplate <typename T> int Vector<T>::disordered() const {\n    int n = 0 ; //计数器\n    for(int i = 1 ; i < _size ; i++) //逐一检查_size-1对相邻元素\n        if(_elem[i-1] > _elem[i]) n++ ; //逆序则计数\n    return n ; //向量有序但且仅当n=0\n}\n\ntemplate <typename T> Rank Vector<T>::uniquify() {\n    Rank i = 0 , j = 0 ; //各对互异\"相邻\"元素的秩\n    while(++j < _size) //逐一扫描，直至末元素\n        if(_elem[i] != _elem[j]) //跳过雷同者\n            _elem[++i] = _elem[j] ; //发现不同元素时，向前移至紧邻于前者右侧\n    _size = ++i ; shrink() ; //直接截除尾部多余元素\n    return  j-1 ; //返回被删除元素总数\n}\n\ntemplate <typename T> Rank Vector<T>::search(const T &e, Rank lo, Rank hi) const {\n    return (random()%2) ?\n        binSearch(_elem,e,lo,hi) : fibSearch(_elem,e,lo,hi) ; //Fibonacci查找\n}\n\ntemplate<typename T> void Vector<T>::sort(Rank lo, Rank hi) {\n\n    switch (random() % 4) { //随机选择排序算法，可根据问题的特点灵活选取或扩充\n        case 1 : bubbleSort(lo,hi) ; break ; //起泡排序\n        case 2 : selectionSort(lo,hi) ; break ; //选择排序\n        case 3 : mergeSort(lo,hi) ; break ; //归并排序\n        case 4 : insertionSort(lo,hi); //插入排序\n        default: quickSort(lo,hi) ; break ; //快速排序\n    }\n}\n\n#endif //VECTOR_VECTOR_H\n```\n\n# 向量测试\n\n在头文件里，我们定义了向量的一些基本运算，下面，我们以一个`main`文件来展示向量的基本操作：\n\n```cpp\n/*\n * 作者：易果啥笔\n * 时间：2021.8.18\n * 内容：Vector模版类的应用\n *\n */\n\n#include <iostream>\n#include \"Vector.h\"\n#include <ctime>\n#include <string>\n\n#define CAPACITY 10\n#define SIZE 5\n#define VALUE 0\n\nusing namespace std;\n\ntemplate<typename T> void print(T a){\n    std::cout<<a<<\"  \";\n}\n\nint main(){\n    clock_t start,finish; //clock_t为CPU时钟计时单元数\n\n    start = clock();\n\n    Vector<int> vector(CAPACITY,SIZE,VALUE);\n    vector[0] = 1 ;\n    vector[1] = 2 ;\n    vector.insert(2,3);\n    vector.insert(3,7);\n    vector[4] = 1 ;\n    //遍历\n    vector.traverse(print);\n    \n    vector.sort();cout<<endl;\n    //遍历\n    vector.traverse(print);\n\n    finish = clock();\n    cout<<endl<<\"进程耗时：\"<<double (finish - start)/CLOCKS_PER_SEC<<'s'<<endl;\n    cout<<vector.isEmpty()<<endl;\n    return 0;\n}\n```\n\n`main`文件中，笔者使用了`C++`中的`ctime库`中的`clock_t对象`来测试向量的一些基本操作的耗时，读者可以忽略。\n","categories":["数据结构与算法"]},{"title":"友情链接","url":"/friend/index.html","content":"\n## 本站信息\n\n站点：luoying\n\n站名：luoying2002\n\ngithub网址：[https://luoying2002.github.io](https://luoying2002.github.io)（源链）\n\nnetlify网址：[https://luoying.netlify.app](https://luoying.netlify.app)（全球CDN，访问更快）\n\n## 友链\n\n{% friendsLink friend/_data.yml %}\n"},{"title":"关于","url":"/about/index.html","content":"## 这里是LuoYing的博客\n\n- 中山大学中山医某不知名研究生\n- 社畜（niu）一枚\n- 博客基于 Hexo & [Reimu](https://github.com/D-Sketon/hexo-theme-reimu) 主题\n- 微信：ly3611544427（来访请说明来意）\n- 邮箱：luoy569@mail2.sysu.edu.cn（来访请说明来意）\n- 图库均来源网络，侵删\n\n## 研究方向\n\n- 生物信息学\n- 基因组学\n- 大数据技术\n- AI大模型\n\n## 致谢\n\n本站点由拔剑 **D-Sketon** 大佬的 [Reimu](https://github.com/D-Sketon/hexo-theme-reimu) 主题提供支持，感谢大佬的主题。\n"}]